{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ivp1144RNvKo",
        "VBQ8y3ZaZcMJ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4aa3ebe24bd7414f9cab11cdc07dc7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5870d62330943d2aecdf658e605e18e",
              "IPY_MODEL_24f566684977428a9d61a6e0ee3a951b",
              "IPY_MODEL_e58e4138fbfa4e119f0c16261a7daaea"
            ],
            "layout": "IPY_MODEL_74b48670e8234e98b24a1de0465e50a2"
          }
        },
        "e5870d62330943d2aecdf658e605e18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a933629ce749b0980c59a79605a5bf",
            "placeholder": "​",
            "style": "IPY_MODEL_b05283864fe1413f8a25cafc9bf72c46",
            "value": "100%"
          }
        },
        "24f566684977428a9d61a6e0ee3a951b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61630904a1194ff9b7e4f94dcb40aba5",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c5c956bb83437fb2638459ac41e2b8",
            "value": 170498071
          }
        },
        "e58e4138fbfa4e119f0c16261a7daaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c0ef5f51ee49ab9eaba2acf4a77e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_a19a9f50fc1b471cb3888f9181109e48",
            "value": " 170498071/170498071 [00:17&lt;00:00, 13468233.38it/s]"
          }
        },
        "74b48670e8234e98b24a1de0465e50a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a933629ce749b0980c59a79605a5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b05283864fe1413f8a25cafc9bf72c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61630904a1194ff9b7e4f94dcb40aba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c5c956bb83437fb2638459ac41e2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c0ef5f51ee49ab9eaba2acf4a77e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19a9f50fc1b471cb3888f9181109e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexdembele/MI201/blob/main/ProjetMI201Demb%C3%A9l%C3%A9Xie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4zsDWUk5cavn"
      },
      "source": [
        "# Unsupervised Learning Tutorial of Gianni Franchi\n",
        "**PLEASE write your name and first name here:** Xie Antoine Dembélé Alex\n",
        "\n",
        "Welcome to ML project!\n",
        "**In this notebook, you will**:\n",
        "- Learn what is SSL\n",
        "- Learn the difficulty with Overfitting\n",
        "- Learn to implement an Convolutional Neural Network.\n",
        "- Learn to train it when we don't have enough data\n",
        "\n",
        "If you have never used jupyter notebooks, nor Colab notebooks, [here](https://colab.research.google.com/notebooks/welcome.ipynb) is a short intro.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from numpy import asarray\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import random\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "#import matplotlib.pyplot as plt\n",
        "#from modules import *\n",
        "#import torchvision.models as models_pytorch\n",
        "#import h5py\n",
        "#import torch.optim as optim\n",
        "#import augmentations\n",
        "from torch.nn.functional import kl_div, softmax, log_softmax\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from os.path import exists, join, split\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from PIL import Image, ImageFilter , ImageDraw\n",
        "import PIL\n",
        "import random\n",
        "#import madgrad \n",
        "import matplotlib.pyplot as plt\n",
        "#! pip install madgrad\n",
        "#! pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "RTJ7Zz6TAaJp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_class = 10 #number of classes\n",
        "\n",
        "seed=111 #seed for the algorithm\n",
        "batch_size = 32\n",
        "num_train =100 # number of training image by classe\n",
        "cutout=16  # parameter for the cutout\n",
        "num_epochs=50\n",
        "#Validation set size\n",
        "valid_size = 200\n",
        "lr=0.1"
      ],
      "metadata": {
        "id": "kFCoFJzWApYo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First let us define a CNN"
      ],
      "metadata": {
        "id": "2Ux1VVt2AtcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_momentum = 0.9\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class WideBasic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(WideBasic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, momentum=bn_momentum)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, momentum=bn_momentum)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(WideResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = int((depth - 4) / 6)\n",
        "        k = widen_factor\n",
        "\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3, nStages[0])\n",
        "        self.layer1 = self._wide_layer(WideBasic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(WideBasic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(WideBasic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=bn_momentum)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "        # self.apply(conv_init)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        # out = F.avg_pool2d(out, 8)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "YDbhFAHJAx97"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now let us define a dataset\n"
      ],
      "metadata": {
        "id": "9Y7RH4rWA9c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_sub_CIFAR(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_feature, data_target,transform,phase='label'):\n",
        "        self.data_feature = data_feature\n",
        "        self.data_target = data_target\n",
        "        self.transform = transform\n",
        "        self.phase=phase\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_feature)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
        "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
        "        if self.phase=='label':\n",
        "            data_feature = self.transform(Image.fromarray(np.uint8(self.data_feature[index])))\n",
        "            data_target =  self.data_target[index]\n",
        "            return data_feature, data_target\n",
        "\n",
        "        else:\n",
        "            data_feature = self.data_feature[index].float()\n",
        "            return data_feature\n",
        "\n",
        "\n",
        "class CutoutDefault(object):\n",
        "    \"\"\"\n",
        "    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n",
        "    \"\"\"\n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.length <= 0:\n",
        "            return img\n",
        "        h, w = img.size(1), img.size(2)\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        y1 = np.clip(y - self.length // 2, 0, h)\n",
        "        y2 = np.clip(y + self.length // 2, 0, h)\n",
        "        x1 = np.clip(x - self.length // 2, 0, w)\n",
        "        x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img *= mask\n",
        "        return img\n",
        "\n",
        "    \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "    CutoutDefault(cutout),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "#Dataset loading\n",
        "CIFAR10_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=None, download=True)\n",
        "CIFAR10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=None, download=True)\n",
        "np.random.seed(seed=seed)\n",
        "permuation=np.random.permutation(len(CIFAR10_train_dataset.targets))\n",
        "\n",
        "Original_train_data_x = (CIFAR10_train_dataset.data)\n",
        "Original_train_data_y = np.array(CIFAR10_train_dataset.targets)\n",
        "Original_train_data_x = Original_train_data_x[permuation]\n",
        "Original_train_data_y = Original_train_data_y[permuation]\n",
        "\n",
        "Original_test_data_x = CIFAR10_test_dataset.data\n",
        "Original_test_data_y = np.array(CIFAR10_test_dataset.targets)\n",
        "\n",
        "\n",
        "\n",
        "#Selection of 250 labeled images for training and 2000 for validation\n",
        "incr_class = torch.zeros(num_class)\n",
        "train_idx_dico = {} #labeled images index dictionnary\n",
        "\n",
        "for i in range(num_class):\n",
        "    train_idx_dico[str(i)] = []\n",
        "\n",
        "valid_idx = np.zeros(num_class * valid_size, dtype=np.int32) #validation images indexes (2000)\n",
        "incr_t = 0\n",
        "incr_v = 0\n",
        "incrtotal = 0\n",
        "\n",
        "for idx in range(len(Original_train_data_y)):\n",
        "    class_y = Original_train_data_y[idx]\n",
        "    incrtotal += 1\n",
        "\n",
        "    train_idx_dico[str(class_y)].append(idx)\n",
        "    incr_class[class_y] += 1 #count the number of image per class\n",
        "    incr_t += 1\n",
        "\n",
        "\n",
        "train_idx = np.zeros(num_class * num_train, dtype=np.int32) #train labeled images indexes (1000)\n",
        "list_train_id = []\n",
        "list_unalabel_id = []\n",
        "valid_idx = []\n",
        "unlabel_idx_dico = {}\n",
        "for i in range(num_class):\n",
        "    unlabel_idx_dico[str(i)] = []\n",
        "for i in range(num_class):\n",
        "    list_train_id = list_train_id + train_idx_dico[str(i)][0:num_train]\n",
        "    valid_idx =valid_idx + train_idx_dico[str(i)][num_train:num_train+valid_size]\n",
        "    list_unalabel_id = list_unalabel_id + train_idx_dico[str(i)][num_train+valid_size::]\n",
        "    unlabel_idx_dico[str(i)] = train_idx_dico[str(i)][num_train::]\n",
        "\n",
        "#Get labeled and unlabeled data\n",
        "\n",
        "x_train = Original_train_data_x[[int(i) for i in list_train_id]]\n",
        "y_train = Original_train_data_y[[int(i) for i in list_train_id]]\n",
        "\n",
        "x_unlabeled = Original_train_data_x[[int(i) for i in list_unalabel_id]]\n",
        "y_unlabeled = Original_train_data_y[[int(i) for i in list_unalabel_id]]\n",
        "\n",
        "#Get validation set data\n",
        "x_valid = Original_train_data_x[[int(i) for i in valid_idx]]\n",
        "y_valid = Original_train_data_y[[int(i) for i in valid_idx]]\n",
        "\n",
        "# Printing the size of the training, validation and test sets\n",
        "print('Number of training examples: ' + str(x_train.shape[0]))\n",
        "print('Number of unlabeled examples: ' + str(x_unlabeled.shape[0]))\n",
        "print('Number of validation examples: ' + str(x_valid.shape[0]))\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#Dataloader creation\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_test),\n",
        "    batch_size = batch_size,\n",
        "    shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_train, y_train, transform=transform_train),\n",
        "    batch_size=batch_size,shuffle=True, num_workers=2) #num_workers = 2 ou 1\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_valid, y_valid, transform=transform_test),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "4aa3ebe24bd7414f9cab11cdc07dc7f1",
            "e5870d62330943d2aecdf658e605e18e",
            "24f566684977428a9d61a6e0ee3a951b",
            "e58e4138fbfa4e119f0c16261a7daaea",
            "74b48670e8234e98b24a1de0465e50a2",
            "e5a933629ce749b0980c59a79605a5bf",
            "b05283864fe1413f8a25cafc9bf72c46",
            "61630904a1194ff9b7e4f94dcb40aba5",
            "62c5c956bb83437fb2638459ac41e2b8",
            "46c0ef5f51ee49ab9eaba2acf4a77e8e",
            "a19a9f50fc1b471cb3888f9181109e48"
          ]
        },
        "id": "JE1_MblIA5V7",
        "outputId": "6db02d26-b776-4e99-e633-d19483ca6513"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aa3ebe24bd7414f9cab11cdc07dc7f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 1000\n",
            "Number of unlabeled examples: 47000\n",
            "Number of validation examples: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we build the CNN and the optimizer"
      ],
      "metadata": {
        "id": "jxIA7jzZBIjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "#Networks creation\n",
        "net = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class)\n",
        "net =net.to(device)\n",
        "net_save = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class) # model where to save the results\n",
        "net_save =net_save.to(device)\n",
        "\n",
        "def learning_rate_scheduler(init, epoch):\n",
        "    optim_factor = 0\n",
        "    if(epoch > 200):\n",
        "        optim_factor = 3\n",
        "    elif(epoch > 160):\n",
        "        optim_factor = 2\n",
        "    elif(epoch > 80):\n",
        "        optim_factor = 1\n",
        "\n",
        "    return init*math.pow(0.1, optim_factor)\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch,net,trainloader,log_interval=15):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate_scheduler(lr, epoch)))\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate_scheduler(lr, epoch), momentum=0.9, weight_decay=5e-4)\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        " \n",
        "        inputs, targets = inputs.to(device), targets.to(device) # GPU settings\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = Variable(inputs), Variable(targets)\n",
        "        outputs = net(inputs)               # Forward Propagation\n",
        "        loss = criterion(outputs, targets)  # Loss\n",
        "        loss.backward()  # Backward Propagation\n",
        "        optimizer.step() # Optimizer update\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct/total))\n",
        "\n",
        "\n",
        "def test(epoch,net,testloader):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            \n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "        \n",
        "    acc = 100.*correct/total\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n",
        "    return acc"
      ],
      "metadata": {
        "id": "5HSobiPQBNjh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "tY_jn6VVBTgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "    train(epoch,net,train_loader)\n",
        "    acc =test(epoch,net,valid_loader)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        net_save.load_state_dict(net.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpnbckfWBWbB",
        "outputId": "e97b1bb6-4493-46ca-85ec-88d06c5b6bf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.1000\n",
            "| Epoch [  0/ 50] Iter[  1/ 32]\t\tLoss: 2.3375 Acc@1: 15.625%\n",
            "| Epoch [  0/ 50] Iter[ 16/ 32]\t\tLoss: 2.4565 Acc@1: 16.016%\n",
            "| Epoch [  0/ 50] Iter[ 31/ 32]\t\tLoss: 2.0866 Acc@1: 15.423%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 3.0526 Acc@1: 21.10%\n",
            "| Saving Best model...\t\t\tTop1 = 21.10%\n",
            "\n",
            "=> Training Epoch #1, LR=0.1000\n",
            "| Epoch [  1/ 50] Iter[  1/ 32]\t\tLoss: 2.3298 Acc@1: 18.750%\n",
            "| Epoch [  1/ 50] Iter[ 16/ 32]\t\tLoss: 2.0156 Acc@1: 19.727%\n",
            "| Epoch [  1/ 50] Iter[ 31/ 32]\t\tLoss: 2.4039 Acc@1: 21.069%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 2.1577 Acc@1: 18.95%\n",
            "\n",
            "=> Training Epoch #2, LR=0.1000\n",
            "| Epoch [  2/ 50] Iter[  1/ 32]\t\tLoss: 2.0679 Acc@1: 18.750%\n",
            "| Epoch [  2/ 50] Iter[ 16/ 32]\t\tLoss: 2.0975 Acc@1: 24.219%\n",
            "| Epoch [  2/ 50] Iter[ 31/ 32]\t\tLoss: 2.1848 Acc@1: 22.984%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 2.0938 Acc@1: 21.70%\n",
            "| Saving Best model...\t\t\tTop1 = 21.70%\n",
            "\n",
            "=> Training Epoch #3, LR=0.1000\n",
            "| Epoch [  3/ 50] Iter[  1/ 32]\t\tLoss: 1.8406 Acc@1: 25.000%\n",
            "| Epoch [  3/ 50] Iter[ 16/ 32]\t\tLoss: 1.9170 Acc@1: 19.336%\n",
            "| Epoch [  3/ 50] Iter[ 31/ 32]\t\tLoss: 2.1907 Acc@1: 20.161%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 2.1099 Acc@1: 24.50%\n",
            "| Saving Best model...\t\t\tTop1 = 24.50%\n",
            "\n",
            "=> Training Epoch #4, LR=0.1000\n",
            "| Epoch [  4/ 50] Iter[  1/ 32]\t\tLoss: 2.1727 Acc@1: 9.375%\n",
            "| Epoch [  4/ 50] Iter[ 16/ 32]\t\tLoss: 2.0806 Acc@1: 27.344%\n",
            "| Epoch [  4/ 50] Iter[ 31/ 32]\t\tLoss: 2.2047 Acc@1: 25.605%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 1.6914 Acc@1: 20.70%\n",
            "\n",
            "=> Training Epoch #5, LR=0.1000\n",
            "| Epoch [  5/ 50] Iter[  1/ 32]\t\tLoss: 1.9909 Acc@1: 28.125%\n",
            "| Epoch [  5/ 50] Iter[ 16/ 32]\t\tLoss: 2.0062 Acc@1: 24.023%\n",
            "| Epoch [  5/ 50] Iter[ 31/ 32]\t\tLoss: 1.7446 Acc@1: 26.008%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 1.5522 Acc@1: 25.70%\n",
            "| Saving Best model...\t\t\tTop1 = 25.70%\n",
            "\n",
            "=> Training Epoch #6, LR=0.1000\n",
            "| Epoch [  6/ 50] Iter[  1/ 32]\t\tLoss: 2.0052 Acc@1: 21.875%\n",
            "| Epoch [  6/ 50] Iter[ 16/ 32]\t\tLoss: 1.7142 Acc@1: 26.953%\n",
            "| Epoch [  6/ 50] Iter[ 31/ 32]\t\tLoss: 1.9798 Acc@1: 27.016%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 2.6725 Acc@1: 29.00%\n",
            "| Saving Best model...\t\t\tTop1 = 29.00%\n",
            "\n",
            "=> Training Epoch #7, LR=0.1000\n",
            "| Epoch [  7/ 50] Iter[  1/ 32]\t\tLoss: 1.9339 Acc@1: 25.000%\n",
            "| Epoch [  7/ 50] Iter[ 16/ 32]\t\tLoss: 1.9234 Acc@1: 27.930%\n",
            "| Epoch [  7/ 50] Iter[ 31/ 32]\t\tLoss: 1.8513 Acc@1: 27.419%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 1.7794 Acc@1: 33.85%\n",
            "| Saving Best model...\t\t\tTop1 = 33.85%\n",
            "\n",
            "=> Training Epoch #8, LR=0.1000\n",
            "| Epoch [  8/ 50] Iter[  1/ 32]\t\tLoss: 1.7712 Acc@1: 25.000%\n",
            "| Epoch [  8/ 50] Iter[ 16/ 32]\t\tLoss: 2.0188 Acc@1: 28.516%\n",
            "| Epoch [  8/ 50] Iter[ 31/ 32]\t\tLoss: 1.9505 Acc@1: 30.343%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 1.2483 Acc@1: 28.45%\n",
            "\n",
            "=> Training Epoch #9, LR=0.1000\n",
            "| Epoch [  9/ 50] Iter[  1/ 32]\t\tLoss: 1.7720 Acc@1: 34.375%\n",
            "| Epoch [  9/ 50] Iter[ 16/ 32]\t\tLoss: 1.8727 Acc@1: 25.391%\n",
            "| Epoch [  9/ 50] Iter[ 31/ 32]\t\tLoss: 2.0300 Acc@1: 25.806%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 1.0115 Acc@1: 28.00%\n",
            "\n",
            "=> Training Epoch #10, LR=0.1000\n",
            "| Epoch [ 10/ 50] Iter[  1/ 32]\t\tLoss: 1.8311 Acc@1: 34.375%\n",
            "| Epoch [ 10/ 50] Iter[ 16/ 32]\t\tLoss: 1.8656 Acc@1: 30.078%\n",
            "| Epoch [ 10/ 50] Iter[ 31/ 32]\t\tLoss: 1.9116 Acc@1: 29.839%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 1.8806 Acc@1: 25.30%\n",
            "\n",
            "=> Training Epoch #11, LR=0.1000\n",
            "| Epoch [ 11/ 50] Iter[  1/ 32]\t\tLoss: 1.8545 Acc@1: 34.375%\n",
            "| Epoch [ 11/ 50] Iter[ 16/ 32]\t\tLoss: 2.0880 Acc@1: 29.688%\n",
            "| Epoch [ 11/ 50] Iter[ 31/ 32]\t\tLoss: 1.7150 Acc@1: 30.242%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 0.9780 Acc@1: 32.75%\n",
            "\n",
            "=> Training Epoch #12, LR=0.1000\n",
            "| Epoch [ 12/ 50] Iter[  1/ 32]\t\tLoss: 2.1014 Acc@1: 28.125%\n",
            "| Epoch [ 12/ 50] Iter[ 16/ 32]\t\tLoss: 1.4967 Acc@1: 35.352%\n",
            "| Epoch [ 12/ 50] Iter[ 31/ 32]\t\tLoss: 1.9799 Acc@1: 35.282%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 1.7969 Acc@1: 31.85%\n",
            "\n",
            "=> Training Epoch #13, LR=0.1000\n",
            "| Epoch [ 13/ 50] Iter[  1/ 32]\t\tLoss: 1.6740 Acc@1: 31.250%\n",
            "| Epoch [ 13/ 50] Iter[ 16/ 32]\t\tLoss: 1.8034 Acc@1: 32.812%\n",
            "| Epoch [ 13/ 50] Iter[ 31/ 32]\t\tLoss: 1.6955 Acc@1: 32.056%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 1.5283 Acc@1: 31.85%\n",
            "\n",
            "=> Training Epoch #14, LR=0.1000\n",
            "| Epoch [ 14/ 50] Iter[  1/ 32]\t\tLoss: 1.6815 Acc@1: 40.625%\n",
            "| Epoch [ 14/ 50] Iter[ 16/ 32]\t\tLoss: 1.7997 Acc@1: 34.570%\n",
            "| Epoch [ 14/ 50] Iter[ 31/ 32]\t\tLoss: 1.6068 Acc@1: 33.669%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 1.5555 Acc@1: 28.30%\n",
            "\n",
            "=> Training Epoch #15, LR=0.1000\n",
            "| Epoch [ 15/ 50] Iter[  1/ 32]\t\tLoss: 1.5700 Acc@1: 40.625%\n",
            "| Epoch [ 15/ 50] Iter[ 16/ 32]\t\tLoss: 1.8241 Acc@1: 33.203%\n",
            "| Epoch [ 15/ 50] Iter[ 31/ 32]\t\tLoss: 1.9144 Acc@1: 32.359%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 1.4269 Acc@1: 29.65%\n",
            "\n",
            "=> Training Epoch #16, LR=0.1000\n",
            "| Epoch [ 16/ 50] Iter[  1/ 32]\t\tLoss: 1.8769 Acc@1: 40.625%\n",
            "| Epoch [ 16/ 50] Iter[ 16/ 32]\t\tLoss: 1.8109 Acc@1: 36.523%\n",
            "| Epoch [ 16/ 50] Iter[ 31/ 32]\t\tLoss: 1.8731 Acc@1: 35.786%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 1.4282 Acc@1: 33.50%\n",
            "\n",
            "=> Training Epoch #17, LR=0.1000\n",
            "| Epoch [ 17/ 50] Iter[  1/ 32]\t\tLoss: 1.4894 Acc@1: 43.750%\n",
            "| Epoch [ 17/ 50] Iter[ 16/ 32]\t\tLoss: 1.9058 Acc@1: 40.234%\n",
            "| Epoch [ 17/ 50] Iter[ 31/ 32]\t\tLoss: 1.4554 Acc@1: 38.810%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 1.7951 Acc@1: 32.80%\n",
            "\n",
            "=> Training Epoch #18, LR=0.1000\n",
            "| Epoch [ 18/ 50] Iter[  1/ 32]\t\tLoss: 1.8596 Acc@1: 40.625%\n",
            "| Epoch [ 18/ 50] Iter[ 16/ 32]\t\tLoss: 2.0965 Acc@1: 37.695%\n",
            "| Epoch [ 18/ 50] Iter[ 31/ 32]\t\tLoss: 1.7321 Acc@1: 34.778%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 1.5120 Acc@1: 30.90%\n",
            "\n",
            "=> Training Epoch #19, LR=0.1000\n",
            "| Epoch [ 19/ 50] Iter[  1/ 32]\t\tLoss: 1.7227 Acc@1: 43.750%\n",
            "| Epoch [ 19/ 50] Iter[ 16/ 32]\t\tLoss: 1.4232 Acc@1: 41.992%\n",
            "| Epoch [ 19/ 50] Iter[ 31/ 32]\t\tLoss: 1.8238 Acc@1: 40.726%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 1.4898 Acc@1: 35.35%\n",
            "| Saving Best model...\t\t\tTop1 = 35.35%\n",
            "\n",
            "=> Training Epoch #20, LR=0.1000\n",
            "| Epoch [ 20/ 50] Iter[  1/ 32]\t\tLoss: 1.6653 Acc@1: 37.500%\n",
            "| Epoch [ 20/ 50] Iter[ 16/ 32]\t\tLoss: 1.9157 Acc@1: 40.039%\n",
            "| Epoch [ 20/ 50] Iter[ 31/ 32]\t\tLoss: 1.5532 Acc@1: 39.516%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 0.7419 Acc@1: 33.30%\n",
            "\n",
            "=> Training Epoch #21, LR=0.1000\n",
            "| Epoch [ 21/ 50] Iter[  1/ 32]\t\tLoss: 1.5188 Acc@1: 40.625%\n",
            "| Epoch [ 21/ 50] Iter[ 16/ 32]\t\tLoss: 1.7057 Acc@1: 38.477%\n",
            "| Epoch [ 21/ 50] Iter[ 31/ 32]\t\tLoss: 1.5116 Acc@1: 37.601%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 1.1816 Acc@1: 38.35%\n",
            "| Saving Best model...\t\t\tTop1 = 38.35%\n",
            "\n",
            "=> Training Epoch #22, LR=0.1000\n",
            "| Epoch [ 22/ 50] Iter[  1/ 32]\t\tLoss: 1.5581 Acc@1: 34.375%\n",
            "| Epoch [ 22/ 50] Iter[ 16/ 32]\t\tLoss: 1.6850 Acc@1: 39.062%\n",
            "| Epoch [ 22/ 50] Iter[ 31/ 32]\t\tLoss: 1.6092 Acc@1: 37.500%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 1.8055 Acc@1: 35.10%\n",
            "\n",
            "=> Training Epoch #23, LR=0.1000\n",
            "| Epoch [ 23/ 50] Iter[  1/ 32]\t\tLoss: 1.8583 Acc@1: 31.250%\n",
            "| Epoch [ 23/ 50] Iter[ 16/ 32]\t\tLoss: 1.4508 Acc@1: 40.625%\n",
            "| Epoch [ 23/ 50] Iter[ 31/ 32]\t\tLoss: 1.8262 Acc@1: 38.206%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 1.2611 Acc@1: 39.30%\n",
            "| Saving Best model...\t\t\tTop1 = 39.30%\n",
            "\n",
            "=> Training Epoch #24, LR=0.1000\n",
            "| Epoch [ 24/ 50] Iter[  1/ 32]\t\tLoss: 1.7060 Acc@1: 31.250%\n",
            "| Epoch [ 24/ 50] Iter[ 16/ 32]\t\tLoss: 1.4013 Acc@1: 41.602%\n",
            "| Epoch [ 24/ 50] Iter[ 31/ 32]\t\tLoss: 1.4250 Acc@1: 39.819%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 1.2591 Acc@1: 38.05%\n",
            "\n",
            "=> Training Epoch #25, LR=0.1000\n",
            "| Epoch [ 25/ 50] Iter[  1/ 32]\t\tLoss: 1.6223 Acc@1: 46.875%\n",
            "| Epoch [ 25/ 50] Iter[ 16/ 32]\t\tLoss: 1.3243 Acc@1: 42.969%\n",
            "| Epoch [ 25/ 50] Iter[ 31/ 32]\t\tLoss: 1.3654 Acc@1: 43.448%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 1.1268 Acc@1: 39.10%\n",
            "\n",
            "=> Training Epoch #26, LR=0.1000\n",
            "| Epoch [ 26/ 50] Iter[  1/ 32]\t\tLoss: 1.8706 Acc@1: 21.875%\n",
            "| Epoch [ 26/ 50] Iter[ 16/ 32]\t\tLoss: 1.5899 Acc@1: 41.602%\n",
            "| Epoch [ 26/ 50] Iter[ 31/ 32]\t\tLoss: 1.6776 Acc@1: 40.625%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 1.6139 Acc@1: 40.90%\n",
            "| Saving Best model...\t\t\tTop1 = 40.90%\n",
            "\n",
            "=> Training Epoch #27, LR=0.1000\n",
            "| Epoch [ 27/ 50] Iter[  1/ 32]\t\tLoss: 1.5799 Acc@1: 37.500%\n",
            "| Epoch [ 27/ 50] Iter[ 16/ 32]\t\tLoss: 1.7027 Acc@1: 41.992%\n",
            "| Epoch [ 27/ 50] Iter[ 31/ 32]\t\tLoss: 1.6026 Acc@1: 39.919%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 1.6039 Acc@1: 40.80%\n",
            "\n",
            "=> Training Epoch #28, LR=0.1000\n",
            "| Epoch [ 28/ 50] Iter[  1/ 32]\t\tLoss: 1.6189 Acc@1: 40.625%\n",
            "| Epoch [ 28/ 50] Iter[ 16/ 32]\t\tLoss: 1.8560 Acc@1: 40.820%\n",
            "| Epoch [ 28/ 50] Iter[ 31/ 32]\t\tLoss: 1.4878 Acc@1: 41.431%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 1.1760 Acc@1: 41.30%\n",
            "| Saving Best model...\t\t\tTop1 = 41.30%\n",
            "\n",
            "=> Training Epoch #29, LR=0.1000\n",
            "| Epoch [ 29/ 50] Iter[  1/ 32]\t\tLoss: 1.5009 Acc@1: 40.625%\n",
            "| Epoch [ 29/ 50] Iter[ 16/ 32]\t\tLoss: 1.7240 Acc@1: 43.359%\n",
            "| Epoch [ 29/ 50] Iter[ 31/ 32]\t\tLoss: 1.4623 Acc@1: 43.347%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 1.4649 Acc@1: 37.25%\n",
            "\n",
            "=> Training Epoch #30, LR=0.1000\n",
            "| Epoch [ 30/ 50] Iter[  1/ 32]\t\tLoss: 1.3766 Acc@1: 40.625%\n",
            "| Epoch [ 30/ 50] Iter[ 16/ 32]\t\tLoss: 1.5227 Acc@1: 44.141%\n",
            "| Epoch [ 30/ 50] Iter[ 31/ 32]\t\tLoss: 1.4765 Acc@1: 43.548%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 1.1593 Acc@1: 39.35%\n",
            "\n",
            "=> Training Epoch #31, LR=0.1000\n",
            "| Epoch [ 31/ 50] Iter[  1/ 32]\t\tLoss: 1.5274 Acc@1: 40.625%\n",
            "| Epoch [ 31/ 50] Iter[ 16/ 32]\t\tLoss: 1.5399 Acc@1: 45.312%\n",
            "| Epoch [ 31/ 50] Iter[ 31/ 32]\t\tLoss: 1.3475 Acc@1: 44.052%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 0.9226 Acc@1: 37.85%\n",
            "\n",
            "=> Training Epoch #32, LR=0.1000\n",
            "| Epoch [ 32/ 50] Iter[  1/ 32]\t\tLoss: 1.3450 Acc@1: 40.625%\n",
            "| Epoch [ 32/ 50] Iter[ 16/ 32]\t\tLoss: 1.4425 Acc@1: 43.164%\n",
            "| Epoch [ 32/ 50] Iter[ 31/ 32]\t\tLoss: 1.8851 Acc@1: 42.238%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 2.1509 Acc@1: 34.40%\n",
            "\n",
            "=> Training Epoch #33, LR=0.1000\n",
            "| Epoch [ 33/ 50] Iter[  1/ 32]\t\tLoss: 1.5632 Acc@1: 59.375%\n",
            "| Epoch [ 33/ 50] Iter[ 16/ 32]\t\tLoss: 1.6653 Acc@1: 46.094%\n",
            "| Epoch [ 33/ 50] Iter[ 31/ 32]\t\tLoss: 1.1980 Acc@1: 45.867%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 1.1322 Acc@1: 39.20%\n",
            "\n",
            "=> Training Epoch #34, LR=0.1000\n",
            "| Epoch [ 34/ 50] Iter[  1/ 32]\t\tLoss: 1.4258 Acc@1: 50.000%\n",
            "| Epoch [ 34/ 50] Iter[ 16/ 32]\t\tLoss: 1.6985 Acc@1: 46.680%\n",
            "| Epoch [ 34/ 50] Iter[ 31/ 32]\t\tLoss: 2.0559 Acc@1: 46.472%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 1.0688 Acc@1: 40.50%\n",
            "\n",
            "=> Training Epoch #35, LR=0.1000\n",
            "| Epoch [ 35/ 50] Iter[  1/ 32]\t\tLoss: 1.0972 Acc@1: 65.625%\n",
            "| Epoch [ 35/ 50] Iter[ 16/ 32]\t\tLoss: 1.6514 Acc@1: 44.336%\n",
            "| Epoch [ 35/ 50] Iter[ 31/ 32]\t\tLoss: 1.5184 Acc@1: 44.657%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 0.9917 Acc@1: 38.15%\n",
            "\n",
            "=> Training Epoch #36, LR=0.1000\n",
            "| Epoch [ 36/ 50] Iter[  1/ 32]\t\tLoss: 1.4151 Acc@1: 50.000%\n",
            "| Epoch [ 36/ 50] Iter[ 16/ 32]\t\tLoss: 1.2494 Acc@1: 50.781%\n",
            "| Epoch [ 36/ 50] Iter[ 31/ 32]\t\tLoss: 1.5198 Acc@1: 46.976%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 0.9286 Acc@1: 43.65%\n",
            "| Saving Best model...\t\t\tTop1 = 43.65%\n",
            "\n",
            "=> Training Epoch #37, LR=0.1000\n",
            "| Epoch [ 37/ 50] Iter[  1/ 32]\t\tLoss: 2.0432 Acc@1: 31.250%\n",
            "| Epoch [ 37/ 50] Iter[ 16/ 32]\t\tLoss: 1.4250 Acc@1: 45.703%\n",
            "| Epoch [ 37/ 50] Iter[ 31/ 32]\t\tLoss: 1.2213 Acc@1: 45.665%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 1.4864 Acc@1: 38.50%\n",
            "\n",
            "=> Training Epoch #38, LR=0.1000\n",
            "| Epoch [ 38/ 50] Iter[  1/ 32]\t\tLoss: 1.6848 Acc@1: 34.375%\n",
            "| Epoch [ 38/ 50] Iter[ 16/ 32]\t\tLoss: 1.2879 Acc@1: 46.680%\n",
            "| Epoch [ 38/ 50] Iter[ 31/ 32]\t\tLoss: 1.3610 Acc@1: 46.270%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 1.6494 Acc@1: 42.75%\n",
            "\n",
            "=> Training Epoch #39, LR=0.1000\n",
            "| Epoch [ 39/ 50] Iter[  1/ 32]\t\tLoss: 1.5968 Acc@1: 43.750%\n",
            "| Epoch [ 39/ 50] Iter[ 16/ 32]\t\tLoss: 1.7222 Acc@1: 47.461%\n",
            "| Epoch [ 39/ 50] Iter[ 31/ 32]\t\tLoss: 1.4865 Acc@1: 49.194%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 0.9535 Acc@1: 45.70%\n",
            "| Saving Best model...\t\t\tTop1 = 45.70%\n",
            "\n",
            "=> Training Epoch #40, LR=0.1000\n",
            "| Epoch [ 40/ 50] Iter[  1/ 32]\t\tLoss: 1.4469 Acc@1: 56.250%\n",
            "| Epoch [ 40/ 50] Iter[ 16/ 32]\t\tLoss: 1.2368 Acc@1: 48.828%\n",
            "| Epoch [ 40/ 50] Iter[ 31/ 32]\t\tLoss: 1.3895 Acc@1: 45.363%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 2.2620 Acc@1: 39.75%\n",
            "\n",
            "=> Training Epoch #41, LR=0.1000\n",
            "| Epoch [ 41/ 50] Iter[  1/ 32]\t\tLoss: 1.3220 Acc@1: 50.000%\n",
            "| Epoch [ 41/ 50] Iter[ 16/ 32]\t\tLoss: 1.1306 Acc@1: 47.266%\n",
            "| Epoch [ 41/ 50] Iter[ 31/ 32]\t\tLoss: 1.1185 Acc@1: 44.657%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 1.1662 Acc@1: 37.95%\n",
            "\n",
            "=> Training Epoch #42, LR=0.1000\n",
            "| Epoch [ 42/ 50] Iter[  1/ 32]\t\tLoss: 1.5102 Acc@1: 43.750%\n",
            "| Epoch [ 42/ 50] Iter[ 16/ 32]\t\tLoss: 2.0485 Acc@1: 47.070%\n",
            "| Epoch [ 42/ 50] Iter[ 31/ 32]\t\tLoss: 1.4293 Acc@1: 46.169%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 1.0376 Acc@1: 46.55%\n",
            "| Saving Best model...\t\t\tTop1 = 46.55%\n",
            "\n",
            "=> Training Epoch #43, LR=0.1000\n",
            "| Epoch [ 43/ 50] Iter[  1/ 32]\t\tLoss: 1.2968 Acc@1: 56.250%\n",
            "| Epoch [ 43/ 50] Iter[ 16/ 32]\t\tLoss: 1.2714 Acc@1: 51.758%\n",
            "| Epoch [ 43/ 50] Iter[ 31/ 32]\t\tLoss: 1.5679 Acc@1: 49.597%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 0.9338 Acc@1: 37.85%\n",
            "\n",
            "=> Training Epoch #44, LR=0.1000\n",
            "| Epoch [ 44/ 50] Iter[  1/ 32]\t\tLoss: 1.4773 Acc@1: 37.500%\n",
            "| Epoch [ 44/ 50] Iter[ 16/ 32]\t\tLoss: 1.6260 Acc@1: 46.484%\n",
            "| Epoch [ 44/ 50] Iter[ 31/ 32]\t\tLoss: 1.3046 Acc@1: 46.976%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 1.1014 Acc@1: 46.60%\n",
            "| Saving Best model...\t\t\tTop1 = 46.60%\n",
            "\n",
            "=> Training Epoch #45, LR=0.1000\n",
            "| Epoch [ 45/ 50] Iter[  1/ 32]\t\tLoss: 1.4470 Acc@1: 40.625%\n",
            "| Epoch [ 45/ 50] Iter[ 16/ 32]\t\tLoss: 1.4836 Acc@1: 49.023%\n",
            "| Epoch [ 45/ 50] Iter[ 31/ 32]\t\tLoss: 1.3672 Acc@1: 48.488%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 1.0121 Acc@1: 45.85%\n",
            "\n",
            "=> Training Epoch #46, LR=0.1000\n",
            "| Epoch [ 46/ 50] Iter[  1/ 32]\t\tLoss: 1.1597 Acc@1: 46.875%\n",
            "| Epoch [ 46/ 50] Iter[ 16/ 32]\t\tLoss: 1.5937 Acc@1: 50.977%\n",
            "| Epoch [ 46/ 50] Iter[ 31/ 32]\t\tLoss: 1.9577 Acc@1: 47.984%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 0.5673 Acc@1: 44.45%\n",
            "\n",
            "=> Training Epoch #47, LR=0.1000\n",
            "| Epoch [ 47/ 50] Iter[  1/ 32]\t\tLoss: 1.3860 Acc@1: 46.875%\n",
            "| Epoch [ 47/ 50] Iter[ 16/ 32]\t\tLoss: 1.6281 Acc@1: 50.195%\n",
            "| Epoch [ 47/ 50] Iter[ 31/ 32]\t\tLoss: 1.5556 Acc@1: 49.294%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 1.1081 Acc@1: 43.75%\n",
            "\n",
            "=> Training Epoch #48, LR=0.1000\n",
            "| Epoch [ 48/ 50] Iter[  1/ 32]\t\tLoss: 1.3452 Acc@1: 50.000%\n",
            "| Epoch [ 48/ 50] Iter[ 16/ 32]\t\tLoss: 1.2934 Acc@1: 53.320%\n",
            "| Epoch [ 48/ 50] Iter[ 31/ 32]\t\tLoss: 1.6721 Acc@1: 51.210%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 0.9463 Acc@1: 50.05%\n",
            "| Saving Best model...\t\t\tTop1 = 50.05%\n",
            "\n",
            "=> Training Epoch #49, LR=0.1000\n",
            "| Epoch [ 49/ 50] Iter[  1/ 32]\t\tLoss: 1.2502 Acc@1: 53.125%\n",
            "| Epoch [ 49/ 50] Iter[ 16/ 32]\t\tLoss: 1.3393 Acc@1: 51.562%\n",
            "| Epoch [ 49/ 50] Iter[ 31/ 32]\t\tLoss: 1.3390 Acc@1: 52.722%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 1.8446 Acc@1: 42.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "weX9mgbZBiNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def test_final(net,testloader):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            \n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            inputs, targets = Variable(inputs), Variable(targets)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.data).cpu().sum()\n",
        "            if batch_idx == 0:\n",
        "                predicted_concat = predicted.clone()\n",
        "            else:\n",
        "                predicted_concat = torch.cat((predicted_concat, predicted), 0)\n",
        "\n",
        "        # Save checkpoint when best model\n",
        "    acc = 100.*correct/total\n",
        "    print(\"\\n| TEST \\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %( loss.item(), acc))\n",
        "    return predicted_concat.cpu().numpy()\n",
        "    \n",
        "\n",
        "predicted_concat = test_final(net,test_loader)\n",
        "\n",
        "\n",
        "id_concat =range(len(predicted_concat))\n",
        "my_submission = pd.DataFrame({'Id': id_concat,'Expected': predicted_concat})\n",
        "\n",
        "# you could use any filename. We choose submission here\n",
        "my_submission.to_csv('submission2.csv', index=False)\n",
        "print('we have saved the submission !! ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqFxbtmBkAL",
        "outputId": "be11724a-6405-4dcb-8faa-82fb03a4a83a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "| TEST \t\t\tLoss: 2.1698 Acc@1: 41.18%\n",
            "we have saved the submission !! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question for the report\n",
        "I want that you send me a small report with the answer to this question and your notebook.\n",
        "- Q0: Please train wideresnet, and please understand a bit wideresnet.\n",
        "- Q1: Please change DNN with a Resnet 18. Try with one that is pre-trained and one that is not pre-trained. \n",
        "- Q2: Please change DNN with an AlexNet. Try with one that is pre-trained and one that is not pre-trained. (Be careful, you need a bit to play with the learning rate, for questions two, one and zeros I want to see the training loss and training accuracy. What other curb is interesting? Plot it and analyse it.)\n",
        "- Q3: Please try to train an SVM and a random forest.\n",
        "- Q4 After you have trained several models please draw a table and make some conclusions.\n",
        "-  Q5 Read the paper fixmatch (https://amitness.com/2020/03/fixmatch-semi-supervised/) and explain it.\n",
        "- Q6 please try to implement it and try to make it work.\n",
        "- Q7 What can we do to avoid overfitting in Deep learning?\n",
        "\n",
        "\n",
        "*Q0-Q5 = 14 pts*\n",
        "\n",
        "*Q6 = 6 pts*\n",
        "\n",
        "*Q7 = 1 pts*"
      ],
      "metadata": {
        "id": "UrJS4AqABprt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rapport TP "
      ],
      "metadata": {
        "id": "p7KXcYVyaJz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders with resized images\n",
        "\n",
        "resized_shape = 256\n",
        "\n",
        "transform_train_resized = transforms.Compose([\n",
        "    transforms.Resize(resized_shape),\n",
        "    transforms.RandomCrop(resized_shape, padding=4, padding_mode = 'reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "    CutoutDefault(resized_shape//2),\n",
        "])\n",
        "\n",
        "transform_test_resized = transforms.Compose([\n",
        "    transforms.Resize(resized_shape),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "test_loader_resized = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_test_resized),\n",
        "    batch_size = batch_size,\n",
        "    shuffle=False, num_workers=2)\n",
        "\n",
        "train_loader_resized = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_train, y_train, transform=transform_train_resized),\n",
        "    batch_size=batch_size,shuffle=True, num_workers=2) #num_workers = 2 ou 1\n",
        "\n",
        "valid_loader_resized = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_valid, y_valid, transform=transform_test_resized),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "I8IyTOQWqWPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TchxW7N5Sc"
      },
      "source": [
        "## Q0 : WideResNet \n",
        "WideResNet est une architecture de réseau de neurones. \n",
        "\n",
        "On dispose d'une couche de neurones appelée WideBasic sous cette forme. ![Couche WideBasic.jpg](data:image/jpeg;base64,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)\n",
        "La particularité de cette couche est que l'entrée suit 2 chemins et y subit différentes transformations et que la sortie est donnée par une somme de ces 2 résultats. On crée ensuite des couches WideLayer qui consistent à mettre en série 4 couches WideBasic avec un stride différent sur la première couche WideBasic.\n",
        "\n",
        "WideResNet consiste à construire un réseau avec la première couche comme une couche de convolution puis d'y mettre plusieurs couches WideLayer et de faire un pooling puis de créer une sortie linéaire (fully connected)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivp1144RNvKo"
      },
      "source": [
        "## Q1 : ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax7iEqbVOHp5"
      },
      "outputs": [],
      "source": [
        "# Initialize the models\n",
        "\n",
        "net18_untrained = models.resnet18(weights = None)\n",
        "net18_untrained = net18_untrained.to(device)\n",
        "net18_untrained_save = models.resnet18(weights = None) # To save the results\n",
        "net18_untrained_save = net18_untrained_save.to(device)\n",
        "\n",
        "net18_pretrained = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "net18_pretrained = net18_pretrained.to(device)\n",
        "net18_pretrained_save = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # To save the results\n",
        "net18_pretrained_save = net18_pretrained_save.to(device)\n",
        "\n",
        "resized = True # If True, neural network train on resized data\n",
        "if resized :\n",
        "    train_loader_resnet = train_loader_resized\n",
        "    test_loader_resnet = test_loader_resized\n",
        "    valid_loader_resnet = valid_loader_resized\n",
        "else :\n",
        "    train_loader_resnet = train_loader\n",
        "    test_loader_resnet = test_loader\n",
        "    valid_loader_resnet = valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training pretrained model\n",
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# False if we want to fine the whole model and True if only the last layer\n",
        "feature_extract = True \n",
        "\n",
        "if feature_extract:\n",
        "    for param in net18_pretrained.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Reshaping the last layer so output=num_classes\n",
        "net18_pretrained.fc = nn.Linear(512, num_class).to(device)\n",
        "net18_pretrained_save.fc = nn.Linear(512, num_class).to(device)\n",
        "\n",
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train(epoch,net18_pretrained,train_loader_resnet)\n",
        "    acc =test(epoch,net18_pretrained,valid_loader_resnet)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        net18_pretrained_save.load_state_dict(net18_pretrained.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeftc27Kqvz8",
        "outputId": "aed802c2-b4ca-46a4-e426-b38533976571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.0100\n",
            "| Epoch [  0/ 50] Iter[  1/ 32]\t\tLoss: 2.8424 Acc@1: 9.375%\n",
            "| Epoch [  0/ 50] Iter[ 16/ 32]\t\tLoss: 1.8339 Acc@1: 21.484%\n",
            "| Epoch [  0/ 50] Iter[ 31/ 32]\t\tLoss: 2.1009 Acc@1: 29.032%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 0.3067 Acc@1: 54.80%\n",
            "| Saving Best model...\t\t\tTop1 = 54.80%\n",
            "\n",
            "=> Training Epoch #1, LR=0.0100\n",
            "| Epoch [  1/ 50] Iter[  1/ 32]\t\tLoss: 1.2805 Acc@1: 56.250%\n",
            "| Epoch [  1/ 50] Iter[ 16/ 32]\t\tLoss: 1.4348 Acc@1: 46.289%\n",
            "| Epoch [  1/ 50] Iter[ 31/ 32]\t\tLoss: 1.7340 Acc@1: 48.488%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 0.3501 Acc@1: 57.30%\n",
            "| Saving Best model...\t\t\tTop1 = 57.30%\n",
            "\n",
            "=> Training Epoch #2, LR=0.0100\n",
            "| Epoch [  2/ 50] Iter[  1/ 32]\t\tLoss: 1.3812 Acc@1: 50.000%\n",
            "| Epoch [  2/ 50] Iter[ 16/ 32]\t\tLoss: 1.0855 Acc@1: 53.516%\n",
            "| Epoch [  2/ 50] Iter[ 31/ 32]\t\tLoss: 1.5918 Acc@1: 54.435%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 0.0939 Acc@1: 56.95%\n",
            "\n",
            "=> Training Epoch #3, LR=0.0100\n",
            "| Epoch [  3/ 50] Iter[  1/ 32]\t\tLoss: 1.2050 Acc@1: 59.375%\n",
            "| Epoch [  3/ 50] Iter[ 16/ 32]\t\tLoss: 1.4133 Acc@1: 54.883%\n",
            "| Epoch [  3/ 50] Iter[ 31/ 32]\t\tLoss: 1.2918 Acc@1: 55.544%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 0.2175 Acc@1: 70.20%\n",
            "| Saving Best model...\t\t\tTop1 = 70.20%\n",
            "\n",
            "=> Training Epoch #4, LR=0.0100\n",
            "| Epoch [  4/ 50] Iter[  1/ 32]\t\tLoss: 0.7496 Acc@1: 81.250%\n",
            "| Epoch [  4/ 50] Iter[ 16/ 32]\t\tLoss: 1.3418 Acc@1: 61.328%\n",
            "| Epoch [  4/ 50] Iter[ 31/ 32]\t\tLoss: 1.4218 Acc@1: 60.282%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 0.3559 Acc@1: 64.15%\n",
            "\n",
            "=> Training Epoch #5, LR=0.0100\n",
            "| Epoch [  5/ 50] Iter[  1/ 32]\t\tLoss: 0.9225 Acc@1: 71.875%\n",
            "| Epoch [  5/ 50] Iter[ 16/ 32]\t\tLoss: 1.3123 Acc@1: 60.547%\n",
            "| Epoch [  5/ 50] Iter[ 31/ 32]\t\tLoss: 1.0698 Acc@1: 60.081%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 0.2259 Acc@1: 72.05%\n",
            "| Saving Best model...\t\t\tTop1 = 72.05%\n",
            "\n",
            "=> Training Epoch #6, LR=0.0100\n",
            "| Epoch [  6/ 50] Iter[  1/ 32]\t\tLoss: 1.2080 Acc@1: 50.000%\n",
            "| Epoch [  6/ 50] Iter[ 16/ 32]\t\tLoss: 0.9958 Acc@1: 63.281%\n",
            "| Epoch [  6/ 50] Iter[ 31/ 32]\t\tLoss: 1.3726 Acc@1: 61.391%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 0.0920 Acc@1: 66.95%\n",
            "\n",
            "=> Training Epoch #7, LR=0.0100\n",
            "| Epoch [  7/ 50] Iter[  1/ 32]\t\tLoss: 0.8434 Acc@1: 75.000%\n",
            "| Epoch [  7/ 50] Iter[ 16/ 32]\t\tLoss: 1.1206 Acc@1: 65.820%\n",
            "| Epoch [  7/ 50] Iter[ 31/ 32]\t\tLoss: 0.7716 Acc@1: 65.927%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 0.6715 Acc@1: 67.30%\n",
            "\n",
            "=> Training Epoch #8, LR=0.0100\n",
            "| Epoch [  8/ 50] Iter[  1/ 32]\t\tLoss: 1.1735 Acc@1: 53.125%\n",
            "| Epoch [  8/ 50] Iter[ 16/ 32]\t\tLoss: 1.1620 Acc@1: 62.891%\n",
            "| Epoch [  8/ 50] Iter[ 31/ 32]\t\tLoss: 1.0114 Acc@1: 66.431%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 0.1632 Acc@1: 70.70%\n",
            "\n",
            "=> Training Epoch #9, LR=0.0100\n",
            "| Epoch [  9/ 50] Iter[  1/ 32]\t\tLoss: 1.2651 Acc@1: 53.125%\n",
            "| Epoch [  9/ 50] Iter[ 16/ 32]\t\tLoss: 1.3892 Acc@1: 66.211%\n",
            "| Epoch [  9/ 50] Iter[ 31/ 32]\t\tLoss: 1.0644 Acc@1: 66.230%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 0.1364 Acc@1: 69.50%\n",
            "\n",
            "=> Training Epoch #10, LR=0.0100\n",
            "| Epoch [ 10/ 50] Iter[  1/ 32]\t\tLoss: 1.0488 Acc@1: 71.875%\n",
            "| Epoch [ 10/ 50] Iter[ 16/ 32]\t\tLoss: 1.4917 Acc@1: 62.891%\n",
            "| Epoch [ 10/ 50] Iter[ 31/ 32]\t\tLoss: 1.0302 Acc@1: 61.794%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 0.1165 Acc@1: 66.70%\n",
            "\n",
            "=> Training Epoch #11, LR=0.0100\n",
            "| Epoch [ 11/ 50] Iter[  1/ 32]\t\tLoss: 0.9442 Acc@1: 65.625%\n",
            "| Epoch [ 11/ 50] Iter[ 16/ 32]\t\tLoss: 0.7607 Acc@1: 63.867%\n",
            "| Epoch [ 11/ 50] Iter[ 31/ 32]\t\tLoss: 0.7284 Acc@1: 62.702%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 0.3024 Acc@1: 68.60%\n",
            "\n",
            "=> Training Epoch #12, LR=0.0100\n",
            "| Epoch [ 12/ 50] Iter[  1/ 32]\t\tLoss: 1.3839 Acc@1: 50.000%\n",
            "| Epoch [ 12/ 50] Iter[ 16/ 32]\t\tLoss: 0.6467 Acc@1: 63.477%\n",
            "| Epoch [ 12/ 50] Iter[ 31/ 32]\t\tLoss: 0.9071 Acc@1: 63.306%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 0.1720 Acc@1: 65.85%\n",
            "\n",
            "=> Training Epoch #13, LR=0.0100\n",
            "| Epoch [ 13/ 50] Iter[  1/ 32]\t\tLoss: 0.7593 Acc@1: 71.875%\n",
            "| Epoch [ 13/ 50] Iter[ 16/ 32]\t\tLoss: 1.3348 Acc@1: 64.648%\n",
            "| Epoch [ 13/ 50] Iter[ 31/ 32]\t\tLoss: 0.7319 Acc@1: 66.532%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 0.1324 Acc@1: 71.00%\n",
            "\n",
            "=> Training Epoch #14, LR=0.0100\n",
            "| Epoch [ 14/ 50] Iter[  1/ 32]\t\tLoss: 1.3154 Acc@1: 50.000%\n",
            "| Epoch [ 14/ 50] Iter[ 16/ 32]\t\tLoss: 0.8538 Acc@1: 67.383%\n",
            "| Epoch [ 14/ 50] Iter[ 31/ 32]\t\tLoss: 1.1878 Acc@1: 68.044%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 0.2589 Acc@1: 72.50%\n",
            "| Saving Best model...\t\t\tTop1 = 72.50%\n",
            "\n",
            "=> Training Epoch #15, LR=0.0100\n",
            "| Epoch [ 15/ 50] Iter[  1/ 32]\t\tLoss: 0.6343 Acc@1: 84.375%\n",
            "| Epoch [ 15/ 50] Iter[ 16/ 32]\t\tLoss: 1.0711 Acc@1: 68.164%\n",
            "| Epoch [ 15/ 50] Iter[ 31/ 32]\t\tLoss: 1.2086 Acc@1: 64.214%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 0.0239 Acc@1: 66.35%\n",
            "\n",
            "=> Training Epoch #16, LR=0.0100\n",
            "| Epoch [ 16/ 50] Iter[  1/ 32]\t\tLoss: 1.1804 Acc@1: 53.125%\n",
            "| Epoch [ 16/ 50] Iter[ 16/ 32]\t\tLoss: 1.1742 Acc@1: 64.453%\n",
            "| Epoch [ 16/ 50] Iter[ 31/ 32]\t\tLoss: 0.9045 Acc@1: 64.718%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 0.0265 Acc@1: 67.40%\n",
            "\n",
            "=> Training Epoch #17, LR=0.0100\n",
            "| Epoch [ 17/ 50] Iter[  1/ 32]\t\tLoss: 1.0641 Acc@1: 59.375%\n",
            "| Epoch [ 17/ 50] Iter[ 16/ 32]\t\tLoss: 1.0210 Acc@1: 72.852%\n",
            "| Epoch [ 17/ 50] Iter[ 31/ 32]\t\tLoss: 1.5222 Acc@1: 69.355%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 0.1384 Acc@1: 70.05%\n",
            "\n",
            "=> Training Epoch #18, LR=0.0100\n",
            "| Epoch [ 18/ 50] Iter[  1/ 32]\t\tLoss: 0.6671 Acc@1: 81.250%\n",
            "| Epoch [ 18/ 50] Iter[ 16/ 32]\t\tLoss: 1.6575 Acc@1: 65.430%\n",
            "| Epoch [ 18/ 50] Iter[ 31/ 32]\t\tLoss: 1.3950 Acc@1: 65.726%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 0.0897 Acc@1: 71.05%\n",
            "\n",
            "=> Training Epoch #19, LR=0.0100\n",
            "| Epoch [ 19/ 50] Iter[  1/ 32]\t\tLoss: 0.8370 Acc@1: 68.750%\n",
            "| Epoch [ 19/ 50] Iter[ 16/ 32]\t\tLoss: 1.3186 Acc@1: 72.461%\n",
            "| Epoch [ 19/ 50] Iter[ 31/ 32]\t\tLoss: 1.2675 Acc@1: 70.464%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 0.0624 Acc@1: 67.85%\n",
            "\n",
            "=> Training Epoch #20, LR=0.0100\n",
            "| Epoch [ 20/ 50] Iter[  1/ 32]\t\tLoss: 1.1990 Acc@1: 59.375%\n",
            "| Epoch [ 20/ 50] Iter[ 16/ 32]\t\tLoss: 0.9411 Acc@1: 66.992%\n",
            "| Epoch [ 20/ 50] Iter[ 31/ 32]\t\tLoss: 1.0869 Acc@1: 66.935%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 0.0326 Acc@1: 68.95%\n",
            "\n",
            "=> Training Epoch #21, LR=0.0100\n",
            "| Epoch [ 21/ 50] Iter[  1/ 32]\t\tLoss: 1.0821 Acc@1: 53.125%\n",
            "| Epoch [ 21/ 50] Iter[ 16/ 32]\t\tLoss: 1.2046 Acc@1: 69.336%\n",
            "| Epoch [ 21/ 50] Iter[ 31/ 32]\t\tLoss: 1.0396 Acc@1: 69.657%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 0.1602 Acc@1: 68.05%\n",
            "\n",
            "=> Training Epoch #22, LR=0.0100\n",
            "| Epoch [ 22/ 50] Iter[  1/ 32]\t\tLoss: 0.8687 Acc@1: 78.125%\n",
            "| Epoch [ 22/ 50] Iter[ 16/ 32]\t\tLoss: 0.7140 Acc@1: 70.898%\n",
            "| Epoch [ 22/ 50] Iter[ 31/ 32]\t\tLoss: 0.8489 Acc@1: 69.153%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 0.5181 Acc@1: 70.85%\n",
            "\n",
            "=> Training Epoch #23, LR=0.0100\n",
            "| Epoch [ 23/ 50] Iter[  1/ 32]\t\tLoss: 0.6313 Acc@1: 75.000%\n",
            "| Epoch [ 23/ 50] Iter[ 16/ 32]\t\tLoss: 0.5303 Acc@1: 74.219%\n",
            "| Epoch [ 23/ 50] Iter[ 31/ 32]\t\tLoss: 1.2116 Acc@1: 73.286%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 0.0119 Acc@1: 69.95%\n",
            "\n",
            "=> Training Epoch #24, LR=0.0100\n",
            "| Epoch [ 24/ 50] Iter[  1/ 32]\t\tLoss: 0.6816 Acc@1: 71.875%\n",
            "| Epoch [ 24/ 50] Iter[ 16/ 32]\t\tLoss: 0.9624 Acc@1: 69.336%\n",
            "| Epoch [ 24/ 50] Iter[ 31/ 32]\t\tLoss: 1.0497 Acc@1: 69.556%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 0.1963 Acc@1: 70.80%\n",
            "\n",
            "=> Training Epoch #25, LR=0.0100\n",
            "| Epoch [ 25/ 50] Iter[  1/ 32]\t\tLoss: 0.8804 Acc@1: 68.750%\n",
            "| Epoch [ 25/ 50] Iter[ 16/ 32]\t\tLoss: 0.7261 Acc@1: 70.898%\n",
            "| Epoch [ 25/ 50] Iter[ 31/ 32]\t\tLoss: 1.1786 Acc@1: 69.052%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 0.0563 Acc@1: 69.60%\n",
            "\n",
            "=> Training Epoch #26, LR=0.0100\n",
            "| Epoch [ 26/ 50] Iter[  1/ 32]\t\tLoss: 0.7863 Acc@1: 65.625%\n",
            "| Epoch [ 26/ 50] Iter[ 16/ 32]\t\tLoss: 1.1275 Acc@1: 71.484%\n",
            "| Epoch [ 26/ 50] Iter[ 31/ 32]\t\tLoss: 0.9783 Acc@1: 71.270%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 0.0158 Acc@1: 71.00%\n",
            "\n",
            "=> Training Epoch #27, LR=0.0100\n",
            "| Epoch [ 27/ 50] Iter[  1/ 32]\t\tLoss: 1.2879 Acc@1: 68.750%\n",
            "| Epoch [ 27/ 50] Iter[ 16/ 32]\t\tLoss: 1.0396 Acc@1: 66.992%\n",
            "| Epoch [ 27/ 50] Iter[ 31/ 32]\t\tLoss: 0.8615 Acc@1: 68.347%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 0.0140 Acc@1: 69.85%\n",
            "\n",
            "=> Training Epoch #28, LR=0.0100\n",
            "| Epoch [ 28/ 50] Iter[  1/ 32]\t\tLoss: 0.5948 Acc@1: 71.875%\n",
            "| Epoch [ 28/ 50] Iter[ 16/ 32]\t\tLoss: 0.6382 Acc@1: 71.094%\n",
            "| Epoch [ 28/ 50] Iter[ 31/ 32]\t\tLoss: 0.9147 Acc@1: 69.859%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 0.0128 Acc@1: 71.45%\n",
            "\n",
            "=> Training Epoch #29, LR=0.0100\n",
            "| Epoch [ 29/ 50] Iter[  1/ 32]\t\tLoss: 0.7248 Acc@1: 71.875%\n",
            "| Epoch [ 29/ 50] Iter[ 16/ 32]\t\tLoss: 1.3182 Acc@1: 71.094%\n",
            "| Epoch [ 29/ 50] Iter[ 31/ 32]\t\tLoss: 0.7068 Acc@1: 72.581%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 0.0714 Acc@1: 69.00%\n",
            "\n",
            "=> Training Epoch #30, LR=0.0100\n",
            "| Epoch [ 30/ 50] Iter[  1/ 32]\t\tLoss: 1.1817 Acc@1: 59.375%\n",
            "| Epoch [ 30/ 50] Iter[ 16/ 32]\t\tLoss: 1.4016 Acc@1: 68.750%\n",
            "| Epoch [ 30/ 50] Iter[ 31/ 32]\t\tLoss: 0.9871 Acc@1: 70.665%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 0.1523 Acc@1: 72.85%\n",
            "| Saving Best model...\t\t\tTop1 = 72.85%\n",
            "\n",
            "=> Training Epoch #31, LR=0.0100\n",
            "| Epoch [ 31/ 50] Iter[  1/ 32]\t\tLoss: 0.6111 Acc@1: 78.125%\n",
            "| Epoch [ 31/ 50] Iter[ 16/ 32]\t\tLoss: 1.1299 Acc@1: 71.484%\n",
            "| Epoch [ 31/ 50] Iter[ 31/ 32]\t\tLoss: 0.8854 Acc@1: 70.464%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 0.0992 Acc@1: 68.95%\n",
            "\n",
            "=> Training Epoch #32, LR=0.0100\n",
            "| Epoch [ 32/ 50] Iter[  1/ 32]\t\tLoss: 0.8425 Acc@1: 65.625%\n",
            "| Epoch [ 32/ 50] Iter[ 16/ 32]\t\tLoss: 0.6797 Acc@1: 72.070%\n",
            "| Epoch [ 32/ 50] Iter[ 31/ 32]\t\tLoss: 0.9464 Acc@1: 69.556%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 0.1142 Acc@1: 69.90%\n",
            "\n",
            "=> Training Epoch #33, LR=0.0100\n",
            "| Epoch [ 33/ 50] Iter[  1/ 32]\t\tLoss: 0.6740 Acc@1: 68.750%\n",
            "| Epoch [ 33/ 50] Iter[ 16/ 32]\t\tLoss: 0.9475 Acc@1: 73.242%\n",
            "| Epoch [ 33/ 50] Iter[ 31/ 32]\t\tLoss: 0.7834 Acc@1: 71.472%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 0.0402 Acc@1: 68.95%\n",
            "\n",
            "=> Training Epoch #34, LR=0.0100\n",
            "| Epoch [ 34/ 50] Iter[  1/ 32]\t\tLoss: 1.0563 Acc@1: 62.500%\n",
            "| Epoch [ 34/ 50] Iter[ 16/ 32]\t\tLoss: 1.4902 Acc@1: 69.922%\n",
            "| Epoch [ 34/ 50] Iter[ 31/ 32]\t\tLoss: 1.2266 Acc@1: 68.649%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 0.0363 Acc@1: 70.75%\n",
            "\n",
            "=> Training Epoch #35, LR=0.0100\n",
            "| Epoch [ 35/ 50] Iter[  1/ 32]\t\tLoss: 0.8009 Acc@1: 71.875%\n",
            "| Epoch [ 35/ 50] Iter[ 16/ 32]\t\tLoss: 1.0281 Acc@1: 70.312%\n",
            "| Epoch [ 35/ 50] Iter[ 31/ 32]\t\tLoss: 1.0200 Acc@1: 71.169%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 0.0548 Acc@1: 71.50%\n",
            "\n",
            "=> Training Epoch #36, LR=0.0100\n",
            "| Epoch [ 36/ 50] Iter[  1/ 32]\t\tLoss: 0.6456 Acc@1: 81.250%\n",
            "| Epoch [ 36/ 50] Iter[ 16/ 32]\t\tLoss: 1.1392 Acc@1: 73.047%\n",
            "| Epoch [ 36/ 50] Iter[ 31/ 32]\t\tLoss: 0.8697 Acc@1: 70.867%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 0.0640 Acc@1: 68.20%\n",
            "\n",
            "=> Training Epoch #37, LR=0.0100\n",
            "| Epoch [ 37/ 50] Iter[  1/ 32]\t\tLoss: 0.6961 Acc@1: 78.125%\n",
            "| Epoch [ 37/ 50] Iter[ 16/ 32]\t\tLoss: 0.9095 Acc@1: 70.898%\n",
            "| Epoch [ 37/ 50] Iter[ 31/ 32]\t\tLoss: 0.7071 Acc@1: 71.774%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 0.0281 Acc@1: 70.90%\n",
            "\n",
            "=> Training Epoch #38, LR=0.0100\n",
            "| Epoch [ 38/ 50] Iter[  1/ 32]\t\tLoss: 1.0084 Acc@1: 62.500%\n",
            "| Epoch [ 38/ 50] Iter[ 16/ 32]\t\tLoss: 0.7525 Acc@1: 68.750%\n",
            "| Epoch [ 38/ 50] Iter[ 31/ 32]\t\tLoss: 1.2764 Acc@1: 68.246%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 0.1760 Acc@1: 68.60%\n",
            "\n",
            "=> Training Epoch #39, LR=0.0100\n",
            "| Epoch [ 39/ 50] Iter[  1/ 32]\t\tLoss: 1.2482 Acc@1: 62.500%\n",
            "| Epoch [ 39/ 50] Iter[ 16/ 32]\t\tLoss: 0.8928 Acc@1: 69.922%\n",
            "| Epoch [ 39/ 50] Iter[ 31/ 32]\t\tLoss: 1.2795 Acc@1: 70.968%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 0.0250 Acc@1: 68.95%\n",
            "\n",
            "=> Training Epoch #40, LR=0.0100\n",
            "| Epoch [ 40/ 50] Iter[  1/ 32]\t\tLoss: 0.8269 Acc@1: 75.000%\n",
            "| Epoch [ 40/ 50] Iter[ 16/ 32]\t\tLoss: 0.8456 Acc@1: 71.094%\n",
            "| Epoch [ 40/ 50] Iter[ 31/ 32]\t\tLoss: 0.9334 Acc@1: 68.649%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 0.0571 Acc@1: 69.90%\n",
            "\n",
            "=> Training Epoch #41, LR=0.0100\n",
            "| Epoch [ 41/ 50] Iter[  1/ 32]\t\tLoss: 1.1418 Acc@1: 65.625%\n",
            "| Epoch [ 41/ 50] Iter[ 16/ 32]\t\tLoss: 0.7407 Acc@1: 75.781%\n",
            "| Epoch [ 41/ 50] Iter[ 31/ 32]\t\tLoss: 0.7207 Acc@1: 72.883%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 0.1245 Acc@1: 70.20%\n",
            "\n",
            "=> Training Epoch #42, LR=0.0100\n",
            "| Epoch [ 42/ 50] Iter[  1/ 32]\t\tLoss: 0.8768 Acc@1: 68.750%\n",
            "| Epoch [ 42/ 50] Iter[ 16/ 32]\t\tLoss: 0.7763 Acc@1: 70.508%\n",
            "| Epoch [ 42/ 50] Iter[ 31/ 32]\t\tLoss: 0.5442 Acc@1: 70.968%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 0.1485 Acc@1: 70.00%\n",
            "\n",
            "=> Training Epoch #43, LR=0.0100\n",
            "| Epoch [ 43/ 50] Iter[  1/ 32]\t\tLoss: 0.9771 Acc@1: 59.375%\n",
            "| Epoch [ 43/ 50] Iter[ 16/ 32]\t\tLoss: 0.8156 Acc@1: 70.117%\n",
            "| Epoch [ 43/ 50] Iter[ 31/ 32]\t\tLoss: 0.6213 Acc@1: 69.859%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 0.0524 Acc@1: 72.15%\n",
            "\n",
            "=> Training Epoch #44, LR=0.0100\n",
            "| Epoch [ 44/ 50] Iter[  1/ 32]\t\tLoss: 0.5607 Acc@1: 87.500%\n",
            "| Epoch [ 44/ 50] Iter[ 16/ 32]\t\tLoss: 0.7703 Acc@1: 75.391%\n",
            "| Epoch [ 44/ 50] Iter[ 31/ 32]\t\tLoss: 0.8673 Acc@1: 70.968%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 0.2709 Acc@1: 65.90%\n",
            "\n",
            "=> Training Epoch #45, LR=0.0100\n",
            "| Epoch [ 45/ 50] Iter[  1/ 32]\t\tLoss: 0.9379 Acc@1: 62.500%\n",
            "| Epoch [ 45/ 50] Iter[ 16/ 32]\t\tLoss: 0.7593 Acc@1: 73.047%\n",
            "| Epoch [ 45/ 50] Iter[ 31/ 32]\t\tLoss: 1.2242 Acc@1: 71.270%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 0.4172 Acc@1: 67.80%\n",
            "\n",
            "=> Training Epoch #46, LR=0.0100\n",
            "| Epoch [ 46/ 50] Iter[  1/ 32]\t\tLoss: 1.2046 Acc@1: 68.750%\n",
            "| Epoch [ 46/ 50] Iter[ 16/ 32]\t\tLoss: 1.1381 Acc@1: 70.117%\n",
            "| Epoch [ 46/ 50] Iter[ 31/ 32]\t\tLoss: 1.3232 Acc@1: 67.742%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 0.0626 Acc@1: 69.10%\n",
            "\n",
            "=> Training Epoch #47, LR=0.0100\n",
            "| Epoch [ 47/ 50] Iter[  1/ 32]\t\tLoss: 0.8499 Acc@1: 71.875%\n",
            "| Epoch [ 47/ 50] Iter[ 16/ 32]\t\tLoss: 0.9100 Acc@1: 71.289%\n",
            "| Epoch [ 47/ 50] Iter[ 31/ 32]\t\tLoss: 0.6884 Acc@1: 70.161%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 0.0832 Acc@1: 71.35%\n",
            "\n",
            "=> Training Epoch #48, LR=0.0100\n",
            "| Epoch [ 48/ 50] Iter[  1/ 32]\t\tLoss: 0.7246 Acc@1: 75.000%\n",
            "| Epoch [ 48/ 50] Iter[ 16/ 32]\t\tLoss: 0.8694 Acc@1: 74.414%\n",
            "| Epoch [ 48/ 50] Iter[ 31/ 32]\t\tLoss: 0.7405 Acc@1: 73.790%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 0.0703 Acc@1: 69.55%\n",
            "\n",
            "=> Training Epoch #49, LR=0.0100\n",
            "| Epoch [ 49/ 50] Iter[  1/ 32]\t\tLoss: 0.4903 Acc@1: 84.375%\n",
            "| Epoch [ 49/ 50] Iter[ 16/ 32]\t\tLoss: 0.7698 Acc@1: 74.609%\n",
            "| Epoch [ 49/ 50] Iter[ 31/ 32]\t\tLoss: 0.6994 Acc@1: 73.185%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 0.1056 Acc@1: 69.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH1Wtjs8PTfr",
        "outputId": "a211cde8-38e6-4eca-bdea-6504de6fb31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.0100\n",
            "| Epoch [  0/ 50] Iter[  1/ 32]\t\tLoss: 6.7891 Acc@1: 0.000%\n",
            "| Epoch [  0/ 50] Iter[ 16/ 32]\t\tLoss: 2.4796 Acc@1: 12.891%\n",
            "| Epoch [  0/ 50] Iter[ 31/ 32]\t\tLoss: 2.1819 Acc@1: 15.827%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 2.1508 Acc@1: 14.05%\n",
            "| Saving Best model...\t\t\tTop1 = 14.05%\n",
            "\n",
            "=> Training Epoch #1, LR=0.0100\n",
            "| Epoch [  1/ 50] Iter[  1/ 32]\t\tLoss: 2.2679 Acc@1: 12.500%\n",
            "| Epoch [  1/ 50] Iter[ 16/ 32]\t\tLoss: 1.9343 Acc@1: 23.828%\n",
            "| Epoch [  1/ 50] Iter[ 31/ 32]\t\tLoss: 2.1441 Acc@1: 25.806%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 1.3202 Acc@1: 27.10%\n",
            "| Saving Best model...\t\t\tTop1 = 27.10%\n",
            "\n",
            "=> Training Epoch #2, LR=0.0100\n",
            "| Epoch [  2/ 50] Iter[  1/ 32]\t\tLoss: 2.3762 Acc@1: 12.500%\n",
            "| Epoch [  2/ 50] Iter[ 16/ 32]\t\tLoss: 2.6234 Acc@1: 28.125%\n",
            "| Epoch [  2/ 50] Iter[ 31/ 32]\t\tLoss: 1.9832 Acc@1: 26.512%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 1.5404 Acc@1: 24.00%\n",
            "\n",
            "=> Training Epoch #3, LR=0.0100\n",
            "| Epoch [  3/ 50] Iter[  1/ 32]\t\tLoss: 2.0372 Acc@1: 34.375%\n",
            "| Epoch [  3/ 50] Iter[ 16/ 32]\t\tLoss: 2.3464 Acc@1: 29.688%\n",
            "| Epoch [  3/ 50] Iter[ 31/ 32]\t\tLoss: 1.8832 Acc@1: 29.335%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 0.3644 Acc@1: 27.80%\n",
            "| Saving Best model...\t\t\tTop1 = 27.80%\n",
            "\n",
            "=> Training Epoch #4, LR=0.0100\n",
            "| Epoch [  4/ 50] Iter[  1/ 32]\t\tLoss: 2.0063 Acc@1: 21.875%\n",
            "| Epoch [  4/ 50] Iter[ 16/ 32]\t\tLoss: 2.2019 Acc@1: 34.180%\n",
            "| Epoch [  4/ 50] Iter[ 31/ 32]\t\tLoss: 1.4858 Acc@1: 33.669%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 1.6713 Acc@1: 25.10%\n",
            "\n",
            "=> Training Epoch #5, LR=0.0100\n",
            "| Epoch [  5/ 50] Iter[  1/ 32]\t\tLoss: 1.6731 Acc@1: 34.375%\n",
            "| Epoch [  5/ 50] Iter[ 16/ 32]\t\tLoss: 2.4590 Acc@1: 33.789%\n",
            "| Epoch [  5/ 50] Iter[ 31/ 32]\t\tLoss: 1.6251 Acc@1: 31.250%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 0.6322 Acc@1: 34.05%\n",
            "| Saving Best model...\t\t\tTop1 = 34.05%\n",
            "\n",
            "=> Training Epoch #6, LR=0.0100\n",
            "| Epoch [  6/ 50] Iter[  1/ 32]\t\tLoss: 1.6407 Acc@1: 37.500%\n",
            "| Epoch [  6/ 50] Iter[ 16/ 32]\t\tLoss: 1.9465 Acc@1: 36.523%\n",
            "| Epoch [  6/ 50] Iter[ 31/ 32]\t\tLoss: 1.7877 Acc@1: 37.298%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 2.3079 Acc@1: 34.65%\n",
            "| Saving Best model...\t\t\tTop1 = 34.65%\n",
            "\n",
            "=> Training Epoch #7, LR=0.0100\n",
            "| Epoch [  7/ 50] Iter[  1/ 32]\t\tLoss: 1.8995 Acc@1: 40.625%\n",
            "| Epoch [  7/ 50] Iter[ 16/ 32]\t\tLoss: 2.2770 Acc@1: 38.867%\n",
            "| Epoch [  7/ 50] Iter[ 31/ 32]\t\tLoss: 2.0164 Acc@1: 39.214%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 2.6270 Acc@1: 31.20%\n",
            "\n",
            "=> Training Epoch #8, LR=0.0100\n",
            "| Epoch [  8/ 50] Iter[  1/ 32]\t\tLoss: 1.5879 Acc@1: 43.750%\n",
            "| Epoch [  8/ 50] Iter[ 16/ 32]\t\tLoss: 1.8650 Acc@1: 42.188%\n",
            "| Epoch [  8/ 50] Iter[ 31/ 32]\t\tLoss: 1.6401 Acc@1: 41.532%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 1.3579 Acc@1: 27.05%\n",
            "\n",
            "=> Training Epoch #9, LR=0.0100\n",
            "| Epoch [  9/ 50] Iter[  1/ 32]\t\tLoss: 1.7155 Acc@1: 46.875%\n",
            "| Epoch [  9/ 50] Iter[ 16/ 32]\t\tLoss: 1.3164 Acc@1: 41.992%\n",
            "| Epoch [  9/ 50] Iter[ 31/ 32]\t\tLoss: 1.6134 Acc@1: 42.238%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 2.3336 Acc@1: 33.75%\n",
            "\n",
            "=> Training Epoch #10, LR=0.0100\n",
            "| Epoch [ 10/ 50] Iter[  1/ 32]\t\tLoss: 1.4677 Acc@1: 43.750%\n",
            "| Epoch [ 10/ 50] Iter[ 16/ 32]\t\tLoss: 1.4507 Acc@1: 46.094%\n",
            "| Epoch [ 10/ 50] Iter[ 31/ 32]\t\tLoss: 1.5521 Acc@1: 46.069%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 0.5515 Acc@1: 32.10%\n",
            "\n",
            "=> Training Epoch #11, LR=0.0100\n",
            "| Epoch [ 11/ 50] Iter[  1/ 32]\t\tLoss: 1.6562 Acc@1: 40.625%\n",
            "| Epoch [ 11/ 50] Iter[ 16/ 32]\t\tLoss: 1.1829 Acc@1: 50.195%\n",
            "| Epoch [ 11/ 50] Iter[ 31/ 32]\t\tLoss: 1.3856 Acc@1: 49.496%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 0.7110 Acc@1: 34.10%\n",
            "\n",
            "=> Training Epoch #12, LR=0.0100\n",
            "| Epoch [ 12/ 50] Iter[  1/ 32]\t\tLoss: 1.5330 Acc@1: 46.875%\n",
            "| Epoch [ 12/ 50] Iter[ 16/ 32]\t\tLoss: 1.3032 Acc@1: 49.609%\n",
            "| Epoch [ 12/ 50] Iter[ 31/ 32]\t\tLoss: 1.5558 Acc@1: 47.984%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 1.4344 Acc@1: 40.50%\n",
            "| Saving Best model...\t\t\tTop1 = 40.50%\n",
            "\n",
            "=> Training Epoch #13, LR=0.0100\n",
            "| Epoch [ 13/ 50] Iter[  1/ 32]\t\tLoss: 1.6248 Acc@1: 40.625%\n",
            "| Epoch [ 13/ 50] Iter[ 16/ 32]\t\tLoss: 1.8124 Acc@1: 50.977%\n",
            "| Epoch [ 13/ 50] Iter[ 31/ 32]\t\tLoss: 1.3558 Acc@1: 51.915%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 1.1663 Acc@1: 37.15%\n",
            "\n",
            "=> Training Epoch #14, LR=0.0100\n",
            "| Epoch [ 14/ 50] Iter[  1/ 32]\t\tLoss: 1.5945 Acc@1: 40.625%\n",
            "| Epoch [ 14/ 50] Iter[ 16/ 32]\t\tLoss: 1.4161 Acc@1: 52.148%\n",
            "| Epoch [ 14/ 50] Iter[ 31/ 32]\t\tLoss: 1.3494 Acc@1: 49.597%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 5.6438 Acc@1: 30.75%\n",
            "\n",
            "=> Training Epoch #15, LR=0.0100\n",
            "| Epoch [ 15/ 50] Iter[  1/ 32]\t\tLoss: 1.5640 Acc@1: 46.875%\n",
            "| Epoch [ 15/ 50] Iter[ 16/ 32]\t\tLoss: 1.7360 Acc@1: 56.445%\n",
            "| Epoch [ 15/ 50] Iter[ 31/ 32]\t\tLoss: 1.4103 Acc@1: 53.730%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 2.0274 Acc@1: 33.90%\n",
            "\n",
            "=> Training Epoch #16, LR=0.0100\n",
            "| Epoch [ 16/ 50] Iter[  1/ 32]\t\tLoss: 1.4292 Acc@1: 46.875%\n",
            "| Epoch [ 16/ 50] Iter[ 16/ 32]\t\tLoss: 1.1020 Acc@1: 59.180%\n",
            "| Epoch [ 16/ 50] Iter[ 31/ 32]\t\tLoss: 1.3121 Acc@1: 55.847%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 3.4755 Acc@1: 35.35%\n",
            "\n",
            "=> Training Epoch #17, LR=0.0100\n",
            "| Epoch [ 17/ 50] Iter[  1/ 32]\t\tLoss: 1.2088 Acc@1: 65.625%\n",
            "| Epoch [ 17/ 50] Iter[ 16/ 32]\t\tLoss: 1.2804 Acc@1: 60.156%\n",
            "| Epoch [ 17/ 50] Iter[ 31/ 32]\t\tLoss: 1.5282 Acc@1: 58.367%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 2.9502 Acc@1: 40.10%\n",
            "\n",
            "=> Training Epoch #18, LR=0.0100\n",
            "| Epoch [ 18/ 50] Iter[  1/ 32]\t\tLoss: 1.1125 Acc@1: 59.375%\n",
            "| Epoch [ 18/ 50] Iter[ 16/ 32]\t\tLoss: 1.1987 Acc@1: 62.500%\n",
            "| Epoch [ 18/ 50] Iter[ 31/ 32]\t\tLoss: 1.4433 Acc@1: 59.980%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 2.3089 Acc@1: 35.30%\n",
            "\n",
            "=> Training Epoch #19, LR=0.0100\n",
            "| Epoch [ 19/ 50] Iter[  1/ 32]\t\tLoss: 1.5097 Acc@1: 53.125%\n",
            "| Epoch [ 19/ 50] Iter[ 16/ 32]\t\tLoss: 1.3898 Acc@1: 58.203%\n",
            "| Epoch [ 19/ 50] Iter[ 31/ 32]\t\tLoss: 1.4820 Acc@1: 57.460%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 2.3997 Acc@1: 28.70%\n",
            "\n",
            "=> Training Epoch #20, LR=0.0100\n",
            "| Epoch [ 20/ 50] Iter[  1/ 32]\t\tLoss: 1.0658 Acc@1: 65.625%\n",
            "| Epoch [ 20/ 50] Iter[ 16/ 32]\t\tLoss: 0.9530 Acc@1: 66.016%\n",
            "| Epoch [ 20/ 50] Iter[ 31/ 32]\t\tLoss: 1.3051 Acc@1: 63.710%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 1.0887 Acc@1: 36.00%\n",
            "\n",
            "=> Training Epoch #21, LR=0.0100\n",
            "| Epoch [ 21/ 50] Iter[  1/ 32]\t\tLoss: 1.2388 Acc@1: 50.000%\n",
            "| Epoch [ 21/ 50] Iter[ 16/ 32]\t\tLoss: 1.0045 Acc@1: 63.672%\n",
            "| Epoch [ 21/ 50] Iter[ 31/ 32]\t\tLoss: 1.0975 Acc@1: 60.484%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 3.7830 Acc@1: 34.00%\n",
            "\n",
            "=> Training Epoch #22, LR=0.0100\n",
            "| Epoch [ 22/ 50] Iter[  1/ 32]\t\tLoss: 0.8931 Acc@1: 68.750%\n",
            "| Epoch [ 22/ 50] Iter[ 16/ 32]\t\tLoss: 0.7447 Acc@1: 69.336%\n",
            "| Epoch [ 22/ 50] Iter[ 31/ 32]\t\tLoss: 1.2559 Acc@1: 67.440%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 0.6187 Acc@1: 34.85%\n",
            "\n",
            "=> Training Epoch #23, LR=0.0100\n",
            "| Epoch [ 23/ 50] Iter[  1/ 32]\t\tLoss: 0.6768 Acc@1: 81.250%\n",
            "| Epoch [ 23/ 50] Iter[ 16/ 32]\t\tLoss: 0.9034 Acc@1: 70.117%\n",
            "| Epoch [ 23/ 50] Iter[ 31/ 32]\t\tLoss: 1.2607 Acc@1: 65.726%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 11.2352 Acc@1: 25.55%\n",
            "\n",
            "=> Training Epoch #24, LR=0.0100\n",
            "| Epoch [ 24/ 50] Iter[  1/ 32]\t\tLoss: 1.0613 Acc@1: 62.500%\n",
            "| Epoch [ 24/ 50] Iter[ 16/ 32]\t\tLoss: 0.8133 Acc@1: 70.898%\n",
            "| Epoch [ 24/ 50] Iter[ 31/ 32]\t\tLoss: 0.8573 Acc@1: 70.565%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 2.3039 Acc@1: 31.70%\n",
            "\n",
            "=> Training Epoch #25, LR=0.0100\n",
            "| Epoch [ 25/ 50] Iter[  1/ 32]\t\tLoss: 1.1071 Acc@1: 59.375%\n",
            "| Epoch [ 25/ 50] Iter[ 16/ 32]\t\tLoss: 0.7435 Acc@1: 70.117%\n",
            "| Epoch [ 25/ 50] Iter[ 31/ 32]\t\tLoss: 0.7073 Acc@1: 68.851%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 2.7595 Acc@1: 36.70%\n",
            "\n",
            "=> Training Epoch #26, LR=0.0100\n",
            "| Epoch [ 26/ 50] Iter[  1/ 32]\t\tLoss: 0.5674 Acc@1: 75.000%\n",
            "| Epoch [ 26/ 50] Iter[ 16/ 32]\t\tLoss: 0.9283 Acc@1: 73.047%\n",
            "| Epoch [ 26/ 50] Iter[ 31/ 32]\t\tLoss: 1.4440 Acc@1: 70.161%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 0.1247 Acc@1: 28.55%\n",
            "\n",
            "=> Training Epoch #27, LR=0.0100\n",
            "| Epoch [ 27/ 50] Iter[  1/ 32]\t\tLoss: 0.9757 Acc@1: 56.250%\n",
            "| Epoch [ 27/ 50] Iter[ 16/ 32]\t\tLoss: 0.5464 Acc@1: 72.852%\n",
            "| Epoch [ 27/ 50] Iter[ 31/ 32]\t\tLoss: 0.8851 Acc@1: 71.069%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 1.4302 Acc@1: 35.00%\n",
            "\n",
            "=> Training Epoch #28, LR=0.0100\n",
            "| Epoch [ 28/ 50] Iter[  1/ 32]\t\tLoss: 0.9079 Acc@1: 78.125%\n",
            "| Epoch [ 28/ 50] Iter[ 16/ 32]\t\tLoss: 0.5888 Acc@1: 72.852%\n",
            "| Epoch [ 28/ 50] Iter[ 31/ 32]\t\tLoss: 0.8698 Acc@1: 71.976%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 1.2771 Acc@1: 33.90%\n",
            "\n",
            "=> Training Epoch #29, LR=0.0100\n",
            "| Epoch [ 29/ 50] Iter[  1/ 32]\t\tLoss: 0.8560 Acc@1: 62.500%\n",
            "| Epoch [ 29/ 50] Iter[ 16/ 32]\t\tLoss: 0.7813 Acc@1: 80.078%\n",
            "| Epoch [ 29/ 50] Iter[ 31/ 32]\t\tLoss: 0.7897 Acc@1: 76.210%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 5.7098 Acc@1: 35.40%\n",
            "\n",
            "=> Training Epoch #30, LR=0.0100\n",
            "| Epoch [ 30/ 50] Iter[  1/ 32]\t\tLoss: 0.5047 Acc@1: 71.875%\n",
            "| Epoch [ 30/ 50] Iter[ 16/ 32]\t\tLoss: 0.6120 Acc@1: 81.445%\n",
            "| Epoch [ 30/ 50] Iter[ 31/ 32]\t\tLoss: 0.7662 Acc@1: 79.133%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 5.5469 Acc@1: 35.75%\n",
            "\n",
            "=> Training Epoch #31, LR=0.0100\n",
            "| Epoch [ 31/ 50] Iter[  1/ 32]\t\tLoss: 0.4707 Acc@1: 81.250%\n",
            "| Epoch [ 31/ 50] Iter[ 16/ 32]\t\tLoss: 0.4898 Acc@1: 81.836%\n",
            "| Epoch [ 31/ 50] Iter[ 31/ 32]\t\tLoss: 0.5793 Acc@1: 79.234%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 0.7816 Acc@1: 35.15%\n",
            "\n",
            "=> Training Epoch #32, LR=0.0100\n",
            "| Epoch [ 32/ 50] Iter[  1/ 32]\t\tLoss: 0.3663 Acc@1: 87.500%\n",
            "| Epoch [ 32/ 50] Iter[ 16/ 32]\t\tLoss: 0.4800 Acc@1: 86.523%\n",
            "| Epoch [ 32/ 50] Iter[ 31/ 32]\t\tLoss: 0.5040 Acc@1: 82.157%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 0.7355 Acc@1: 38.75%\n",
            "\n",
            "=> Training Epoch #33, LR=0.0100\n",
            "| Epoch [ 33/ 50] Iter[  1/ 32]\t\tLoss: 0.2648 Acc@1: 96.875%\n",
            "| Epoch [ 33/ 50] Iter[ 16/ 32]\t\tLoss: 0.7519 Acc@1: 88.281%\n",
            "| Epoch [ 33/ 50] Iter[ 31/ 32]\t\tLoss: 0.5266 Acc@1: 82.964%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 3.1218 Acc@1: 37.25%\n",
            "\n",
            "=> Training Epoch #34, LR=0.0100\n",
            "| Epoch [ 34/ 50] Iter[  1/ 32]\t\tLoss: 0.4901 Acc@1: 84.375%\n",
            "| Epoch [ 34/ 50] Iter[ 16/ 32]\t\tLoss: 0.7773 Acc@1: 81.055%\n",
            "| Epoch [ 34/ 50] Iter[ 31/ 32]\t\tLoss: 0.6414 Acc@1: 80.040%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 7.3007 Acc@1: 34.60%\n",
            "\n",
            "=> Training Epoch #35, LR=0.0100\n",
            "| Epoch [ 35/ 50] Iter[  1/ 32]\t\tLoss: 0.4603 Acc@1: 81.250%\n",
            "| Epoch [ 35/ 50] Iter[ 16/ 32]\t\tLoss: 0.4146 Acc@1: 86.523%\n",
            "| Epoch [ 35/ 50] Iter[ 31/ 32]\t\tLoss: 0.7647 Acc@1: 82.056%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 2.0208 Acc@1: 35.70%\n",
            "\n",
            "=> Training Epoch #36, LR=0.0100\n",
            "| Epoch [ 36/ 50] Iter[  1/ 32]\t\tLoss: 0.4439 Acc@1: 81.250%\n",
            "| Epoch [ 36/ 50] Iter[ 16/ 32]\t\tLoss: 0.4122 Acc@1: 82.227%\n",
            "| Epoch [ 36/ 50] Iter[ 31/ 32]\t\tLoss: 0.3843 Acc@1: 82.560%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 3.1999 Acc@1: 41.80%\n",
            "| Saving Best model...\t\t\tTop1 = 41.80%\n",
            "\n",
            "=> Training Epoch #37, LR=0.0100\n",
            "| Epoch [ 37/ 50] Iter[  1/ 32]\t\tLoss: 0.3042 Acc@1: 87.500%\n",
            "| Epoch [ 37/ 50] Iter[ 16/ 32]\t\tLoss: 0.5895 Acc@1: 86.914%\n",
            "| Epoch [ 37/ 50] Iter[ 31/ 32]\t\tLoss: 0.4085 Acc@1: 85.988%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 1.5567 Acc@1: 35.10%\n",
            "\n",
            "=> Training Epoch #38, LR=0.0100\n",
            "| Epoch [ 38/ 50] Iter[  1/ 32]\t\tLoss: 0.3056 Acc@1: 90.625%\n",
            "| Epoch [ 38/ 50] Iter[ 16/ 32]\t\tLoss: 0.1690 Acc@1: 90.234%\n",
            "| Epoch [ 38/ 50] Iter[ 31/ 32]\t\tLoss: 0.6457 Acc@1: 86.794%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 0.6606 Acc@1: 34.80%\n",
            "\n",
            "=> Training Epoch #39, LR=0.0100\n",
            "| Epoch [ 39/ 50] Iter[  1/ 32]\t\tLoss: 0.4205 Acc@1: 81.250%\n",
            "| Epoch [ 39/ 50] Iter[ 16/ 32]\t\tLoss: 0.2682 Acc@1: 85.156%\n",
            "| Epoch [ 39/ 50] Iter[ 31/ 32]\t\tLoss: 0.5069 Acc@1: 84.677%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 3.8216 Acc@1: 38.45%\n",
            "\n",
            "=> Training Epoch #40, LR=0.0100\n",
            "| Epoch [ 40/ 50] Iter[  1/ 32]\t\tLoss: 0.4910 Acc@1: 84.375%\n",
            "| Epoch [ 40/ 50] Iter[ 16/ 32]\t\tLoss: 0.1459 Acc@1: 89.844%\n",
            "| Epoch [ 40/ 50] Iter[ 31/ 32]\t\tLoss: 0.5704 Acc@1: 88.407%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 3.7873 Acc@1: 38.35%\n",
            "\n",
            "=> Training Epoch #41, LR=0.0100\n",
            "| Epoch [ 41/ 50] Iter[  1/ 32]\t\tLoss: 0.1522 Acc@1: 93.750%\n",
            "| Epoch [ 41/ 50] Iter[ 16/ 32]\t\tLoss: 0.2694 Acc@1: 89.648%\n",
            "| Epoch [ 41/ 50] Iter[ 31/ 32]\t\tLoss: 0.2499 Acc@1: 88.206%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 5.9433 Acc@1: 32.40%\n",
            "\n",
            "=> Training Epoch #42, LR=0.0100\n",
            "| Epoch [ 42/ 50] Iter[  1/ 32]\t\tLoss: 0.2751 Acc@1: 90.625%\n",
            "| Epoch [ 42/ 50] Iter[ 16/ 32]\t\tLoss: 0.1487 Acc@1: 90.430%\n",
            "| Epoch [ 42/ 50] Iter[ 31/ 32]\t\tLoss: 0.3146 Acc@1: 89.315%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 3.8877 Acc@1: 39.65%\n",
            "\n",
            "=> Training Epoch #43, LR=0.0100\n",
            "| Epoch [ 43/ 50] Iter[  1/ 32]\t\tLoss: 0.1408 Acc@1: 96.875%\n",
            "| Epoch [ 43/ 50] Iter[ 16/ 32]\t\tLoss: 0.3109 Acc@1: 92.773%\n",
            "| Epoch [ 43/ 50] Iter[ 31/ 32]\t\tLoss: 0.3264 Acc@1: 90.121%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 2.3471 Acc@1: 36.15%\n",
            "\n",
            "=> Training Epoch #44, LR=0.0100\n",
            "| Epoch [ 44/ 50] Iter[  1/ 32]\t\tLoss: 0.1252 Acc@1: 100.000%\n",
            "| Epoch [ 44/ 50] Iter[ 16/ 32]\t\tLoss: 0.1442 Acc@1: 91.406%\n",
            "| Epoch [ 44/ 50] Iter[ 31/ 32]\t\tLoss: 0.3388 Acc@1: 89.315%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 2.5551 Acc@1: 33.65%\n",
            "\n",
            "=> Training Epoch #45, LR=0.0100\n",
            "| Epoch [ 45/ 50] Iter[  1/ 32]\t\tLoss: 0.3386 Acc@1: 96.875%\n",
            "| Epoch [ 45/ 50] Iter[ 16/ 32]\t\tLoss: 0.4386 Acc@1: 91.797%\n",
            "| Epoch [ 45/ 50] Iter[ 31/ 32]\t\tLoss: 0.2950 Acc@1: 91.633%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 3.3401 Acc@1: 39.85%\n",
            "\n",
            "=> Training Epoch #46, LR=0.0100\n",
            "| Epoch [ 46/ 50] Iter[  1/ 32]\t\tLoss: 0.2362 Acc@1: 87.500%\n",
            "| Epoch [ 46/ 50] Iter[ 16/ 32]\t\tLoss: 0.1694 Acc@1: 91.797%\n",
            "| Epoch [ 46/ 50] Iter[ 31/ 32]\t\tLoss: 0.0834 Acc@1: 93.246%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 4.6103 Acc@1: 41.50%\n",
            "\n",
            "=> Training Epoch #47, LR=0.0100\n",
            "| Epoch [ 47/ 50] Iter[  1/ 32]\t\tLoss: 0.2941 Acc@1: 87.500%\n",
            "| Epoch [ 47/ 50] Iter[ 16/ 32]\t\tLoss: 0.2115 Acc@1: 94.531%\n",
            "| Epoch [ 47/ 50] Iter[ 31/ 32]\t\tLoss: 0.2331 Acc@1: 92.339%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 13.0484 Acc@1: 34.05%\n",
            "\n",
            "=> Training Epoch #48, LR=0.0100\n",
            "| Epoch [ 48/ 50] Iter[  1/ 32]\t\tLoss: 0.2137 Acc@1: 96.875%\n",
            "| Epoch [ 48/ 50] Iter[ 16/ 32]\t\tLoss: 0.1796 Acc@1: 93.750%\n",
            "| Epoch [ 48/ 50] Iter[ 31/ 32]\t\tLoss: 0.2334 Acc@1: 92.339%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 1.0503 Acc@1: 41.50%\n",
            "\n",
            "=> Training Epoch #49, LR=0.0100\n",
            "| Epoch [ 49/ 50] Iter[  1/ 32]\t\tLoss: 0.2443 Acc@1: 90.625%\n",
            "| Epoch [ 49/ 50] Iter[ 16/ 32]\t\tLoss: 0.2019 Acc@1: 91.602%\n",
            "| Epoch [ 49/ 50] Iter[ 31/ 32]\t\tLoss: 0.1454 Acc@1: 91.230%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 9.3854 Acc@1: 36.45%\n"
          ]
        }
      ],
      "source": [
        "# Training not pretrained model\n",
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "    train(epoch,net18_untrained,train_loader_resnet)\n",
        "    acc =test(epoch,net18_untrained,valid_loader_resnet)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        net18_untrained_save.load_state_dict(net18_untrained.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0fQoGYhKvA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36203fa3-67e4-42c7-ff43-9e1311bc9104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained network\n",
            "\n",
            "| TEST \t\t\tLoss: 0.7712 Acc@1: 67.68%\n",
            "Not pretrained network\n",
            "\n",
            "| TEST \t\t\tLoss: 2.8787 Acc@1: 35.03%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "\n",
        "# Pretrained\n",
        "print(\"Pretrained network\")\n",
        "predicted_concat = test_final(net18_pretrained,test_loader_resnet)\n",
        "\n",
        "# Not pretrained\n",
        "print(\"Not pretrained network\")\n",
        "predicted_concat = test_final(net18_untrained,test_loader_resnet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkxGbIukXEc"
      },
      "source": [
        "## Q2 : AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFgwUgZmkqp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a242428a9a7b410da36dbe7937c62ce0",
            "8f8c3da8ac404dd59d0395431044564c",
            "ec91c34f3b4548dc86a031e58418337e",
            "70bc16f4a2564b8f82808414f040800b",
            "7eff7a5445104e9f9728e5577089d195",
            "e6b57cddbd554d0b8aaa6a9e6e7458fb",
            "c8eee06a5e894e07b9366cfaa8d3297d",
            "a5dea9ae3d514d6fb633d3d457010dfb",
            "59d2ba7113be490aa7be3be5e018f60c",
            "dcf0c26a859b4f87b3924ef8750a3840",
            "d6d79698d12248658073699dc66bd865"
          ]
        },
        "outputId": "2b6fc0ab-f286-42a2-a042-65d2ace743e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a242428a9a7b410da36dbe7937c62ce0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize the models\n",
        "\n",
        "alexnet_untrained = models.alexnet(weights = None)\n",
        "alexnet_untrained = alexnet_untrained.to(device)\n",
        "alexnet_untrained_save = models.alexnet(weights = None) # To save the results\n",
        "alexnet_untrained_save = alexnet_untrained_save.to(device)\n",
        "\n",
        "alexnet_pretrained = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "alexnet_pretrained = alexnet_pretrained.to(device)\n",
        "alexnet_pretrained_save = models.alexnet(weights = None) # To save the results\n",
        "alexnet_pretrained_save = alexnet_pretrained_save.to(device)\n",
        "\n",
        "resized = True # If True, neural network train on resized data, has to be True, Alexnet doesn't work en 3x32x32\n",
        "if resized :\n",
        "    train_loader_alexnet = train_loader_resized\n",
        "    test_loader_alexnet = test_loader_resized\n",
        "    valid_loader_alexnet = valid_loader_resized\n",
        "else :\n",
        "    train_loader_resnet = train_loader\n",
        "    test_loader_alexnet = test_loader\n",
        "    valid_loader_alexnet = valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJHbu1shkqp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f993b1a1-59a1-4263-b811-69e2f15ab23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.0100\n",
            "| Epoch [  0/ 50] Iter[  1/ 32]\t\tLoss: 6.9080 Acc@1: 0.000%\n",
            "| Epoch [  0/ 50] Iter[ 16/ 32]\t\tLoss: 6.7806 Acc@1: 7.812%\n",
            "| Epoch [  0/ 50] Iter[ 31/ 32]\t\tLoss: 6.5567 Acc@1: 8.871%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 6.2162 Acc@1: 10.00%\n",
            "| Saving Best model...\t\t\tTop1 = 10.00%\n",
            "\n",
            "=> Training Epoch #1, LR=0.0100\n",
            "| Epoch [  1/ 50] Iter[  1/ 32]\t\tLoss: 6.7318 Acc@1: 21.875%\n",
            "| Epoch [  1/ 50] Iter[ 16/ 32]\t\tLoss: 5.6802 Acc@1: 9.375%\n",
            "| Epoch [  1/ 50] Iter[ 31/ 32]\t\tLoss: 4.1497 Acc@1: 9.879%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 15.4427 Acc@1: 10.00%\n",
            "\n",
            "=> Training Epoch #2, LR=0.0100\n",
            "| Epoch [  2/ 50] Iter[  1/ 32]\t\tLoss: 5.3559 Acc@1: 3.125%\n",
            "| Epoch [  2/ 50] Iter[ 16/ 32]\t\tLoss: 3.0532 Acc@1: 8.789%\n",
            "| Epoch [  2/ 50] Iter[ 31/ 32]\t\tLoss: 2.5765 Acc@1: 8.871%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 2.8715 Acc@1: 10.00%\n",
            "\n",
            "=> Training Epoch #3, LR=0.0100\n",
            "| Epoch [  3/ 50] Iter[  1/ 32]\t\tLoss: 2.3702 Acc@1: 9.375%\n",
            "| Epoch [  3/ 50] Iter[ 16/ 32]\t\tLoss: 2.4468 Acc@1: 9.180%\n",
            "| Epoch [  3/ 50] Iter[ 31/ 32]\t\tLoss: 2.4880 Acc@1: 8.972%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 2.1578 Acc@1: 10.00%\n",
            "\n",
            "=> Training Epoch #4, LR=0.0100\n",
            "| Epoch [  4/ 50] Iter[  1/ 32]\t\tLoss: 2.4048 Acc@1: 0.000%\n",
            "| Epoch [  4/ 50] Iter[ 16/ 32]\t\tLoss: 2.4244 Acc@1: 8.984%\n",
            "| Epoch [  4/ 50] Iter[ 31/ 32]\t\tLoss: 2.4138 Acc@1: 10.081%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 2.0007 Acc@1: 10.00%\n",
            "\n",
            "=> Training Epoch #5, LR=0.0100\n",
            "| Epoch [  5/ 50] Iter[  1/ 32]\t\tLoss: 2.4820 Acc@1: 6.250%\n",
            "| Epoch [  5/ 50] Iter[ 16/ 32]\t\tLoss: 2.3085 Acc@1: 10.156%\n",
            "| Epoch [  5/ 50] Iter[ 31/ 32]\t\tLoss: 2.3845 Acc@1: 10.181%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 2.6053 Acc@1: 11.15%\n",
            "| Saving Best model...\t\t\tTop1 = 11.15%\n",
            "\n",
            "=> Training Epoch #6, LR=0.0100\n",
            "| Epoch [  6/ 50] Iter[  1/ 32]\t\tLoss: 2.3516 Acc@1: 12.500%\n",
            "| Epoch [  6/ 50] Iter[ 16/ 32]\t\tLoss: 2.4043 Acc@1: 11.523%\n",
            "| Epoch [  6/ 50] Iter[ 31/ 32]\t\tLoss: 2.4476 Acc@1: 10.484%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 1.8620 Acc@1: 10.00%\n",
            "\n",
            "=> Training Epoch #7, LR=0.0100\n",
            "| Epoch [  7/ 50] Iter[  1/ 32]\t\tLoss: 2.3313 Acc@1: 12.500%\n",
            "| Epoch [  7/ 50] Iter[ 16/ 32]\t\tLoss: 2.2454 Acc@1: 10.547%\n",
            "| Epoch [  7/ 50] Iter[ 31/ 32]\t\tLoss: 2.3162 Acc@1: 12.298%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 2.3544 Acc@1: 10.45%\n",
            "\n",
            "=> Training Epoch #8, LR=0.0100\n",
            "| Epoch [  8/ 50] Iter[  1/ 32]\t\tLoss: 2.2755 Acc@1: 9.375%\n",
            "| Epoch [  8/ 50] Iter[ 16/ 32]\t\tLoss: 2.3405 Acc@1: 11.914%\n",
            "| Epoch [  8/ 50] Iter[ 31/ 32]\t\tLoss: 2.3916 Acc@1: 10.383%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 2.6831 Acc@1: 16.10%\n",
            "| Saving Best model...\t\t\tTop1 = 16.10%\n",
            "\n",
            "=> Training Epoch #9, LR=0.0100\n",
            "| Epoch [  9/ 50] Iter[  1/ 32]\t\tLoss: 2.2783 Acc@1: 15.625%\n",
            "| Epoch [  9/ 50] Iter[ 16/ 32]\t\tLoss: 2.2606 Acc@1: 13.281%\n",
            "| Epoch [  9/ 50] Iter[ 31/ 32]\t\tLoss: 2.2011 Acc@1: 13.306%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 2.7353 Acc@1: 14.65%\n",
            "\n",
            "=> Training Epoch #10, LR=0.0100\n",
            "| Epoch [ 10/ 50] Iter[  1/ 32]\t\tLoss: 2.3940 Acc@1: 15.625%\n",
            "| Epoch [ 10/ 50] Iter[ 16/ 32]\t\tLoss: 2.3701 Acc@1: 15.234%\n",
            "| Epoch [ 10/ 50] Iter[ 31/ 32]\t\tLoss: 2.3557 Acc@1: 12.601%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 1.7561 Acc@1: 18.15%\n",
            "| Saving Best model...\t\t\tTop1 = 18.15%\n",
            "\n",
            "=> Training Epoch #11, LR=0.0100\n",
            "| Epoch [ 11/ 50] Iter[  1/ 32]\t\tLoss: 2.2201 Acc@1: 15.625%\n",
            "| Epoch [ 11/ 50] Iter[ 16/ 32]\t\tLoss: 2.3212 Acc@1: 13.086%\n",
            "| Epoch [ 11/ 50] Iter[ 31/ 32]\t\tLoss: 2.2482 Acc@1: 13.810%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 2.6803 Acc@1: 12.60%\n",
            "\n",
            "=> Training Epoch #12, LR=0.0100\n",
            "| Epoch [ 12/ 50] Iter[  1/ 32]\t\tLoss: 2.3971 Acc@1: 12.500%\n",
            "| Epoch [ 12/ 50] Iter[ 16/ 32]\t\tLoss: 2.1469 Acc@1: 16.211%\n",
            "| Epoch [ 12/ 50] Iter[ 31/ 32]\t\tLoss: 2.1528 Acc@1: 17.944%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 2.3267 Acc@1: 17.20%\n",
            "\n",
            "=> Training Epoch #13, LR=0.0100\n",
            "| Epoch [ 13/ 50] Iter[  1/ 32]\t\tLoss: 2.0742 Acc@1: 18.750%\n",
            "| Epoch [ 13/ 50] Iter[ 16/ 32]\t\tLoss: 2.2466 Acc@1: 17.578%\n",
            "| Epoch [ 13/ 50] Iter[ 31/ 32]\t\tLoss: 2.0973 Acc@1: 18.548%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 1.5008 Acc@1: 18.75%\n",
            "| Saving Best model...\t\t\tTop1 = 18.75%\n",
            "\n",
            "=> Training Epoch #14, LR=0.0100\n",
            "| Epoch [ 14/ 50] Iter[  1/ 32]\t\tLoss: 1.9799 Acc@1: 18.750%\n",
            "| Epoch [ 14/ 50] Iter[ 16/ 32]\t\tLoss: 2.2471 Acc@1: 19.727%\n",
            "| Epoch [ 14/ 50] Iter[ 31/ 32]\t\tLoss: 2.1588 Acc@1: 17.944%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 1.6610 Acc@1: 22.75%\n",
            "| Saving Best model...\t\t\tTop1 = 22.75%\n",
            "\n",
            "=> Training Epoch #15, LR=0.0100\n",
            "| Epoch [ 15/ 50] Iter[  1/ 32]\t\tLoss: 2.1907 Acc@1: 25.000%\n",
            "| Epoch [ 15/ 50] Iter[ 16/ 32]\t\tLoss: 1.8779 Acc@1: 20.117%\n",
            "| Epoch [ 15/ 50] Iter[ 31/ 32]\t\tLoss: 2.4537 Acc@1: 19.052%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 2.0945 Acc@1: 21.35%\n",
            "\n",
            "=> Training Epoch #16, LR=0.0100\n",
            "| Epoch [ 16/ 50] Iter[  1/ 32]\t\tLoss: 2.0963 Acc@1: 15.625%\n",
            "| Epoch [ 16/ 50] Iter[ 16/ 32]\t\tLoss: 2.1111 Acc@1: 25.586%\n",
            "| Epoch [ 16/ 50] Iter[ 31/ 32]\t\tLoss: 1.9184 Acc@1: 23.387%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 2.6777 Acc@1: 16.55%\n",
            "\n",
            "=> Training Epoch #17, LR=0.0100\n",
            "| Epoch [ 17/ 50] Iter[  1/ 32]\t\tLoss: 2.4642 Acc@1: 9.375%\n",
            "| Epoch [ 17/ 50] Iter[ 16/ 32]\t\tLoss: 1.8412 Acc@1: 22.852%\n",
            "| Epoch [ 17/ 50] Iter[ 31/ 32]\t\tLoss: 1.9340 Acc@1: 21.270%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 1.3575 Acc@1: 24.70%\n",
            "| Saving Best model...\t\t\tTop1 = 24.70%\n",
            "\n",
            "=> Training Epoch #18, LR=0.0100\n",
            "| Epoch [ 18/ 50] Iter[  1/ 32]\t\tLoss: 1.9318 Acc@1: 34.375%\n",
            "| Epoch [ 18/ 50] Iter[ 16/ 32]\t\tLoss: 2.2443 Acc@1: 22.852%\n",
            "| Epoch [ 18/ 50] Iter[ 31/ 32]\t\tLoss: 2.2049 Acc@1: 24.899%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 0.6373 Acc@1: 22.80%\n",
            "\n",
            "=> Training Epoch #19, LR=0.0100\n",
            "| Epoch [ 19/ 50] Iter[  1/ 32]\t\tLoss: 2.2073 Acc@1: 21.875%\n",
            "| Epoch [ 19/ 50] Iter[ 16/ 32]\t\tLoss: 2.1038 Acc@1: 26.367%\n",
            "| Epoch [ 19/ 50] Iter[ 31/ 32]\t\tLoss: 2.0338 Acc@1: 24.496%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 2.2078 Acc@1: 27.80%\n",
            "| Saving Best model...\t\t\tTop1 = 27.80%\n",
            "\n",
            "=> Training Epoch #20, LR=0.0100\n",
            "| Epoch [ 20/ 50] Iter[  1/ 32]\t\tLoss: 2.0579 Acc@1: 18.750%\n",
            "| Epoch [ 20/ 50] Iter[ 16/ 32]\t\tLoss: 2.0291 Acc@1: 24.609%\n",
            "| Epoch [ 20/ 50] Iter[ 31/ 32]\t\tLoss: 1.9090 Acc@1: 24.294%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 1.8992 Acc@1: 30.70%\n",
            "| Saving Best model...\t\t\tTop1 = 30.70%\n",
            "\n",
            "=> Training Epoch #21, LR=0.0100\n",
            "| Epoch [ 21/ 50] Iter[  1/ 32]\t\tLoss: 1.6460 Acc@1: 34.375%\n",
            "| Epoch [ 21/ 50] Iter[ 16/ 32]\t\tLoss: 1.8216 Acc@1: 27.930%\n",
            "| Epoch [ 21/ 50] Iter[ 31/ 32]\t\tLoss: 2.0284 Acc@1: 27.117%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 1.8052 Acc@1: 31.30%\n",
            "| Saving Best model...\t\t\tTop1 = 31.30%\n",
            "\n",
            "=> Training Epoch #22, LR=0.0100\n",
            "| Epoch [ 22/ 50] Iter[  1/ 32]\t\tLoss: 1.8186 Acc@1: 31.250%\n",
            "| Epoch [ 22/ 50] Iter[ 16/ 32]\t\tLoss: 2.0029 Acc@1: 28.906%\n",
            "| Epoch [ 22/ 50] Iter[ 31/ 32]\t\tLoss: 2.1133 Acc@1: 28.226%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 1.7308 Acc@1: 27.55%\n",
            "\n",
            "=> Training Epoch #23, LR=0.0100\n",
            "| Epoch [ 23/ 50] Iter[  1/ 32]\t\tLoss: 2.1778 Acc@1: 25.000%\n",
            "| Epoch [ 23/ 50] Iter[ 16/ 32]\t\tLoss: 1.9517 Acc@1: 29.492%\n",
            "| Epoch [ 23/ 50] Iter[ 31/ 32]\t\tLoss: 1.8979 Acc@1: 30.948%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 1.6449 Acc@1: 29.00%\n",
            "\n",
            "=> Training Epoch #24, LR=0.0100\n",
            "| Epoch [ 24/ 50] Iter[  1/ 32]\t\tLoss: 1.9345 Acc@1: 25.000%\n",
            "| Epoch [ 24/ 50] Iter[ 16/ 32]\t\tLoss: 1.9995 Acc@1: 32.031%\n",
            "| Epoch [ 24/ 50] Iter[ 31/ 32]\t\tLoss: 1.9267 Acc@1: 29.335%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 1.5165 Acc@1: 26.80%\n",
            "\n",
            "=> Training Epoch #25, LR=0.0100\n",
            "| Epoch [ 25/ 50] Iter[  1/ 32]\t\tLoss: 1.7876 Acc@1: 40.625%\n",
            "| Epoch [ 25/ 50] Iter[ 16/ 32]\t\tLoss: 1.7760 Acc@1: 30.078%\n",
            "| Epoch [ 25/ 50] Iter[ 31/ 32]\t\tLoss: 2.2553 Acc@1: 29.839%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 1.6429 Acc@1: 30.90%\n",
            "\n",
            "=> Training Epoch #26, LR=0.0100\n",
            "| Epoch [ 26/ 50] Iter[  1/ 32]\t\tLoss: 2.0250 Acc@1: 31.250%\n",
            "| Epoch [ 26/ 50] Iter[ 16/ 32]\t\tLoss: 2.1716 Acc@1: 30.859%\n",
            "| Epoch [ 26/ 50] Iter[ 31/ 32]\t\tLoss: 2.0224 Acc@1: 31.048%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 2.0800 Acc@1: 31.70%\n",
            "| Saving Best model...\t\t\tTop1 = 31.70%\n",
            "\n",
            "=> Training Epoch #27, LR=0.0100\n",
            "| Epoch [ 27/ 50] Iter[  1/ 32]\t\tLoss: 1.7253 Acc@1: 28.125%\n",
            "| Epoch [ 27/ 50] Iter[ 16/ 32]\t\tLoss: 2.0880 Acc@1: 30.664%\n",
            "| Epoch [ 27/ 50] Iter[ 31/ 32]\t\tLoss: 1.8277 Acc@1: 31.048%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 1.3690 Acc@1: 29.10%\n",
            "\n",
            "=> Training Epoch #28, LR=0.0100\n",
            "| Epoch [ 28/ 50] Iter[  1/ 32]\t\tLoss: 1.8411 Acc@1: 34.375%\n",
            "| Epoch [ 28/ 50] Iter[ 16/ 32]\t\tLoss: 2.0022 Acc@1: 26.953%\n",
            "| Epoch [ 28/ 50] Iter[ 31/ 32]\t\tLoss: 1.7886 Acc@1: 30.645%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 1.9370 Acc@1: 34.50%\n",
            "| Saving Best model...\t\t\tTop1 = 34.50%\n",
            "\n",
            "=> Training Epoch #29, LR=0.0100\n",
            "| Epoch [ 29/ 50] Iter[  1/ 32]\t\tLoss: 1.5038 Acc@1: 56.250%\n",
            "| Epoch [ 29/ 50] Iter[ 16/ 32]\t\tLoss: 1.5446 Acc@1: 33.203%\n",
            "| Epoch [ 29/ 50] Iter[ 31/ 32]\t\tLoss: 1.9553 Acc@1: 32.560%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 1.4274 Acc@1: 35.65%\n",
            "| Saving Best model...\t\t\tTop1 = 35.65%\n",
            "\n",
            "=> Training Epoch #30, LR=0.0100\n",
            "| Epoch [ 30/ 50] Iter[  1/ 32]\t\tLoss: 1.5663 Acc@1: 46.875%\n",
            "| Epoch [ 30/ 50] Iter[ 16/ 32]\t\tLoss: 1.4596 Acc@1: 37.695%\n",
            "| Epoch [ 30/ 50] Iter[ 31/ 32]\t\tLoss: 1.9774 Acc@1: 34.073%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 1.5389 Acc@1: 34.35%\n",
            "\n",
            "=> Training Epoch #31, LR=0.0100\n",
            "| Epoch [ 31/ 50] Iter[  1/ 32]\t\tLoss: 1.6557 Acc@1: 46.875%\n",
            "| Epoch [ 31/ 50] Iter[ 16/ 32]\t\tLoss: 1.4704 Acc@1: 33.203%\n",
            "| Epoch [ 31/ 50] Iter[ 31/ 32]\t\tLoss: 1.9318 Acc@1: 34.073%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 2.5062 Acc@1: 26.60%\n",
            "\n",
            "=> Training Epoch #32, LR=0.0100\n",
            "| Epoch [ 32/ 50] Iter[  1/ 32]\t\tLoss: 2.0423 Acc@1: 18.750%\n",
            "| Epoch [ 32/ 50] Iter[ 16/ 32]\t\tLoss: 1.7457 Acc@1: 32.227%\n",
            "| Epoch [ 32/ 50] Iter[ 31/ 32]\t\tLoss: 1.7922 Acc@1: 32.863%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 1.7160 Acc@1: 32.70%\n",
            "\n",
            "=> Training Epoch #33, LR=0.0100\n",
            "| Epoch [ 33/ 50] Iter[  1/ 32]\t\tLoss: 1.7749 Acc@1: 34.375%\n",
            "| Epoch [ 33/ 50] Iter[ 16/ 32]\t\tLoss: 1.8266 Acc@1: 34.375%\n",
            "| Epoch [ 33/ 50] Iter[ 31/ 32]\t\tLoss: 1.7200 Acc@1: 34.476%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 1.6684 Acc@1: 38.15%\n",
            "| Saving Best model...\t\t\tTop1 = 38.15%\n",
            "\n",
            "=> Training Epoch #34, LR=0.0100\n",
            "| Epoch [ 34/ 50] Iter[  1/ 32]\t\tLoss: 1.6976 Acc@1: 37.500%\n",
            "| Epoch [ 34/ 50] Iter[ 16/ 32]\t\tLoss: 1.9601 Acc@1: 39.258%\n",
            "| Epoch [ 34/ 50] Iter[ 31/ 32]\t\tLoss: 1.6089 Acc@1: 37.097%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 1.8683 Acc@1: 30.35%\n",
            "\n",
            "=> Training Epoch #35, LR=0.0100\n",
            "| Epoch [ 35/ 50] Iter[  1/ 32]\t\tLoss: 1.7371 Acc@1: 34.375%\n",
            "| Epoch [ 35/ 50] Iter[ 16/ 32]\t\tLoss: 1.7408 Acc@1: 37.109%\n",
            "| Epoch [ 35/ 50] Iter[ 31/ 32]\t\tLoss: 1.6291 Acc@1: 37.298%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 1.1012 Acc@1: 36.70%\n",
            "\n",
            "=> Training Epoch #36, LR=0.0100\n",
            "| Epoch [ 36/ 50] Iter[  1/ 32]\t\tLoss: 1.6754 Acc@1: 40.625%\n",
            "| Epoch [ 36/ 50] Iter[ 16/ 32]\t\tLoss: 1.4084 Acc@1: 38.477%\n",
            "| Epoch [ 36/ 50] Iter[ 31/ 32]\t\tLoss: 1.9119 Acc@1: 37.198%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 1.0554 Acc@1: 35.10%\n",
            "\n",
            "=> Training Epoch #37, LR=0.0100\n",
            "| Epoch [ 37/ 50] Iter[  1/ 32]\t\tLoss: 1.7285 Acc@1: 28.125%\n",
            "| Epoch [ 37/ 50] Iter[ 16/ 32]\t\tLoss: 1.7567 Acc@1: 42.383%\n",
            "| Epoch [ 37/ 50] Iter[ 31/ 32]\t\tLoss: 1.6643 Acc@1: 38.710%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 1.5056 Acc@1: 34.65%\n",
            "\n",
            "=> Training Epoch #38, LR=0.0100\n",
            "| Epoch [ 38/ 50] Iter[  1/ 32]\t\tLoss: 1.7457 Acc@1: 46.875%\n",
            "| Epoch [ 38/ 50] Iter[ 16/ 32]\t\tLoss: 1.8697 Acc@1: 37.891%\n",
            "| Epoch [ 38/ 50] Iter[ 31/ 32]\t\tLoss: 1.8064 Acc@1: 40.927%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 1.0823 Acc@1: 37.95%\n",
            "\n",
            "=> Training Epoch #39, LR=0.0100\n",
            "| Epoch [ 39/ 50] Iter[  1/ 32]\t\tLoss: 1.6152 Acc@1: 46.875%\n",
            "| Epoch [ 39/ 50] Iter[ 16/ 32]\t\tLoss: 1.7766 Acc@1: 41.211%\n",
            "| Epoch [ 39/ 50] Iter[ 31/ 32]\t\tLoss: 1.6134 Acc@1: 38.206%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 1.6664 Acc@1: 35.15%\n",
            "\n",
            "=> Training Epoch #40, LR=0.0100\n",
            "| Epoch [ 40/ 50] Iter[  1/ 32]\t\tLoss: 1.4917 Acc@1: 46.875%\n",
            "| Epoch [ 40/ 50] Iter[ 16/ 32]\t\tLoss: 2.0316 Acc@1: 41.602%\n",
            "| Epoch [ 40/ 50] Iter[ 31/ 32]\t\tLoss: 1.7994 Acc@1: 39.214%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 2.1415 Acc@1: 37.35%\n",
            "\n",
            "=> Training Epoch #41, LR=0.0100\n",
            "| Epoch [ 41/ 50] Iter[  1/ 32]\t\tLoss: 1.6898 Acc@1: 43.750%\n",
            "| Epoch [ 41/ 50] Iter[ 16/ 32]\t\tLoss: 1.7332 Acc@1: 40.234%\n",
            "| Epoch [ 41/ 50] Iter[ 31/ 32]\t\tLoss: 1.8887 Acc@1: 40.625%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 1.5062 Acc@1: 36.00%\n",
            "\n",
            "=> Training Epoch #42, LR=0.0100\n",
            "| Epoch [ 42/ 50] Iter[  1/ 32]\t\tLoss: 1.4566 Acc@1: 46.875%\n",
            "| Epoch [ 42/ 50] Iter[ 16/ 32]\t\tLoss: 1.5869 Acc@1: 41.992%\n",
            "| Epoch [ 42/ 50] Iter[ 31/ 32]\t\tLoss: 1.5603 Acc@1: 41.835%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 0.7050 Acc@1: 39.20%\n",
            "| Saving Best model...\t\t\tTop1 = 39.20%\n",
            "\n",
            "=> Training Epoch #43, LR=0.0100\n",
            "| Epoch [ 43/ 50] Iter[  1/ 32]\t\tLoss: 1.5214 Acc@1: 40.625%\n",
            "| Epoch [ 43/ 50] Iter[ 16/ 32]\t\tLoss: 1.2228 Acc@1: 45.508%\n",
            "| Epoch [ 43/ 50] Iter[ 31/ 32]\t\tLoss: 1.5709 Acc@1: 43.145%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 1.9633 Acc@1: 37.90%\n",
            "\n",
            "=> Training Epoch #44, LR=0.0100\n",
            "| Epoch [ 44/ 50] Iter[  1/ 32]\t\tLoss: 1.4779 Acc@1: 50.000%\n",
            "| Epoch [ 44/ 50] Iter[ 16/ 32]\t\tLoss: 1.3820 Acc@1: 41.992%\n",
            "| Epoch [ 44/ 50] Iter[ 31/ 32]\t\tLoss: 1.4203 Acc@1: 40.726%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 1.1179 Acc@1: 37.55%\n",
            "\n",
            "=> Training Epoch #45, LR=0.0100\n",
            "| Epoch [ 45/ 50] Iter[  1/ 32]\t\tLoss: 1.3785 Acc@1: 50.000%\n",
            "| Epoch [ 45/ 50] Iter[ 16/ 32]\t\tLoss: 1.6348 Acc@1: 43.945%\n",
            "| Epoch [ 45/ 50] Iter[ 31/ 32]\t\tLoss: 1.2664 Acc@1: 41.835%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 1.2019 Acc@1: 40.95%\n",
            "| Saving Best model...\t\t\tTop1 = 40.95%\n",
            "\n",
            "=> Training Epoch #46, LR=0.0100\n",
            "| Epoch [ 46/ 50] Iter[  1/ 32]\t\tLoss: 1.3799 Acc@1: 50.000%\n",
            "| Epoch [ 46/ 50] Iter[ 16/ 32]\t\tLoss: 1.5173 Acc@1: 46.289%\n",
            "| Epoch [ 46/ 50] Iter[ 31/ 32]\t\tLoss: 1.4690 Acc@1: 43.649%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 2.3394 Acc@1: 35.65%\n",
            "\n",
            "=> Training Epoch #47, LR=0.0100\n",
            "| Epoch [ 47/ 50] Iter[  1/ 32]\t\tLoss: 1.8995 Acc@1: 34.375%\n",
            "| Epoch [ 47/ 50] Iter[ 16/ 32]\t\tLoss: 1.7216 Acc@1: 44.336%\n",
            "| Epoch [ 47/ 50] Iter[ 31/ 32]\t\tLoss: 1.5568 Acc@1: 42.440%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 2.2262 Acc@1: 36.55%\n",
            "\n",
            "=> Training Epoch #48, LR=0.0100\n",
            "| Epoch [ 48/ 50] Iter[  1/ 32]\t\tLoss: 1.5625 Acc@1: 31.250%\n",
            "| Epoch [ 48/ 50] Iter[ 16/ 32]\t\tLoss: 1.5825 Acc@1: 43.945%\n",
            "| Epoch [ 48/ 50] Iter[ 31/ 32]\t\tLoss: 1.5735 Acc@1: 43.448%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 1.6272 Acc@1: 40.55%\n",
            "\n",
            "=> Training Epoch #49, LR=0.0100\n",
            "| Epoch [ 49/ 50] Iter[  1/ 32]\t\tLoss: 1.2606 Acc@1: 59.375%\n",
            "| Epoch [ 49/ 50] Iter[ 16/ 32]\t\tLoss: 1.4468 Acc@1: 48.633%\n",
            "| Epoch [ 49/ 50] Iter[ 31/ 32]\t\tLoss: 1.6722 Acc@1: 47.681%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 1.4128 Acc@1: 39.10%\n"
          ]
        }
      ],
      "source": [
        "# Training not pretrained model\n",
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train(epoch,alexnet_untrained,train_loader_alexnet)\n",
        "    acc =test(epoch,alexnet_untrained,valid_loader_alexnet)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        alexnet_untrained_save.load_state_dict(alexnet_untrained.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training pretrained model\n",
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# False if we want to fine the whole model and True if only the last layer\n",
        "feature_extract = True \n",
        "\n",
        "if feature_extract:\n",
        "    for param in alexnet_pretrained.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Reshaping the last layer so output=num_classes\n",
        "alexnet_pretrained.classifier[6] = nn.Linear(4096,num_class).to(device)\n",
        "alexnet_pretrained_save.classifier[6] = nn.Linear(4096,num_class).to(device)\n",
        "\n",
        "\n",
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "    train(epoch,alexnet_pretrained,train_loader_alexnet)\n",
        "    acc =test(epoch,alexnet_pretrained,valid_loader_alexnet)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        alexnet_pretrained_save.load_state_dict(alexnet_pretrained.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ],
      "metadata": {
        "id": "8CQF-pwGTafK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c382a3bd-d17c-483b-ac95-c817431ef7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.0100\n",
            "| Epoch [  0/ 50] Iter[  1/ 32]\t\tLoss: 2.3777 Acc@1: 9.375%\n",
            "| Epoch [  0/ 50] Iter[ 16/ 32]\t\tLoss: 2.2982 Acc@1: 32.812%\n",
            "| Epoch [  0/ 50] Iter[ 31/ 32]\t\tLoss: 2.1894 Acc@1: 38.105%\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 1.9588 Acc@1: 53.65%\n",
            "| Saving Best model...\t\t\tTop1 = 53.65%\n",
            "\n",
            "=> Training Epoch #1, LR=0.0100\n",
            "| Epoch [  1/ 50] Iter[  1/ 32]\t\tLoss: 2.4289 Acc@1: 43.750%\n",
            "| Epoch [  1/ 50] Iter[ 16/ 32]\t\tLoss: 1.9938 Acc@1: 49.805%\n",
            "| Epoch [  1/ 50] Iter[ 31/ 32]\t\tLoss: 1.2662 Acc@1: 49.294%\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 0.0544 Acc@1: 52.85%\n",
            "\n",
            "=> Training Epoch #2, LR=0.0100\n",
            "| Epoch [  2/ 50] Iter[  1/ 32]\t\tLoss: 2.5108 Acc@1: 50.000%\n",
            "| Epoch [  2/ 50] Iter[ 16/ 32]\t\tLoss: 1.9043 Acc@1: 53.906%\n",
            "| Epoch [  2/ 50] Iter[ 31/ 32]\t\tLoss: 3.1376 Acc@1: 51.714%\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 3.5198 Acc@1: 54.70%\n",
            "| Saving Best model...\t\t\tTop1 = 54.70%\n",
            "\n",
            "=> Training Epoch #3, LR=0.0100\n",
            "| Epoch [  3/ 50] Iter[  1/ 32]\t\tLoss: 2.0757 Acc@1: 43.750%\n",
            "| Epoch [  3/ 50] Iter[ 16/ 32]\t\tLoss: 1.3012 Acc@1: 55.078%\n",
            "| Epoch [  3/ 50] Iter[ 31/ 32]\t\tLoss: 2.6313 Acc@1: 52.923%\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 3.6948 Acc@1: 52.10%\n",
            "\n",
            "=> Training Epoch #4, LR=0.0100\n",
            "| Epoch [  4/ 50] Iter[  1/ 32]\t\tLoss: 1.9783 Acc@1: 59.375%\n",
            "| Epoch [  4/ 50] Iter[ 16/ 32]\t\tLoss: 2.5498 Acc@1: 55.469%\n",
            "| Epoch [  4/ 50] Iter[ 31/ 32]\t\tLoss: 2.2988 Acc@1: 55.847%\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 0.7689 Acc@1: 60.85%\n",
            "| Saving Best model...\t\t\tTop1 = 60.85%\n",
            "\n",
            "=> Training Epoch #5, LR=0.0100\n",
            "| Epoch [  5/ 50] Iter[  1/ 32]\t\tLoss: 1.8228 Acc@1: 53.125%\n",
            "| Epoch [  5/ 50] Iter[ 16/ 32]\t\tLoss: 1.5525 Acc@1: 57.227%\n",
            "| Epoch [  5/ 50] Iter[ 31/ 32]\t\tLoss: 2.1740 Acc@1: 57.157%\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 0.9936 Acc@1: 63.20%\n",
            "| Saving Best model...\t\t\tTop1 = 63.20%\n",
            "\n",
            "=> Training Epoch #6, LR=0.0100\n",
            "| Epoch [  6/ 50] Iter[  1/ 32]\t\tLoss: 1.5065 Acc@1: 62.500%\n",
            "| Epoch [  6/ 50] Iter[ 16/ 32]\t\tLoss: 2.0967 Acc@1: 58.008%\n",
            "| Epoch [  6/ 50] Iter[ 31/ 32]\t\tLoss: 1.6484 Acc@1: 57.056%\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 1.6270 Acc@1: 62.95%\n",
            "\n",
            "=> Training Epoch #7, LR=0.0100\n",
            "| Epoch [  7/ 50] Iter[  1/ 32]\t\tLoss: 1.9425 Acc@1: 46.875%\n",
            "| Epoch [  7/ 50] Iter[ 16/ 32]\t\tLoss: 1.0093 Acc@1: 56.250%\n",
            "| Epoch [  7/ 50] Iter[ 31/ 32]\t\tLoss: 1.4858 Acc@1: 57.157%\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 2.1094 Acc@1: 55.45%\n",
            "\n",
            "=> Training Epoch #8, LR=0.0100\n",
            "| Epoch [  8/ 50] Iter[  1/ 32]\t\tLoss: 1.7952 Acc@1: 50.000%\n",
            "| Epoch [  8/ 50] Iter[ 16/ 32]\t\tLoss: 1.7010 Acc@1: 64.062%\n",
            "| Epoch [  8/ 50] Iter[ 31/ 32]\t\tLoss: 2.6044 Acc@1: 60.988%\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 1.1475 Acc@1: 59.75%\n",
            "\n",
            "=> Training Epoch #9, LR=0.0100\n",
            "| Epoch [  9/ 50] Iter[  1/ 32]\t\tLoss: 0.9437 Acc@1: 65.625%\n",
            "| Epoch [  9/ 50] Iter[ 16/ 32]\t\tLoss: 1.6014 Acc@1: 60.742%\n",
            "| Epoch [  9/ 50] Iter[ 31/ 32]\t\tLoss: 2.4978 Acc@1: 60.181%\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 0.0844 Acc@1: 65.10%\n",
            "| Saving Best model...\t\t\tTop1 = 65.10%\n",
            "\n",
            "=> Training Epoch #10, LR=0.0100\n",
            "| Epoch [ 10/ 50] Iter[  1/ 32]\t\tLoss: 1.7106 Acc@1: 56.250%\n",
            "| Epoch [ 10/ 50] Iter[ 16/ 32]\t\tLoss: 1.2749 Acc@1: 64.453%\n",
            "| Epoch [ 10/ 50] Iter[ 31/ 32]\t\tLoss: 2.1903 Acc@1: 62.500%\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 2.0809 Acc@1: 57.95%\n",
            "\n",
            "=> Training Epoch #11, LR=0.0100\n",
            "| Epoch [ 11/ 50] Iter[  1/ 32]\t\tLoss: 2.5150 Acc@1: 56.250%\n",
            "| Epoch [ 11/ 50] Iter[ 16/ 32]\t\tLoss: 1.6728 Acc@1: 63.867%\n",
            "| Epoch [ 11/ 50] Iter[ 31/ 32]\t\tLoss: 1.6797 Acc@1: 59.476%\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 0.1015 Acc@1: 56.50%\n",
            "\n",
            "=> Training Epoch #12, LR=0.0100\n",
            "| Epoch [ 12/ 50] Iter[  1/ 32]\t\tLoss: 2.0309 Acc@1: 56.250%\n",
            "| Epoch [ 12/ 50] Iter[ 16/ 32]\t\tLoss: 1.2459 Acc@1: 61.914%\n",
            "| Epoch [ 12/ 50] Iter[ 31/ 32]\t\tLoss: 1.6919 Acc@1: 61.089%\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 0.0001 Acc@1: 53.45%\n",
            "\n",
            "=> Training Epoch #13, LR=0.0100\n",
            "| Epoch [ 13/ 50] Iter[  1/ 32]\t\tLoss: 2.5365 Acc@1: 50.000%\n",
            "| Epoch [ 13/ 50] Iter[ 16/ 32]\t\tLoss: 1.6058 Acc@1: 61.328%\n",
            "| Epoch [ 13/ 50] Iter[ 31/ 32]\t\tLoss: 2.0154 Acc@1: 61.492%\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 0.4260 Acc@1: 56.15%\n",
            "\n",
            "=> Training Epoch #14, LR=0.0100\n",
            "| Epoch [ 14/ 50] Iter[  1/ 32]\t\tLoss: 1.0980 Acc@1: 75.000%\n",
            "| Epoch [ 14/ 50] Iter[ 16/ 32]\t\tLoss: 2.6626 Acc@1: 65.234%\n",
            "| Epoch [ 14/ 50] Iter[ 31/ 32]\t\tLoss: 1.4507 Acc@1: 60.988%\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 0.1120 Acc@1: 63.85%\n",
            "\n",
            "=> Training Epoch #15, LR=0.0100\n",
            "| Epoch [ 15/ 50] Iter[  1/ 32]\t\tLoss: 1.4845 Acc@1: 65.625%\n",
            "| Epoch [ 15/ 50] Iter[ 16/ 32]\t\tLoss: 1.7263 Acc@1: 67.578%\n",
            "| Epoch [ 15/ 50] Iter[ 31/ 32]\t\tLoss: 2.2144 Acc@1: 65.222%\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 0.5366 Acc@1: 64.80%\n",
            "\n",
            "=> Training Epoch #16, LR=0.0100\n",
            "| Epoch [ 16/ 50] Iter[  1/ 32]\t\tLoss: 1.4581 Acc@1: 75.000%\n",
            "| Epoch [ 16/ 50] Iter[ 16/ 32]\t\tLoss: 2.0791 Acc@1: 66.992%\n",
            "| Epoch [ 16/ 50] Iter[ 31/ 32]\t\tLoss: 1.4815 Acc@1: 64.617%\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 0.8867 Acc@1: 63.55%\n",
            "\n",
            "=> Training Epoch #17, LR=0.0100\n",
            "| Epoch [ 17/ 50] Iter[  1/ 32]\t\tLoss: 1.2882 Acc@1: 65.625%\n",
            "| Epoch [ 17/ 50] Iter[ 16/ 32]\t\tLoss: 0.7931 Acc@1: 66.602%\n",
            "| Epoch [ 17/ 50] Iter[ 31/ 32]\t\tLoss: 1.8806 Acc@1: 66.331%\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 0.3251 Acc@1: 65.15%\n",
            "| Saving Best model...\t\t\tTop1 = 65.15%\n",
            "\n",
            "=> Training Epoch #18, LR=0.0100\n",
            "| Epoch [ 18/ 50] Iter[  1/ 32]\t\tLoss: 2.3356 Acc@1: 50.000%\n",
            "| Epoch [ 18/ 50] Iter[ 16/ 32]\t\tLoss: 1.2996 Acc@1: 66.211%\n",
            "| Epoch [ 18/ 50] Iter[ 31/ 32]\t\tLoss: 1.4030 Acc@1: 65.222%\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 0.0328 Acc@1: 62.20%\n",
            "\n",
            "=> Training Epoch #19, LR=0.0100\n",
            "| Epoch [ 19/ 50] Iter[  1/ 32]\t\tLoss: 1.4573 Acc@1: 62.500%\n",
            "| Epoch [ 19/ 50] Iter[ 16/ 32]\t\tLoss: 1.0051 Acc@1: 65.430%\n",
            "| Epoch [ 19/ 50] Iter[ 31/ 32]\t\tLoss: 1.1702 Acc@1: 62.702%\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 0.5870 Acc@1: 64.00%\n",
            "\n",
            "=> Training Epoch #20, LR=0.0100\n",
            "| Epoch [ 20/ 50] Iter[  1/ 32]\t\tLoss: 1.1916 Acc@1: 68.750%\n",
            "| Epoch [ 20/ 50] Iter[ 16/ 32]\t\tLoss: 1.1587 Acc@1: 62.500%\n",
            "| Epoch [ 20/ 50] Iter[ 31/ 32]\t\tLoss: 1.9086 Acc@1: 62.298%\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 0.8801 Acc@1: 67.50%\n",
            "| Saving Best model...\t\t\tTop1 = 67.50%\n",
            "\n",
            "=> Training Epoch #21, LR=0.0100\n",
            "| Epoch [ 21/ 50] Iter[  1/ 32]\t\tLoss: 2.0843 Acc@1: 53.125%\n",
            "| Epoch [ 21/ 50] Iter[ 16/ 32]\t\tLoss: 0.9000 Acc@1: 68.750%\n",
            "| Epoch [ 21/ 50] Iter[ 31/ 32]\t\tLoss: 2.1159 Acc@1: 67.036%\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 3.4246 Acc@1: 62.15%\n",
            "\n",
            "=> Training Epoch #22, LR=0.0100\n",
            "| Epoch [ 22/ 50] Iter[  1/ 32]\t\tLoss: 0.7684 Acc@1: 78.125%\n",
            "| Epoch [ 22/ 50] Iter[ 16/ 32]\t\tLoss: 1.6249 Acc@1: 65.234%\n",
            "| Epoch [ 22/ 50] Iter[ 31/ 32]\t\tLoss: 1.4090 Acc@1: 63.004%\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 1.7305 Acc@1: 59.45%\n",
            "\n",
            "=> Training Epoch #23, LR=0.0100\n",
            "| Epoch [ 23/ 50] Iter[  1/ 32]\t\tLoss: 1.7217 Acc@1: 71.875%\n",
            "| Epoch [ 23/ 50] Iter[ 16/ 32]\t\tLoss: 2.6151 Acc@1: 67.188%\n",
            "| Epoch [ 23/ 50] Iter[ 31/ 32]\t\tLoss: 1.3975 Acc@1: 64.718%\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 0.4429 Acc@1: 62.40%\n",
            "\n",
            "=> Training Epoch #24, LR=0.0100\n",
            "| Epoch [ 24/ 50] Iter[  1/ 32]\t\tLoss: 1.1212 Acc@1: 62.500%\n",
            "| Epoch [ 24/ 50] Iter[ 16/ 32]\t\tLoss: 1.8381 Acc@1: 65.234%\n",
            "| Epoch [ 24/ 50] Iter[ 31/ 32]\t\tLoss: 1.2274 Acc@1: 64.617%\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 2.3611 Acc@1: 64.00%\n",
            "\n",
            "=> Training Epoch #25, LR=0.0100\n",
            "| Epoch [ 25/ 50] Iter[  1/ 32]\t\tLoss: 1.7988 Acc@1: 68.750%\n",
            "| Epoch [ 25/ 50] Iter[ 16/ 32]\t\tLoss: 1.7941 Acc@1: 67.773%\n",
            "| Epoch [ 25/ 50] Iter[ 31/ 32]\t\tLoss: 1.5731 Acc@1: 65.927%\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 0.1409 Acc@1: 58.30%\n",
            "\n",
            "=> Training Epoch #26, LR=0.0100\n",
            "| Epoch [ 26/ 50] Iter[  1/ 32]\t\tLoss: 1.2045 Acc@1: 71.875%\n",
            "| Epoch [ 26/ 50] Iter[ 16/ 32]\t\tLoss: 0.9629 Acc@1: 66.602%\n",
            "| Epoch [ 26/ 50] Iter[ 31/ 32]\t\tLoss: 2.1957 Acc@1: 67.036%\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 1.8559 Acc@1: 62.45%\n",
            "\n",
            "=> Training Epoch #27, LR=0.0100\n",
            "| Epoch [ 27/ 50] Iter[  1/ 32]\t\tLoss: 1.5962 Acc@1: 65.625%\n",
            "| Epoch [ 27/ 50] Iter[ 16/ 32]\t\tLoss: 1.3452 Acc@1: 67.969%\n",
            "| Epoch [ 27/ 50] Iter[ 31/ 32]\t\tLoss: 0.8188 Acc@1: 67.137%\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 1.4066 Acc@1: 66.20%\n",
            "\n",
            "=> Training Epoch #28, LR=0.0100\n",
            "| Epoch [ 28/ 50] Iter[  1/ 32]\t\tLoss: 1.5129 Acc@1: 59.375%\n",
            "| Epoch [ 28/ 50] Iter[ 16/ 32]\t\tLoss: 0.8825 Acc@1: 71.484%\n",
            "| Epoch [ 28/ 50] Iter[ 31/ 32]\t\tLoss: 0.9460 Acc@1: 68.952%\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 0.2543 Acc@1: 62.10%\n",
            "\n",
            "=> Training Epoch #29, LR=0.0100\n",
            "| Epoch [ 29/ 50] Iter[  1/ 32]\t\tLoss: 1.6665 Acc@1: 59.375%\n",
            "| Epoch [ 29/ 50] Iter[ 16/ 32]\t\tLoss: 1.2332 Acc@1: 70.117%\n",
            "| Epoch [ 29/ 50] Iter[ 31/ 32]\t\tLoss: 1.4612 Acc@1: 68.548%\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 1.1736 Acc@1: 65.50%\n",
            "\n",
            "=> Training Epoch #30, LR=0.0100\n",
            "| Epoch [ 30/ 50] Iter[  1/ 32]\t\tLoss: 1.0236 Acc@1: 75.000%\n",
            "| Epoch [ 30/ 50] Iter[ 16/ 32]\t\tLoss: 0.7578 Acc@1: 70.508%\n",
            "| Epoch [ 30/ 50] Iter[ 31/ 32]\t\tLoss: 1.2161 Acc@1: 67.339%\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 1.5503 Acc@1: 63.35%\n",
            "\n",
            "=> Training Epoch #31, LR=0.0100\n",
            "| Epoch [ 31/ 50] Iter[  1/ 32]\t\tLoss: 1.9225 Acc@1: 59.375%\n",
            "| Epoch [ 31/ 50] Iter[ 16/ 32]\t\tLoss: 0.6003 Acc@1: 64.062%\n",
            "| Epoch [ 31/ 50] Iter[ 31/ 32]\t\tLoss: 2.4886 Acc@1: 63.004%\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 0.7456 Acc@1: 61.45%\n",
            "\n",
            "=> Training Epoch #32, LR=0.0100\n",
            "| Epoch [ 32/ 50] Iter[  1/ 32]\t\tLoss: 2.3763 Acc@1: 40.625%\n",
            "| Epoch [ 32/ 50] Iter[ 16/ 32]\t\tLoss: 2.1760 Acc@1: 62.109%\n",
            "| Epoch [ 32/ 50] Iter[ 31/ 32]\t\tLoss: 1.1997 Acc@1: 65.222%\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 2.2216 Acc@1: 64.90%\n",
            "\n",
            "=> Training Epoch #33, LR=0.0100\n",
            "| Epoch [ 33/ 50] Iter[  1/ 32]\t\tLoss: 0.9504 Acc@1: 71.875%\n",
            "| Epoch [ 33/ 50] Iter[ 16/ 32]\t\tLoss: 1.1103 Acc@1: 71.094%\n",
            "| Epoch [ 33/ 50] Iter[ 31/ 32]\t\tLoss: 1.3844 Acc@1: 68.347%\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 1.1989 Acc@1: 63.10%\n",
            "\n",
            "=> Training Epoch #34, LR=0.0100\n",
            "| Epoch [ 34/ 50] Iter[  1/ 32]\t\tLoss: 1.7993 Acc@1: 62.500%\n",
            "| Epoch [ 34/ 50] Iter[ 16/ 32]\t\tLoss: 0.8740 Acc@1: 67.969%\n",
            "| Epoch [ 34/ 50] Iter[ 31/ 32]\t\tLoss: 1.6496 Acc@1: 65.423%\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 0.5797 Acc@1: 61.50%\n",
            "\n",
            "=> Training Epoch #35, LR=0.0100\n",
            "| Epoch [ 35/ 50] Iter[  1/ 32]\t\tLoss: 1.2909 Acc@1: 62.500%\n",
            "| Epoch [ 35/ 50] Iter[ 16/ 32]\t\tLoss: 1.6273 Acc@1: 65.234%\n",
            "| Epoch [ 35/ 50] Iter[ 31/ 32]\t\tLoss: 1.5129 Acc@1: 67.238%\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 0.7569 Acc@1: 62.40%\n",
            "\n",
            "=> Training Epoch #36, LR=0.0100\n",
            "| Epoch [ 36/ 50] Iter[  1/ 32]\t\tLoss: 1.2181 Acc@1: 78.125%\n",
            "| Epoch [ 36/ 50] Iter[ 16/ 32]\t\tLoss: 0.9117 Acc@1: 69.336%\n",
            "| Epoch [ 36/ 50] Iter[ 31/ 32]\t\tLoss: 1.6896 Acc@1: 67.036%\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 0.9799 Acc@1: 59.55%\n",
            "\n",
            "=> Training Epoch #37, LR=0.0100\n",
            "| Epoch [ 37/ 50] Iter[  1/ 32]\t\tLoss: 0.3107 Acc@1: 84.375%\n",
            "| Epoch [ 37/ 50] Iter[ 16/ 32]\t\tLoss: 1.4594 Acc@1: 67.383%\n",
            "| Epoch [ 37/ 50] Iter[ 31/ 32]\t\tLoss: 0.9944 Acc@1: 65.827%\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 1.0920 Acc@1: 62.15%\n",
            "\n",
            "=> Training Epoch #38, LR=0.0100\n",
            "| Epoch [ 38/ 50] Iter[  1/ 32]\t\tLoss: 1.7045 Acc@1: 56.250%\n",
            "| Epoch [ 38/ 50] Iter[ 16/ 32]\t\tLoss: 0.7337 Acc@1: 68.164%\n",
            "| Epoch [ 38/ 50] Iter[ 31/ 32]\t\tLoss: 2.2975 Acc@1: 68.145%\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 2.0656 Acc@1: 62.65%\n",
            "\n",
            "=> Training Epoch #39, LR=0.0100\n",
            "| Epoch [ 39/ 50] Iter[  1/ 32]\t\tLoss: 1.1769 Acc@1: 59.375%\n",
            "| Epoch [ 39/ 50] Iter[ 16/ 32]\t\tLoss: 1.1017 Acc@1: 67.383%\n",
            "| Epoch [ 39/ 50] Iter[ 31/ 32]\t\tLoss: 2.5116 Acc@1: 66.230%\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 1.3895 Acc@1: 59.60%\n",
            "\n",
            "=> Training Epoch #40, LR=0.0100\n",
            "| Epoch [ 40/ 50] Iter[  1/ 32]\t\tLoss: 1.4422 Acc@1: 78.125%\n",
            "| Epoch [ 40/ 50] Iter[ 16/ 32]\t\tLoss: 1.0225 Acc@1: 70.117%\n",
            "| Epoch [ 40/ 50] Iter[ 31/ 32]\t\tLoss: 1.4506 Acc@1: 67.238%\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 0.7847 Acc@1: 66.55%\n",
            "\n",
            "=> Training Epoch #41, LR=0.0100\n",
            "| Epoch [ 41/ 50] Iter[  1/ 32]\t\tLoss: 0.8687 Acc@1: 81.250%\n",
            "| Epoch [ 41/ 50] Iter[ 16/ 32]\t\tLoss: 3.3666 Acc@1: 69.336%\n",
            "| Epoch [ 41/ 50] Iter[ 31/ 32]\t\tLoss: 1.0409 Acc@1: 69.456%\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 1.2262 Acc@1: 61.65%\n",
            "\n",
            "=> Training Epoch #42, LR=0.0100\n",
            "| Epoch [ 42/ 50] Iter[  1/ 32]\t\tLoss: 2.2368 Acc@1: 59.375%\n",
            "| Epoch [ 42/ 50] Iter[ 16/ 32]\t\tLoss: 2.2691 Acc@1: 66.992%\n",
            "| Epoch [ 42/ 50] Iter[ 31/ 32]\t\tLoss: 1.3163 Acc@1: 67.641%\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 4.3479 Acc@1: 55.75%\n",
            "\n",
            "=> Training Epoch #43, LR=0.0100\n",
            "| Epoch [ 43/ 50] Iter[  1/ 32]\t\tLoss: 1.9392 Acc@1: 59.375%\n",
            "| Epoch [ 43/ 50] Iter[ 16/ 32]\t\tLoss: 0.9187 Acc@1: 67.969%\n",
            "| Epoch [ 43/ 50] Iter[ 31/ 32]\t\tLoss: 1.6026 Acc@1: 67.238%\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 0.9409 Acc@1: 61.25%\n",
            "\n",
            "=> Training Epoch #44, LR=0.0100\n",
            "| Epoch [ 44/ 50] Iter[  1/ 32]\t\tLoss: 2.2556 Acc@1: 53.125%\n",
            "| Epoch [ 44/ 50] Iter[ 16/ 32]\t\tLoss: 1.4808 Acc@1: 67.383%\n",
            "| Epoch [ 44/ 50] Iter[ 31/ 32]\t\tLoss: 1.0492 Acc@1: 70.766%\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 0.6899 Acc@1: 63.10%\n",
            "\n",
            "=> Training Epoch #45, LR=0.0100\n",
            "| Epoch [ 45/ 50] Iter[  1/ 32]\t\tLoss: 1.6102 Acc@1: 68.750%\n",
            "| Epoch [ 45/ 50] Iter[ 16/ 32]\t\tLoss: 1.0403 Acc@1: 72.656%\n",
            "| Epoch [ 45/ 50] Iter[ 31/ 32]\t\tLoss: 0.8783 Acc@1: 71.976%\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 0.5798 Acc@1: 63.30%\n",
            "\n",
            "=> Training Epoch #46, LR=0.0100\n",
            "| Epoch [ 46/ 50] Iter[  1/ 32]\t\tLoss: 1.0626 Acc@1: 68.750%\n",
            "| Epoch [ 46/ 50] Iter[ 16/ 32]\t\tLoss: 1.6282 Acc@1: 66.797%\n",
            "| Epoch [ 46/ 50] Iter[ 31/ 32]\t\tLoss: 1.6180 Acc@1: 66.129%\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 0.3792 Acc@1: 65.15%\n",
            "\n",
            "=> Training Epoch #47, LR=0.0100\n",
            "| Epoch [ 47/ 50] Iter[  1/ 32]\t\tLoss: 1.2209 Acc@1: 75.000%\n",
            "| Epoch [ 47/ 50] Iter[ 16/ 32]\t\tLoss: 0.9386 Acc@1: 71.680%\n",
            "| Epoch [ 47/ 50] Iter[ 31/ 32]\t\tLoss: 1.2731 Acc@1: 69.960%\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 1.9006 Acc@1: 66.95%\n",
            "\n",
            "=> Training Epoch #48, LR=0.0100\n",
            "| Epoch [ 48/ 50] Iter[  1/ 32]\t\tLoss: 1.4463 Acc@1: 71.875%\n",
            "| Epoch [ 48/ 50] Iter[ 16/ 32]\t\tLoss: 1.3882 Acc@1: 66.797%\n",
            "| Epoch [ 48/ 50] Iter[ 31/ 32]\t\tLoss: 1.5257 Acc@1: 66.230%\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 0.9301 Acc@1: 65.75%\n",
            "\n",
            "=> Training Epoch #49, LR=0.0100\n",
            "| Epoch [ 49/ 50] Iter[  1/ 32]\t\tLoss: 0.9861 Acc@1: 81.250%\n",
            "| Epoch [ 49/ 50] Iter[ 16/ 32]\t\tLoss: 0.6221 Acc@1: 68.359%\n",
            "| Epoch [ 49/ 50] Iter[ 31/ 32]\t\tLoss: 1.3206 Acc@1: 65.524%\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 1.6803 Acc@1: 61.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EnS0ihhkqp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0037277a-2a31-4db6-c74b-9a530571fb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained network\n",
            "\n",
            "| TEST \t\t\tLoss: 3.3919 Acc@1: 62.07%\n",
            "Not pretrained network\n",
            "\n",
            "| TEST \t\t\tLoss: 1.4141 Acc@1: 38.62%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "\n",
        "# Pretrained\n",
        "print(\"Pretrained network\")\n",
        "predicted_concat = test_final(alexnet_pretrained,test_loader_alexnet)\n",
        "\n",
        "# Not pretrained\n",
        "print(\"Not pretrained network\")\n",
        "predicted_concat = test_final(alexnet_untrained,test_loader_alexnet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBQ8y3ZaZcMJ"
      },
      "source": [
        "## Q3 : SVM et RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set the database in 2D\n",
        "\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "for data in train_loader.dataset :\n",
        "    X_train.append(data[0])\n",
        "    Y_train.append(data[1])\n",
        "\n",
        "for data in test_loader.dataset :\n",
        "    X_test.append(data[0])\n",
        "    Y_test.append(data[1])\n",
        "\n",
        "X_train = torch.cat(X_train)\n",
        "X_train = X_train.reshape(len(train_loader.dataset),-1)\n",
        "\n",
        "X_test = torch.cat(X_test)\n",
        "X_test = X_test.reshape(len(test_loader.dataset),-1)"
      ],
      "metadata": {
        "id": "vYXvlqUVeSdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMctJFVKZjv6"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipk_HGv7ZZRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d05b00-2d44-4870-d11b-fe4e0c770cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "| TEST on SVM \t\t\tAccuracy: 34.04%\n",
            "Parameters are\n",
            "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 111, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
          ]
        }
      ],
      "source": [
        "# SVM (Default OneVersusRest)\n",
        "from sklearn import svm\n",
        "\n",
        "parameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              'C': np.logspace(-2,1,5),\n",
        "              'degree': [k for k in range(3,6)],\n",
        "              'decision_function_shape': ['ovo', 'ovr'],\n",
        "              }\n",
        "\n",
        "svc = svm.SVC(kernel = 'rbf', C = 100, decision_function_shape = 'ovr', random_state=seed)\n",
        "#svc = GridSearchCV(svc, parameters)\n",
        "\n",
        "svc.fit(X_train, Y_train)\n",
        "\n",
        "acc = svc.score(X_test, Y_test)\n",
        "\n",
        "print(\"\\n| TEST on SVM \\t\\t\\tAccuracy: %.2f%%\" %(acc*100))\n",
        "print(\"Parameters are\")\n",
        "print(svc.get_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnfK1RH1Zlre"
      },
      "source": [
        "### RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvcPq-KXZpxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73cb4f48-faa5-42e6-f4dc-3d9a093a9abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "| TEST on a single tree \t\t\tAccuracy: 20.46%\n"
          ]
        }
      ],
      "source": [
        "# Single tree\n",
        "clf = tree.DecisionTreeClassifier(criterion = 'gini',max_depth=6, random_state = seed) # Arbre de décision\n",
        "clf = clf.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# # To see the tree\n",
        "# print(\"L'arbre de décision est\")\n",
        "# plt.figure(figsize=(25,20))\n",
        "# tree.plot_tree(clf,\n",
        "#                filled=True, rounded=True,\n",
        "#                class_names = classes)\n",
        "# print(\" \")\n",
        "\n",
        "\n",
        "# # To cleary see the tree with all nodes :\n",
        "# import graphviz\n",
        "\n",
        "# dot_data = tree.export_graphviz(clf, out_file=None) \n",
        "# graph = graphviz.Source(dot_data) \n",
        "\n",
        "# print(\"L'arbre de décision est\")\n",
        "# dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "#                     #  feature_names=X_train.columns.values,  \n",
        "#                      class_names=classes,  \n",
        "#                      filled=True, rounded=True,  \n",
        "#                      special_characters=True)  \n",
        "# graph = graphviz.Source(dot_data)  \n",
        "# display(graph)\n",
        "\n",
        "# Evaluation\n",
        "acc = clf.score(X_test,Y_test)\n",
        "print(\"\\n| TEST on a single tree \\t\\t\\tAccuracy: %.2f%%\" %(acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On a randomforest\n",
        "clf = ensemble.RandomForestClassifier(criterion = 'gini',n_estimators=1000, random_state = seed)\n",
        "clf = clf.fit(X_train, Y_train)\n",
        "\n",
        "# Evaluation\n",
        "acc = clf.score(X_test,Y_test)\n",
        "print(\"\\n| TEST on a random forest \\t\\t\\tAccuracy: %.2f%%\" %(acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Os1JExbf-PT",
        "outputId": "b4d17944-dc4b-49e5-e8d3-2d835bcdffe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "| TEST on a random forest \t\t\tAccuracy: 33.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4 : Comparaisons des différents modèles\n",
        "\n",
        "On donne plusieurs tableaux comparatifs des modèles en fonctions de certains paramètres.\n",
        "\n",
        "* On remarque que pour le SVM et le RandomForest, au mieux les résultats sont très semblables (autour de 34% de performance) pour une exécution en un temps quasi-similaire également.\n",
        "\n",
        "![SVM.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RCWRXhpZgAATU0AKgAAAAgABAE7AAIAAAAMAAAISodpAAQAAAABAAAIVpydAAEAAAAYAAAQduocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFudG9pbmUgWGllAAAB6hwABwAACAwAAAhoAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBAG4AdABvAGkAbgBlACAAWABpAGUAAAD/4QpkaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLwA8P3hwYWNrZXQgYmVnaW49J++7vycgaWQ9J1c1TTBNcENlaGlIenJlU3pOVGN6a2M5ZCc/Pg0KPHg6eG1wbWV0YSB4bWxuczp4PSJhZG9iZTpuczptZXRhLyI+PHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyIvPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIj48ZGM6Y3JlYXRvcj48cmRmOlNlcSB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6bGk+QW50b2luZSBYaWU8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgBlQJ0AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8AxNd13XR4r11I/EWuRRx6texpHFqtwioq3EiqoUOAAAAMCqX9u69/0M3iD/wc3X/xyjXf+Ru8Qf8AYav/AP0qkqjX0VGjTdKLcVsuh5dSpNTepe/t3Xv+hm8Qf+Dm6/8AjlH9u69/0M3iD/wc3X/xyqNFa+wpfyr7iPaT7svf27r3/QzeIP8Awc3X/wAco/t3Xv8AoZvEH/g5uv8A45VGij2FL+VfcHtJ92Xv7d17/oZvEH/g5uv/AI5R/buvf9DN4g/8HN1/8cqjRR7Cl/KvuD2k+7L39u69/wBDN4g/8HN1/wDHKP7d17/oZvEH/g5uv/jlUaKPYUv5V9we0n3Ze/t3Xv8AoZvEH/g5uv8A45R/buvf9DN4g/8ABzdf/HKo0Uewpfyr7g9pPuy9/buvf9DN4g/8HN1/8co/t3Xv+hm8Qf8Ag5uv/jlUaKPYUv5V9we0n3Ze/t3Xv+hm8Qf+Dm6/+OUh1zXj18S6+frrNz/8cqlRR7Cl/KvuD2k+7L39u69/0M3iD/wc3X/xyj+3de/6GbxB/wCDm6/+OVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/45R/buvf9DN4g/wDBzdf/AByqNFHsKX8q+4PaT7svf27r3/QzeIP/AAc3X/xyj+3de/6GbxB/4Obr/wCOVRoo9hS/lX3B7Sfdl7+3de/6GbxB/wCDm6/+OUf27r3/AEM3iD/wc3X/AMcqjRR7Cl/KvuD2k+7L39u69/0M3iD/AMHN1/8AHKP7d17/AKGbxB/4Obr/AOOVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/wCOUf27r3/QzeIP/Bzdf/HKo0Uewpfyr7g9pPuy9/buvf8AQzeIP/Bzdf8Axyj+3de/6GbxB/4Obr/45VGij2FL+VfcHtJ92Xv7d17/AKGbxB/4Obr/AOOUn9ua9nP/AAkuv59f7Zuf/jlUqKPYUv5V9we0n3Ze/t3Xv+hm8Qf+Dm6/+OUf27r3/QzeIP8Awc3X/wAcqjRR7Cl/KvuD2k+7L39u69/0M3iD/wAHN1/8co/t3Xv+hm8Qf+Dm6/8AjlUaKPYUv5V9we0n3Ze/t3Xv+hm8Qf8Ag5uv/jlH9u69/wBDN4g/8HN1/wDHK4TUr65u/EM1i+p/2ZBEBtbONxwD1yPX1q/pUOsWeoiOW4+32DrkTlxkHH1z7d65oOlOVlT02vZGr50ruX5nWf27r3/QzeIP/Bzdf/HKP7d17/oZvEH/AIObr/45XG6Pc3Ft4mvdOu55ZVPzReY5bA6jGfY/pTtVup7nxPZadazyRIvzzeW5XI64OPYfrQnRcFLkWrtayD95zNc3mdh/buvf9DN4g/8ABzdf/HKP7d17/oZvEH/g5uv/AI5Xm2r6hqEPiK68i6nEcDB/LEjBcDHGPxrd8Q6i/wDY9v8AYZWSW7ZdjK2CB1PI/CpVSg4ylyLTyRTjUTS5tzrP7d17/oZvEH/g5uv/AI5R/buvf9DN4g/8HN1/8crj/B11cXVlcNczyTFZAAZHLY4966KuinTo1IKSgtfJGUpTjK3MXv7d17/oZvEH/g5uv/jlH9u69/0M3iD/AMHN1/8AHKo0VfsKX8q+4n2k+7L39u69/wBDN4g/8HN1/wDHKQa5rwAA8S6+AOgGs3P/AMcqlRR7Cl/KvuD2k+7L39u69/0M3iD/AMHN1/8AHKP7d17/AKGbxB/4Obr/AOOVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/wCOUf27r3/QzeIP/Bzdf/HKo0Uewpfyr7g9pPuy9/buvf8AQzeIP/Bzdf8Axyj+3de/6GbxB/4Obr/45VGij2FL+VfcHtJ92Xv7d17/AKGbxB/4Obr/AOOUf27r3/QzeIP/AAc3X/xyqNFHsKX8q+4PaT7svf27r3/QzeIP/Bzdf/HKP7d17/oZvEH/AIObr/45VGij2FL+VfcHtJ92Xv7d17/oZvEH/g5uv/jlH9u69/0M3iD/AMHN1/8AHKo0Uewpfyr7g9pPuy9/buvf9DN4g/8ABzdf/HKP7d17/oZvEH/g5uv/AI5VGij2FL+VfcHtJ92XTrmvHGfEuvnHT/ic3PH/AJEpf7d17/oZvEH/AIObr/45VGij2FL+VfcHtJ92Xv7d17/oZvEH/g5uv/jlH9u69/0M3iD/AMHN1/8AHKo0Uewpfyr7g9pPuy9/buvf9DN4g/8ABzdf/HKP7d17/oZvEH/g5uv/AI5VGij2FL+VfcHtJ92Xv7d17/oZvEH/AIObr/45R/buvf8AQzeIP/Bzdf8AxyqNFHsKX8q+4PaT7svf27r3/QzeIP8Awc3X/wAco/t3Xv8AoZvEH/g5uv8A45VGij2FL+VfcHtJ92Xv7d17/oZvEH/g5uv/AI5R/buvf9DN4g/8HN1/8cqjRR7Cl/KvuD2k+7L39u69/wBDN4g/8HN1/wDHKP7d17/oZvEH/g5uv/jlUaKPYUv5V9we0n3Ze/t3Xv8AoZvEH/g5uv8A45R/buvf9DN4g/8ABzdf/HKo0Uewpfyr7g9pPuz3b4F3V5qfhTWH1PUL6+ki1Zo0kuruSVlX7PA23czE4yxOPeiov2fv+RR1z/sNN/6S29FfO1klVkl3Z6lPWCPHNd/5G7xB/wBhq/8A/SqSqNXtd/5G7xB/2Gr/AP8ASqSqNfRUP4UfRHl1PjfqFFFFbEBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzN3c6VqOsT2es2qW0kXEc7S43jtzx255zVG0WHTfFFtBot41xFLxKoYMMfUcHjmupvdKsdRwby3WQjo3IP5jmkstJsdOJNnbJGx4LclvzPNcP1ebmpO2j36v9Do9pHltr6dDD8TKdP1ix1VAcK2yTH+fQmn+GU+3ajfatIP9Y+yPPYf/AKsVvXllb39uYLuPzIyQcZI5+opbSzgsbcQWkflxqSQuSf51caDVbnvpv82S6icOXr+hyy2wvPGGqQH+OBl/MLVXQnl1C+toJR8thBJjPqcj+o/Kuwj061hv5L2OLFxIMO+4nI47Zx2FJbaZZ2c001tDseY5kO4nd37njrWSwsrp373/ADRftlZr+vMwvA//AB4XX/XUfyrp6rWOm2umxullF5aucsNxOT+JqzXXRg4U1F9DGpJSk2gooorUgKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPcf2fv+RR1z/sNN/6S29FH7P3/ACKOuf8AYab/ANJbeivmK/8AFl6s9en8C9Dk4vDeh3t9q9xe6Np9xM2s6jukltUdji8mAySM9AB+FTf8Ij4b/wChe0r/AMAo/wD4mrlh/rtV/wCw1qX/AKWzVcr1qUY+zjp0Rwzb5mY//CI+G/8AoXtK/wDAKP8A+Jo/4RHw3/0L2lf+AUf/AMTWxRWnJHsTzMx/+ER8N/8AQvaV/wCAUf8A8TR/wiPhv/oXtK/8Ao//AImtiijkj2DmZj/8Ij4b/wChe0r/AMAo/wD4mj/hEfDf/QvaV/4BR/8AxNbFFHJHsHMzH/4RHw3/ANC9pX/gFH/8TR/wiPhv/oXtK/8AAKP/AOJrYoo5I9g5mY//AAiPhv8A6F7Sv/AKP/4mj/hEfDf/AEL2lf8AgFH/APE1sUUckewczMf/AIRHw3/0L2lf+AUf/wATR/wiPhv/AKF7Sv8AwCj/APia2KKOSPYOZmP/AMIj4b/6F7Sv/AKP/wCJo/4RHw3/ANC9pX/gFH/8TWxRRyR7BzMx/wDhEfDf/QvaV/4BR/8AxNH/AAiPhv8A6F7Sv/AKP/4mtiijkj2DmZj/APCI+G/+he0r/wAAo/8A4mj/AIRHw3/0L2lf+AUf/wATWxRRyR7BzMx/+ER8N/8AQvaV/wCAUf8A8TR/wiPhv/oXtK/8Ao//AImtiijkj2DmZj/8Ij4b/wChe0r/AMAo/wD4mj/hEfDf/QvaV/4BR/8AxNbFFHJHsHMzH/4RHw3/ANC9pX/gFH/8TR/wiPhv/oXtK/8AAKP/AOJrYoo5I9g5mY//AAiPhv8A6F7Sv/AKP/4mj/hEfDf/AEL2lf8AgFH/APE1sUUckewczMf/AIRHw3/0L2lf+AUf/wATR/wiPhv/AKF7Sv8AwCj/APia2KKOSPYOZmP/AMIj4b/6F7Sv/AKP/wCJo/4RHw3/ANC9pX/gFH/8TWxRRyR7BzMx/wDhEfDf/QvaV/4BR/8AxNH/AAiPhv8A6F7Sv/AKP/4mtiijkj2DmZj/APCI+G/+he0r/wAAo/8A4mj/AIRHw3/0L2lf+AUf/wATS+K/+RN1n/rxm/8AQDXkGk+Ph4e+GVppGkuravcySjcWAFspc4Yk8ZPb06ntnCdSEJOLXS/rraxrGEpRTT6nr3/CI+G/+he0r/wCj/8AiaP+ER8N/wDQvaV/4BR//E1ieCfBlr4O0yXUNSlSbU5kMl1dschB1Kgnt3J7/lWRJ8YAZJLq08NahcaPE+x9QGQB+G3A6jgsOvaqcqcbKdkyUpS+HY7L/hEfDf8A0L2lf+AUf/xNH/CI+G/+he0r/wAAo/8A4msfxJ8Q7PQtC0vV7W3+32moSBVYSbCi4yTjByR6cVTHxGvV8L6jrlz4ZubS3tWj8hbiUoblXbGRlOMAg8ZHPWhzpJtPpvoCjNpNdTpP+ER8N/8AQvaV/wCAUf8A8TR/wiPhv/oXtK/8Ao//AImuKn+MXl20N7F4ZvpNObCyXhYqgfuqnbhse5GfQV02u+PNK0Tw1aawRJcrfKDawxjDSkjP4Y7+lCnRab7ByzvYv/8ACI+G/wDoXtK/8Ao//iaP+ER8N/8AQvaV/wCAUf8A8TXP6B8SRqOuRaRrmiXeh3dwM263GSJPblVIz24x71maV/ycHrH/AF4r/wCgxUc0G42W9/wC0rO72/zOz/4RHw3/ANC9pX/gFH/8TR/wiPhv/oXtK/8AAKP/AOJrYorXkj2I5mY//CI+G/8AoXtK/wDAKP8A+Jo/4RHw3/0L2lf+AUf/AMTWxRRyR7BzMx/+ER8N/wDQvaV/4BR//E0f8Ij4b/6F7Sv/AACj/wDia2KKOSPYOZmP/wAIj4b/AOhe0r/wCj/+Jo/4RHw3/wBC9pX/AIBR/wDxNbFFHJHsHMzH/wCER8N/9C9pX/gFH/8AE0f8Ij4b/wChe0r/AMAo/wD4mtiijkj2DmZj/wDCI+G/+he0r/wCj/8AiaP+ER8N/wDQvaV/4BR//E1sUUckewczMf8A4RHw3/0L2lf+AUf/AMTR/wAIj4b/AOhe0r/wCj/+JrYoo5I9g5mY/wDwiPhv/oXtK/8AAKP/AOJo/wCER8N/9C9pX/gFH/8AE1sUUckewczMf/hEfDf/AEL2lf8AgFH/APE0f8Ij4b/6F7Sv/AKP/wCJrYoo5I9g5mY//CI+G/8AoXtK/wDAKP8A+Jo/4RHw3/0L2lf+AUf/AMTWxRRyR7BzMx/+ER8N/wDQvaV/4BR//E0f8Ij4b/6F7Sv/AACj/wDia2KKOSPYOZmP/wAIj4b/AOhe0r/wCj/+Jo/4RHw3/wBC9pX/AIBR/wDxNbFFHJHsHMzH/wCER8N/9C9pX/gFH/8AE0f8Ij4b/wChe0r/AMAo/wD4mtiijkj2DmZj/wDCI+G/+he0r/wCj/8AiaP+ER8N/wDQvaV/4BR//E1sUUckewczMf8A4RHw3/0L2lf+AUf/AMTR/wAIj4b/AOhe0r/wCj/+JrYoo5I9g5mY/wDwiPhv/oXtK/8AAKP/AOJo/wCER8N/9C9pX/gFH/8AE1sUUckewczMf/hEfDf/AEL2lf8AgFH/APE0f8Ij4b/6F7Sv/AKP/wCJrYoo5I9g5mb3wi06ytLHxJb2lnbwQx6z8kcUSqq5s7YnAAwOST+NFWfhV/qfE/8A2Gh/6RWtFeHV/iS9WejD4UcZYf67Vf8AsNal/wCls1XKwYvEmh2V9q9ve6zp9vMus6jujlukRhm8mIyCc9CD+NTf8Jd4b/6GHSv/AANj/wDiq9ilKPs469EcE0+ZmxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFVpzx7k8r7GxRWP8A8Jd4b/6GHSv/AANj/wDiqP8AhLvDf/Qw6V/4Gx//ABVHPHuHK+xsUVj/APCXeG/+hh0r/wADY/8A4qj/AIS7w3/0MOlf+Bsf/wAVRzx7hyvsbFFY/wDwl3hv/oYdK/8AA2P/AOKo/wCEu8N/9DDpX/gbH/8AFUc8e4cr7GxRWP8A8Jd4b/6GHSv/AANj/wDiqP8AhLvDf/Qw6V/4Gx//ABVHPHuHK+xsUVj/APCXeG/+hh0r/wADY/8A4qj/AIS7w3/0MOlf+Bsf/wAVRzx7hyvsbFFY/wDwl3hv/oYdK/8AA2P/AOKo/wCEu8N/9DDpX/gbH/8AFUc8e4cr7GxRWP8A8Jd4b/6GHSv/AANj/wDiqP8AhLvDf/Qw6V/4Gx//ABVHPHuHK+xsUVj/APCXeG/+hh0r/wADY/8A4qj/AIS7w3/0MOlf+Bsf/wAVRzx7hyvsbFFY/wDwl3hv/oYdK/8AA2P/AOKo/wCEu8N/9DDpX/gbH/8AFUc8e4cr7GxRWP8A8Jd4b/6GHSv/AANj/wDiqP8AhLvDf/Qw6V/4Gx//ABVHPHuHK+xsUVj/APCXeG/+hh0r/wADY/8A4qj/AIS7w3/0MOlf+Bsf/wAVRzx7hyvsbFFY/wDwl3hv/oYdK/8AA2P/AOKo/wCEu8N/9DDpX/gbH/8AFUc8e4cr7GxRWP8A8Jd4b/6GHSv/AANj/wDiqP8AhLvDf/Qw6V/4Gx//ABVHPHuHK+xsUVj/APCXeG/+hh0r/wADY/8A4qj/AIS7w3/0MOlf+Bsf/wAVRzx7hyvsbFFY/wDwl3hv/oYdK/8AA2P/AOKo/wCEu8N/9DDpX/gbH/8AFUc8e4cr7C+K/wDkTdZ/68Zv/QDXlng/4eaf4h+GNzdqhOq3DP5MrHiMoThR7Hofr7V6fL4p8LXELwz67pEsUilXR7yIqwPUEE8io7PxD4Q0+2FvYavolrApJEUFzCignrwDiuedOE5uUn0t/wAE1jOUYpJdbnE+Etfu/FHw/wBX8M3RI1m0tZIURzh5FwQM+4Pyn8PWuQ0O98OQeEpLTX9f8SWlzGzxy6XazERyAnspXaOvIYjkGvX4tV8Dwag1/Df+H47xiS1wk0AkJPXLZzzTZNS8CTXwvZb3w7JdghhcNLAZAR0O7OamVPms3JXtZ/5jUraJO17nnvjmwtbD4d+F7eyS8W1N0XjS+2+aFbLYbbx36V2vxVAHwzvwBgAxYA/66LWle654M1JUXUdU0K7WNtyCe4hcKfUZPBp934i8I39s1tfaxotzA2N0U11E6nHIyCcVUoJqaT3/AMkhRk04u23+ZyviKNU/Z+hAHH2G1P4lkrlfFVpKvgnwRqrfaBZWsSrPJbNiSPO0gqex4OD64r1KXXfBs2niwm1TQpLMKFFu9xCY8DoNucYGB+VOXxD4QSxFmur6ItqF2CAXMOwL6bc4x7UVIRnJyT7fgEJOKSt3/Gx57pi+FNZ8ZaVHY654o1u8hcTRSTSBo4dpyd3mKCBwM4rW0r/k4PWP+vFf/QYq6ew1jwTpe/8AszUdAs9/3/s88Me764IzTk1zwbHqD36apoS3ki7XuRcQiRhxwWzkjgflTjFRcXdaNv71YTk3fTdW/G50VFY//CXeG/8AoYdK/wDA2P8A+Ko/4S7w3/0MOlf+Bsf/AMVW/PHuZ8r7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7GxRWP/wl3hv/AKGHSv8AwNj/APiqP+Eu8N/9DDpX/gbH/wDFUc8e4cr7Hf8Awq/1Pif/ALDQ/wDSK1oqt8ItRsrux8SXFpeW88Mms/JJFKrK2LO2BwQcHkEfhRXh1f4kvVnow+FFjwl/yCr7/sNap/6Xz1uVh+Ev+QVff9hrVP8A0vnrcraOyIe4UUUUxBRRRQAUUUUAFFFFABRRRQAUUUUAFc/41/5ANt/2F9N/9LoK6Cuf8a/8gG2/7C+m/wDpdBQ9hmpqWr6bo1stxrGoWthAzhBLdTLEpY84yxAzwePakvNa0vTpbaPUNSs7V7tttss86oZjxwgJ+Y8jp6ivL/2kf+Sb2f8A2FI//RclJ8VL63tNe+HqT6XaXzTXgVJLhpQ0B3Q/Mux1BPP8QYcDjrmYu7t5pfeNq1vRv7j16ivLPHfxQ13wt8SbHw7pGjQ6ql3aCSOBQwmeVi4ADZwFG0E/KeM89xW8M/FLxWnxHt/CXj/QLXTbi9QtbtasTt4JGTvcMDtIyCMGiMlJ2X9PsKScdz1yivJdc+KHivUvGGoaD8M/D1tqh0o7by4u3wu7OCF+dAMHI6knBwMDNbPhD4oN4k8IatfzaLcrq+jFo7rTLZTI7yDOAgxnkgjHbB+tCknHm+fyG007HoNFeMax8T/iB4V0bTvEfibw/pMWk3s4jNkhmS8hyCQHLfKDhSen1ArV+JPxS1bwfrugW2iadb6hFqsTP5Uit5rMSAiqQ2BksOoNHMvxsK3+Z6lRXO+CbzxXfaG83jnTrPTr8zEJBaNuAjwMEnewznPQ10VWIKKKKQBRRRQAVz9n/wAlK1n/ALBGn/8Ao68roK5+z/5KVrP/AGCNP/8AR15QM6CivG9a+LHi+H4nav4R8OeH7PVZoQFtB8yMp2KxeRi+0qMkfw9Rz66vgP4m6zqfjC48I+OtGi0nWo4zLF5BPlyAc7QCzduQQxBwelTGSla3UJLl3PT6K8f1H4reLNe8UX+k/C/w3b6pDprlLi7u2wjEccfOgHIOMkkgZxXR/Dn4jv4z/tHTNX046XrumHbdWuSQRnG5c8jB4I5xxyc0udNXXa4NW3Ox03WNM1mF5tH1G0v4o32O9rOsqq3XBKk4PPSrlfOPw48Qa14W+C3iLWvDtva3E9pq2+WO6RmXytiBiNrKcjIPXoDXo/iz4pHR/hLp/irSooJb3UxCttBKCyeY3LqQCCcBWHXqBVcytf0/Epx97l9fwPR6KqaU97Lo9nJqqxLevCjXCwqQiuQNwAJJxn3q3VNWdiE7q4UUUUgCiiigAooooAK5/wAA/wDJNfDP/YItf/RK10FcHa61ceHPgBp+sWKRSXFnoFvLGswJQkQp1AIOPxqZSUVdlJNuyO7ZgilmIVQMkk8AVU0zWNN1q3a40fUbTUIVbY0lrOsqhsA4JUkZwRx715f4J8e+O/HEUV7NoGn2vh5reVbi9DEO8ioc+WpfON2ByD0PPavPfhJ4l8c6d4NvbLwJ4Yh1Py7xri4urlsIMoo2KNyZb5c8EnkcUc1m0+1/xC2iaPp6s218SaHfak2nWWs6fcXyZ3W0V0jyrjrlQc8V5pB8UNQ8W/CDXr7TtGI1iyikt762W4EX2dTG2Z1LckDBO3rlSPes79nezP8AYCXMnhW1iQeaY9e82NpZW3AGLbjeoA98ce9OLvNx8r/1/XluKWkU/O39f157Ht1FFFMQUUUUAFFFFABRRRQAUUUUAc/4j/5D3hL/ALC8n/pDdV0Fc/4j/wCQ94S/7C8n/pDdVzHxD+JN54a8UaX4b0VNNiv7+PzWvNXmaO2hXJAyVwckqe/p1zU3s/UpK56PVKz1jTNQu7m1sNRtLq4tG23EME6u8JyRh1BypyD19K5HwX4s8U3/AIivNE8XaFHE0MfmwatpschsrgcfKrtnnn17EYGOef8AhrqtmPiJ8QmOm2liLS6ZprmFpi0wEkuWcO7KDwT8oXqeOlPmV/Kzf3Bb3W/NL7z1uivFdN+LvjjxDc3OseG/Bkd54XtJCsjF8XDqOSVO4AtjB2qrY6Z71b8P/FzWda+GHijxObSxSfSpitrGInCsvykbxvJJ57EVLmkm30V/kHK7287Hr9FeCz/Gvx3F4ZsfE/8AwidkuhErFcXLuQZpM4bYN+UXIIBIYcde1WtX+NvirTRYeIG8JxweEr2UJDLcSZuJRycjD4XIBIypHHU9armV7Ctc9worgfiL8TF8HW2nW2kWDarrGqn/AEO1XOMcYY45PJAAHXnkYrnLH4reLvD3iHT7D4oeG7bTLbU32QXdo+VjPT5hvcHkjIyCAc4NCabt8vn2B6K/z+R6pNrGmW+qQ6ZPqNpFfzruitHnVZZBzyqE5I4PQdjV2vJ/FF9bxftHeFrR9LtJppLIlb12lEsQ/fcKA4THHdSeT7YTxN8UvE0/jq58K/DjQbfVbqxGbua5J2A45A+ZAuCQMluTkAUlJWXnf8BuNn8l+J6YNZ0s6udKGpWh1ELvNmJ184LjOdmd2Md8Vdr5/wDBurX+tftMS3Os6Y2lX62DRXFqzhtjrGoyCOoPBB9+/WvoCnF3in/W4nu1/WwUUUUxFTwR/wAhXxf/ANhpP/SC0oo8Ef8AIV8X/wDYaT/0gtKK5Zbs1WxneEv+QVff9hrVP/S+etyuK0DxTYafbajbT2+rPIms6nkwaPdzIc3054dIip69jweDyK1f+E10v/n11z/wQX3/AMZroi1ZGb3Ogorn/wDhNdL/AOfXXP8AwQX3/wAZo/4TXS/+fXXP/BBff/Gaq6A6Ciuf/wCE10v/AJ9dc/8ABBff/GaP+E10v/n11z/wQX3/AMZougOgorn/APhNdL/59dc/8EF9/wDGaP8AhNdL/wCfXXP/AAQX3/xmi6A6Ciuf/wCE10v/AJ9dc/8ABBff/GaP+E10v/n11z/wQX3/AMZougOgorn/APhNdL/59dc/8EF9/wDGaP8AhNdL/wCfXXP/AAQX3/xmi6A6Ciuf/wCE10v/AJ9dc/8ABBff/GaP+E10v/n11z/wQX3/AMZougOgrn/Gv/IBtv8AsL6b/wCl0FH/AAmul/8APrrn/ggvv/jNYfi3xbp1zotvHFa6zu/tTT3+fQ7xAQt5CxGTEATgcDqTgDJIFJtWA579pH/km9n/ANhSP/0XJVH4w/8AIy/DT/r+H/oUFen/APCW2P8A0D/EH/hO3/8A8Zo/4S2x/wCgf4g/8J2//wDjNSrJ3v1T+4ptu3o1955t4kUN+1Z4YDDONPY/+Oz1H42/5Og8Hf8AXoP5zV6b/wAJbY/9A/xB/wCE7f8A/wAZo/4S2x/6B/iD/wAJ2/8A/jNCsuXXZ3/MJXfN5qx8761o/h/wR8Ste/4WV4bvdU03UJmuLC6tZHT7zFsDDoDw2Dk5BXpg12GjxXOnfCLxFr3gDwbdeGby5Eawg3ctzLPErcyqjj5cKzYIznkjoK9Y/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGalRShyp9LDbblzWPlrxONA1L4e2WpWF1reteIQ8bapeXnmvHaZBBjLEbeWIxyTx17V6X4+lSf4lfC6WFg8biJlYHggumDXrX/CW2P8A0D/EH/hO3/8A8Zo/4S2x/wCgf4g/8J2//wDjNVHljK9+qf3XIkm1byaNyisP/hLbH/oH+IP/AAnb/wD+M0f8JbY/9A/xB/4Tt/8A/GarmXcLM3KKw/8AhLbH/oH+IP8Awnb/AP8AjNH/AAltj/0D/EH/AITt/wD/ABmjmXcLM3KKw/8AhLbH/oH+IP8Awnb/AP8AjNH/AAltj/0D/EH/AITt/wD/ABmjmXcLM3K5+z/5KVrP/YI0/wD9HXlSf8JbY/8AQP8AEH/hO3//AMZrCtPE9mvxC1eY2OubX0uxQKNCvS4Iluzkr5W4D5hgkYODjODhcy7hZnls3il/B/7R/ijVjplzqNpHb7btbVd0kMW2ImQA4BAIUHJHB61q+D7q6+Jvxyj8aWWnXFloumWphjlnABlO1lA4yN2XYkAnAAyea2NC06bTPjVrni+e21RtP1C28qKJNA1Eyqf3f3gbfGPkPQntXoX/AAltj/0D/EH/AITt/wD/ABmphZQhd7L/ADKnrKVup4n4a8Ty/A7Xtc0jxXo19LYXl0ZrS9tkDeYOccsQGyMZ+bIOeK6T4TabquteO/EXj/UNPk0201NDFaQyjDOuV+bHoAg57knFekf8JbY/9A/xB/4Tt/8A/GaP+Etsf+gf4g/8J2//APjNJJJavZW/QUryv5u55f8As/2EGq/DnxFYXi74Lq+lhkX1VolB/nXFeB9J1HV/iFpHgPVk32PhW/urqQkn5lDKRkehcD8HNe3+J/El5d+G7uHwvHrVjqrKPs9xN4cviiHcCcg27dsjoetcp8M9IPhK41TWPEn9t6lruqPmeeLw7qG1VznAJgGcnk8DoB2ppr2ifRL77bfiOd3F+bfyvv8Ameu0Vh/8JbY/9A/xB/4Tt/8A/GaP+Etsf+gf4g/8J2//APjNXzLuTZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5XmWq/wDJsEf/AGLcH/olK7H/AIS2x/6B/iD/AMJ2/wD/AIzWF4H8T2dv8PfDsL2OuM0el2yFotCvZEJESjKssRVh6EEg9qidpRcb7lRvFplX4Sf8kN0z/r2n/wDQ3ryb4T/FCL4eeDLmLWtFv57K6uWltbu1RSjybVDRsSQBjaD3PPTpX0B/wltj/wBA/wAQf+E7f/8Axmj/AIS2x/6B/iD/AMJ2/wD/AIzVSd5OSe5KVoqLWx5F4A0PUrf4Z+P/ABHqtk1idct7iWGBwQQgSQ5we2XIHHOM9CK674Af8khsf+vif/0M11//AAltj/0D/EH/AITt/wD/ABmj/hLbH/oH+IP/AAnb/wD+M0R5Yu67JfcN3a17t/eblFYf/CW2P/QP8Qf+E7f/APxmj/hLbH/oH+IP/Cdv/wD4zT5l3FZm5RWH/wAJbY/9A/xB/wCE7f8A/wAZo/4S2x/6B/iD/wAJ2/8A/jNHMu4WZuUVh/8ACW2P/QP8Qf8AhO3/AP8AGaP+Etsf+gf4g/8ACdv/AP4zRzLuFmblFYf/AAltj/0D/EH/AITt/wD/ABmj/hLbH/oH+IP/AAnb/wD+M0cy7hZm5RWH/wAJbY/9A/xB/wCE7f8A/wAZo/4S2x/6B/iD/wAJ2/8A/jNHMu4WZH4j/wCQ94S/7C8n/pDdVwfxjTQ59W02Hxl4aupNIZCP+Ehspm32RPVWQIQR0PJPUkDINdH4g8T2cmt+F2Wx1wCLVHch9CvVJH2O5GFBiyx56DJwCegJG7/wltj/ANA/xB/4Tt//APGaiVpdSldHi3wi01rL4qSjwLqWpaj4QEDNcXFzE0UTPtwFwQAzg7ecA4zxjrqfDuwOq+Ovitp6tsN3NJCGzjG55hn9a9V/4S2x/wCgf4g/8J2//wDjNMl8U2MsLxmx8RLvUruTw/fhhnuD5PBoaja1+jX3gm9fVP7jxf4d/EO6+H+jXHgfUfDOpXGvw3En2aCBFxIW6bjnIGf4gGBHNZfgZmb9nvx60gAYz5YAYAOErZ/sv4naVPc2+heL9bubCZuJNS0HUZJgOnG61facf3WHrxXbfDTTtN+H3hltO8rxBeXNxMZ7if8A4Ru/UFiAMAeSeAB+PJ46VHxxkpPeNh/A1Zdb/mcbrX/JoFj/ALsX/pRSfFP/AJNs8If9uX/pO1ex/wDCW2P/AED/ABB/4Tt//wDGaP8AhLbH/oH+IP8Awnb/AP8AjNaTtJS13af3EwvHl8k1955b8TNN1bSNc8IeO9L06TU7fSrdEuoI8kooGQcc4BDN82OCBntWN4o8USfHTUtE0TwlpF9Fa2tyJ728ukVRCOnVSQBgk9QScYFe1/8ACW2P/QP8Qf8AhO3/AP8AGaP+Etsf+gf4g/8ACdv/AP4zTur76Xv89xWdvO1jzbxaNv7UPhADtYEf+j6xbjXZPg98ZfEGp69pd5caTrh8yG5twGOSd2BuIBIO4Fcgjg9MV7H/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM1KsrNPa/4lPXddvwPGfBWvT+Jv2lZNXm06fTkubFzBDcLiQxBAFYj3Az6c9T1r6CrD/4S2x/6B/iD/wnb/8A+M0f8JbY/wDQP8Qf+E7f/wDxmqi4qKV/6uS7ttm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0+ZdwszR8Ef8hXxf/wBhpP8A0gtKKq/D7UIru78V3EcV1Gr6yuFuLSWFxixtRyjqGHTuBkYPQiiuaW5otiDwl/yCr7/sNap/6Xz1D4o8e+GvBklvH4l1MWT3IZol8mSQsBjJ+RTjqOtTeEv+QVff9hrVP/S+evHL7RR8XvjD4ojlfOn6LYvZWr9Qk+Cqn3+fzG/4CK1cmklHs39yJSWrf9XZ7xZXtvqNhb3tlKJra5jWWKQdHVhkH8jU9eW/ATX5NQ8Cy6Nfti90OdrZ0Y/MqZJXP0O5f+A1z0XjD4lfEPVdYuvh9d2OnaRpcrRRLNGjPdEZIGWRvmIGf4QMgZ71pKST09fkTGLa19Pme50V5Ze/ErxF4c+Dra/4q0UWWueaLaCCQbVmY8iQqDlRjcSpwcr2B4x7LUvjXpc+lapfx2mu2WoOpk063jRXgUjPzMFXacdDuYZ6+5f3uX0/EPs3Pa6K801nxbrdr+0DoXhu3vNmkXdk0s1t5SHc22U53Y3DlV6HtUfijxfrmnfHjw14ds77y9KvrYPcW/kod7Zl53Fdw+6vQjpQpX5fN2/r7gatfyVz0+ivDL7xb8SNa+LPiDwn4S1O1hS3YPFLdQJttY1C55CEkksByG/qOr1+T4gLe6fYR6zZaHpkFmrah4imjgcTT45VYnYbRn2HfnjmVO8VK242rSa7HpFFeSfDH4lalqbeKLTxPfW2pR6AGlXUrVFUTxqXy2F+UjC5BHr3rnrDxV8XvGGj3XizwzLY2+lxSMIdMWFXknVTyFyhLH1+ZckHAo5107X+Qcr697HvlFePeKfHPjHw43g3XdXT+ytOvZBb6xppSNwj7j84bBYZXLAbuNoB71reKfFutS/GPw94S8N3v2eExm61MrEj7o+u3LA7eFPIx98VV9bedv1+6xPS/lc9LrD8W/8AIKsf+w1pf/pfBW5WH4t/5BVj/wBhrS//AEvgolsxrc76iiiuU1CiiigAooooAKr39/aaXYTX2pXMVrawLvlmmcKqD1JNWKwfF3hDT/Gukw6ZrEtwtpHdR3LxQMoE+w5CPkHKE9RweBzQMzPD3xa8DeKdX/svQ/EMFxekkJC8ckRkPopdQGPHbNafinxv4c8FWkdz4o1aGwSUkRqwZ3kx12ooLEDIyQOMiuH+LMdnrOteEvC+jwxya+mpw3kTQr81hbRnLyEj7q8AAcZI45FYUniCY/H/AMUzWPhm58Ta3p8Fva6ZbK6RR2sXl75HaV/ljyzYHc5I7mjfbz+5W2+bt8n2Dbfy/H/ganrPhjxfoPjLTWv/AAzqcN/bq21ygKsh9GVgGX8QK2q85+HusaRqvjPXmufDM3hnxfsj/tO0kmMizRj7kisvyOOcbgAeepr0SRWaJ1jfY5UhWxnafXFD2uStXZlC58QaXZ+ILLRLi8VNSv45JLe32ks6oMseBgD64zzjOKj8ReJtG8J6U2peItRhsLRTtDynlm/uqo5Y8HgAng15Xb+EB4Y+PfhK4u9Uu9Y1XULO+e9v7psGUqihQqD5UUZOFHrSeOtZj/4aC0u1m0W51+fTtIM2mabCqkNdSSYMjM3yoFVPvHpgHrR0j53/AAv/AJDW8r9Lfjb/ADPR/Cnj/wAL+N0mPhfV4b8wf62MI8bqPUo4DY98YpLH/kqeu/8AYF03/wBH31cp4Z1+y1X4pKvi3wbN4Y8Y/YWFs5uxOl1b5ywDx4RyOuCCRjg11dj/AMlT13/sC6b/AOj76n0TEt2jpKKKKQwooooAKKKKACud8V+PvC/giOJvFGsQ2Bm5jjKtJI49QiAtj3xiuirn7fwfpdn43v8AxfJJNNqF1bJb5nZTHbRoORHwCoPU5J59KQyz4b8V6H4v0z+0PDepQ6hbZ2s0ZIKH0ZTgqfYgVy2pfHL4daTql1p2oeIhFdWkrQzRiyuG2upwRkRkHkdQcVk/D0wah8R/HHizw/bldCuBFbwvCmFvp4lPmSIB1GcjI+8ST61zXgOX4r+HvAbX1l4Y0tYPtE97d2mpSTR392zOWZlXhUOOAGyTjODkU/PZWv8A1+ffbTcLdFq72/D/AD0PctN1G11fS7XUtOl860u4Vmgk2ld6MMqcEAjg9CKs1j+E/Elp4v8ACmn69p6skF9CJAj9UPRlP0II/Csb4heJ73SrO10TwyFl8S605gsUxnyF/juHH9xBz7nA55pzTi7WJi01e5u6Z4l0jWNW1PTNMvUuLvSnWO8jRWxEzAkDcRgng5wTjGDisHXfi54F8NaydK1nxFbwXqna8SRyS+WfRiikKfYkVyvwf8PQeFvHnjvR7WWWZbd7HfNKxZ5XaEs7knuzEn8a6i20Twt8LvAuqPfzNJp7vLc39xf7ZJLp3JJDYUByc7QMc9KUtFfyTKWrt5nW2V7a6jYw3lhcRXNtOgeKaJwyup6EEdawvhx/ySzwp/2BbP8A9EJWJ8E9HvdF+FlhBqMD2hmlluYbST71vFI5ZEP4HP41t/Dj/klnhT/sC2f/AKISqkrOxKd0dJRRRUjCiiigAooooAK4qf4w+ALbxCdEn8TWiXwk8phtfy1b0Mu3YPTlq7KaJZ4JIZN2yRSrbWKnBGOCOR9RXkvxObS/BXwyufCOh+ELubT7m1ZRcpbPLZ2W4nM00nzPuU/PnBPA5qW7f1/Vikr6HroORkcisuPxLpE3imbw5Feo+rQW4upbZVYlIycAlsbQeRxnOCDjFctP4ntvBXwm0ZtNuE129ks4LLSkhbcdQn2BV298cbiewB71yXgDw1ceGfjrcR6ndte6te+HBealcsciS4e4+baOgUABQBjhRWlv3nL01/Jv/h/kZ39zm66fml/w3/APaqpavq9hoGj3Oqaxcpa2VrGZJpnyQqj2HJPsOSelXa8Q+Jc83xHsPEsdrI48LeGbOd5JY2wt/frGSFBHVIup7FvXFZyk0tP6/r8zSKTev9f1/wAE9nsL631PTra/sZPNtrqJZoX2kbkYZBweRwe9Vo/EGly+JJtAivFfVIbYXUtuqklIy20EnGBz2znvjFY3hi2urz4S6PbadfHT7qXR4EiuxEJDCxiXDbTwcehrifA/hi28J/HzV7K2ubq8kl8PxXFzd3kpkluJWnIZ2PvgcDjitZRtV5Omv4J/5f10yUm6al10/Fr/ADO88Uf8jF4M/wCw1J/6b7yukrm/FH/IxeDP+w1J/wCm+8rpKgsKKKKACiiigAooooAz9b17S/DelSalrt9DY2cXDSzNgZ7AdyT6Dmsbwr8S/B/jW6ktvDOuQ3lxGNzQlHicjuQrqpI9xVrxF4N03xRqujXurPPIuj3DXMNqGXyZZCMBpFKnO3qMEdT1rivFAtvEPx48K22hRrJqGhCW51W8iH/HvCybUidu5Yk4XqAc45NEdWk+v9X/AK/PQHs2un9WOn8VfFLwd4J1SPTvE+sCyu5IhMsf2aaTKEkA5RCByp461o+FPGWg+NtLk1HwxffbrWKYwvJ5MkeHABIw6g9GHPvXmssHxCk+NPirUfCmiWKp9ntrSDUNd86OAxqu5ljCDL5ck5HAxz1rtvh/40u/FEWp6fr2nLpuu6NcC3v7aN98ZJGVkQ/3WGSByRRHWN36/j/w3/DBLSVv62/r7jsKy7vxLpFl4ksdAub1E1TUEeS2tgrFnVBliSBhRwepGcHGcU3xP4jsfCfh271jVHIgt0yEX70rnhY1HdmOAB7147pWh6pbfGjwX4h8Ulv7e1xL6a5g3HbaRCIeVbqP9gMcnqSTnNEdZW/rZ/1/SB6Rv/X9f13PWvFPjfw54KtI7nxRq0NgkpIjVgzvJjrtRQWIGRkgcZFSeGPF+g+MtNa/8M6nDf26ttcoCrIfRlYBl/ECvJpPEEx+P/imax8M3PibW9Pgt7XTLZXSKO1i8vfI7Sv8seWbA7nJHc11vw91jSNV8Z681z4Zm8M+L9kf9p2kkxkWaMfckVl+RxzjcADz1NEdUn31/rv59glo7dv6+X6nReF/+Ri8Z/8AYaj/APTfZ0UeF/8AkYvGf/Yaj/8ATfZ0UAcjBqN1pPgPXr7T7Sa9u4dS1ZoLeCMu8j/bpwoCgEnnH4V5X4E+AVn4h8LpqvjOXWbHU7mV2aBSsTKucAsroTuJBP0Ir0nQ/E1zYQ6lbR+GtWvFTWdSxPA9qEbN7MeN8ytxnHIHI7jmtL/hMrv/AKE/XP8Av7Zf/JFdEYX95roZuXS55t4P8H6l8MvjY2n6VZane+HNStRG140JkWM4yN7qoUEMpHbhqpaL/wAJr8HtT1rSdM8H3XiDT764M1nc2wdgvYFtqt2xlTt5B5xXq3/CZXf/AEJ+uf8Af2y/+SKP+Eyu/wDoT9c/7+2X/wAkU+SVlv1Xy3FzLX5fejhNZ8KeOfH3wVe28VJAuvR3C3VpAqrGzqoI2yYO0MQzYHGOM4OcU7Xxv8VtUTSdF0nwZNpN1buiXV9eQt5EqqMH7ygKvf5WJOMD39H/AOEyu/8AoT9c/wC/tl/8kUf8Jld/9Cfrn/f2y/8Akiq5WpNrZ2/AOZNW66/ief8AxO0rxPpHxS0DxtouiS65FZ24hlgtUYtuG8H5VBIBD8HBxjn3yYIvGfiX46eG/EmueFrzS7MLsjQI0ggjAf8A1j4wpLMeCF7cevq3/CZXf/Qn65/39sv/AJIo/wCEyu/+hP1z/v7Zf/JFKMGmn2dwlJNPzVjjfBujapa/tC+LdRudNu4bG4gIhupIGWKQ5j4VyMHoeh7Vh+NfD983xql1TxZ4X1fxR4fe3C2EWnxtKsLYXhlBAA3BsgkA5zzXp3/CZXf/AEJ+uf8Af2y/+SKP+Eyu/wDoT9c/7+2X/wAkUvZu0V2DmV5PueZfDDwlqSeJ/HFhrXh+60K11e2ZIUEP7mNHLfIkg+QkBxwD2PpVDQNV+JHw68NXXg+z8F3V7cLJJ9j1S3RpIo9x+9wpVueRkr7ivXP+Eyu/+hP1z/v7Zf8AyRR/wmV3/wBCfrn/AH9sv/kihU2kkr7W/G4+ZO7fe/6HP+KPD2t+KPgbdWvi9bf+3I7Y3WIAAqSJllGckZwNpI45OK5r9n+0u9cudX8ZaziW6kWLT4ZSvO2NFDH8QE59Qa1PiJBrPjmxtbSzs/E2iwxlxcJA9oy3KMB8rAXaggY7561teFb1fCPhq00XTPB+vGC2XG95LHdIxOWY4uOpJpxi1OUrf13+7QmTXLGN/wCu336noFYfi3/kFWP/AGGtL/8AS+CqX/CZXf8A0J+uf9/bL/5IrO1zxFqOp2VtDB4R1lWi1CzumLy2YBWG5jlYcXHUqhA98dOtNp22BNXPXKK4r/hY0v8A0JviD/v5Y/8AyTR/wsaX/oTfEH/fyx/+Sa5/Zz7GnNHudrRXFf8ACxpf+hN8Qf8Afyx/+SaP+FjS/wDQm+IP+/lj/wDJNHs59g5o9ztaK4r/AIWNL/0JviD/AL+WP/yTR/wsaX/oTfEH/fyx/wDkmj2c+wc0e52tcf8AE/xJrfhnwbJP4W0i81XVbhxBAtpatOYMgkysqg8ADgHgkgVF/wALGl/6E3xB/wB/LH/5Jo/4WNL/ANCb4g/7+WP/AMk0nTm1azGpxTOJ8EeKrHwrG6p4B+IV5quoSK2oateaL+8uZOm5jv8AlQdlHAHqck62qwav8Pfijq/iqx8P32vaNr8EK3UelxiW5tpohtBEfBZSPQ9evQZ6D/hY0v8A0JviD/v5Y/8AyTR/wsaX/oTfEH/fyx/+SabhO6aX/DdhKUbNN7/1cyfBVlrHiT4maj481bR7rQ7NtPXTdPs75dtw6B97SSIPuc8AH/657Lwz4lg8UWV1cW9lfWRtbuS0khvohHIHTGTtBPBBBFYf/Cxpf+hN8Qf9/LH/AOSao6T4vj0a1kgtfB3iR/OnkuJZJZrFmkkdizEn7T74A7AAdqOSe1tLfrf/ADByW9/+Gtb/ACJvEOnXs/xv8HX8NncSWdvZ3yzXCRMY4iyrtDNjAJ7Z61Q8a6Zq/h34laf4/wBD0ebW4FsG07UbK0ANwI929ZI1P3iDwQOenqSNf/hY0v8A0JviD/v5Y/8AyTR/wsaX/oTfEH/fyx/+SaXs5pKy2v8Ajf8AzHzRu79bfhb/ACMDSv7Y+IPxS0fxPP4e1LQNG8PwTrCNWi8m4uZpV2n93k4UDuTz/LsLH/kqeu/9gXTf/R99Wd/wsaX/AKE3xB/38sf/AJJrItvGN5D401LV28Ia4be60+0tUUS2W8NFJcMxI+0YxiZcc9j04y+SVkrf1uLmV73PTKK4r/hY0v8A0JviD/v5Y/8AyTR/wsaX/oTfEH/fyx/+SaPZz7BzR7na0VxX/Cxpf+hN8Qf9/LH/AOSaP+FjS/8AQm+IP+/lj/8AJNHs59g5o9ztaK4r/hY0v/Qm+IP+/lj/APJNH/Cxpf8AoTfEH/fyx/8Akmj2c+wc0e52teK/E7xBq2qeM/8AhHL3wz4tufCVsga8Oiaa8h1NyAfLMmVxEM4O05JyPQjtf+FjS/8AQm+IP+/lj/8AJNH/AAsaX/oTfEH/AH8sf/kml7Od9h88bbjfCfipfENjcaLovhbxF4UFrZlbWbVNKFvDHxtUIMkEjIO3HQVzNv8AEDx3p+gN4f1bwLrWpeKlVoEvoIEFhcE8LK0wIVBjkjA6Y4zx1H/Cxpf+hN8Qf9/LH/5Jo/4WNL/0JviD/v5Y/wDyTTdOUr3T1EpJbMqaFGnwf+Eel22qW95qJtNqXX9nxCQo8jlnbkjCKzH5j2xxU3if4U2HibxafEf/AAkXiLSL82y2u7Sb5YB5YOcfcJ5PJGccVW1fxfHrditpe+DvEnkedHK6JNYr5mxgwVv9J+7kDI79OlXv+FjS/wDQm+IP+/lj/wDJNNwnJ8zWt/6/UFJJWucl8PPh/e+H/it4ov7rVvFE9raNB9nlvrhnTUg0J3GQ7R5xQ8DH3elYEPiu+1vxm+v+OvAPji9jsZ86NpdtorNbWoHSZ9zLvlPuML27Y9M/4WNL/wBCb4g/7+WP/wAk0f8ACxpf+hN8Qf8Afyx/+SaXJO6dtl/TDmjr5m74X8Rf8JPo/wBv/sfVdI/eNH9m1a18ibjHzbcng54Psap/Dj/klnhT/sC2f/ohKzv+FjS/9Cb4g/7+WP8A8k1keE/GN5oPgvRNIvPCGuPcafp8FrK0UtkUZkjVSVJuAcZHGQKOSXYOZdz0yiuK/wCFjS/9Cb4g/wC/lj/8k0f8LGl/6E3xB/38sf8A5Jo9nPsHNHudrRXFf8LGl/6E3xB/38sf/kmj/hY0v/Qm+IP+/lj/APJNHs59g5o9ztaK4r/hY0v/AEJviD/v5Y//ACTR/wALGl/6E3xB/wB/LH/5Jo9nPsHNHudfeRzzWM8VpP8AZ7h42WKbaG8tiOGweDg84NeU2/j7xrYaDJ4e1/wJrereJVRoBeW1sh0+6JyFkaUEKgI5Ixx7ZwOn/wCFjS/9Cb4g/wC/lj/8k0f8LGl/6E3xB/38sf8A5Jpeyk7pp2Y+dLVM5rSfgdC/hHwva6vr+s6fqmhwShJtHu1h2PMxZwGKE8Z25GMgVn6R8ML3TPjpFOfEHi+6sbbS0nGoXd6ziaQTf8ezybMMmOTH1712v/Cxpf8AoTfEH/fyx/8Akmj/AIWNL/0JviD/AL+WP/yTVcs+bmt3/G/+ZN4uPLc2G1+3vvFV74Ua11CCdbH7R9rMYWGRGIU+W+clgWGeOK8y174Gw6J8PtVt/D3irxpKsNnM0Glx6iGhmYqTs8pIxuDE8gdcmuni8Xxx69cav/wh3iR7qaBLf55rErHGpJwo+08ZLEk9+PQVe/4WNL/0JviD/v5Y/wDyTUOlNx2d/wDh7FqaUt9Cx8MfD83hv4f6ZaXV5qdzNJBHNImpyl3t2Ma5iUEAqikYC9uaz7PTr1f2gtS1FrO4Fi/h+GFboxN5TSCYkoHxgtjnHWrH/Cxpf+hN8Qf9/LH/AOSaP+FjS/8AQm+IP+/lj/8AJNaSjNz5rd/yaM1yqHLft+dzR8Uf8jF4M/7DUn/pvvK6SvM9Z8Y3mo6t4fuoPCGuKmm6g91MHlsgWU2s8OFxccndKp5xwD9Dr/8ACxpf+hN8Qf8Afyx/+San2c+xXNHudrRXFf8ACxpf+hN8Qf8Afyx/+SaP+FjS/wDQm+IP+/lj/wDJNHs59g5o9ztaK4r/AIWNL/0JviD/AL+WP/yTR/wsaX/oTfEH/fyx/wDkmj2c+wc0e52tFcV/wsaX/oTfEH/fyx/+SaP+FjS/9Cb4g/7+WP8A8k0ezn2Dmj3KHxe8TeItF0izsPCelavc3GoSFbi+0ywa6eyhGNzKo43nOFyR0J9KzPh/4o0rRFtPD2i/D7xvYJdT5mv9R0rAeRvvTTylycnue3YAcV0X/Cxpf+hN8Qf9/LH/AOSaP+FjS/8AQm+IP+/lj/8AJNEac10YSlF9TKv/ABd4u8GeLNVi1zw/rPiXRLuQS6VcaLZpK9uMfNDIi4IAPRjnPv2l+HulaxZ3Hijxr4l0ySyvtckSZNLiIklighjIjU46yNk8fToeBof8LGl/6E3xB/38sf8A5JpsvxDlkhdB4Q8RRllIDpJY5X3GbnrS9nNR0Tva39fcPmi3voRapoOk/GTwjo+oTXGuaNFDcG7txA6W9xFKhZPm4fDAg4xyD3ridZ+El7B8TPCqW/ijxvfWjLdGfUZdQaR7MhAVCyBMRhzwQfvYxXY6T4yj0XSLbTbHwX4iFvbRiNN8tkzHHcn7TySeSe5NXP8AhY0v/Qm+IP8Av5Y//JNVySUrpf1sLmTjZs5/VINX+HnxQ1bxTY+H7/X9G1+3hW6TS4xLc200Q2g+XwWUj0PXr0GbXgqy1jxJ8TNR8eato91odm2nrpun2d8u24dA+9pJEH3OeAD/APXOt/wsaX/oTfEH/fyx/wDkmj/hY0v/AEJviD/v5Y//ACTSjCatptt/X4Dcovrvb8P+GNHwv/yMXjP/ALDUf/pvs6Kz/AWqvqt94svf7OurQy6yn7i4MRdMWNoOdjsvOM8E8Ed8iio2Gc5oP+o1L/sNan/6XT1qVl6D/qNS/wCw1qf/AKXT1qV6lP4EccviYUUUVZIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFLWdVg0PRbzVLtZHgtIWmkWIAsQBk4yQM/jXnA/aD8KEgGw1ge5gi4/8iV2PxC/5Jxr/wD14S/+gmsf4PxpN8I9KjmRZEYTBlYZBHmvwRWT5nNpPZL9TT3VFN9WdJ4c8T6V4r0sX+iXIniztdSMNG391h2Na9eEeENRj8GfEbx3HZRZ0+ztprkQpwoMbgqvt98iub/4TbVb6wn164+IdxZ6wHZ4tHjt5vJIHQZH7sZ9CD2yeuIVePKm+qv+g/Zu7XnY+m6K8d8RfEvV7r4Z+Hp9HeO21bXJTbtIn8BVtrFR2ycfQH6Gsfx1pvjnwF4Sjkbxjeajb3U6rLJvkSa3kwSNr7ixU4IPIHTiqnVUb6aIUYc1vM96orxz4k6r4gi8TeELLQNWubOa/gEZ2zMEZmKruZc4bGc85qDxrqmufDjw3YaEvie6vL3VLh3l1W6DFreIbRhRliOucjJ647U5VOW91s7fMSje3pc9qorwDwx44uNC8c6XYWnjSfxVpmoyrDcfa4ZUaFmIUEeZk9SDwcdcjoaZ4i8c3PiHxtqlpeeM7jwppunyNDbLbQyu0zK20lvLwexPJ44wOppe2jZPvf8AAfs3d/1ufQVMmmjt4JJp3WOKNS7uxwFAGSSa84+DvjK+8S6dqNjqt2t9PpsqrHdhSpmjbOCQQD/D1IzyM81d+M2qy6X8M70QMUe7dLbcP7rHLD8VBH406lTlp86FGN58rOl8MeJLXxXoq6pp0NxFavI6Rm4UKZApwWABPGQeuDx0rYry/wAYfaPDPwDtV0e6ms5oILUCa2kMbZLLuORg8kn865ufR/H6eA4fGZ8aXImitUuVsVLbPKxkEnO1m28ncpyepJolU5G018O7CMeZJ99j3SivIvEHxO1ST4Z+H7rR1SLWNdfyA+BiNlba7KD6tjGegNZ+vab46+G2lweJH8Xz6wqSot5Z3BdowGPQbmORnjICkZFEqii3fZaXBRbXme20V5R468S3kniL4f3Ol391aWmpzpJLFFOyLIjNEcOAcMMMRz6mp/i3q2o6b4h8Hx6dqF1aR3F6yzLBMyCUb4uGAPI5PX1NVz/nYFG/3X/P/I9QorxnxnceJNR+NUXh7Qteu9Niu7NQxSVikQwzM4TIG7C9Rg+4r1Lw7pVxomgW1he6lcapPEDvu7gkvISSe5J746npRCXMm7f0hSXK7FGXxrp0PjyHwm0N0b+aHzlkCL5QG0nk7s5+U9q6KvCvHviSLwl8dU1maFp/s+nYSJTjezI6qM9hkjJ9K6HwNqGoxeCtU8fa7rNxqUs0M00dis7+RbhSflCZwDkY6cD6ms41U079L3+TZUoaq3W35HqlFfMn/CbarfWE+vXHxDuLPWA7PFo8dvN5JA6DI/djPoQe2T1x1fjXxzrGofDLwtrmm3k1le3N0UmFtK0auy5BBAPKkjOD60/bLlvbt+Icjvb1/A9woryLxHpHiPwf8Ltbv7/xZqF/qNw0DK6yvGLY+YNyoQxxnOOMDA6VgaraeOoPh1a+NZfGd0rRxROtlCWVRGxCqWOcO3IJ3Kc88miVXlvdbWuChzWs99j3yivGvG3xI1W28B+GPsl0un3utwCS5vFUnyVAUMVABIyWzwCQBxzWL4Y8cXGheOdLsLTxpP4q0zUZVhuPtcMqNCzEKCPMyepB4OOuR0NV7Rc/J52+YuV8vN8z1628Z6fdeOrrwpHDdC+tYRM8jIvlFSFPB3Zz847etdDXk+k/8nM652/4ly/+gRVxsl7p3mN/xezWF5PH2K84/wDH6zVX3U31/wA2W6ert5firn0VRXjWg36w+AvGFxpfj3UPEc8NkGWSWOeFrQ7XwVLsTk+2Pu1m+HNC8e+KvAkWvR+Nby2MKSG0thI+ZgjHPmOGHJYEfMG4x0HFVKrbp0uSoefWx7vRXj1r8V9QX4KPrkuyTV47n7AJWUBWkI3CTHTIU5x0yPSqV74f+IWieFG8Xv40upbyOIXMuntuaJUPJGCduQO2wDrg05VEr9la79f+AJQbt3Z6f4v8X2HgrR49R1WG5lhknEAW2VWbcQTn5mAx8p71uxuJYkkXOGUMM+9eK/E7X/8AhKPglomsGNY3ub2MyIpyFcLIrAe2Qa2dc1PUfC3xW8OXcuoXTaLrEK20ls8zGKOTAXIXOByUOcf3qFP3nF90vwBx91Ndm/uZ6nWJ4c8VWHib7ctmk0E+n3LW1zb3AUSIw74BIwecHPY1x2marqHiT46ahHbX9ymkaHb+U8EczCKWXp8yg4JyW6/3BVawm/sX9pC/s4Dtg1iyEskY6bwuc/X5W/76NEZ3cX0d/wDgfkwcbJrqrf1+J6rRRRWpAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBe+HP+v8V/8AYaX/ANIbWij4c/6/xX/2Gl/9IbWivLqfGzsj8KOd0H/Ual/2GtT/APS6etSuf0eHxM66m2nabpM1sdZ1LY8+pSROf9NmzlRAwHOe5yOeOlaH2bxj/wBAjQ//AAcTf/Itd0JxUUc8ou7NCis/7N4x/wCgRof/AIOJv/kWj7N4x/6BGh/+Dib/AORar2kRcjNCis/7N4x/6BGh/wDg4m/+RaPs3jH/AKBGh/8Ag4m/+RaPaRDkZoUVn/ZvGP8A0CND/wDBxN/8i0fZvGP/AECND/8ABxN/8i0e0iHIzQorP+zeMf8AoEaH/wCDib/5Fo+zeMf+gRof/g4m/wDkWj2kQ5GaFFZ/2bxj/wBAjQ//AAcTf/ItH2bxj/0CND/8HE3/AMi0e0iHIzQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFZ/wBm8Y/9AjQ//BxN/wDItU9UuvFek2aXFzo2jMj3EFsBHq8pO6WVIlPNsOAzgn2z16Ue0iHJI3KKz/s3jH/oEaH/AODib/5Fo+zeMf8AoEaH/wCDib/5Fo9pEORmhRWf9m8Y/wDQI0P/AMHE3/yLR9m8Y/8AQI0P/wAHE3/yLR7SIcjKnjHT7nVfBWr2FhF5tzc2kkcUe4LuYrgDJIA/GvMPDcXxd8MeHbfRNO8M6abeDcElmnjZxuYsScTAcE+letfZvGP/AECND/8ABxN/8i0fZvGP/QI0P/wcTf8AyLWb5W73ZS5rWscN4M+GU9hpWuS+KrlbnU9fR0uWi5EatknBwMkk5PbgY6VgaRofxY8Kae3hrQodPlsBKfI1J2QmFWbJIVmzjqSCjdTjPFesfZvGP/QI0P8A8HE3/wAi0fZvGP8A0CND/wDBxN/8i0fu+jtpYfvddepwHxL8NzXvgfSjqfiGyh1vT5BJHdXkkdulzJjLKM4APAI+nPXNcJ8S7nxxqHgyyuPGQ0+ztxcqsFtasrPcsUY+aSrMMAehx83TpXsXibwdrni7STp+taDoksQbejLrUyvG2MblP2Xrz9K5DSvgI+l6jHdvpFjfGNgyxXWvSFMg5GQtmufoTisppSk+zt/Vio+6l3Ra8UeFtZ1fxl4K1PT7PzbPThG11J5qL5Y3KehIJ4B6A1o/E7wVf+J7bT9R8PzJFrGlS+bb7zgPyDjJ4BBUEZ4rrPs3jH/oEaH/AODib/5Fo+zeMf8AoEaH/wCDib/5FreTg7+t/mZxUlb0scZ4b/4WfqniGC48UfYtF0y3H722tljdrk845y5Hudw46DvWNeeFPG3gzxpqmreArW01Kz1ZvMltrhwvltknnLr0JbBB6NyK9M+zeMf+gRof/g4m/wDkWj7N4x/6BGh/+Dib/wCRan3NNXdfqP3tdDM8F2vii30h5PGmoR3V9M+5Yoo0VbdcfdyqjJ9evse9Yvxm0qXVPhnemBS72jpc7R/dU4Y/gpJ/Cut+zeMf+gRof/g4m/8AkWqPneJ7zVrzRZND0V3htYppd2ry7GSVpUA/49uT+6bPHcdecFRxnDluEFKMrnC+Pr+PVP2ebe8hIKywWh47EMoI/AgisW30z4nap4C0/wAP2Menz6Ne2cW2/LhJI4mUHy2y2eBxwpOO9do3wu1p/AsnhM2ViNOabzVP9uP5kfz79qn7HjGfUE89a6PStG8V6Ro9pp1tpWjNDaQpBG0msyliqgAZxagZ49KTcZyk5dbflqhpOKSXQ5DxD8Kmu/h3pOi6PeLHqGjt5sE7gqsjnl84zty3I64wPrWJf+Hvid46trbQ/FcFjpmmRyK891Eys8+3vhXbJ74wozXqv2bxj/0CND/8HE3/AMi0fZvGP/QI0P8A8HE3/wAi037Ntt9RLmSscJ8SfAmq6lZaBceERG9zoTAQ28jAblG3aQWwMgoODjOa5zW/C3xI8Va7oWra9p9kgs7pSbS0lRfIQMpZ2LOck46Anp0Hf177N4x/6BGh/wDg4m/+RaPs3jH/AKBGh/8Ag4m/+RaPc5ua73v8w961rdLHF3XhbWJPjvZ+Iks86VHaeW9x5qcNsYY253dSO1eiVn/ZvGP/AECND/8ABxN/8i0fZvGP/QI0P/wcTf8AyLVxlCKsv6vqJxk3c4TVfBN/qnxws9cutMjudFitgrSyOhUOFbHyE5OCR2qPw34G1TQ9V8ReG5bZ5fCeqxubedZkJt2YYK7Sd3Q4zg/dX1Nd/wDZvGP/AECND/8ABxN/8i0fZvGP/QI0P/wcTf8AyLUWp/n+JXv/AJfgeT6RofxY8Kae3hrQodPlsBKfI1J2QmFWbJIVmzjqSCjdTjPFbPxH8IeJde8LaBaW/wDxN9QtLgSXc+6OEN8vLAHaMZ6AV3/2bxj/ANAjQ/8AwcTf/ItH2bxj/wBAjQ//AAcTf/ItP3LWbfT8Be9e6Xf8TC+Jeiah4g+Ht9pmkW/2i8lMeyPeqZw6k8sQOgPes7X/AA1q178D4/D9rab9UWxtojB5iD50KbhuJ28bT3rrvs3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWiXI1JX3/QI80XG3Q831r4c6zqPw/8MHTylp4h0GNCkbupBIwSu4ZGQVBB6Vq+G/8AhZ+qeIYLjxR9i0XTLcfvba2WN2uTzjnLke53DjoO9dn9m8Y/9AjQ/wDwcTf/ACLVPSLrxXrWh2OqWujaMkF9bx3MayavKGCuoYAgWxGcH1NHNBSvfzFaXLaxzWneGNXg+Oeq+IZrTbpVxZCKO481DubbGMbc7h909R2rpT4J8Kk5PhnRyf8Arwi/+Jq59m8Y/wDQI0P/AMHE3/yLR9m8Y/8AQI0P/wAHE3/yLTi4KKXYbUm7/wBdjnvGGiaVo/w58R/2RplnYebYSeZ9lt0i34U4ztAzjJ/OvNPByfElPhxa23hWKyu9NvxKEkdlWWz+dlbG5gME5I4bqelev6zoXirXNFvNLu9K0dILuFoZGi1mUMARg4zakZ/Cq/hnwr4m8K+HrfR9P0zSZLe33bGn1qUudzFjki0A6n0rN8spO70sl+Y9VFW3ucxb/CUL8JH8Ly3SLfySfa2uACUE/Yeu3A25/HHasObRfizqugjwlf2+nxaeVWGTUvMUs8Y7cNkjA/uAnua9Y+zeMf8AoEaH/wCDib/5Fo+zeMf+gRof/g4m/wDkWql7Nt+f6CXMjz/x38P7+T4W6T4a8MW7X0ljcRs26RIywCvub5iByzdM96ufGDS4rn4XyTzOkNzpzRTQuzYIcEKVB9SCfxArtPs3jH/oEaH/AODib/5FrkPFnwr1XxnrNtqOs6Xp2+3jEQjh1yRUddxOG/0QnuehFTUaaaju39xUU01foN+DOlTWvgltVvyXvdZuHu5XbqwJwv54Lf8AAqy7CH+2v2j7+8hBMOj2Qjdx08wrjb9fmb/vk16Db6f4stbaK3ttE0GOGJAkaLrE2FUDAA/0X0rK8O+DvEfhoXzWWl6TNNqFy11cTXGtSM7u3bItBwOcD3NW5Q5o22X+Vl+BCjLld93/AMOdTRWf9m8Y/wDQI0P/AMHE3/yLR9m8Y/8AQI0P/wAHE3/yLV+0iLkZoUVn/ZvGP/QI0P8A8HE3/wAi0fZvGP8A0CND/wDBxN/8i0e0iHIzQorDvbrxXYXmnW82jaMz6hcG2iK6vLhWEUkuW/0bptiYcZ5I+oufZvGP/QI0P/wcTf8AyLR7SIckjQorP+zeMf8AoEaH/wCDib/5Fo+zeMf+gRof/g4m/wDkWj2kQ5GaFFZ/2bxj/wBAjQ//AAcTf/ItH2bxj/0CND/8HE3/AMi0e0iHIzQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFZ/wBm8Y/9AjQ//BxN/wDItH2bxj/0CND/APBxN/8AItHtIhyM0KKz/s3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWj2kQ5GaFFZ/2bxj/0CND/APBxN/8AItH2bxj/ANAjQ/8AwcTf/ItHtIhyM0KKz/s3jH/oEaH/AODib/5Fo+zeMf8AoEaH/wCDib/5Fo9pEORm98Of9f4r/wCw0v8A6Q2tFQfDQahG3ilb+3tYrn+2V8xILhpEH+hWuMMUUnjHYc5HuSvOnrJnVHZDfCX/ACCr7/sNap/6Xz1uVh+Ev+QVff8AYa1T/wBL563K6I7Ize4UUUUxBRRRQAUUUUAFFFFABRRRQAUUUUAFc/41/wCQDbf9hfTf/S6Cugrn/Gv/ACAbb/sL6b/6XQUPYZ0FFFFAgooooAKKKKACiiigAooooAKKKKACuK+IXxKsvAUdpB9in1PVL5ttrYwHDPyBknBIyTgYBJPau1rmPFOneFLC6h8Y+Joo459JTMN28jjy+uAFBwxJY4GDkke1TLTrZdSomD4I+LkHinxFJ4e1jQ7zw/rKoXW1uSTvAGcZKqQcc4K9O9dLZ/8AJStZ/wCwRp//AKOvK858C2Wo/EH4qSfEe9s3sNJtYjb6XHKMPMMFdx9sMxJ6ZIAzgmvRrP8A5KVrP/YI0/8A9HXlNX5VfcX2nY6CiiimIKKKKACiiigAooooAKKKKACiiigAryPXfjxHYa1qFpoXhe+1qz0til9fROUSEgkE8I3y8HliucH6162SACScAdSa8w+IGlXuueD763+Ft7o0EbGQ6ulo0Ye4Gz/V5RT8xHqVOMc4rObcVdf1/wAA0gk3ZndeGPEdj4s8N2mtaWW+zXSZCuMMhBwVPuCCKq+Af+Sa+Gf+wRa/+iVrn/gnqmk6l8MbJNEtZLSKzd4JYpZfMYSZ3MxbAzu3A9BjOMcV0HgH/kmvhn/sEWv/AKJWtZK0tDKLujoKKKKQwooooAKKKKACiiigAooooAKKKKACvPdS+LVjafFOy8FWVl9slmcR3F0J9q27kE7du07iBjPIxnHY1ofFDxsPA/g2W9gKHULlhb2SucL5jfxHPGFGTzxwB3rwuytdD8MfFDwXKNf0+/lI+06tqKXiSRidmYtukzgY4GSeeveoUr1Eul0n/X9dCmrQb62/r+vU+hvEf/Ie8Jf9heT/ANIbqugrndfkSXWvCEkTq6PqrsrKchgbG6wQa6Kr6khRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHB/Eb4lSeBLzSrKy0STW73U2cR20MxRxt24wAjFiS3THapvAnjnW/Fl9dwa14L1Dw6kEYdJbsviUk42jdGn171zHj7wNqXjH4p2M+meLbDSJLKzKRxRylryI8lnWMYOCGHO4Y49aj+F+veItJ+I2teAfE2qSayLOPz7e8lYs+PlPJJLchxwScEYBxUU227S8/wKmrK68vx/qx6t4I/5Cvi/wD7DSf+kFpRR4I/5Cvi/wD7DSf+kFpRWEt2WtjO8Jf8gq+/7DWqf+l89blcVoFt4mkttRbTtX0mC2Os6nsjn0uSVx/p0+csLhQecn7owOOetav2Pxj/ANB3Q/8AwSTf/JVdEdkZvc6Ciuf+x+Mf+g7of/gkm/8Akqj7H4x/6Duh/wDgkm/+SqoDoKK5/wCx+Mf+g7of/gkm/wDkqj7H4x/6Duh/+CSb/wCSqAOgorn/ALH4x/6Duh/+CSb/AOSqPsfjH/oO6H/4JJv/AJKoA6Ciuf8AsfjH/oO6H/4JJv8A5Ko+x+Mf+g7of/gkm/8AkqgDoKK5/wCx+Mf+g7of/gkm/wDkqj7H4x/6Duh/+CSb/wCSqAOgorn/ALH4x/6Duh/+CSb/AOSqPsfjH/oO6H/4JJv/AJKoA6Cuf8a/8gG2/wCwvpv/AKXQUfY/GP8A0HdD/wDBJN/8lVi+KrHxW2k2q3OtaM6NqunKBHo8qkMb2EKcm5PAbBI7gEZGchN6AjuqKof8I74x/wChk0P/AMEU3/yXR/wjvjH/AKGTQ/8AwRTf/JdT7SI+Vl+iqH/CO+Mf+hk0P/wRTf8AyXR/wjvjH/oZND/8EU3/AMl0e0iHKy/RVD/hHfGP/QyaH/4Ipv8A5Lo/4R3xj/0Mmh/+CKb/AOS6PaRDlZfoqh/wjvjH/oZND/8ABFN/8l0f8I74x/6GTQ//AARTf/JdHtIhysv0VQ/4R3xj/wBDJof/AIIpv/kuj/hHfGP/AEMmh/8Agim/+S6PaRDlZfoqh/wjvjH/AKGTQ/8AwRTf/JdH/CO+Mf8AoZND/wDBFN/8l0e0iHKy/XlPxc+Hfi3x7qmnjRr/AEyDTLJd4gu5Hy8xJyxURsCMYAzn+L1r0f8A4R3xj/0Mmh/+CKb/AOS6P+Ed8Y/9DJof/gim/wDkuplKMtxpNHB+EdA+K2n+IbJvE/iTSLvRYgyy2trCqsRsIULiBcYO3uOB+FdXZ/8AJStZ/wCwRp//AKOvK0f+Ed8Y/wDQyaH/AOCKb/5LrBs9B8Vn4i6xEuv6MJ10qwZ5Do0pVlMt3tAX7VkEENk5OcjgYya9ohcrOtoqh/wjvjH/AKGTQ/8AwRTf/JdH/CO+Mf8AoZND/wDBFN/8l0e0iHKy/RVD/hHfGP8A0Mmh/wDgim/+S6P+Ed8Y/wDQyaH/AOCKb/5Lo9pEOVl+iqH/AAjvjH/oZND/APBFN/8AJdH/AAjvjH/oZND/APBFN/8AJdHtIhysv0VQ/wCEd8Y/9DJof/gim/8Akuj/AIR3xj/0Mmh/+CKb/wCS6PaRDlZfoqh/wjvjH/oZND/8EU3/AMl0f8I74x/6GTQ//BFN/wDJdHtIhysv0VQ/4R3xj/0Mmh/+CKb/AOS6P+Ed8Y/9DJof/gim/wDkuj2kQ5WX68Uvfg94v0bVNUj+Hvia307RdWJNxbT5DRg5yFwjdATggqcYHbNeuf8ACO+Mf+hk0P8A8EU3/wAl0f8ACO+Mf+hk0P8A8EU3/wAl1LlBu7KXMlZGT4B8GW3gPwnDo1rM1wwYyzzsMeZIepx2HAAHtUvgH/kmvhn/ALBFr/6JWtH/AIR3xj/0Mmh/+CKb/wCS6wfAmg+K5vh14bltdf0aKB9KtWjjk0aV2RTEuAWF0AxA74GfQdKp1E3clRsjraKof8I74x/6GTQ//BFN/wDJdH/CO+Mf+hk0P/wRTf8AyXR7SIcrL9FUP+Ed8Y/9DJof/gim/wDkuj/hHfGP/QyaH/4Ipv8A5Lo9pEOVl+iqH/CO+Mf+hk0P/wAEU3/yXR/wjvjH/oZND/8ABFN/8l0e0iHKy/RVD/hHfGP/AEMmh/8Agim/+S6P+Ed8Y/8AQyaH/wCCKb/5Lo9pEOVl+iqH/CO+Mf8AoZND/wDBFN/8l0f8I74x/wChk0P/AMEU3/yXR7SIcrL9FUP+Ed8Y/wDQyaH/AOCKb/5Lo/4R3xj/ANDJof8A4Ipv/kuj2kQ5WU/E/g7QvGVpDbeJLH7ZDA/mRr5zx7WxjOUYE8V5nrH7PukzeNdKudFsrS38PxL/AKfaSXc5kmOT9089sfxDpXrH/CO+Mf8AoZND/wDBFN/8l0f8I74x/wChk0P/AMEU3/yXU3he47StYytcgjtdV8HW8C7YotUZEXJOFFhdADmukrkvEOg+K013wqs2v6M7yaq6xMujSqEb7FdHLD7Udw2hhgEckHPGDvf8I74x/wChk0P/AMEU3/yXVe0V7sXLYv0VQ/4R3xj/ANDJof8A4Ipv/kuj/hHfGP8A0Mmh/wDgim/+S6PaRDlZfoqh/wAI74x/6GTQ/wDwRTf/ACXR/wAI74x/6GTQ/wDwRTf/ACXR7SIcrL9FUP8AhHfGP/QyaH/4Ipv/AJLo/wCEd8Y/9DJof/gim/8Akuj2kQ5WX6Kof8I74x/6GTQ//BFN/wDJdH/CO+Mf+hk0P/wRTf8AyXR7SIcrL9FUP+Ed8Y/9DJof/gim/wDkuj/hHfGP/QyaH/4Ipv8A5Lo9pEOVl+iqH/CO+Mf+hk0P/wAEU3/yXR/wjvjH/oZND/8ABFN/8l0e0iHKzgvHvw01fVfFtr4t8D6vFpOuwx+VIZx+7lXGAfutzgkEFSDx0xza+HPw4vfDGqaj4h8Uamuq+IdSG2aaMHZGuQcLkDOcDsAAAAOK7P8A4R3xj/0Mmh/+CKb/AOS6P+Ed8Y/9DJof/gim/wDkupjKMXdf1fcbTkrP+rEngj/kK+L/APsNJ/6QWlFQ+A7XULXUPFsN/d2txcrrKeZLBatEjf6DaEYQyMRwQPvHkE8ZwCsnqy1sVPCX/IKvv+w1qn/pfPXA/FX4r6x4Q8RW+j+FrKzvrhbR7u8+0Ru/lIMkfdZcYVWJz2xXe+FWCaRfs5Cqus6oST2H2+evnbRPiZ4bh+JPirxD4ps72+j1RHtLVLaJHAgJ2kNuZf4FQd+prSUnok+jf4afiJLRt/1/SPorwZ4jj8WeDdN1qPYGuoA0qIeEkHDr+DAirWpeI9E0eZIdX1nT7CWQZRLq6SJm+gYjNeN/s4eJopIdZ8NIzmOCQ3ln5mAxjJ2sCB0wdp4J5Y1m/DLwVo/xRbxRrnjJJrrUJLxo0Pnsn2fIzkAEdM4AOQAoGK0lJt3iul/+B95nFJJ3ezt/XyPoVJY5IVljdXjZdyupyCPXPpWdZeJtB1K+az07W9Ou7pc7oILuN3GOvyg5rxnx1Zf8IJ+z6ul+Htel1a0vL1Ymu1kUqsbAsyIVzhSU6ZP3m9a1/wDhSfg+303w9e2eqT6Heo8T/bVufnupCu4Bd52q2RkbR0B4PZp3k0tlZfeDVoq+7v8AgerSaxpkOrRaXNqNpHqEy747Rp1ErrzyEzkjg847GifWdLttUh0251Kzhv5xuhtZJ1WWQc8qhOT0PQdjXk3iRxH+1X4X3ZP/ABLyPzWcVF40kVv2ovCCqQWS0G4enM1JSu4+bt+Y5K3N5JM9WuPFPh+0luY7rXdNgktCBcLJeRqYc9N4J+XPvUl34h0WwsYb2+1ewtrScAxTzXKJHID/AHWJwfwrwqw8H6T4z/aN8U2evxPcWdupnMCyMgdsIoyVIPG41teL38H2fxItbG20DU/FOr6fYrbQaJFGj2VrHtGNwZSQcEHPIGRnnFSptwjJ9f8Agg0uZpdP+Aex2Go2Wq2i3Wl3lve27HCzW8qyIfoykiql14n0Gx1AWF9renW14cYt5ruNJDnp8pOa8K+E+oXmi6h8SZLay/s6SzgkuE04OJFt5FMhCZAwcdMgdqX4efC/w14z+Fl3r3iG4kTVLqWZ31OW4b/Rtp+8RuCkcEnd6nkU1JvVLpf8bBy20fe36nvc2taXbapDptxqVnFf3C7obWSdVlkHPKoTkjg9B2NF9rGmaZNbw6lqNpZy3TbLdLidY2mbgYUE/MeRwPUV4z8TPDH/AAi/gXwr4i0S+m1SXw1PHtvJHDGSEtlcleNoYKo9jirUNzH8R/2gdPurU+dpHh+wjulbIKmSRQ6n65df+/dUneXL5/ha9xPSN/L8b2/ryPaaw/Fv/IKsf+w1pf8A6XwVuVh+Lf8AkFWP/Ya0v/0vgolswW531FFFcpqFFFFABRRRQAVzPj3xgvgnwz/aCWbX95cTx2llaK20zzucKuew6nPtXTUyaaK2t5J7iRIoYlLvI7BVRQMkknoAKTGjy+48beP/AAfqGmT/ABA0nQZNG1G7jtDPo8svmWbuflMgk4Ydjt9OvQHU8b+KvFVr400fwv4Fh0eS/vLWa7uH1ZZTHFGhUKcxnIySw6Ht0rKnlm+MPiCw/s+J4fBej3q3T3kqFTqs8edqxA9YlPVj1PA6Zqz4i+Gnh/xx8UJtQ1vXPta22nJazaFbTmJgpYuGlZH3bSTkDA5AOTinq7X8/utp+P4C0V7dl999fw/E6bwj/wAJxm7/AOE8/wCEfx8n2X+xvP8Afdv83/gOMe9b1/eRafp1ze3B2xW8TSufRVBJ/lXmHgex/wCEH+MGp+CNJuLiTQZdKTUra1nlMgsn8zYyKTyFOc4P/wCvufG1rb33gfWLO91WDR7e6tHgkv7jGyAONu45ZR39RSqX5Lx7f8D80OHx2kcD4b174y+KPDtjrdjB4It7W+jE0Ud0t4sgQnjIBI5HPXvXQeOfG2s6Trml+F/B+mW+o+IdTjaYG6crb2sSnBkfHJGcjAIP44B4rxB8HNC8JfDefX9E1PUE8RaNYfaINaW8cNJ5a5C7dxURkDAUDpgZPfY1Cw8U6nP4T+JfhSytr7UzpKQ3+lTSCD7RFKofCOeFIYnrx/I3K19Nk9fxt+K1JV7X6tf5X/PQ3/DXi7xBD4qTwr4/sdPttVuLdrmyu9Lkdra6RT86gP8AMrrkHB6jJ476tj/yVPXf+wLpv/o++rziW48U6v8AHnwPdeJLC20dktr100uG6+0PCnlYLySABSWYgAAYG3qTXo9j/wAlT13/ALAum/8Ao++pfZT9fzYbSa9PyOkooopDCiiigAooooAK8+8Q+M/E1742ufCfw9sNMmvbC3S4v73VpJBBBv5SMLH8xYjnPSvQawPF3jHS/BumJc6kZJZ528u0sbdN893J2SNByTyPYZ5pPTcaMbwL401fWNc1fw14u023sNe0gRvIbOQtBcxuPlkj3cgex9fXIHO6N4q+KnjBb7UvCkPhCPR0v57e0bUVuhLIkblQ52Eg5x145B4Fbfg3w5qdlJr3jDxfNBY6zrUYLRhgY9Nt0U7IyxwCQOWOQCR+Ncro3wD8KL4IimXWrvVNQSJ5rLXLa7eNYSSWVoVVygXPPfJyc88EnbWXRa/18vS97AtdI9Xp93+f4bnsGm/bv7Ltf7Y+z/b/ACV+0/Zd3leZj5tm7nbnOM84qS5uYLK0luruVIIIUMkssjbVRQMkknoAK5L4S+IL7xP8K9E1TVXMl5JE0cspHMhR2Tf+IXOfeuK+L/jvQh4rsfBHiTU20rRmRb3VZxFI5uUDfJbKEUkBiMseOBjPaqqXUuXzJhrG7Ol+GnxKuPiBrfiRfsa2um6fLCLFmjZZZYnViHfJ6MAGGAOD361mWnjf4heMY7vV/h/pGg/2FbzyQwHVZpRPfbDgtHswqAkEDdWR8LvHnhXU/i/4st9H1BXTV2tTpqLbSIJEhgIfGVG0Ljoce1dv4y8cTWN8PDHhGAan4puk/dwjmKxU/wDLedv4VGcgdW4A60paJW6pW9f6+Q1u79/wNLwF4vj8ceD7bWktXspXZ4p7VzkwyoxVlz35GfoaT4cf8ks8Kf8AYFs//RCU7wJ4Tj8FeDrPRUnN1LHukuLhhgzTOdzt+Z49gKb8OP8AklnhT/sC2f8A6ISqla+glsdJRRRUjCiiigAooooAK808QfF61t/Hei+GvDSJqLXOppZ6jebGaG2znMQcEAy8ZxzjacjPT0uvM/iXZ21jrXgGOyt4bdG8URyMsSBAWZHJbA7k8k96F8cfVfmhS+CVuz/I6H4g+MZvB2i2r6dYjUdU1K8jsbC1Z9ivK/Tc3ZQAT/h1GDpPjTxlovjPSvD/AMRtO0dRrQkFje6M8pRZEXcY3WTJzjuOPryQz4y51S10DwvYQxnWdXv92n3bzNH9heFd5nBXkkA4A75rn7zSde8F/ErwrrXjzXh4utri4/syznNuLVtPnlBAcRISrhgMFjz+Qohq9e9vw29b/wBdBy0Xyv8Ai9fT/gntlcX8UPiBF8PvCcl5DEt3qs4ZbGzILeYyjczkDnYi/Mx444yM12FxOlrayzzHEcSF2IGcADJr5lu/if4P8SaZ4s8Q69rGzXdQ06fT9I0s20zCygKkAbwmzfIfmY5wAQM9RUSbs0u39feXFK6b/r/hj2fWPiGdA+FWneKbyy+1319b2/k2VvlRNcTKMIpOSBkn14Hc1jxeM/HvhdrK/wDiPpGiR6Nezx27y6VNIZdPZzhTMHJVlyQCUPHXnpWda2Vv8UfgTo0PhDUov7R0b7K8Es0TqiXcCKSjZAOOcbhkc96wvivqnxA1v4ZT23iDw7ZeHIhc28bMuoLcvfSGRQqxKg+QZ+Y7iTgY9TWzVqjX95fdp/wfwMo6wWvT8f6/W56z4o/5GLwZ/wBhqT/033ldJXM+JAV17wUG6jWJAf8AwX3ddNUDWquFFFFAwooooAKKKKAKOs61pvh7SZ9T1u8isrKAZkmmbAHoPck8ADknpXIfDj4iT+PdW8Rg6e1jZadPClms0TJM6Ohbe4J74BGAOCOvWu3urO2voRFe28NxGGVwkyBwGByDg9wRkGvP/h//AMlT+JH/AF/Wn/pPRHd37fqhS0St3/R/5Dda8Z+MNW8b6l4b+HWn6O7aPHG1/e6zJJ5e+RdyxosfOcc56dRxwTt/D7xlP4v0u+XVLAadq+lXj2V/bI+9FkXujd1IOf8AHqeEj0nXvGfxS8Tat4F1xPCUNjINMvrlYBdtqE0YHzNExCLtB2huv5nGz8Gs6RJ4k8K6jEra5pd8J9QvklaQX7TLuWYluQxAwV6DHvRDVfK/4rX0t+nqOej072/D/P8Aroek3l5bafZzXd9PHbW0CF5ZpXCoijkkk8AVwHg74pL41+I+o6PpdoV0W209bm3u5onR7pvM2l0zx5fUDjJIPPavQLm2gvLWS2vII7iCVSskUqBlcHqCDwRXnunIsf7SOppGoVV8MwBVUYAHnniiPxq/n+TFL4Hby/NFnxR408QyeMf+ER+H+m2N3qsNut1e3mpSMttaIx+VWCfMzN6Dpx15xf8ABev+Kb2/1DSPG2hx2V9Y7WS+sVc2V2jd42bkEd1JzXnthoWreJfjl4/06PxDe6HZA2clw+nMsd1MPJxGFkIJRRyTgZOQK6PwTdaz4a+J+peBNT1q616xGnLqVld3zb7iFS+wxyP/ABc8g+3bpRDZeav+v4fiOejflb9PzOq8L/8AIxeM/wDsNR/+m+zoo8L/APIxeM/+w1H/AOm+zooA5K20u41vwLrul2d8bCW81PVYRciPeYw19OCQMjnGe9WfAHgyDwH4Sh0WC4+1ssjyS3Hl+X5jMeu3JxgYHU9KwdJstUk/tNrXxNqdlEdZ1LbBDDalV/02bOC8LNyeeSevYcVf/s/W/wDoctY/78WX/wAj12Qpu111RhKS2fQiufhtu+LUHjiw1X7K4jEdzZ/Ztwn+UqTv3DHG3seVrB1z4HC68QX2peF/FV/4dTUWLXltbqSkhJyQNrrwcng5HPpxXR/2frf/AEOWsf8Afiy/+R6P7P1v/octY/78WX/yPR7HS1v6Y/af16EOm/CPw7YfDu48IsJp7e7bzJ7liBK0vGHHGBjAwPTg5yc8tafs/B7mzi1/xhqWraRZPug050KqgH8IJdgB2O1Rx6V1/wDZ+t/9DlrH/fiy/wDkej+z9b/6HLWP+/Fl/wDI9P2b5uawudWsUvH/AMJrbxnqVhqun6tPoep2KCKK5t03fIDlcAMpBBJwQR1+lZejfBBdI8a6X4lk8TXmoXloxe5a8iMj3L4K53l8qACODu6dfTof7P1v/octY/78WX/yPR/Z+t/9DlrH/fiy/wDkehUmndLzBzTVn6C6F8Pf7F+JmteLv7T8/wDtSPZ9k+z7fK5U537jn7voOtUNa+F11cePJfFnhfxNNoF/dReVdAWiXCyjAHAYgDhR1B5APFXv7P1v/octY/78WX/yPR/Z+t/9DlrH/fiy/wDkej2TslbYOdXb7lXwT8LV8F+I9Y1Fdal1ODVYwssN3ADIWzks0gOGyS3G0dfbnmbv9n3bNd22h+MdS0vRrt902mKpdG9iQ4BHYZUnjvXYf2frf/Q5ax/34sv/AJHo/s/W/wDoctY/78WX/wAj0vY7K2we0313Mfxf/wAId8OPhQ/he+klitbuzmhtk8ppJJ5MZLFgu0NuYHJwPTpVL9njwy2jeAZNUuYtk+rzeYuRz5KjCfmSx+hFa+peE5daEQ1jXrzUBCS0X2qw0+XYT1I3Wxx07VdXTdZRAieMNXVVGAot7IAD/wAB6apyUnJ9dPkDlGyiuh21Yfi3/kFWP/Ya0v8A9L4Kxv7P1v8A6HLWP+/Fl/8AI9QXeh6nfRJHdeLtYkSOaKdR5NmMPHIsiHi37MinHQ454odOTQc6PXqK8xx4k/6HbWP/AAGsf/kajHiT/odtY/8AAax/+Rqx9hMv2kT06ivMceJP+h21j/wGsf8A5Gox4k/6HbWP/Aax/wDkaj2Ew9pE9OorzHHiT/odtY/8BrH/AORqMeJP+h21j/wGsf8A5Go9hMPaRPTq5L4keDL7x54VOiWOuHRo5Jle4kFt53nIM/uyNy8E4J65xiuex4k/6HbWP/Aax/8AkajHiT/odtY/8BrH/wCRqTw83uCqxRJZeA/iLYrbwxfFNFtYAqrbx+GbVFCD+EYPAwMcdK0/FXw8udW8Sx+JfC3iK48Na6IPs0tzFbpcR3EWcgPE2AxHY54/AYyMeJP+h21j/wABrH/5Gox4k/6HbWP/AAGsf/kaqdCbEqkUdD4K8Bp4VuL/AFPUNVudc13Uiv2zUrlQpYL91EQcIg/ujP5AAV/DlhdeKvButab4vvDrFpd3lzbRTtbrb+Zbg7RhVHZg2G5JwDmsbHiT/odtY/8AAax/+RqMeJP+h21j/wABrH/5GpPDze/aw/axWq3vf+v66EI+DmrXdnDoeueP9T1HwrAVC6UbaOKSSNT8sclwp3OvTIwPbGBjo/F/gD/hILjStQ0LVpvD2saOGSyvLeFZVRGADI0bcMuB04xWFjxJ/wBDtrH/AIDWP/yNRjxJ/wBDtrH/AIDWP/yNTdCoxe0ibfhH4fPoOuXXiHX9cufEXiC6hEDX08SxLFEDnZHEvCAnBPv6ZOb9j/yVPXf+wLpv/o++rlceJP8AodtY/wDAax/+Rqqx6drUWqz6knjHWBd3EMcEsnkWXzJGzsgx9nwMGV+QMndz0GD2Ew9pE9YorzHHiT/odtY/8BrH/wCRqMeJP+h21j/wGsf/AJGpewmP2kT06ivMceJP+h21j/wGsf8A5Gox4k/6HbWP/Aax/wDkaj2Ew9pE9OorzHHiT/odtY/8BrH/AORqMeJP+h21j/wGsf8A5Go9hMPaRPTq8z8RfDDxLq3xEk8WaR46XS5lhEFrC+jR3X2WPA3BTI+AWOSWAB5x0puPEn/Q7ax/4DWP/wAjUY8Sf9DtrH/gNY//ACNR9Xne4e1jax0Hhnwz4qsJ7oeL/Ga+JrO4gMQtW0iG1CknkkoSWyMjB9a5gfBzV7Wxk0HSfiBqlj4UlYg6UtrG0qRsctGlwfmVevGDwec5OZ8eJP8AodtY/wDAax/+RqMeJP8AodtY/wDAax/+RqPq8w9pFG14psrrwv8AD6z07wRdnSpbWW3trREt1nMoLBfLw2eucl+SME12leY48Sf9DtrH/gNY/wDyNRjxJ/0O2sf+A1j/API1P2FR7i9pFbHVaL4SbRvF3iXXUvhK2uNAwhMOPIMUezru+bPXoK4bRvhH438P3F/PpHxQEE2ozm4upW8PQSPK59Xdy2B2GcDsKv48Sf8AQ7ax/wCA1j/8jUY8Sf8AQ7ax/wCA1j/8jUvq8/wt8h+1iztvC+m61pWj/Z/Emv8A9v3nmM32v7Glr8pxhdiEjjnn3qn8OP8AklnhT/sC2f8A6ISuVx4k/wCh21j/AMBrH/5Gqrpuna1pGlWmm6f4x1iG0s4Uggj8iybYiKFUZNuScADknNP2E2L2kUesUV5jjxJ/0O2sf+A1j/8AI1GPEn/Q7ax/4DWP/wAjUvYTH7SJ6dRXmOPEn/Q7ax/4DWP/AMjUY8Sf9DtrH/gNY/8AyNR7CYe0ienUV5jjxJ/0O2sf+A1j/wDI1GPEn/Q7ax/4DWP/AMjUewmHtInp1c54q8J/8JNf+H7n7b9l/sbU0v8Ab5W/ztqsNmcjb97rz9K5THiT/odtY/8AAax/+RqMeJP+h21j/wABrH/5Go9hO9xe0i1Y6jxv4ItPGum20Ut3cadfWM4ubG/tWxJbSjoR6j1Hf261haV8M9Ul8SWOs+O/GFx4ol0xvMsbf7FHaQxSf89CiEhmHYnpVTHiT/odtY/8BrH/AORqMeJP+h21j/wGsf8A5GoVCad0N1Ivc6e0udXb4oahbHUWn0ePTo3+y/ZlUW8zPgfvMZYsqscZ4GOORWp4l0b/AISLwtqejef9n+32slv52zf5e9Su7bkZxnpkVwmPEn/Q7ax/4DWP/wAjUY8Sf9DtrH/gNY//ACNSeGm48rGqqUuZHSaj4CsdZ+Gtv4P1O4laKG1hhW6hHlyK8QXbIvXByucc+lYdh8LtUutb0+/8deM7vxNFpUomsbNrOO1iWQfdeQIT5jDsT/Uiq+PEn/Q7ax/4DWP/AMjUY8Sf9DtrH/gNY/8AyNVexqc3N1I54cvL0Oq8Uf8AIxeDP+w1J/6b7yukrye607Wr25sp7nxjrDy2Mxnt28iyGxzG8ZPFvz8kjjByOc9QKtY8Sf8AQ7ax/wCA1j/8jUvYTK9pE9OorzHHiT/odtY/8BrH/wCRqMeJP+h21j/wGsf/AJGo9hMPaRPTqK8xx4k/6HbWP/Aax/8AkajHiT/odtY/8BrH/wCRqPYTD2kT06ivMceJP+h21j/wGsf/AJGox4k/6HbWP/Aax/8Akaj2Ew9pE9OrnPD/AIT/ALC8VeJNZ+2+f/bs8M3k+Vt8jy49mN2Tuz16CuUx4k/6HbWP/Aax/wDkajHiT/odtY/8BrH/AORqPYTTv/X9aC9pFl3WPhpqQ8UXuveBvF1z4YutTwb+L7HHdwzsBgOEcgK3qf5ZOdLwt4Ig8F6FqjR6tPc6rqG6e91m7AeR5NpAYr02r2XpWBjxJ/0O2sf+A1j/API1GPEn/Q7ax/4DWP8A8jUvq8+Wy9B+1je7Ou8CXGq3fgfS7jX7h7q/liLyTvAIWkBYlGKAAKSu3jtTIPCfk/Eq68W/bd32jTUsPsvlfd2yF9+/PPXGMfjXKY8Sf9DtrH/gNY//ACNRjxJ/0O2sf+A1j/8AI1U6E+a4vaRtY2PFXw8m1fxEniPwx4gufDWuiEW8t1DCs8dxEDkLJE3DY7H+eBix4M8B/wDCM319rGravca9r+ohVutRuIxH8i/dRI14Re+B3/AVz+PEn/Q7ax/4DWP/AMjUY8Sf9DtrH/gNY/8AyNSWHmthurF7nVeF/wDkYvGf/Yaj/wDTfZ0VkfDZLtpPFP2zUri8n/tld9xMkSs/+hWuMhEVeBgcAdPXJorFqzsWndXMPQf9RqX/AGGtT/8AS6etSsvQf9RqX/Ya1P8A9Lp61K9On8COSXxMKKKKskKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArzD4q+JfEukeI/Dul+FtRSyk1N2iJkhR1LFkVSSysQBu7V6fXkfxX/5KZ4D/wCvwf8Ao2Osp6uK7tFx2b8itrOqfFbwJarrOuX+na1p0bqJ44Y1G0E45IjQjJOMjODjIr0q38W6TL4Rt/Ed1dR2dhPCsu+ZgNuf4fds5GB3FYfxe1C1sfhlqkdzIiyXKLFDGzDLsWHQd8Dn8K8g8Q217beAfh9YXTRLazNLMwuywhy0gK7yOQu1+3OCaz53FuK12/G5fKpJP1/A928P+OvDfimd4NC1WK5mQZMRRo3x6hXAJHuKXxB448N+Fpkh13VYrWWQZWIK0j49SqAkD3NeZ/8ACG6va/EDQb+5uPBWi3MEqstrpk0lu91GW5whHzEjcBjrnBp/hLTtN1741eLl8UWtve3MTkW0N2gcbA2MhW4OFCc9garnk7RW7v8AgTyxV29tPxPSZ/EdlqvgrUNX8ParAUjtpWjuwCywuqE5ZcE8cEjaT7Gs7wf4lH/Cu4da8Sa7aXiqX83UEQxRsA5AABRDnoPu8n1rCs9P8HaZ4L8ZQeDbxZpDbXH2uPzi3lkI4ACnooyQCBz6muWsNGt9e/Z40yzn1iy0qUXjyQPfTiKORg7/ACEn2JPGelDnK7a7L8yuVWSfd/ken6L8R/CfiHUVsNJ1mKa6b7kTxvGX9l3qMn2FUNZ1vULb4s6NpUOu2tvZXFuXl014GMk5/efMH8sgDgdXH3Tx6+aajqviLRNZ0ST4m+GoL6G1mCWd/DIYnQ5BBDRNtONuQrKM47c11Xifn9o7wt/14n/2tTUm3H1t+AuWyl6XO88QeMfD/hUR/wBvanFaNIMpGQzuw9dqgnHvjFTaD4m0bxPaNc6FqEV5GhAfZkMmem5Tgjp3FeU6BYaXr3x38SR+Loobq4hJWytrrDIyg4GFPBwmDjB6k+9S6TbWej/tHvZeF1jis5LRvtsEHEcbbCSMDgYYJx2JpQqOXK3tK/6/5ClFK6XQ72f4leELX7b9p1qKJrGbyZ1eNwwfJBCjbl+h+7mtXQfEmkeJ7E3ehX0d5CrbWKgqVPoVIBH4ivJ/hx4b0nXPiP4zuNY0+3vvst4yxJcIHVd0kmTtPBPyjntVv4Q2sWn/ABG8a2Nmvl20NxsjjB4UCRwB+AopzlJx5vtK/wBw6kVHmt0dvvPTfEt5Pp/hTVryzfy7i3sppYnwDtZUJBweDyO9eTeFZ/i34u0CLV9N8U6dFbyMyhbiCNXypweBCR+tep+Mv+RF13/sHT/+i2rxz4deAde1/wAGW9/pvjnUdHt3kkUWluJNikMQTxKo569KmXM6rSvt38xqypp+f6HqGlX+q+EvCM998SdYtp5Ipstc20RKqh2hRtWNTnOf4e9bF14l0my8NDxBdXezS2iSUT+W5+R8bTtA3c7h2rhviJpd1ovwKu9Pv9Sm1S4h8sPdzZ3y5mB5ySe+Op6VQ8U6laj9muzVp4w09lawxLvBLsrJkD1I2nPpg1UqjipeVhRgm4363O/vfGvh/T9CstZvL/y7C+ZVt5vJkO8sCRwFyOAeoFVF+JXg9tZXS1162a6ZtgADFC3p5mNn615b48Gf2f8AwiPV4f8A0W9XPjF4R0PQPh5pkulaZbWlxFdRxGaJAHcGNidzdW5UHJpTqSi5Poml+QRgpKPdpv7j17W9f0rw5YG91u9is4M4DSHlj6ADkn2ArP0bx34a8QQXMukarHcC1jMsy7HV1QdW2sAxHuBXm/jpYdQ+KPgmy17a+lPbIxWZsI8hJzk98kIDXWxeHfAGm/EZRB9ltNaktsLYRny4mVgyn92AFJK5yvPHOO9XzTbdrbtfcTaNl6J/eZfhT4v2mv8Ajq9026nigsndYdLCQuWuDuI3McfLkY4OMZra8Ga3qGpeMPE1pe67a6jBZ3GyC1hgZGtRvcbWJjUMcADhm6dfXjvhfpGmt8VPGAbT7Uixuz9lBgX/AEfErgbOPl4A6Yp3giS4h8WfE6WxBNykkrQgf3w0uP1rKFRqMZPtJmkoayS7pHe6t8SfCOh6k1hqetwx3Kna8aI8mw+jFFIU+xrZOuab/YT6yl5FLpyRNMbiI712L1I25zjB4HNeTfB3w/4U1jwXeXesWtlf37TSfa3uwrvEvY/N90Yydwxznnis7wFIw+G/xAtbWRpNKhWb7IzHPVHzj8AhqnUlGLvva5KjFtW72PSpvir4Kt7e3nl16EJcjdGBFIzYzjLKFyv/AAICuos7y21Cziu7GeO4t5lDRyxtlWHqDXjHhHwhoVx8BL3U7rTLaa+ltbqb7S6BpEZN4Xax5XG0cCuu+CTM3wtsQxJCzTAZPQbzWkZSc3GXa5EklFSXexb+KPjS68FeGornTYI5bu6nEETTfcj4JLHpnpwM+/bFcnPd/F7QrOHWZLuw8QWrlS1lZwCRtrdxsjUke4J9eRXU/FDVfDNpo9pp/jGxuriyv5tqS26j9w4xhiSwI4J6Z4B47VwfiH4fP4B0GfxF4P8AGd1awRhZEgkkGLg5GAGUhWPoCpzWMpNOUr6L8PkapJpLqdV8T/GWs6L4C0rV9FaXSrq7njEkU0Ks8YaNmKMrqcEEenaugi+I/hQapFpM2uW/287UZcNt3kdN+NgOeMZ68V5r8S9aufEXwS8O6pfoEuLm6UyBVwCQsgyB6HGfxqT4veE9D0L4caVPpOmW9rPHcRxGaOMB5FMbE7m6tyAeaqU5Qc30TX5LYSipKK6tM9b17xLo/hiyW616/js4nbahYFix9AoBJ/AVB4e8ZeH/ABV5v9ganHdtFy6bWR1HrtYA498Yrh/F+uWS+LPDdlZ+HjrvidbZZrRpboxRwZBO4jO1j8pPIGMDmsXwWdU/4aF1I65FaQX72RaeOyJMYJWMjryTjGffNWpv2nK9rtfcRb3L+j+89Cn+KHg21+1faNbjja0mMEqNFJuDgkEBduWxjkrkD8RW1ofiHSvElh9s0O+ivIM4LJkFT6FTgg+xFeOfDLRtA1j4keLV1y1tby5jupDbQXShwVMj7yEPBIwvPbPvVXSG/sjxh8Q7bwi2NPi0yZ4xAdypIuMYPsWkA+lZRrS5VKXVN/cW4LmaXRpfeeq3PxN8G2mrnTbjXrdblW2N8rFFPoZANo/PiupVldAyEMrDIIOQRXzf4W8LXus/DOaWCPwbFZszrNf6iZFurds4GZMYTtgdMEZHJr2z4e2Vxp3gLTLO6vrTUGhjZFubOYyxOm47drEDOBgfhW0JN/F5GcklsdLRRRWhIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBe+HP+v8V/8AYaX/ANIbWij4c/6/xX/2Gl/9IbWivLqfGzsj8KOd0H/Ual/2GtT/APS6etSsjQvCGl6lBqN3dSamJZNZ1LcIdWuoV4vpgMIkgUcDsOevU1qf8IFon/PXWP8Awe3v/wAershUtFKxhKGo+imf8IFon/PXWP8Awe3v/wAeo/4QLRP+eusf+D29/wDj1V7TyFyD6KZ/wgWif89dY/8AB7e//HqP+EC0T/nrrH/g9vf/AI9R7TyDkH0Uz/hAtE/566x/4Pb3/wCPUf8ACBaJ/wA9dY/8Ht7/APHqPaeQcg+imf8ACBaJ/wA9dY/8Ht7/APHqP+EC0T/nrrH/AIPb3/49R7TyDkH0Uz/hAtE/566x/wCD29/+PUf8IFon/PXWP/B7e/8Ax6j2nkHIPopn/CBaJ/z11j/we3v/AMeo/wCEC0T/AJ66x/4Pb3/49R7TyDkH0Uz/AIQLRP8AnrrH/g9vf/j1Y3ijwhpunaRBNZ3OsRyNqNjAW/tu8OUkuoo3HMvdWYZ6jPHNHtfIOQ3KKZ/wgWif89dY/wDB7e//AB6j/hAtE/566x/4Pb3/AOPUe08g5B9FM/4QLRP+eusf+D29/wDj1H/CBaJ/z11j/wAHt7/8eo9p5ByD65Lxp8OdI8dTWkmr3F7CbRWVPsroud2M53KfSuq/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMeqZSUtGhqLWzPOdM+BXhDT71LiX7dfhCCIrqZShPuFVc/Q8V2HiPwrpPirRv7M1e23wKQ0ZQ7WiI4BU9uOPStb/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6jmjy8ttB8rve5xfhT4TeG/CGqDUbEXV1dqCI5buQN5WRg7QqqM47kGn+LfhX4c8Y6gL/AFBbm2uyArzWkgUyADA3BgQcDvjNdj/wgWif89dY/wDB7e//AB6j/hAtE/566x/4Pb3/AOPUm4tWaBKSd0zmtG+H2haD4ZvtE0yKWOHUI2juZy+6Vwylc5IxwDwMY9utJb/DvQYfBKeFbiOa805GLqZ3HmBixbIZQMEEn8ODmum/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMepuUXuhcrXU4uy+FWi299a3N/qGsautkQ1rb6jeebFCR02qAOmBweOK1r/AMGafqHjWw8UTTXS3thF5UUaOojI+bqNuc/OehHat7/hAtE/566x/wCD29/+PUf8IFon/PXWP/B7e/8Ax6hTS6Byvucn4u+GPh3xncrdalFNBeABTc2rhHcDoGyCD9SM+9WvCPgLQ/BUEi6NA5mlGJLmdg0jj0yAAB7ACui/4QLRP+eusf8Ag9vf/j1Y1t4Q02Txvqenvc6wbWDTrOeOP+27z5XkkuVc583PIjTjpx7mhSjF3SG4tqzZF4d8Gaf4Z1bV9QsJrqSXVpvOnWZ1KqcsflwowPnPXPak0HwVp3h3xBq2sWU11JcatIZJ1mdSincW+UBQRyx6k1v/APCBaJ/z11j/AMHt7/8AHqP+EC0T/nrrH/g9vf8A49QppWsthOLd7vcg1Owi1XSbvT7hnWK7heF2QgMFZSDjOeeaoeFfDNn4R0CLSNNlnlt42Zg1wwZ8scnkAD9K1v8AhAtE/wCeusf+D29/+PUf8IFon/PXWP8Awe3v/wAep+0V72DldrXK2raVZ65pNxpupwie1uE2SIe49QexB5B7EVwEPwG8IRQ3CF9RkaZcLI865h56rhcZ7cg16R/wgWif89dY/wDB7e//AB6j/hAtE/566x/4Pb3/AOPVMnGTu0NKSVkzlNW+G+kax4Q07w5dXN6lnpxUxPHIgkbapUbiVI6HsBV7xf4O0/xposWmapNcxQxTLMGtmVWyAR/EpGPmPat3/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6m5JpprcFFq1nsYHiXwNovizR7fT9XikZbYYgnjbbJHwAcHGOcDIIxx0rO8JfCzw54N1A32nLc3F5tKpPdyBjGD12hQAM+uM/ma7D/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6nzrm5rai5Xy8t9DjJvhT4el8ar4nRryG8W4FyYo5F8ppAc7iCpPJ5ODWroHgzT/DuuavqtlNdST6tL5s6zMpVTuZvlAUEDLHqTW9/wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1KMox2Q3Fvdnn+sfBLwlrGqPehbyxaRtzxWkqrGxJyThlOPoMCunh8IaRaeEZ/DlhAbSwnheJ/KPzncMFsnOW9zmtn/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6knFJpR3BqTd2zD0zwfp+leCW8L281y1i0MsJkkZTJtkLFuQoGfmOOKm8K+GbPwjoEWkabLPLbxszBrhgz5Y5PIAH6Vrf8IFon/PXWP8Awe3v/wAerG8IeENN1TwRoeoX1zrEt1d6dbzzSf23eLvdo1ZjgSgDJJ4HFV7RXvbUXI7WuW9d0HTfEmlSadrNstzbOQdpJBUjoQRyDXB2vwE8IW94JpX1K6QHPkS3ChD/AN8qG/WvSv8AhAtE/wCeusf+D29/+PUf8IFon/PXWP8Awe3v/wAeqW4t3aHaSVrnO+KPAuk+K9BtdHuzPaWlo6vCtmVTbtUqF5UjGD6VJ4s8Gad4x0KHSdTmuooIZVlVrd1ViVUqMkqRjDHtW9/wgWif89dY/wDB7e//AB6j/hAtE/566x/4Pb3/AOPU3JO91uCi1az2OW8Q/DrSPEV1Y3ctxfWN9YoI4byxnEcu0dATg+p5AzzUei/DPRdA8Tpr2n3OofbPKMcvnXHmCcnq7lgWLHg8EDjpXW/8IFon/PXWP/B7e/8Ax6j/AIQLRP8AnrrH/g9vf/j1HNG/NbUXK7WueCeC/A+j+N/EnjS31lZlaDUN0M8D7XjzJLnGQRg4HUGvXfCngnRfBumy2ejwMfOIM80xDSS4GBuOAMdeAAOT61vf8IFon/PXWP8Awe3v/wAeo/4QLRP+eusf+D29/wDj1TBqEUrdLFSTlJu553c/Avwfc6sb3bewxs+82kUwER9R93cB9GHtivQbS0gsLOG0s4lht4EEccajhVAwBT/+EC0T/nrrH/g9vf8A49R/wgWif89dY/8AB7e//HqqMlFWiiXFt3bH0Uz/AIQLRP8AnrrH/g9vf/j1H/CBaJ/z11j/AMHt7/8AHqr2nkLkH0Uz/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6j2nkHIPorD1vwhptpq/h6G3udYSO81F4J1/tu8O9Ba3EgHMvHzRocjnj0JrZ/wCEC0T/AJ66x/4Pb3/49R7XyDkH0Uz/AIQLRP8AnrrH/g9vf/j1H/CBaJ/z11j/AMHt7/8AHqPaeQcg+imf8IFon/PXWP8Awe3v/wAeo/4QLRP+eusf+D29/wDj1HtPIOQfRTP+EC0T/nrrH/g9vf8A49R/wgWif89dY/8AB7e//HqPaeQcg+imf8IFon/PXWP/AAe3v/x6j/hAtE/566x/4Pb3/wCPUe08g5B9FM/4QLRP+eusf+D29/8Aj1H/AAgWif8APXWP/B7e/wDx6j2nkHIPopn/AAgWif8APXWP/B7e/wDx6j/hAtE/566x/wCD29/+PUe08g5B9FM/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMeo9p5ByGj8Of8AX+K/+w0v/pDa0VH8OtLt9Pn8VWls1wYotZXaZrqWVubG1PLuxY8nufboKK4Ju8mzpjsReEv+QVff9hrVP/S+etysPwl/yCr7/sNap/6Xz1uV0R2Rm9wooopiCiiigAooooAKKKKACiiigAooooAK5/xr/wAgG2/7C+m/+l0FdBXP+Nf+QDbf9hfTf/S6Ch7DOf8Ai/49uvAvheFtIjV9U1CbyLbcu4Jxlmx3I4AHqR16VyS/DT4nvpf9rP8AEO9XWdnm/wBnB38nd12Z3bfb7m3PtzVj9onT7pdK0DxBbQmaLSbwmYDooYqQT7ZQDPuK7BPi94Ibw3/bB160VPL3m1Mg+0A/3fKzuznjpjvnHNZaWk29U/u0L1vFLr/mcv4O+M5l+HN/rHiuzuJbzRrhLe9FlEu5gxwsm0soHOQQD1HTnA7fWvH2i6H4Fj8WXDTTadKkbxLAqmR9+MAAkDPPPPY15b8F/DLeJvCvjK91OAxWfiKVoowfbeSw+jPjPqp9K4zRJNR8UN4c+F18jq2l6vObwHp5Sc4z7ZmH4rVXk2ovdpf8H/Mm0Vd9E3/wP8j0/wCI3xN1aOw8O6X4Kt5LfVvEiJLEblF8yCN8BeMlQxJ6nIAB/DJ1XwD8S/C+iS+ILD4hXupX1pGZ5rGQu0RAGWC72KtgZwCoz7UfGPd4W+KPhDxhNA76ZbbbeYxj7m1icfXa5IHfbXY+Kvix4PtPBN5eWmuWV9NPbMtvawTBpXdlO0Mg+ZevO4DH14qG1ySmt7v/AIH3/iUr86i9rL/gmp8NPGZ8deCLbV5Y1iugzQ3KJ90SL1I9iCD7ZxXW15d+z7otzpPwwSW7RozqF091GrDB2FVVT+O3P0Ir1GuiW5jHYKKKKkoKKKKACiiigArn7P8A5KVrP/YI0/8A9HXldBXP2f8AyUrWf+wRp/8A6OvKBnmnifxL4t8d/E668E+CtS/sax05c3t8mQ+RjcQw54JChQRk5ycdM7xCvj74NPZ61J4puPFGjyzCK6ivQxK55wNzMVyAcMD1xkHumh6xafDj9oPxJD4mf7Haa0TLBdyfcG996knsvLKT2I57mrnxy8daHrfhWDw14cv4NX1C/uoyFspBKqgHj5lyNxbAA61gm1TjJfE/89rGjV5yi9l/luehw/EjRZfF+m+HTHdx3Op2a3lpO6KIZUZSwAO7O7g8Y6ip7vx7pdr8QrTwcLe8n1K5h87fEimKJcMfnJYEcLngHqPWvN/ih4auvDfgPwh4hs0zqHhX7NHMwPVAFHPqN4A/4EavfB6NvFXjPxT4/nU+XeXBtLLeMMsa4P8A6CIx9Qa2TvNx7N/d0/P8DLaCfdL7+pzGlaV4q8efE7xfp9p481jRoNNvZPLSKeV12mRgFCiRQoGKv6DqninwN8a9P8IX/im48TWV8g837QSzxEqxH3mYqQVz1wVP5YGifDnTviJ8U/HdvqV3dWr2l7K8DwFcbmlcfMCDkcDgEfWtT4M2um+DfiVqHhfxHpkMPiBNy2eoFmPmrjO1QTgbl5BABIyD75Ub+56ff5Gla15+v3H0JRRRWxmFFFFABRRRQAUUUUAFc/4B/wCSa+Gf+wRa/wDola6Cuf8AAP8AyTXwz/2CLX/0StHUZ0FFFFAgooooAKKKKACiiigAooooAKKKKACiiigDn/Ef/Ie8Jf8AYXk/9Ibqugrn/Ef/ACHvCX/YXk/9IbqugoGFFFFAgooooAKKKKACiiigAooooAKKKKACiiigCp4I/wCQr4v/AOw0n/pBaUUeCP8AkK+L/wDsNJ/6QWlFcst2arYzvCX/ACCr7/sNap/6Xz1uVxWgeD/DWp22o3eo+HdJu7mTWdT3zT2Mbu2L6cDLFcnAAH0Fav8AwgPg7/oU9D/8FsP/AMTXRG9kZvc6Ciuf/wCEB8Hf9Cnof/gth/8AiaP+EB8Hf9Cnof8A4LYf/iarUDoKK5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+Jo1A6Ciuf/4QHwd/0Keh/wDgth/+Jo/4QHwd/wBCnof/AILYf/iaNQOgorn/APhAfB3/AEKeh/8Agth/+Jo/4QHwd/0Keh/+C2H/AOJo1A6Ciuf/AOEB8Hf9Cnof/gth/wDiaP8AhAfB3/Qp6H/4LYf/AImjUDoKK5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+Jo1A6Cuf8a/8gG2/7C+m/wDpdBR/wgPg7/oU9D/8FsP/AMTWN4n8D+E7fTbNoPDGjRM2radGxTT4gSrXsKsvC9CpII7gkUnewLc7WeCK5geC5iSaKRSrxyKGVgeoIPUVxZ+DPw/N/wDa/wDhG4PN3btvnS+Xn/rnu249sYrtv+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8Aiay9or3sXyu1rjYLeG1t44LWKOGGNQqRxqFVAOgAHAFY1n4L8P6f4quvElnpyx6tdqVmufMc7gcZ+UnaCdo5AH6mtv8A4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJp+01vYXLpYgv9Ps9VsZLLU7WG7tpRh4ZkDqw9wa5Kz+DngGwv1vLfw3bmVTuAllklTP+4zFf0rtP+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4ml7RXvYfK7WuKAFUBQAAMADtS03/hXHgj/oTfD/AP4K4P8A4mj/AIVx4I/6E3w//wCCuD/4mn7XyFyjqKb/AMK48Ef9Cb4f/wDBXB/8TR/wrjwR/wBCb4f/APBXB/8AE0e08g5R1FN/4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJo9p5ByjqKb/wrjwR/wBCb4f/APBXB/8AE0f8K48Ef9Cb4f8A/BXB/wDE0e08g5R1c/Z/8lK1n/sEaf8A+jryt7/hXHgj/oTfD/8A4K4P/ia5+z8A+D2+JOs2reE9DNvHpNhIkR02HYrNNeBmA24BIRQT32j0FL2nkHKW/EPhTQ/Fdmtt4h0yC+jQ5QyAhk/3WGGX8DWd4e+G3hDwrefa9C0OC3ue0zu8rr/ulySv4Yrpv+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8AiaFUSd0h8ratcrarpdlrek3Om6pALizukMcsRJG5T7jBH1FQaD4f0zwxo8WlaFai0soixSIOz4LHJOWJJ5Pc1of8K48Ef9Cb4f8A/BXB/wDE0f8ACuPBH/Qm+H//AAVwf/E0e062FymPpHhDQ9B1nUdV0qx8i91N993L5zt5jZLZwzEDknoBUGteBPDniHXLTWNX07ztQstvkXCTyRsm1ty/cYZweec1v/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TR7RK2m2w+W9/MdRTf8AhXHgj/oTfD//AIK4P/iaP+FceCP+hN8P/wDgrg/+Jp+08hco6im/8K48Ef8AQm+H/wDwVwf/ABNH/CuPBH/Qm+H/APwVwf8AxNHtPIOUdRTf+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mj2nkHKOopv/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNHtPIOUdXP8AgH/kmvhn/sEWv/ola3v+FceCP+hN8P8A/grg/wDia5/wD4B8H3nw28NXV54T0Oe4m0m1klll02FnkYwqSzErkkk5JNL2nkHKdFRTf+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8AiaftPIOUdRTf+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mj2nkHKOopv/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNHtPIOUdRTf+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaPaeQco6im/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TR7TyDlHUU3/AIVx4I/6E3w//wCCuD/4mj/hXHgj/oTfD/8A4K4P/iaPaeQco6im/wDCuPBH/Qm+H/8AwVwf/E0f8K48Ef8AQm+H/wDwVwf/ABNHtPIOUwfEf/Ie8Jf9heT/ANIbqugrnfEfgHwfBr3hOODwnocaXGrSRzKmmwgSL9hum2sAvI3Kpwe6g9q6D/hXHgj/AKE3w/8A+CuD/wCJpe08g5R1FN/4Vx4I/wChN8P/APgrg/8AiaP+FceCP+hN8P8A/grg/wDiaftPIOUdRTf+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaPaeQco6im/8ACuPBH/Qm+H//AAVwf/E0f8K48Ef9Cb4f/wDBXB/8TR7TyDlHUU3/AIVx4I/6E3w//wCCuD/4mj/hXHgj/oTfD/8A4K4P/iaPaeQco6im/wDCuPBH/Qm+H/8AwVwf/E0f8K48Ef8AQm+H/wDwVwf/ABNHtPIOUdRTf+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8AiaPaeQco6im/8K48Ef8AQm+H/wDwVwf/ABNH/CuPBH/Qm+H/APwVwf8AxNHtPIOUreCP+Qr4v/7DSf8ApBaUUzwTpGm6Zqvi6z03T7WztYtZTy4LeBY0TNhaE4UDAyST9SaKybu7llHwl/yCr7/sNap/6Xz14p8T7K8+J3xSvtB0okxeHdMll45Ek2A232JYov8AwE169pmq2+h+D9a1S9bbBZ6nq0zn2W+nOK8R+HHh34l6zb6j4s8Jazpumf2xcuZ2u0DPKQxJIzE+FyzDgjp7Cra5mo9l/wABCT5Vfu/+Cz1n4L+Jf+Ek+GVgZWzc6ePsU2Tk5QDafxUr+tYuu/HIWevX+n+GfC1/4gj0wkXt1AxVIsZyflRvlGDycDg9ua5j4T/2p4C+LeqeDvEk0LS6pCJ0e3J8p5QC4KghcAqXHQcqBVf4Y+M9G+GEnifQfGsk1pfJetIv7hn88AYwMA9cZBOAQ3WrlNyale11f57MiMVFNW2a+5nqFj8V/D158OZvGJaaK0tz5c1uVBlWXjEYGcEncMHOMHJxzjlLH4/p9usj4h8Jaho2lXzYt9RlYsjj+9gooI5BO0nHvWJ431VviH8ADqeg6DNpVrYXyyPbKq7GjUFWZNuMqCwycD7p9K2H+OPg86RoEFlp02tXxeKM2Qt8SWrbduVLLtZs8AKe55FUn77+Wne4Ne6vnr6dDs9Q+IH2D4raX4MGm+YNQtjP9t+0Y2YDnGzbz9zruHWma38Q/wCx/iho/g/+zPO/tOHzftf2jb5XL8bNpz9z1HWvPviLrMHhj9oXwxr+sLNbaetjteXyy23PmKw4zkjeMgZPP0rOufGGm+NP2k/DN9obSS2MCfZ0neNkEpAkYkBucfNjkClGV3Bf3mn6XYSSSk/7qa9Tr9b+N02l+MdU8N2HhK71W+s5AkCWkxZp+MsSojJUAem78K1tU+J17barpuhaR4Xn1LxDd2a3c+nfa0hFopGdryMMZH0Hb1Fcv4HRT+014yYqCy25wSORzFTPF3jHWNQ+Ll54TuvFSeDtGtbcSC52qr3B2qeJGIwTuOMED5ehNSpPkg29Xr+Y2velbp/wDt/AnxJtfGZ1S2utPk0jUdJfbeW00gdU5IyHGM4KnPA/GuQu/wBoNfOurnRvCGpalolpJsm1RWKovPXGwgdRjcwPI6Vy3wltV1bVviPY6TfzXxvLSSK2u7l8yT7jIFkYnBJOQSfepvh38T/DXg34W3mg+IoJDqlrJOG02W3bFySfuk7So9Du6Y6GhSbSbdtL+rvYfLa6WutvTS/oehXXxgsotS8LG205ptH8R/JHqDTbDBJu2FGTaeQSM/N6+nOp4n8f/wBg+N9B8MWem/2heauxLn7R5f2ePON5G07uA5xx92uS8fQp8QvgRHrunabNpktkov7WCRQGVEyG27f4SuSDxnA4rO+EtzN8QviRqXjjUI2UWNnDZ26tjAkKDzCPyY/9tK0TfPy9nf5W0/HQh/Dzd1b5/wDDanuFYfi3/kFWP/Ya0v8A9L4K3Kw/Fv8AyCrH/sNaX/6XwUS2YLc76iiiuU1CiiigAooooAKxfFui33iLw3PpemaxJo0lwVWS7hj3SLHn5lT5htJHG7nGelbVc5468VTeDPDD63HpcmpQW8qfakjk2tDCThpfunO3rj07ik7dRq/Q8tuvDvhrwd8RvDlj8K7qZddfUFj1mzt7x7hXtB/rXuAWYIRkYzjluB0x6T4/8WT+HNLtrPRoVuvEGry/ZdLtieDIfvSN/sIPmJ+g4zmvOPiZq3gvWrHTbr4fXOm3XjS6v4X06bSShuN5YFzKU+YLtLZD/l1rc1Pwn8TI/iZqHifRZvCl2kkK21iNWa5LWkQHzBAigKWbJJySeOnSnq4pS7u/3LRf1pqLRO67fq9/612JfgLaXNh4Y8QWl/dte3UHiC7jmuWGDM42gv8Aiea9Srx/4Ff8JT9o8T/2x/ZH2D+2bvzvsvm+b9r3Lv27uPKxnGfm9a67xrDqHjf4f6jYfD/W9PF1cP8AZnuhc5RACPMTdGGIbHHTIz2ok3yxa7L8l+ARS5mn3f5s808X+IdQ8ZeO/C2r2Evl+FrDxNBY2eOft82SZJwf7i7di9c5Y+1ev+LZvEy6bFB4NtbSS9uJPLe6vJMR2aYOZSvVyOgUdzzxXi3jHTPiRo1n4L026t/BltbWutW0WmRaeLoKswVtnmbv4OuSPmzXv9h9s/s62/tPyPtvlL9o+z58vzMfNtzztznGecU7Lksu/wCi/ryE2+e/l+r/AK8zzr4ExXMHg/WYb+7a9uo9fvEmuXGDM4YAuR2yRnHvXU2P/JU9d/7Aum/+j76ud+C//IB8Rf8AYy3/AP6GK6Kx/wCSp67/ANgXTf8A0ffUbqPovyQLd+r/ADZ0lFFFIYUUUUAFFFFABXBeNvAWkeJdWbVvHmsF/DlnbBU015mtYInzzNJIHG49AOgHvXe1w2u+PdFsPGk/hPxtaWlhp1xaLPaX2oSr9nvMH50IZdqlTjqTnjpkZT1a7/8AAH0Mb4NHy73xPaaFdXV54Ot7qNNFmuGZwPlPnJE7ctGrYAPI46nk1yvxu8Q6h4n03VNP0KXy9D8PXEA1O5HIurppVAt19kDbmPPzYGOKt6BC2oePvGUXweuLW00iTSRF50WVsl1EnCvHtBHCdSoxnHXiue8Z+G/iL4T+DM2kagnhEaPDJCZpLM3TXU0hmU+YzP8AKzM+Cx9M47VV7yi35fPW36X87oNuZLz/ACv/AMD7z6RT/Vr9BWD408V23g3wzNqc8TXE5ZYbS0Q/PdTtwka+5P5AE9qfp+qXOkeGLS48eX2kWN6SEmlgmMdsXJO1UMpByRjg981x3jXwn491P4jWHiDw5N4dnstOtytpaay0+2KZvvyhYxgtjABJ4GeM80pb2Jh8NzN+DVrrFp468dp4muludVeWzluWQfKjPEzbF/2VztHstU/jgfF93o1y8httM8N2V7aqqI/mTakzSoMtjiNFJ6cklfTGHfDP/hN/+Fy+L/7a/sDbvtv7V+yednd5B8ryN3bpu3fhXR/Hb/klk/8A1/Wf/pQlV9qm/wDD+gpfDP5/kejVzfw4/wCSWeFP+wLZ/wDohK6Sub+HH/JLPCn/AGBbP/0QlSUdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfij/kYvBn/Yak/wDTfeV0lc34o/5GLwZ/2GpP/TfeV0lABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBzfhf8A5GLxn/2Go/8A032dFHhf/kYvGf8A2Go//TfZ0UAcLpniLweNK1XSfEWsaGM6xqXnWd9dQ8g30zDcjn0wRkehrUsvGHgPTbOO007xF4ctLaPISGC+gRE5zwobA5NUtB/1Gpf9hrU//S6etSu6FO8U7nPKepRn8R/Di61SHU7nWPC01/AAIruS6t2ljAzja5OR1PQ96ZqWufDPWJkm1fU/Cd/LGMI91cW0rL9CxOK0aKr2XmL2g2Pxx4JhgWGLxRoCRIoVY11CEKoHGAN3Ss6z1f4X6dfG90/UPCNrdEkmeCe2SQ56/MDnvWnRR7J3vcOfS1ipqXif4eazbiDWNb8MX8KncI7q7t5VB9cMSKhTXPhnHc2txHqnhNZ7NdttKtxbBoBzwhzlRyenrWjRR7LzDnKcHiX4dWupzajba14XhvrgYmuo7u3WWQccM4OT0HU9qj1LXvhrrE0Uur6r4Uv5If8AVvdXNtKU+hYnFaFFHsvMPaFO38S/Dq01KXULXWvC8N7MoWW5jurdZJF44ZgckcDr6Cq95q/wv1C++23+oeEbq7GP9Immtnk4/wBonNalFHsvMOc4n4mfECV9HisvAet+Gbz7YkkN48+qW6tCpAAZd0qju3ZqsfDG78H+BfA9tpU/i7QHvHZp7p01KEqZG7A7uQAAPwrrqKUaNm3fcHUukrbC/wDCfeDv+hs0P/wZQ/8AxVY3ifxx4TuNNs1g8T6NKy6tp0jBNQiJCrewszcN0CgknsATWxRTdJtWuHtPI3/+Fj+CP+hy8P8A/g0g/wDiqP8AhY/gj/ocvD//AINIP/iqwKKy+reZXtvI3/8AhY/gj/ocvD//AINIP/iqP+Fj+CP+hy8P/wDg0g/+KrAoo+reYe28jf8A+Fj+CP8AocvD/wD4NIP/AIqj/hY/gj/ocvD/AP4NIP8A4qsCij6t5h7byN//AIWP4I/6HLw//wCDSD/4qkPxG8DkEHxj4fIPUHVIP/iqwaKPq3mHtvItaZr/AMKNFupLnR9W8G6fPKMSS2tzaxM/1KkE1q/8LH8Ef9Dl4f8A/BpB/wDFVgUU/q3mHtfI1rPxt8OtOWYaf4m8L2onlaaUQX9unmSN952w3LHuTyayvCXiXwP4c0+8i/4S/wALRveX0128drqMCRR724VRuHRQuTgZOT3pKKX1bz8v6+4Pa36f1/TNa78bfDrUGgN/4m8L3RtpRNAZr+3fypB0dctwwz1HNWf+Fj+CP+hy8P8A/g0g/wDiqwKKPq3mHtvI1rLxt8OtNjkTTvE3he0SWVppFgv7dA8jcs5Ablj3PU1kWfj7wevxJ1m6bxZoYt5NJsI0lOpQ7GZZrwsoO7BIDqSO24eopaKPq3mHtfI3/wDhY/gj/ocvD/8A4NIP/iqP+Fj+CP8AocvD/wD4NIP/AIqsCij6t5h7byN//hY/gj/ocvD/AP4NIP8A4qj/AIWP4I/6HLw//wCDSD/4qsCij6t5h7byN/8A4WP4I/6HLw//AODSD/4qj/hY/gj/AKHLw/8A+DSD/wCKrAoo+reYe28jf/4WP4I/6HLw/wD+DSD/AOKqlqni74aa5ai11rxB4U1G3DBhFd3ttKgPrhiRmsxmCKWYhVAyST0rMtfE+g3t4LSy1vTbi5JwIYruN3J/3Qc0fVltcftXvY6ux8b/AA70uzS00zxP4Ys7aMYSG31C3jRfooYAUl/42+HeqWbWmp+JvDF5bOQWhuL+3kRiDkZUsRwQDWTRT+reYva+QvjDxL4G8UeH/wCym8X+Fikk8TO8+owN5aq4LMg3cPgEA8Yzmt7/AIWP4I/6HLw//wCDSD/4qsCil9W8w9r5GtB42+HVreXN3beJvC8NzdlTcTR39urzFRhd7BstgcDPSi/8bfDrVLU2up+JvC95blgxiuL+3kQkHIOCxGQQCKyaKPq3mHtfI3/+Fj+CP+hy8P8A/g0g/wDiq5/wD4+8H2fw28NWt54s0OC4h0m1jlil1KFXjYQqCrAtkEEYINLRR9W8w9t5G/8A8LH8Ef8AQ5eH/wDwaQf/ABVH/Cx/BH/Q5eH/APwaQf8AxVYFFH1bzD23kb//AAsfwR/0OXh//wAGkH/xVH/Cx/BH/Q5eH/8AwaQf/FVgUUfVvMPbeRv/APCx/BH/AEOXh/8A8GkH/wAVR/wsfwR/0OXh/wD8GkH/AMVWBRR9W8w9t5G//wALH8Ef9Dl4f/8ABpB/8VR/wsfwR/0OXh//AMGkH/xVYFFH1bzD23kb/wDwsfwR/wBDl4f/APBpB/8AFUf8LH8Ef9Dl4f8A/BpB/wDFVgUUfVvMPbeRv/8ACx/BH/Q5eH//AAaQf/FUf8LH8Ef9Dl4f/wDBpB/8VWBRR9W8w9t5G/8A8LH8Ef8AQ5eH/wDwaQf/ABVH/Cx/BH/Q5eH/APwaQf8AxVYFFH1bzD23kJ4j8feD59e8JyQeLNDkS31aSSZk1KEiNfsN0u5iG4G5lGT3YDvXQf8ACx/BH/Q5eH//AAaQf/FVgUUfVvMPbeRv/wDCx/BH/Q5eH/8AwaQf/FUf8LH8Ef8AQ5eH/wDwaQf/ABVYFFH1bzD23kb/APwsfwR/0OXh/wD8GkH/AMVR/wALH8Ef9Dl4f/8ABpB/8VWBRR9W8w9t5G//AMLH8Ef9Dl4f/wDBpB/8VR/wsfwR/wBDl4f/APBpB/8AFVgUUfVvMPbeRv8A/Cx/BH/Q5eH/APwaQf8AxVH/AAsfwR/0OXh//wAGkH/xVYFFH1bzD23kb/8AwsfwR/0OXh//AMGkH/xVH/Cx/BH/AEOXh/8A8GkH/wAVWBRR9W8w9t5G/wD8LH8Ef9Dl4f8A/BpB/wDFUf8ACx/BH/Q5eH//AAaQf/FVgUUfVvMPbeRv/wDCx/BH/Q5eH/8AwaQf/FUf8LH8Ef8AQ5eH/wDwaQf/ABVYFFH1bzD23kafgnV9N1PVfF15puoWt5ay6ynlz286yI+LC0BwwODggj6g0VF8Of8AX+K/+w0v/pDa0VyyVm0bJ3VzndB/1Gpf9hrU/wD0unrUrL0H/Ual/wBhrU//AEunrUr06fwI5JfEwoooqyQooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPI/i3e3us+LtA8E21y9ta6iyyXZj6upfAB9QArHHTOM9K09S+BnhO50xYNNjn0+7QqRdrM8jHHXKsdvPtjn8qrfFjw5q39taN4w8P2rXtxpLr51sgJZkVtwIA5I+8DjnnPrVWf47RX9stp4Z8Pahc6y5Ci3ljBRT3+4xY/kK5Vye8prW/zt0N3zXTjtb/hz1HS7JtN0q2snuprs28SxmecgvJgYyxHU1bqppU97c6TbTaparZ3kkYaa3STeI2P8O7Az/nr1q3XW9zBbBRRRSAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigC98Of9f4r/7DS/8ApDa0UfDn/X+K/wDsNL/6Q2tFeXU+NnZH4UcXpeu21odUhktNWkZdZ1LLQaRdTIc3sx4dIyp69jweOoq9/wAJNaf8+Guf+CG9/wDjVbvhL/kFX3/Ya1T/ANL563K6o1JKKMnFXOG/4Sa0/wCfDXP/AAQ3v/xqj/hJrT/nw1z/AMEN7/8AGq7miq9pIXIjhv8AhJrT/nw1z/wQ3v8A8ao/4Sa0/wCfDXP/AAQ3v/xqu5oo9pIORHDf8JNaf8+Guf8Aghvf/jVH/CTWn/Phrn/ghvf/AI1Xc0Ue0kHIjhv+EmtP+fDXP/BDe/8Axqj/AISa0/58Nc/8EN7/APGq7mij2kg5EcN/wk1p/wA+Guf+CG9/+NUf8JNaf8+Guf8Aghvf/jVdzRR7SQciOG/4Sa0/58Nc/wDBDe//ABqj/hJrT/nw1z/wQ3v/AMaruaKPaSDkRw3/AAk1p/z4a5/4Ib3/AONVHP4u062jD3NtrMKF1jDSaJeKCzMFVcmLqWIAHckCu9rn/Gv/ACAbb/sL6b/6XQUe0kHIjG/4Sa0/58Nc/wDBDe//ABqj/hJrT/nw1z/wQ3v/AMaruaKPaSDkRw3/AAk1p/z4a5/4Ib3/AONUf8JNaf8APhrn/ghvf/jVdzRR7SQciOG/4Sa0/wCfDXP/AAQ3v/xqj/hJrT/nw1z/AMEN7/8AGq7mij2kg5EcN/wk1p/z4a5/4Ib3/wCNUf8ACTWn/Phrn/ghvf8A41Xc0Ue0kHIjhv8AhJrT/nw1z/wQ3v8A8ao/4Sa0/wCfDXP/AAQ3v/xqu5rE8S+MvD/g+2jn8SanFZJKSI1ZWd3x1wqgsQMjJxxmk6rW4ezTMH/hJrT/AJ8Nc/8ABDe//GqP+EmtP+fDXP8AwQ3v/wAarpfD/iXR/FOmi/8AD9/Fe227aWjyCp64ZTgqeehArTJABJOAOpNP2kkHIjh/+EmtP+fDXP8AwQ3v/wAao/4Sa0/58Nc/8EN7/wDGqtWnxV8EX2uDSLXxDbSXjP5artcI7dgshGwk54wea64kAEk4A6k0vaytcORXscP/AMJNaf8APhrn/ghvf/jVRr4u05rl7dbbWTPGiyPENEvNyqxIViPKyASrAHvtPpXS+HvFmieK4bmXw9fLex2sxhldUZQH64BYDI9xkVXs/wDkpWs/9gjT/wD0deUe0kHIjG/4Sa0/58Nc/wDBDe//ABqj/hJrT/nw1z/wQ3v/AMaruaKftJByI4b/AISa0/58Nc/8EN7/APGqP+EmtP8Anw1z/wAEN7/8aruaKPaSDkRw3/CTWn/Phrn/AIIb3/41R/wk1p/z4a5/4Ib3/wCNV3NFHtJByI4b/hJrT/nw1z/wQ3v/AMao/wCEmtP+fDXP/BDe/wDxqu5oo9pIORHDf8JNaf8APhrn/ghvf/jVH/CTWn/Phrn/AIIb3/41Xc0Ue0kHIjhv+EmtP+fDXP8AwQ3v/wAao/4Sa0/58Nc/8EN7/wDGq67VNVsdF02bUNWuorS0hGZJpWwq9h+OeMd6xvDXxC8LeMLiSDw7rEV3PGu5oijxvj1CuASORyKPaybsHIrXMr/hJrT/AJ8Nc/8ABDe//GqP+EmtP+fDXP8AwQ3v/wAaruayfEfijRvCWljUPEN8tlalxGHKM5Zj0AVQSeh6DtSdVrcPZpnOf8JNaf8APhrn/ghvf/jVR2/i7Tru2iuLW21meCZBJHLHol4yupGQwIiwQRzmu6ilSeFJYjuSRQynGMg8isLwD/yTXwz/ANgi1/8ARK0/aSTsLli0Y3/CTWn/AD4a5/4Ib3/41R/wk1p/z4a5/wCCG9/+NV3NFHtJD5EcN/wk1p/z4a5/4Ib3/wCNUf8ACTWn/Phrn/ghvf8A41Xc0Ue0kHIjhv8AhJrT/nw1z/wQ3v8A8ao/4Sa0/wCfDXP/AAQ3v/xqu5oo9pIORHDf8JNaf8+Guf8Aghvf/jVH/CTWn/Phrn/ghvf/AI1Xc0Ue0kHIjhv+EmtP+fDXP/BDe/8Axqj/AISa0/58Nc/8EN7/APGq7mij2kg5EcN/wk1p/wA+Guf+CG9/+NUf8JNaf8+Guf8Aghvf/jVdzRR7SQciOG/4Sa0/58Nc/wDBDe//ABqj/hJrT/nw1z/wQ3v/AMaruaxo/Fuhy+LJPDMV+r6xHF5z2yox2rx1bG0HkcZzzR7SWwciObk8XadDJCk1trMbzv5cStol4DI20ttUeVydqscDsCe1Sf8ACTWn/Phrn/ghvf8A41Wz4j/5D3hL/sLyf+kN1XQUe0kHIjhv+EmtP+fDXP8AwQ3v/wAao/4Sa0/58Nc/8EN7/wDGq7mij2kg5EcN/wAJNaf8+Guf+CG9/wDjVH/CTWn/AD4a5/4Ib3/41Xc0Ue0kHIjhv+EmtP8Anw1z/wAEN7/8ao/4Sa0/58Nc/wDBDe//ABqu5oo9pIORHDf8JNaf8+Guf+CG9/8AjVH/AAk1p/z4a5/4Ib3/AONV3NFHtJByI4b/AISa0/58Nc/8EN7/APGqP+EmtP8Anw1z/wAEN7/8aruaKPaSDkRw3/CTWn/Phrn/AIIb3/41R/wk1p/z4a5/4Ib3/wCNV3NY0fi3Q5fFknhmK/V9Yji857ZUY7V46tjaDyOM55o9pLYORHP/APCTWn/Phrn/AIIb3/41R/wk1p/z4a5/4Ib3/wCNVveJfGXh/wAH20c/iTU4rJJSRGrKzu+OuFUFiBkZOOM1P4f8S6P4p00X/h+/ivbbdtLR5BU9cMpwVPPQgUlVk9g5Etyv8Mb6K5HiiZI7qNX1kYWe1kicYsrUco6hh07jpg9DRWj4I/5Cvi//ALDSf+kFpRXHLWTN1sZ3hL/kFX3/AGGtU/8AS+etysPwl/yCr7/sNap/6Xz1uV0R2Rm9wooopiCiiigAooooAKKKKACiiigAooooAK5/xr/yAbb/ALC+m/8ApdBXQVz/AI1/5ANt/wBhfTf/AEugoewzoKKKKBBRRRQAUUUUAFFFFABXiF7ZWnir9qabT9eto72z03TwYbeZQ8ZOxW5U8HmQn8BXt9eN+OtJ8SeEvizB488M6HLrltcW32e8tLcEybsbegBIGAhyAfunOKiVlKLe2v5MtaxaX9aog+GsMPh74/eMfD2mIINPaETpAv3UIKHAGeAPNI+ldv8AF7UJ9M+EuvXFq5SQwLFuU4IDuqH9GNc18KPD2vT+Ldf8c+KdPfTLjVf3dvZSAh1TIOSDyMBVAyAeDwOKvw6ldfF34c+JNKu9HfQ7xJGtFguZCxEiqroWyilRkjjHSpkn7FQ6qOv3jg17Xm6X/r8jznxF4O0Oz/Zo0vWrTT4YtTUQXBvFQCV2d8EFhyR83APTAr0u/wBA1b4i+CvDOdcm07TLmxSbVI4OJLrciEKD2H3s89+hrzGeD4ia/wCCNP8AhrL4PubT7PKkc2pyBhCY0bK/NjZxxyGOdvAzX0PpmnppWiWmnQsXS0t0gVj1IVQM/pVSScZvo3p9xnqnFdUtTyL9mlQnhTW1HRdQwM/7gr0mz/5KVrP/AGCNP/8AR15XCfs/aNqmi+HNZi1jTbvT5JL/AHol1A0RZdg5AYDI967uz/5KVrP/AGCNP/8AR15V9F6L8inZSlbu/wAzoKKKKCQooooAKKKKACiiigAooooA8Z/aBla6n8IaJKzCz1DUf36q2NwBRR+khqh440fTPBXxp8CXfhyxg04Xcv2eaO2TYrjeqZIGBkiQ5PfAzmur+NHhDVfEWi6ZqXhuEXGp6LdC4jh4zIvGQM9SCqnHcA98CuX0228WfE74oaFreveGrnw7pmhDzCtyGVpJM7vl3KpOSF6DAAPOazh8a/xXfpYufwP0t87nuVfOfx28H6jaaVN4l13W5r+abU/IsrVeIrW3YOwXGOW+Vcnjp3617Bb+M7mX4oXPhKfRJYII7X7TDqLyHbcABMhVK4OC+CQx5Fcz+0DpGpaz8PrW20fT7q/nXUY3MVrA0rBdkgzhQTjkc+9TV1gpL+tSqekuV/1pc9H0r/kDWX/XvH/6CKyvAP8AyTXwz/2CLX/0Sta2mI0ek2iOpVlgQMpGCDtHFZPgH/kmvhn/ALBFr/6JWump8bMIfAjoKKKKgoKKKKACiiigAooooAKKKKACiiigDI8UWOq6n4burPw/qA02/mCrHdlc+UNw3ED125A9+4614r4A8PR+Fv2lNQ0mK6nvPJ08s9xcNl5XZI2Zj9WJP9TX0DXkem6Nqkf7UGq6q+m3i6dJYBEvDAwhZvLiGA+ME5B79jUJWqJ+v5Fbwa9PzR3niP8A5D3hL/sLyf8ApDdV0Fc/4j/5D3hL/sLyf+kN1XQVYgooooEFFFFABRRRQAUUUUAFFFFAGR4osdV1Pw3dWfh/UBpt/MFWO7K58obhuIHrtyB79x1rxXwB4ej8LftKahpMV1PeeTp5Z7i4bLyuyRszH6sSf6mvoGvI9N0bVI/2oNV1V9NvF06SwCJeGBhCzeXEMB8YJyD37GoStUT9fyK3g16fmjMvbK08VftTTafr1tHe2em6eDDbzKHjJ2K3Kng8yE/gKk+GsMPh74/eMfD2mIINPaETpAv3UIKHAGeAPNI+lT+OtJ8SeEvizB488M6HLrltcW32e8tLcEybsbegBIGAhyAfunOKt/Cfw7r1x4u1/wAceKdPfS7jVcR29nICGRMg5IPIwFUDODweBxSpfEvJSv8APYKmz8+W3yWp6d4I/wCQr4v/AOw0n/pBaUUeCP8AkK+L/wDsNJ/6QWlFYy3Za2OV0DW7+1ttRhg8L6texrrOp4ngltAjZvpzwHnVuM45A5HGRzWr/wAJHqn/AEJeuf8Af6x/+Sak8Jf8gq+/7DWqf+l89Y3jv4qaD8Pbu0ttZhvbia6RpFS0jRiqg4y25lxk5x16Gt7pJXZFm3oav/CR6p/0Jeuf9/rH/wCSaP8AhI9U/wChL1z/AL/WP/yTWppGqW2uaLZ6pYMWtryFZoywwdrDIB9/WrlW007MlNNXOf8A+Ej1T/oS9c/7/WP/AMk0f8JHqn/Ql65/3+sf/kmugooGc/8A8JHqn/Ql65/3+sf/AJJo/wCEj1T/AKEvXP8Av9Y//JNdBRQBz/8Awkeqf9CXrn/f6x/+SaP+Ej1T/oS9c/7/AFj/APJNdBRQBz//AAkeqf8AQl65/wB/rH/5Jo/4SPVP+hL1z/v9Y/8AyTXQUUAc/wD8JHqn/Ql65/3+sf8A5Jo/4SPVP+hL1z/v9Y//ACTXQUUAc/8A8JHqn/Ql65/3+sf/AJJrE8Wa7qdxo9tG3hHWYc6pp5DSTWeCReQkLxcHliAo7ZIyQMkd3WH4t/5BVj/2GtL/APS+Ck9gW5J/amu/9CPrn/gRYf8AyTR/amu/9CPrn/gRYf8AyTXdUVj7SRfKjhf7U13/AKEfXP8AwIsP/kmj+1Nd/wChH1z/AMCLD/5JruqKPaSDlRwv9qa7/wBCPrn/AIEWH/yTR/amu/8AQj65/wCBFh/8k13VFHtJByo4X+1Nd/6EfXP/AAIsP/kmj+1Nd/6EfXP/AAIsP/kmu6oo9pIOVHC/2prv/Qj65/4EWH/yTR/amu/9CPrn/gRYf/JNd1XI+K/iRpPhTVIdKaz1TWNWmi85dO0i0NxOI843kZAAz6ml7Rj5UU/7U13/AKEfXP8AwIsP/kmszQrTUvD1lJBZ+CPEUrzzNPcXE93YPJPI3V2P2nrwBwAAAAAK6jwf480bxra3T6Ybi2ubFwl5ZX0JhntmOcB1PToeQSOD6VzZ+Ofhhryf7LYa5d6VbSeXca5bacz2MJHXdIDnA9dvf05p88k/62Fyqxf/ALU13/oR9c/8CLD/AOSaP7U13/oR9c/8CLD/AOSa7a3uIbu1iubWVJoJkDxyRsGV1IyCCOoIrA8X+OdK8GRWov4ry8vL1ylpp+nwGa4uCBk7EHoOpJFJ1JLcFFPYyP7U13/oR9c/8CLD/wCSawrTUdaHxD1dx4O1lpDpdiGhE9luQCW7wxP2jbg5IGCT8pyBxnrvCHxB0jxjcXdnawX+m6nZANc6bqluYLiJT0Ypk8HjkE9RnGRUtj/yVPXf+wLpv/o++pucgsjJ/tTXf+hH1z/wIsP/AJJo/tTXf+hH1z/wIsP/AJJruqKPaSDlRwv9qa7/ANCPrn/gRYf/ACTR/amu/wDQj65/4EWH/wAk13VFHtJByo4X+1Nd/wChH1z/AMCLD/5Jo/tTXf8AoR9c/wDAiw/+Sa7qij2kg5UcL/amu/8AQj65/wCBFh/8k0f2prv/AEI+uf8AgRYf/JNd1XI+K/iRpPhTVIdKaz1TWNWmi85dO0i0NxOI843kZAAz6ml7Rj5UU/7U13/oR9c/8CLD/wCSaP7U13/oR9c/8CLD/wCSa1fB/jzRvGtrdPphuLa5sXCXllfQmGe2Y5wHU9Oh5BI4PpXNn45+GGvJ/sthrl3pVtJ5dxrltpzPYwkdd0gOcD129/TmnzyvYXKrF/8AtTXf+hH1z/wIsP8A5Jo/tTXf+hH1z/wIsP8A5Jrtre4hu7WK5tZUmgmQPHJGwZXUjIII6gisDxf450rwZFai/ivLy8vXKWmn6fAZri4IGTsQeg6kkUnUktwUU9jlYbTUofElxrjeCPEU17NEIFaW7sCsEYwSiD7TwCRuPUk98AAaf9qa7/0I+uf+BFh/8k1o+EPiDpHjG4u7O1gv9N1OyAa503VLcwXESnoxTJ4PHIJ6jOMisrW/jDoek61d6XYaXrmvz2BxfPo1gbiO0PcSNkAEc5xnGCOoIo9o1ZByp3ZJ/amu/wDQj65/4EWH/wAk1heBtR1pPh54dSHwdrNxGul2wSaOeyCyDylwwDXAbB68gH1Ar0Xw94g03xToNtrGh3K3NlcrujkAIPBwQQeQQQQRWb8OP+SWeFP+wLZ/+iEpuck9QSTWhk/2prv/AEI+uf8AgRYf/JNH9qa7/wBCPrn/AIEWH/yTXdUUe0kHKjhf7U13/oR9c/8AAiw/+SaP7U13/oR9c/8AAiw/+Sa7qij2kg5UcL/amu/9CPrn/gRYf/JNH9qa7/0I+uf+BFh/8k13VFHtJByo4X+1Nd/6EfXP/Aiw/wDkmj+1Nd/6EfXP/Aiw/wDkmu6JCqSxwBySe1ebTfHLw1FO8o07XpdGjl8p9ei05msFIO0/vM5IzxkKetL2jvYfLpcv/wBqa7/0I+uf+BFh/wDJNH9qa7/0I+uf+BFh/wDJNdvBPFc28c9vIssMqh45EOVZSMgg9wRXP2fjnR9Q8fXvhCzaWXUbG1FzcOqjykyQNmc53fMDjGOeueKfPK9hWVrmR/amu/8AQj65/wCBFh/8k0f2prv/AEI+uf8AgRYf/JNd1WR4q8T6b4O8NXeua3IyWlquSEALyE8BVBIyxPA5pOq0rsahd2Rzn9qa7/0I+uf+BFh/8k0f2prv/Qj65/4EWH/yTXX6TqUOs6LZanaq6Q3kCTxrIAGCuoYA4JGcH1rKsfG2j6l44vvCtjK09/YWwuLlkwY48tt2E5zvGQSMcA9c8U3OSly9SbJrm6HEeINR1ptc8Ll/B2sxMuqOURp7ImU/YrkbVxcEA4JbnAwp5zgHd/tTXf8AoR9c/wDAiw/+Sa1vFH/IxeDP+w1J/wCm+8rpKXtJD5UcL/amu/8AQj65/wCBFh/8k0f2prv/AEI+uf8AgRYf/JNd1RT9pIOVHC/2prv/AEI+uf8AgRYf/JNH9qa7/wBCPrn/AIEWH/yTXdUUe0kHKjhf7U13/oR9c/8AAiw/+SaP7U13/oR9c/8AAiw/+Sa7qij2kg5UcL/amu/9CPrn/gRYf/JNH9qa7/0I+uf+BFh/8k10HirxZpXg3R/7R1mSQI8iwwwwxmSWeRvuoijqxrH8L/E7SPE2tto0mn6voereWZo7HWrM20s0Y6ugyQR1754PHFCqSewOKSuyv/amu/8AQj65/wCBFh/8k0f2prv/AEI+uf8AgRYf/JNdhqepWmjaVc6lqU6wWlrE0s0rdFUDJNUPCXiey8ZeF7PXtLjnitbwMY0uFCuMMV5AJHUetHtJByo57+1Nd/6EfXP/AAIsP/kmj+1Nd/6EfXP/AAIsP/kmus1zWLbw/oF/q9+HNtY273EojALFVUkgZIGeOORXFaR8XotZvLKG38C+NYor10VLubSAsCq5GHZw5wmDkn05oVSTdkDikrss/wBqa7/0I+uf+BFh/wDJNH9qa7/0I+uf+BFh/wDJNXvFnxF0rwnqNvpj2WqaxqlxGZk0/SLQ3E4jBwXK5AC59TVzwh410jxrp81xpBniltZPJu7O7iMU9rJ/ckQ9D+Y4PPBoVST1QOKW5k+ALi5kvPFj3WmXVlK2srut53iLp/oNrjJR2XkYPBPBHfIorS8L/wDIxeM/+w1H/wCm+zorPcoxfCX/ACCr7/sNap/6Xz14gt14f8efF/xZeeKNYsbLT7a0k06xN3cpFyQU3puPOMO3HdhXrcEmqR+A9ebw/bfadTOpastrFvVcub6cA5YgcZz17VxPgH4EaGnhOJvHmjedrMkjtKPtjjy1zhV/dvtPAznnrWvK5PyS/PT8ib2Xnf8ALUsfs9eIftfhK98P3E6yz6NcMEKtuDRMSQVPQjcG6dsVzujnxt8YNQ1zV9K8X3OgWNjO0NlaWzOofjKh9rL2xlju5J4xxW/oXw51TwN8aVvvCmmEeFry28q4/wBJU+TkcjDtvOGVTnnhiKzoPCHxK+HWsavb/D6zsNT0jUpjLH57qGtienDOvIBx/EDgcdqcm5Wbvt+P/DCWl0u6+7/hzT1/xZ418BfBT7T4ne3bxDJcC1t54yJCqsMhn42lwFYcZH3Sc81R0/wV8VdJk0jWdM8YyaxNcsr3ljfTOIIlI3EfMxyO2VVSOMe2rN8M/EviL4PSaD4t1v7ZrZmFzbSStvWBh0RnxlsgsCecbuMgc5Nvpvxt1X+y9Iu2tNDtLGRd+pQTIXmVRj5lDNu4/h2qCcZ9r19o776W9Ovl6iduRJba/f0NbXta1OD9pbw5pialdRafNYM0totwwhdts3JTOCcgdR2FR+L9Z1S2/aM8KabbaleQ2E9qGmtY52WKQ5l5ZAcHoOo7Cj4k+CvF0nj3RvGPgmODULywgEL29wyJkgt8xyVBBDkEAgjt7ZNl4M+ImpfGDQfFniuztCkY/fLZyoEtECsAmC25jls8buvX0mN+aC7S/C7CbVpecV95RnTxh4u+Nnibw1pPi3UNIsYz5rOkrv5KqFwsa7htyzDOCP6HpfGcF3pupaZZ+IviIdD0C0sVV2tr5o9SvZQMGQ/KSQT6Z+nPF3wp4Q1zTfjl4m8QXtj5Wl30O23uPOQ7zlP4Q24fdPUDpWR4h8EeJLL4yXHiyy8N2fiuyu4QiQXNzHF9lYKoB+f02kggHgnoalJqEF9/rqN6zk/u/AqfCTx/fPH4wiv9Wudc0rRYmurO5uSTM8QLnlmG45Cg89KytA0v4k/ETw3c+MbDxnc2dy0r/Y9Lgdo4n2nG0/MFXuBkNnHJ5rpPh74B8Raf4s8YN4v06BLTXoWBntJ1aJi5JZFGd44cjlR936ViWHhb4v8Ag3Rrzwp4agsbvS5nfyNSEyxywhupXLqVPf7rYJ4NCu0ua+343/yHpqltf8Lf5mh461Lxh4Rt/BvijW9RlR7eZbXWLWznf7PMMkhigwpYruzx1xjoK0/Eet6h4h+O2geHNE1O6t7Cwg+26h9luGRZQcMFfafmGAg5/vmtbX/C97N8Db7SfF+qx3+oRWTSyXsmAqyp864OAcAgDJ5POeuK5j9nXSrmfSdT8Uam7zXF40dnDJJ18qFQOPboP+AVpH+I129779PzIfwJ99P6+R7VWH4t/wCQVY/9hrS//S+CtysPxb/yCrH/ALDWl/8ApfBTlswW531FFFcpqFFFFABRRRQAUUUUAFYj6V4f8P6pqviudYrO5uYUF9fTTMF8uMYX7x2qAPQDPfNbdeN/ELT/ABxrvj+IN4IbxD4U04K9vZf2tBbR3c2AfMlViS6qcgIQBxnkEgrroPoyx4Z0u98Z6p448XWUEmn2ev2I0/SjIux7hFjKi4IPQMSNpPbtWb4L+I2iaF8O7fwTf6VfxeJ7K1e0fQ1sZGed+QWDAbNrZ3FiwHU/X0Dwtrni7WJri28R+C/+EXgSD9xcrqkN3ufOAoRBxgc5PHGK5Saf4xvos/hmXR9NuLqUPD/wlJvkSPYxPz/Z1UMHCnHAxkZwaUo6OK2a/wA+vTd3v30BS1Un0f8Al9+y2Nb4ETz3HwU0BrrO9EljGeyrM6qPyArtb2xthMdVi0y3u9UtoHS3kZFWUgjPliQjKgn8K5icSfCz4YWFto2mnWI9MSKCRTOsBKk4eXJBydxztGSc4FN8baf4vtte03xJ4Kk/tD7HG8N3oU92YYrtG5DKT8qyA927fTB0qNSm2u7/AK/r/MiGkbfh+hy/hLUb+6+Ol3eeOtObQNbuNL+y6VYKyzRTW6vvdvPU4d938OFwK7ux/wCSp67/ANgXTf8A0ffVzOi6F4r8VfELTvFnjTSrfQINGglj0/TIrtbmVpJBteR5FAXG3oB/+vprH/kqeu/9gXTf/R99S2il/W7/AOHHvJv+tv6/rU6SiiikMKKKKACiiigArEfSvD/h/VNV8VzrFZ3NzCgvr6aZgvlxjC/eO1QB6AZ75rbrxv4haf4413x/EG8EN4h8KacFe3sv7Wgto7ubAPmSqxJdVOQEIA4zyCQV10H0ZY8M6Xe+M9U8ceLrKCTT7PX7EafpRkXY9wixlRcEHoGJG0nt2rN8F/EbRNC+Hdv4Jv8ASr+LxPZWr2j6GtjIzzvyCwYDZtbO4sWA6n6+geFtc8XaxNcW3iPwX/wi8CQfuLldUhu9z5wFCIOMDnJ44xXKTT/GN9Fn8My6PptxdSh4f+EpN8iR7GJ+f7Oqhg4U44GMjODSlHRxWzX+fXpu7376ApaqT6P/AC+/ZbGt8CJ57j4KaA11neiSxjPZVmdVH5AV2t7Y2wmOqxaZb3eqW0DpbyMirKQRnyxIRlQT+FcxOJPhZ8MLC20bTTrEemJFBIpnWAlScPLkg5O452jJOcCm+NtP8X22vab4k8FSf2h9jjeG70Ke7MMV2jchlJ+VZAe7dvpg6VGpTbXd/wBf1/mRDSNvw/Q5Lw5q2oSfGjUdR8caa2g65Lo5g0rT1ZZoprdG8x289Th33D7uFwKw/hLqXxAufhpBP4H0bRFiM8891dazPJ5moTM7FjGsfTHC7nPOPau10fQfFXiz4gaf4r8baVbaDbaPBLFYaXHdLcyNJKNrySSKAuNvQD/9ebo+mfEH4Z21z4f8MeG7TxNoxnkl064bUVtntFdt2yRX+8AST8vX2zgTsrPt+rf47+v3FvXbv+lvw2+fzOt+GWv6f4h8JvPYaNDodxBdywX+nxIqiG5U/vPugZzkHPU5q58OP+SWeFP+wLZ/+iEqr8NvCN34Q8MzQ6tcxXOq6heS6hfyQgiPzpCCQuecAADJq18OP+SWeFP+wLZ/+iEpv/IlHSUUUUhhRRRQAUUUUANlijnheKZFkjkUq6OMhgeCCO4rzb4pnX9L8EXOheDfCkMmjy2TxXNxbNGPscRyHEdtld5C5IwRzjrXot5b/bLGe2E0kBmjaPzYW2umRjcp7EdQa8rtJfi7ouit4XTQrLWZUVobfxNcaoApQ/deWJsyMwHX39epmSvdf0/IqLs0/wCkXpfGNno/wv8ADmn+AJhqeo6pax2Who4wWKKFaWQdhGAS2e4xWP4H8K2/g/45NpsMjXE58Mia8u5OXup2uSXkYnkkn17YHatyx+BvhCTwhomj+JbH+1pdKhZFn+0SxZZ2LyEBHHBYnGegrG0j4H6Do3xhh1LT/D3k6HaWCTW0n22Rtl6suc4MhY/LjqNv41rf97d9W/us/wCvN2Rnb93ZeX5r+vJXPYSQqkscAckntXhvjLPxN0XxL4il+fwroWn3SaQh+7e3QjYPckd1Q5VD65Ir1E61cXnja88L3ukbLE6f9ojvftIPngsEZNgGVxk8k844rhPEv7PngX/hFtT/AOEd8M/8Tb7LJ9i/0+f/AF207PvybeuOvHrWMtYt+Tt+K/4b/hjWDtJLzV/z/wCH8tDsvDGnjVfhLo9g1zc2oudHgjM9rJ5cseYlGVbsfeuP8H+G9K8KfHvUdL0K0W1tU8NwsQCS0jGc5dmPLMe5Ndj8OPCFp4L8D2Gm2tj9inaJJr2PzjJm4KKJDksR1HY49KqWuganH8b9Q8QPbY0ubQ4rRJ/MXmUSliu3O7oc5xj3rebXtrrz/J/qYRT9lb0/NGh4o/5GLwZ/2GpP/TfeV0lc34o/5GLwZ/2GpP8A033ldJWZoFFFFABRRRQAUUUUAVrrTbG9uLae9sre4mtH8y3kliV2hbGNyEj5TjuK8kudU1S7+N/hu68e6O3h21thPBopjlS5S7nkXaRJKp+Q7cbUK8nPNdt4/wBI8S3trp2o+C78w6jpdx5/2KWZo4L9MYaKTBx9CeAfTqOabSfGvxC8SaHP4u8P2/hjR9EvFv8A7OL9Lua6nT7mGQAKgzznk/yIfEn5/wBP7gl8LXl/S/z8h+uk/E7xdNokB8zwp4fkLao4Py314oytv/tInDN2JwOwNX/gUMfBbQQOm2X/ANHPUWofAb4c309zdzeHPMup2eVn+3XA3OxJJx5mByfpTfhD4EfwB8PCX0byPEFxGz3kP2rd5zoz+Wu7cyL8pAyPXmiLtF38vv1/r7glq1b+kafxd0fWvEPwx1PSPDVr9qv7zy4whlWMbPMUsSWIHQGuS1e9+IXwy0+y8Qa74g07WtEjlhgv9Mh09YBZxsQuYZAdzbSQPm7dvTpb86/8Q/hbbX2hTyeGtbeQTwxrdMyK8chBjd0A3o2DnAxyOtc/qum/EP4lwWvh/wAUeG7Pw1oqzxy6lcDUEuXvFRg2yJV+4CR/F0HfjBcdJW81935d/PtuDacfKz+/+reXc9G1O3/s+G91rQtCttQ1mSFUADJBJcgHhWmI4A685rgPhVdzTePPF8nie3fTPFd88M1xphUeXFbIuyJo5ASJRz8zcc9q1fElp440Dxm3iDwjb/8ACR6bdWywXGhz3/2fyHXpLEX+Rcj7wxk++eDwb4b8Q3fji/8AHHjO2t9OvrizWws9Mt5hN9mgDbzvkHDMW9OP5Ahvf1/r5u3yB/Db0/r5fmkbvhf/AJGLxn/2Go//AE32dFHhf/kYvGf/AGGo/wD032dFIDwK5+Pv/CH61rWh/wDCNfbPs2sX58/7f5e7fdSv93yzjG7HXtTf+Go/+pP/APKn/wDaqKKvnkKyD/hqP/qT/wDyp/8A2qj/AIaj/wCpP/8AKn/9qooo55ByoP8AhqP/AKk//wAqf/2qj/hqP/qT/wDyp/8A2qiijnkHKg/4aj/6k/8A8qf/ANqo/wCGo/8AqT//ACp//aqKKOeQcqD/AIaj/wCpP/8AKn/9qo/4aj/6k/8A8qf/ANqooo55ByoP+Go/+pP/APKn/wDaqP8AhqP/AKk//wAqf/2qiijnkHKjkvHfxc0f4hR2Ka34WvIhZMzR/ZdWRS27GQd1uePlHTFb+i/tFWPh/RbbStK8EiC0tU2Rp/amcD1JMXJJ5JoopKTWwNJ7l7/hqP8A6k//AMqf/wBqqjq37SP9qWsEP/CK+V5N7a3ef7R3Z8meObb/AKodfLxntnPOMUUU+eQWRv8A/DXP/Uk/+Vb/AO00f8Nc/wDUk/8AlW/+00UVAw/4a5/6kn/yrf8A2mj/AIa5/wCpJ/8AKt/9poooAP8Ahrn/AKkn/wAq3/2mj/hrn/qSf/Kt/wDaaKKAD/hrn/qSf/Kt/wDaaP8Ahrn/AKkn/wAq3/2miigA/wCGuf8AqSf/ACrf/aaP+Guf+pJ/8q3/ANpoooAP+Guf+pJ/8q3/ANpo/wCGuf8AqSf/ACrf/aaKKAK1/wDtUWmpwxxX/gJZ445UmVG1Y43odykjyecEA89wKs/8Nc/9ST/5Vv8A7TRRQAf8Nc/9ST/5Vv8A7TWbB+1F5Piq+1n/AIRDd9rsra08n+0/ueS877t3lc58/GMcbe+eCigDS/4a5/6kn/yrf/aaP+Guf+pJ/wDKt/8AaaKKAD/hrn/qSf8Ayrf/AGmj/hrn/qSf/Kt/9poooAP+Guf+pJ/8q3/2mj/hrn/qSf8Ayrf/AGmiigA/4a5/6kn/AMq3/wBpo/4a5/6kn/yrf/aaKKAD/hrn/qSf/Kt/9po/4a5/6kn/AMq3/wBpoooArX/7VFpqcMcV/wCAlnjjlSZUbVjjeh3KSPJ5wQDz3Aqz/wANc/8AUk/+Vb/7TRRQAf8ADXP/AFJP/lW/+00f8Nc/9ST/AOVb/wC00UUAH/DXP/Uk/wDlW/8AtNZvhz9qL/hH/CulaN/wiH2j+zrKG087+09nmeWgTdt8o4zjOMmiigDS/wCGuf8AqSf/ACrf/aaP+Guf+pJ/8q3/ANpoooAP+Guf+pJ/8q3/ANpo/wCGuf8AqSf/ACrf/aaKKAD/AIa5/wCpJ/8AKt/9po/4a5/6kn/yrf8A2miigA/4a5/6kn/yrf8A2mj/AIa5/wCpJ/8AKt/9poooAP8Ahrn/AKkn/wAq3/2mj/hrn/qSf/Kt/wDaaKKAK0X7VFpDqU+oR+AlF3cIkcs39rEllTO1f9TwBuY4HcmrP/DXP/Uk/wDlW/8AtNFFAB/w1z/1JP8A5Vv/ALTR/wANc/8AUk/+Vb/7TRRQBm6p+1F/aWo6Ndf8Ih5X9l3rXe3+08+bm3mh258rj/Xbs8/dx3yNL/hrn/qSf/Kt/wDaaKKAD/hrn/qSf/Kt/wDaaP8Ahrn/AKkn/wAq3/2miigA/wCGuf8AqSf/ACrf/aaP+Guf+pJ/8q3/ANpoooAP+Guf+pJ/8q3/ANpo/wCGuf8AqSf/ACrf/aaKKAD/AIa5/wCpJ/8AKt/9po/4a5/6kn/yrf8A2miigA/4a5/6kn/yrf8A2mmy/tarNC8b+CTtdSpxq5BwfcQ5FFFG+jAisf2rLbTbCCysPAaQW1vGI4ok1XARQMAD9zU//DXP/Uk/+Vb/AO00UUbgH/DXP/Uk/wDlW/8AtNH/AA1z/wBST/5Vv/tNFFAHffCDx5/wmWmeIfEH9m/Y/t2sZ+z+f5mzZaW0f3toznZnoOtFFFAH/9k=)![RandomForest.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RDuRXhpZgAATU0AKgAAAAgABAE7AAIAAAAMAAAISodpAAQAAAABAAAIVpydAAEAAAAYAAAQzuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFudG9pbmUgWGllAAAFkAMAAgAAABQAABCkkAQAAgAAABQAABC4kpEAAgAAAAMwNQAAkpIAAgAAAAMwNQAA6hwABwAACAwAAAiYAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMzowMToyNCAxNDo0NjowMAAyMDIzOjAxOjI0IDE0OjQ2OjAwAAAAQQBuAHQAbwBpAG4AZQAgAFgAaQBlAAAA/+ELHmh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjMtMDEtMjRUMTQ6NDY6MDAuMDQ4PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkFudG9pbmUgWGllPC9yZGY6bGk+PC9yZGY6U2VxPg0KCQkJPC9kYzpjcmVhdG9yPjwvcmRmOkRlc2NyaXB0aW9uPjwvcmRmOlJERj48L3g6eG1wbWV0YT4NCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVuZD0ndyc/Pv/bAEMABwUFBgUEBwYFBggHBwgKEQsKCQkKFQ8QDBEYFRoZGBUYFxseJyEbHSUdFxgiLiIlKCkrLCsaIC8zLyoyJyorKv/bAEMBBwgICgkKFAsLFCocGBwqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKv/AABEIATgCdAMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AON03xD4hm0q0kk8T6+XeBGYjWLkclR2D1a/t3Xv+hm8Qf8Ag5uv/jlY2k/8gWx/694//QRVuvpYUaTivdX3HkyqTu9WXv7d17/oZvEH/g5uv/jlH9u69/0M3iD/AMHN1/8AHKo0VXsKX8q+4XtJ92Xv7d17/oZvEH/g5uv/AI5R/buvf9DN4g/8HN1/8cqjRR7Cl/KvuD2k+7L39u69/wBDN4g/8HN1/wDHKP7d17/oZvEH/g5uv/jlUaKPYUv5V9we0n3Ze/t3Xv8AoZvEH/g5uv8A45R/buvf9DN4g/8ABzdf/HKo0Uewpfyr7g9pPuy9/buvf9DN4g/8HN1/8co/t3Xv+hm8Qf8Ag5uv/jlUaKPYUv5V9we0n3Ze/t3Xv+hm8Qf+Dm6/+OUf27r3/QzeIP8Awc3X/wAcqjRR7Cl/KvuD2k+7L39u69/0M3iD/wAHN1/8cpDrmvHGfEuvnHT/AInNzx/5EqlRR7Cl/KvuD2k+7L39u69/0M3iD/wc3X/xyj+3de/6GbxB/wCDm6/+OVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/45R/buvf9DN4g/wDBzdf/AByqNFHsKX8q+4PaT7svf27r3/QzeIP/AAc3X/xyj+3de/6GbxB/4Obr/wCOVRoo9hS/lX3B7Sfdl7+3de/6GbxB/wCDm6/+OUf27r3/AEM3iD/wc3X/AMcqjRR7Cl/KvuD2k+7L39u69/0M3iD/AMHN1/8AHKP7d17/AKGbxB/4Obr/AOOVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/wCOUf27r3/QzeIP/Bzdf/HKo0Uewpfyr7g9pPuy9/buvf8AQzeIP/Bzdf8Axyj+3de/6GbxB/4Obr/45XE66bufxPa2VtezWqyxDJjc4By3OAR6VV1SPUvDwhuF1iW6LPjy5M8/gSeK5HKlG7dPRO19DdRm7Lm1fqegf27r3/QzeIP/AAc3X/xykGua8M48S6+M9f8Aic3PP/kSsO91e3sIoTOsjSzfchjXc7fhSafrVtqM8kCLLDPHy0UybWAro5MPzcllf0RlzVbXuze/t3Xv+hm8Qf8Ag5uv/jlH9u69/wBDN4g/8HN1/wDHK5aXxZp0DTLIJg8LlNu0ZYj056fXFXdM1e11aFpLUsNhwyOMFamKw03aKX3IbdWKu7m5/buvf9DN4g/8HN1/8co/t3Xv+hm8Qf8Ag5uv/jlcq/i7S0uvI3yEZwZQvyD9c/pUXhS8lntLyS6uHkCS8NI5O0Y9+1QnhpTUYxT37dBv2qjdtnX/ANu69/0M3iD/AMHN1/8AHKP7d17/AKGbxB/4Obr/AOOVyb+MdLS48secy5x5ip8v88/pV+81i1s9NS+JaWByApiAJOfqRVL6q02ktPQT9snZ3N3+3de/6GbxB/4Obr/45R/buvf9DN4g/wDBzdf/AByuWXxbpbXgg3yAE480rhAfrnP44p9v4o0661AWkTSbmO1ZGXCsfQd/0oX1Vuyt+A/33mdN/buvf9DN4g/8HN1/8co/t3Xv+hm8Qf8Ag5uv/jlUa5K7S91Dxdc2UGpXFqioGGxmwPlXsCPWirGlC1oJ38kKDnK/vWsd3/buvf8AQzeIP/Bzdf8Axyj+3de/6GbxB/4Obr/45XMadot7Z3qzT6xPdIoOYn3YPHuxpdQ8T6fp1wYJDJLIvDCJQdv1JIo5aMY3qRUfuC9Ru0W2dN/buvf9DN4g/wDBzdf/AByj+3de/wChm8Qf+Dm6/wDjlYtnqtrf2b3Nq5ZUB3rjDLxnGKoW/iuwup4IYY7gyTNtC7B8vPfmqccMmlZa+SC9V31Z1B1zXiCD4l18g9QdZuf/AI5S/wBu69/0M3iD/wAHN1/8crl7vxXptndGBjLKynDNGoIU/if5Vdl1eyi00X5mBgb7pUZJPpj1pJYZ3slp6Beqrbm3/buvf9DN4g/8HN1/8co/t3Xv+hm8Qf8Ag5uv/jlc5b+IbWa7jt5YLm1eX/V/aItof6c1lan4nNtr6Qr5i2tuxEyqo3O3PTnp09KiUsNFJ2Wrtsioqs3a7O4/t3Xv+hm8Qf8Ag5uv/jlH9u69/wBDN4g/8HN1/wDHKz4pBNCki5AdQwz706uj2FL+VfcZe0n3Ze/t3Xv+hm8Qf+Dm6/8AjlH9u69/0M3iD/wc3X/xyqNFHsKX8q+4PaT7svf27r3/AEM3iD/wc3X/AMco/t3Xv+hm8Qf+Dm6/+OVRoo9hS/lX3B7Sfdl7+3de/wChm8Qf+Dm6/wDjlH9u69/0M3iD/wAHN1/8cqjRR7Cl/KvuD2k+7L39u69/0M3iD/wc3X/xyj+3de/6GbxB/wCDm6/+OVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/45R/buvf9DN4g/wDBzdf/AByqNFHsKX8q+4PaT7su/wBua9nP/CS6/n1/tm5/+OUv9u69/wBDN4g/8HN1/wDHKo0Uewpfyr7g9pPuy9/buvf9DN4g/wDBzdf/AByj+3de/wChm8Qf+Dm6/wDjlUaKPYUv5V9we0n3Ze/t3Xv+hm8Qf+Dm6/8AjlH9u69/0M3iD/wc3X/xyqNFHsKX8q+4PaT7svf27r3/AEM3iD/wc3X/AMco/t3Xv+hm8Qf+Dm6/+OVRoo9hS/lX3B7Sfdl7+3de/wChm8Qf+Dm6/wDjlH9u69/0M3iD/wAHN1/8cqjRR7Cl/KvuD2k+7L39u69/0M3iD/wc3X/xyj+3de/6GbxB/wCDm6/+OVRoo9hS/lX3B7Sfdl7+3de/6GbxB/4Obr/45R/buvf9DN4g/wDBzdf/AByqNFHsKX8q+4PaT7svf27r3/QzeIP/AAc3X/xyj+3de/6GbxB/4Obr/wCOVRoo9hS/lX3B7Sfdn0Z8H5rjUfhbptzqF3dXdw092rTT3LyOwW6lUZYkk4AA59KKb8E/+SSaZ/18Xv8A6VzUV81PSTPWjsj5q0n/AJAtj/17x/8AoIq3VTSf+QLY/wDXvH/6CKt19RT+BHjy3YUUUVYgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDktfs47/xdZ2sxZUkhAJQ89WNU30238P+IIft0X2izkOY5H/gPvjg4rsJNOtZr+O9kizcRDCPuPA57Zx3NLe2FtqMIivIhIgO4DJGD9RXA8K7uatzXuvTszpVbaPSxj6vfyHXbWysYLb7S6bluZ1ztBz90/h+tUdHEq+NrgXFwtxKIiGkVQATheMD06fhW/PomnXUEUU9sHSFdqZZsgemc5p1vo2n2tytxbWyxSqu0FSRx7jODVexqOopN6Xv/SJ9pFRsuxi+GYkbW9XkKgssuASORlmz/KoNIjP27xBFAMNhlQDty2K6W10+1spZpLaLY87bpDuJ3Hn1PuaLbTrW0uJp7eLZJOcyNuJ3HOe596UcM0oJ9L/iDqpuT72/A53w1f6Zb6DLHdSwxvlvNV8ZcduO/FUtJV5PCerC3BzuyB/s8Z/Suok0DS5bo3ElmhkJyTk4J9xnFT2enWunq62cXliRtzDcTk/jU/V6krKVtE1oV7WKu13uYGnahpKeEzFJJCreURJESAzN9O/1rMZJE8BL5uQGucpn0/8A15rqX8O6TJcec1km/OeCQPyzirV3YWt7ai3uYg0IIIQErjHTpRLD1Jxd7XtYFVinp3ucx4mijTw9pgVAMFQMDplean8SxpFqGjCNQoWTaMdgCvFbt1pdne28cFzDvjixsXcRjAx2NOutOtb2SGS5i3tAd0Z3EbTx6H2FaToNuTXVr8CY1Ekr9L/iWa46602HVfG11b3DSKnlhsxkA5Cr6g12NVl061TUHvlixcuu1n3Hkcds47CtK1L2rjfZMinPkuU9L8P2ukTvLbSTMzrtPmMCP0ArG8M3VpZXV8moSRw3XmnLykLkdxk+9ddVG90XT9Qk8y7tVd/7wJUn6kEZqZUXFxdO2l9PUaqXTU+pgaOUl1fWJrMYtDGwBAwCfb9as+D4wNBmaMASNIwz68DFb0Nnb21r9ngiWOLBBVeM5ptlY22nweTZx+XHndjcTz+NTTw7g1d9GvvdxyqKSZxei5S0u45NXjsDuIlilgVi4x6nk9+P8au/YtOXwqIpdSYwNPuin+zsAGxjGPTrW/daDpl5cGe4tFaQ9WDFc/XB5q09nbva/ZngjMGMeXtG0D6VnHCyUWnba3X/AD0+Rcqybuv0OQnbU9JuLM372+owM4ERcByOnIJGQf0q7q0scPjewkmdY0WLlnOAPvd617bQNMs5xNb2irIOQSS2Ppk8VLfaTZakUN7AJCn3Tkgj8QaaoVFHfVNP7vMXtY3+Vi2rK6hkIZWGQQcgilpscaxRrHGMKoAUegp1d5zhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB9FfBP8A5JJpn/Xxe/8ApXNRR8E/+SSaZ/18Xv8A6VzUV8rP42exH4UcJ4P8H+GrnwPoU9z4d0qaaXTrd5JJLGNmdjGpJJK5JJ71s/8ACE+FP+hZ0f8A8AIv/iaPBP8AyT/w9/2C7b/0UtblejGKstDlbdzD/wCEJ8Kf9Czo/wD4ARf/ABNH/CE+FP8AoWdH/wDACL/4mtyinyrsK7MP/hCfCn/Qs6P/AOAEX/xNH/CE+FP+hZ0f/wAAIv8A4mtyijlXYLsw/wDhCfCn/Qs6P/4ARf8AxNH/AAhPhT/oWdH/APACL/4mtyijlXYLsw/+EJ8Kf9Czo/8A4ARf/E0f8IT4U/6FnR//AAAi/wDia3KKOVdguzD/AOEJ8Kf9Czo//gBF/wDE0f8ACE+FP+hZ0f8A8AIv/ia3KKOVdguzD/4Qnwp/0LOj/wDgBF/8TR/whPhT/oWdH/8AACL/AOJrcoo5V2C7MP8A4Qnwp/0LOj/+AEX/AMTR/wAIT4U/6FnR/wDwAi/+Jrcoo5V2C7MP/hCfCn/Qs6P/AOAEX/xNH/CE+FP+hZ0f/wAAIv8A4mtyijlXYLsw/wDhCfCn/Qs6P/4ARf8AxNH/AAhPhT/oWdH/APACL/4mtyijlXYLsw/+EJ8Kf9Czo/8A4ARf/E0f8IT4U/6FnR//AAAi/wDia3KKOVdguzD/AOEJ8Kf9Czo//gBF/wDE0f8ACE+FP+hZ0f8A8AIv/ia3KKOVdguzD/4Qnwp/0LOj/wDgBF/8TR/whPhT/oWdH/8AACL/AOJrcoo5V2C7MP8A4Qnwp/0LOj/+AEX/AMTR/wAIT4U/6FnR/wDwAi/+Jrcoo5V2C7MP/hCfCn/Qs6P/AOAEX/xNH/CE+FP+hZ0f/wAAIv8A4mtyijlXYLsw/wDhCfCn/Qs6P/4ARf8AxNH/AAhPhT/oWdH/APACL/4mtyijlXYLsw/+EJ8Kf9Czo/8A4ARf/E0f8IT4U/6FnR//AAAi/wDia3K8N0yxvPjT4o1ebVtUubTQdPkEdvaWrAbsk4PORnAySQeuBxUSaUlFK7KWqu2erf8ACE+FP+hZ0f8A8AIv/iaP+EJ8Kf8AQs6P/wCAEX/xNcr4X+GepeDfFaT6H4imOhFf31jcjeztgjthR2IYAHtgjrBrHxgl07xVqWgWXhi61O9tHCQpbSlmm4yxKhCVAH1o5oK3MrMLPodj/wAIT4U/6FnR/wDwAi/+Jo/4Qnwp/wBCzo//AIARf/E1w2pXlrdfGnwnLqOmXdvqk+nCQKLtdkGRKSjJ5eWI5GQw+nHPNp8QvErfGOZ30LUbhYUMEekBnzCp2gy4Cd/vZI6N1xS5o3Ubbtr7huLs3fon9567/wAIT4U/6FnR/wDwAi/+Jo/4Qnwp/wBCzo//AIARf/E1zHiT4rjTPEU+i+HfD974hvLQZuhbEhYvb5VYnGcHgAetXbD4mafqngPUvEdhayNLpqE3FjK+x1Ydt2Dwexx+FPmp2b7C5ZXSNr/hCfCn/Qs6P/4ARf8AxNH/AAhPhT/oWdH/APACL/4muY8I/E+88YapbQWfha8isZEbz9QaQmKFwuSoOzDdh1B56VQ+DuoaPZ+C9YvbeOews7e8d52u7lZsYRSWysaYGO2D9aE4X+Vws7Hbf8IT4U/6FnR//ACL/wCJo/4Qnwp/0LOj/wDgBF/8TXBN8cWlMt5p3hDU7rRoWxJqAJAQdyQFKj6FhXV6r8QrG1+HLeLtKh/tC2whWEyeW2S4UqTg4IJ9D0/Gjmp2uPllexpf8IT4U/6FnR//AAAi/wDiaP8AhCfCn/Qs6P8A+AEX/wATXA3Hx08q1gv4fCWoyaW+1Zb5mKxq/dVOzDYORyVzjoK9Q0zUbfV9KtdRsmL291EssZIwdrDIz7048kr26Eu63M3/AIQnwp/0LOj/APgBF/8AE0f8IT4U/wChZ0f/AMAIv/ia3KKrlXYV2Yf/AAhPhT/oWdH/APACL/4mj/hCfCn/AELOj/8AgBF/8TW5RRyrsF2Yf/CE+FP+hZ0f/wAAIv8A4mj/AIQnwp/0LOj/APgBF/8AE1uUUcq7BdmH/wAIT4U/6FnR/wDwAi/+Jo/4Qnwp/wBCzo//AIARf/E1uUUcq7BdmH/whPhT/oWdH/8AACL/AOJo/wCEJ8Kf9Czo/wD4ARf/ABNblFHKuwXZh/8ACE+FP+hZ0f8A8AIv/iaP+EJ8Kf8AQs6P/wCAEX/xNblFHKuwXZh/8IT4U/6FnR//AAAi/wDiaP8AhCfCn/Qs6P8A+AEX/wATW5RRyrsF2Yf/AAhPhT/oWdH/APACL/4mj/hCfCn/AELOj/8AgBF/8TW5RRyrsF2Yf/CE+FP+hZ0f/wAAIv8A4mj/AIQnwp/0LOj/APgBF/8AE1uUUcq7BdmH/wAIT4U/6FnR/wDwAi/+Jo/4Qnwp/wBCzo//AIARf/E1uUUcq7BdmH/whPhT/oWdH/8AACL/AOJo/wCEJ8Kf9Czo/wD4ARf/ABNblFHKuwXZh/8ACE+FP+hZ0f8A8AIv/iaP+EJ8Kf8AQs6P/wCAEX/xNblFHKuwXZh/8IT4U/6FnR//AAAi/wDiaP8AhCfCn/Qs6P8A+AEX/wATW5RRyrsF2Yf/AAhPhT/oWdH/APACL/4mj/hCfCn/AELOj/8AgBF/8TW5RRyrsF2Yf/CE+FP+hZ0f/wAAIv8A4mj/AIQnwp/0LOj/APgBF/8AE1uUUcq7BdmH/wAIT4U/6FnR/wDwAi/+Jo/4Qnwp/wBCzo//AIARf/E1uUUcq7Bdl/4XWVrB4DSGG2hjij1HUUREjAVFF9OAAOwAGMUVP8M/+RJ/7impf+l09FeXLdnYtjjfBP8AyT/w9/2C7b/0UtblcV4P8YeGrbwPoUFz4i0qGaLTrdJI5L6NWRhGoIILZBB7Vs/8Jt4U/wChm0f/AMD4v/iq9OMlZanI07m5RWH/AMJt4U/6GbR//A+L/wCKo/4Tbwp/0M2j/wDgfF/8VT5l3FZm5RWH/wAJt4U/6GbR/wDwPi/+Ko/4Tbwp/wBDNo//AIHxf/FUcy7hZm5RWH/wm3hT/oZtH/8AA+L/AOKo/wCE28Kf9DNo/wD4Hxf/ABVHMu4WZuUVh/8ACbeFP+hm0f8A8D4v/iqP+E28Kf8AQzaP/wCB8X/xVHMu4WZuUVh/8Jt4U/6GbR//AAPi/wDiqP8AhNvCn/QzaP8A+B8X/wAVRzLuFmblFYf/AAm3hT/oZtH/APA+L/4qj/hNvCn/AEM2j/8AgfF/8VRzLuFmblFYf/CbeFP+hm0f/wAD4v8A4qj/AITbwp/0M2j/APgfF/8AFUcy7hZm5RWH/wAJt4U/6GbR/wDwPi/+Ko/4Tbwp/wBDNo//AIHxf/FUcy7hZm5RWH/wm3hT/oZtH/8AA+L/AOKo/wCE28Kf9DNo/wD4Hxf/ABVHMu4WZuUVh/8ACbeFP+hm0f8A8D4v/iqP+E28Kf8AQzaP/wCB8X/xVHMu4WZuUVh/8Jt4U/6GbR//AAPi/wDiqP8AhNvCn/QzaP8A+B8X/wAVRzLuFmblFYf/AAm3hT/oZtH/APA+L/4qj/hNvCn/AEM2j/8AgfF/8VRzLuFmblFYf/CbeFP+hm0f/wAD4v8A4qj/AITbwp/0M2j/APgfF/8AFUcy7hZm5RWH/wAJt4U/6GbR/wDwPi/+Ko/4Tbwp/wBDNo//AIHxf/FUcy7hZm5RWH/wm3hT/oZtH/8AA+L/AOKo/wCE28Kf9DNo/wD4Hxf/ABVHMu4WZtnkV4Z4M1y3+E3i3XNC8WCa1tLqUS2tyI2dGUZweMkggjpnBBBr1j/hNvCn/QzaP/4Hxf8AxVVNQ8ReBNWgEOq6x4dvYgciO5uoJFB9cMTUS+JSiy1s4tGVpPxY0rxD4wh0Tw/ZXmowyJue9jTYkXuVbBC+/rwAa5/waqn9obxYxUErAcHHTmOu10/xF4E0mEw6VrHh2yiY5KW11BGpPrhSKSHxB4DttQmv7fV/DsV5OMS3MdzAskg/2mByeg6+lCXvRk3tf8RPZpLt+ByHif8A5OO8L/8AXkf/AGtWXda5p3hr9pDUr3W5za20lokaOY2bcxjjA4UE9jz7V6JL4h8CT6lFqE2r+HZL2FdsVy9zAZEHPAbOQOT09TUd9rXw+1O4jn1LUvDV5NEMRyXE9vIyc54JORzUqNra7Nv7ynK99OiX3Hj0Een+HviR4ktfFuva54fE87TwXGmTMgmVnZhu2qxPDDB6DDCt3SrPQv8AhVXjPU/Db65JDdxFZZtWMZ851ySy7eT97kn/ABr0XUdb+H+r7P7W1Pw1feX9z7TcW8m36bicVM/ifwRJp5sJNb8PvZlPLNu13AYyv93bnGPaoVNKDhfpYpzbkpW63M34Rqq/CnSNqgZSQnA6nzGrzrwJpl3rHwR8WWOnKz3Ml0xREGS+1UbaPcgY/GvWLTxV4K0+0S1sNd0G2t4xhIYbyFEXvwAcCo9P8ReBNJheLStY8O2UbtvZLa6gjDN6kKRk+9aTjGbeu6sRBuK263/M868M/FLwxpXwrGkX4kj1C2tZLc2RgY+cxzzuAwAc85I71nxaRe6R+zNqA1GN4murlLiONxgqhkjA47Z25/GvTptU+HNxqAv7i+8Ly3gIIuHmt2kz67ic1avfFHgnUrR7XUdc0C7t3xuhnu4XRsHIyCcHmplHmTbau1b8bji+Vqy0Tucb4miVP2Z4VA4GnWbDjuWjP9a7D4c/8k20H/ryj/lSS+IvAs+mDTp9Y8OyWIVUFq91AYgq4wNhOMDAwMdqmtvFvg2zto7e08QaFBBEu2OKK9hVUHoADgCtbrnlK+5GvKo9v+B/kdDRWH/wm3hT/oZtH/8AA+L/AOKo/wCE28Kf9DNo/wD4Hxf/ABVPmXcVmblFYf8Awm3hT/oZtH/8D4v/AIqj/hNvCn/QzaP/AOB8X/xVHMu4WZuUVh/8Jt4U/wChm0f/AMD4v/iqP+E28Kf9DNo//gfF/wDFUcy7hZm5RWH/AMJt4U/6GbR//A+L/wCKo/4Tbwp/0M2j/wDgfF/8VRzLuFmblFYf/CbeFP8AoZtH/wDA+L/4qj/hNvCn/QzaP/4Hxf8AxVHMu4WZuUVh/wDCbeFP+hm0f/wPi/8AiqP+E28Kf9DNo/8A4Hxf/FUcy7hZm5RWH/wm3hT/AKGbR/8AwPi/+Ko/4Tbwp/0M2j/+B8X/AMVRzLuFmblFYf8Awm3hT/oZtH/8D4v/AIqj/hNvCn/QzaP/AOB8X/xVHMu4WZuUVh/8Jt4U/wChm0f/AMD4v/iqP+E28Kf9DNo//gfF/wDFUcy7hZm5RWH/AMJt4U/6GbR//A+L/wCKo/4Tbwp/0M2j/wDgfF/8VRzLuFmblFYf/CbeFP8AoZtH/wDA+L/4qj/hNvCn/QzaP/4Hxf8AxVHMu4WZuUVh/wDCbeFP+hm0f/wPi/8AiqP+E28Kf9DNo/8A4Hxf/FUcy7hZm5RWH/wm3hT/AKGbR/8AwPi/+Ko/4Tbwp/0M2j/+B8X/AMVRzLuFmblFYf8Awm3hT/oZtH/8D4v/AIqj/hNvCn/QzaP/AOB8X/xVHMu4WZuUVh/8Jt4U/wChm0f/AMD4v/iqP+E28Kf9DNo//gfF/wDFUcy7hZm5RWH/AMJt4U/6GbR//A+L/wCKo/4Tbwp/0M2j/wDgfF/8VRzLuFmdl8M/+RJ/7impf+l09FQfC69tZ/AaTQ3MMkUmo6i6OkgKupvpyCD3BBzmivLluzsWxR8A/wDJNfDP/YItf/RK10Fc/wCAf+Sa+Gf+wRa/+iVroK6lsZhRRRQIKKKKACiiigAooooAKKKKACiiigArn/Ef/Ie8Jf8AYXk/9Ibqugrn/Ef/ACHvCX/YXk/9IbqhjOgorz/4m/Ee58GyadpWg6aNT13VGK20DA7FGcZIGCck4ABHQnIxzyOofF3xzoOpaLo/iXwxZ6dqN9dojyHMkMsLMFyhWQ4cZ5BLdRwOlSpJuy72Bqy/E9hm1jTLfVIdMn1G0iv513RWjzqssg55VCckcHoOxq7Xk/ii+t4v2jvC1o+l2k00lkSt67SiWIfvuFAcJjjupPJ9sQa38VfFVr8UNV8I6B4fttWlijX7Gq7kYMUVi0jFtu0ZP93tz6ilovn+A3Gz+S/E9fqlZ6xpmoXdza2Go2l1cWjbbiGCdXeE5Iw6g5U5B6+led/Dz4m67rnjO/8ACfjTR7fTtWtYjKPs2duBjKkFm7MCCDg1B8Lb63ufib49hh0u0s3hvcPPA0pec+ZJy4d2UHjPyhRzTTu1bZpsT0i32aX3nrFFFFMQUUUUAFFFFABRRRQAVz/hz/kPeLf+wvH/AOkNrXQVz3h0hdd8WknAGrIST/142tJjOhorxeb4teNfEF9qNz8PPC1tqGiabIUluLljvlxySo3r2GcAMeRnritm7+LT3fwWuPGmhWkSXcDpFJbXQLokm9VYfKVJGGyDx1H0pc65eb+tR8r5uU9PprukUbPIyoijLMxwAPUmvDL74xfEGDw5a+J4/B9pFoBVBLcTOd0pPBZQHyik9CVYdOTVX45eJ9Y1r4d6FfaZbCHw/qaRzTS78SCUqxERAblcZJ+UjKjmplOybXewRjd2PflZXQMjBlYZBByCKWvF9a+JfjPwT8O9E1DXNH02G8uLzyGgGXBtwgKsCshwx56n8K3LP4heJtF8H6r4l+ImiWumWsew6da2z5lnL5wrHc2D93kgHqccVcpRTfl/X3+RMbtLzPTKK8Pb4tfEiy0pPE2p+CbVfDTkNlXKzBGPBJLk4/2jGAcj1rofiD8VptA8B6J4m8LxW11Bqk6ri7jY4QoxIwrDDArjqR1ockld/wBXHa7sj0+ivEr/AOL3j3QBa634k8Fw2nhu6dQhWQmdFbkbju4OOzIuenFdPP8AEW/s/ixpGhzxWb+H9ctRNYXiIwkLFcgElsHJGPuj7y0J3dvO3z3B6a/M9GorgR461O9+NZ8IaVBaPp1naedfzujGRWxkKpDAD70fUHvXfU07q6B6OwUUUUCOf8ff8k18Tf8AYIuv/RLV0Fc/4+/5Jr4m/wCwRdf+iWroKOowooooEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAc/ef8lK0b/sEah/6Os66CufvP8AkpWjf9gjUP8A0dZ10FAwooooEFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAQfDv/kU5f8AsL6n/wCl89FHw7/5FOX/ALC+p/8ApfPRXK9zYxvAP/JNfDP/AGCLX/0StdBXB+CPF2m23w/8PQSW2ss8Wl2yMY9EvJFJESjhliIYe4JB7Vuf8Jrpf/Prrn/ggvv/AIzXSmrGR0FFc/8A8Jrpf/Prrn/ggvv/AIzR/wAJrpf/AD665/4IL7/4zTugOgorn/8AhNdL/wCfXXP/AAQX3/xmj/hNdL/59dc/8EF9/wDGaLoDoKK5/wD4TXS/+fXXP/BBff8Axmj/AITXS/8An11z/wAEF9/8ZougOgorn/8AhNdL/wCfXXP/AAQX3/xmj/hNdL/59dc/8EF9/wDGaLoDoKK5/wD4TXS/+fXXP/BBff8Axmj/AITXS/8An11z/wAEF9/8ZougOgorn/8AhNdL/wCfXXP/AAQX3/xmj/hNdL/59dc/8EF9/wDGaLoDoK5/xH/yHvCX/YXk/wDSG6o/4TXS/wDn11z/AMEF9/8AGaxNd8Wafca54YMVrrR8rVHdgdDvFJH2O5X5QYsscsOBk4yegJCbQHJ/GW3v/D/jrw148gsZL6w0z91drGc+WNxIJ9Mhm56ZAz2rkPH3j0ePPE/gy70/SLyy0uLUAIbi8RVaeQvHuCgE8KNvOeSfavQ/iKuq+JI7O58Jat4p0S9tCcxLompJDOCQRvCw9RjuDnOMVyll4Z8T6/4p0vVPiVq2qX8GkyiW3t7PwzfDccg4OLZAOVXJwSQMcVlDSSXRO5Utr+Vja8Xf8nR+EP8ArwP/ALXpPDShv2rPE5I5XTgR+UFek/8ACW2P/QP8Qf8AhO3/AP8AGaP+Etsf+gf4g/8ACdv/AP4zVxtFp32v+ISvK/y/A8y0r/k7fWP+wcP/AEVFUvwh/wCSsfEb/r//APastekf8JbY/wDQP8Qf+E7f/wDxmj/hLbH/AKB/iD/wnb//AOM0QtG2uya+8JXkmu9vwRuUVh/8JbY/9A/xB/4Tt/8A/GaP+Etsf+gf4g/8J2//APjNVzLuTZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5RWH/AMJbY/8AQP8AEH/hO3//AMZo/wCEtsf+gf4g/wDCdv8A/wCM0cy7hZm5XN6HF5+reMYicCTVFXPpmwtRVj/hLbH/AKB/iD/wnb//AOM1heH/ABPZx634oZrHXCJdURwE0K9YgfY7YYYCLKnjocHBB6EEzJxasxq61PAtPsPC/ga81TRPiX4PvtR1KOYmxnt55I1mXGAOHUbSQCGAY/MQRxivQPEWl22nfs1arLZ+GZPDK3k8U5sJLuSdh+9RQzFwCpIUcemK9a/4S2x/6B/iD/wnb/8A+M0f8JbY/wDQP8Qf+E7f/wDxmpsnHlv2KvaSlY878WqE/ZSgCjA/sqxP/j0Vc746srm7/Zd8MPawPKtv9nlmKLnYnluNx9ssPzr2b/hLbH/oH+IP/Cdv/wD4zR/wltj/ANA/xB/4Tt//APGaqpablru0/uFBuKS7X/Gx4Z8TfFtj4y+Gnhi/0yC6hih1MWxFyiqWZYxkjBPHNen/ABl8LX/iz4azWukRtNd20qXMcKnmXaCCo9ThiQO5FdJ/wltj/wBA/wAQf+E7f/8Axmj/AIS2x/6B/iD/AMJ2/wD/AIzRPlmmm93f8v8AIUbxa8lY8W1T4vt4j+H7+C7Pw1qX/CR3FutlJB5QKJwFZgM7s47FRjPXiq/xT8PXPhX4EeEtHvSDdW95mUBshXZZGK59i2Pwr3H/AIS2x/6B/iD/AMJ2/wD/AIzXn/xe0+bx/wCH7Cx0a21WCW2uxO5utA1FVK7GGBtt255pSd9W9W1+DHBWaXRX/I5Tx98R7vx34cj8Dad4Y1ODxBPLEt1BKgCxFSD8pzkjOPmYKAOa6P4q+FLjSPhT4f1CyfdqPhL7OyyqOqqFVj/30FP0Br0ZPFdksaqdP8QZAA/5F2//APjNeefE2LxJ4zmi0/Qr3VdP0GaEJewS+HL/AHuwYnIxbEkYxxvAOKUnZPleraf3bCgtr7JW+/cs/Ayyl1Gy1vxrfxbLvXr52TknbErHgH03Fh/wEV6xXJeH9S0jw54esdHsdO8QeRZwrEpPh2/y2OrH9z1JyfxrR/4S2x/6B/iD/wAJ2/8A/jNa3ivdi9ESlJ6vdm5RWH/wltj/ANA/xB/4Tt//APGaP+Etsf8AoH+IP/Cdv/8A4zS5l3HZkfj7/kmvib/sEXX/AKJaugrhvHHiezuPh74ihSx1xWk0u5QNLoV7GgJiYZZmiCqPUkgDvW7/AMJbY/8AQP8AEH/hO3//AMZpcyvuFmblFYf/AAltj/0D/EH/AITt/wD/ABmj/hLbH/oH+IP/AAnb/wD+M0+ZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwszcorD/wCEtsf+gf4g/wDCdv8A/wCM0f8ACW2P/QP8Qf8AhO3/AP8AGaOZdwsyO8/5KVo3/YI1D/0dZ10FcNd+J7NviFpEwsdc2ppd8hU6FehyTLaHIXytxHynJAwMjOMjO7/wltj/ANA/xB/4Tt//APGaXMu4WZuUVh/8JbY/9A/xB/4Tt/8A/GaP+Etsf+gf4g/8J2//APjNPmXcLM3KKw/+Etsf+gf4g/8ACdv/AP4zR/wltj/0D/EH/hO3/wD8Zo5l3CzNyisP/hLbH/oH+IP/AAnb/wD+M0f8JbY/9A/xB/4Tt/8A/GaOZdwszcorD/4S2x/6B/iD/wAJ2/8A/jNH/CW2P/QP8Qf+E7f/APxmjmXcLM3KKw/+Etsf+gf4g/8ACdv/AP4zR/wltj/0D/EH/hO3/wD8Zo5l3CzNyisP/hLbH/oH+IP/AAnb/wD+M0f8JbY/9A/xB/4Tt/8A/GaOZdwszcorD/4S2x/6B/iD/wAJ2/8A/jNH/CW2P/QP8Qf+E7f/APxmjmXcLM1fh3/yKcv/AGF9T/8AS+eiofhtdxy+DTKqTqJNU1JwskDowBvpzgqwBU+oIBHQ0VzPc1MzwD/yTXwz/wBgi1/9ErVbxD8SfCXhXV00vXtXW0vHRXEfkSPhSSASVUgdO5qx4DYJ8M/DbOQqrpFqST2HkrXgsfhyX4rW/j/xewLvG2zSzjtH820D18tVX/gZraU3Hborv0IUb/kj6bByMjkUVwPwz8aQ6t8IrbWb+bc+m27x3rDlgYl5J9yoB/GuBsPFXxe8YaPdeLPDMtjb6XFIwh0xYVeSdVPIXKEsfX5lyQcCrlJRk18/kTFNxu/6Z75RXlfjP4leIfDvgHRJG0hLPxTrMnkJaSkMsTA4LDnvlcAnjdz05h0G6+L2h+MNOs/FEdtr+mXv+vmtERBaDOCSwVORnODnIzg5ov73L8g+zzHrVFeaaH4t1u8/aA17w3c3u/SbSyEsFt5SDY2IudwG4/fbqe9R6f4v1yf9orUvDEt9u0eCzEsdt5KDa3lxnO7bu6se/ehST5fP9BtWv5frb/M9PorwLw14o+KfjbxFrOmaFrVnbW+m3zeZdXVtHlY95VY1AjOeFJ554+8O/YeJ7vx2/iC+xr9h4N0G0iAtb26S3ma+kxzkO3yDOfTHHB7TzrlUrb/1/X4By6tdj02ivIvA/wAW729+E2teIvEccU11ozmPdENguCVXZkDgEs2CRx7ViWWvfGq90O08XWTWF5Y3bq0ekRQKXMZOAfu7tvvvyAcmm5JO3p+IrO1/60PeKK8r1Dxl4k0L4u+HbXWZTb6Hr9sqixdIybW4KgFPMUZbD7e5HzH2q1a+LNb1v49XOgaXe+XoWkWm69jWJD5spHTcQWHLgYBH3DTTu0vX8Nweib9PxPSqx9U/5Gzwf/2F5f8A0gu62Kx9U/5Gzwf/ANheX/0gu6UvhBbndUUUVzGoUUUUAFFFFABVDW9d0zw5pMup65ew2NlDjfNK2AM9AO5J9Byav1l6z4a0jxDLYya1Zi7/ALPuBc2yu7bFkAwGKg4YjtuBxSdwM3wp8RfCfjeSaPwvrMN9LCMyRbHikA/vbXAJHI5AxW3quq2WiaTc6nqtwttZ2sZlmmfOFUfTk/QcnoK8kGuQeJv2gtAnutLuvDT6bbXKQvqluYJtWLLt2R4yrImS2C2fm6da1PjT4POt+Etb1bU9Wu5LDT9MkltdKjIjhE6qx81yOXPTCngY75NKbtDmRUV7/K/L+v8AgnplndwX9jBeWj+Zb3EayxPgjcrDIODyOD3rM8UeLNE8GaQNU8S3v2KzMgiEvlPJ8xzgYQE9j2o8H/8AIjaF/wBg63/9FrWzWlSPLJpGdOXNFN9TzcftBfDEkAeJuf8Arwuf/jddN4p8e+GPBVvDN4n1iGxE/wDqkKs8jj1CICxHvjArj2z8RPjRLbzASeH/AAaVYxnlbjUGGQSO/ljP0P1qjcaho3h/9o/U77xtNb2YuNLhGi3t8QkMYXPmqrt8qtknuOpHfmVZ8vnf7raff+RT0v5fndflfXzPTPD3iXR/Fekpqfh3UIb+0c48yIn5T/dYHBU8jggGs/wv/wAjF4z/AOw1H/6b7OuE8IeI9K1H9ozXIvC8kcunXujJNcTQf6q4uI5QpkUjhuHKlhkEg13fhf8A5GLxn/2Go/8A032dPon3/wA7C6tdjpKKKKQwooooAKKKKACuV8U/E3wd4KvI7TxLrkNncyLuEIjeVwOxKorFR9cV1Vcnq8GleCF1TxJp3hvUNV1HU5F+1Lp8bXE8xC4HDN8qADoOB6Um7DWp0Ol6rYa1pkOo6Tdw3lnOu6OeFwysPr+ntXLWfxg8A3/iEaJaeJbWS+aTy1Xa4jdugCyFdjEk4GG5ry7TdSTSf2bfGuo6fLDBcXl7O0mnW4Zf7LMzpH5BVgCpUH0A9K7rxn4R0m2/Z7vNKjs4ki07SfPtyqjKSxpuEgIx8xYZJ75OetOXu3k9lb8Vd/d+IRV2o9W2vu/zv8j0uue8V+PPDPgiGKTxRq8Nh5xxGhVnkf3CICxHvjAqfwbqMur+BtD1G4JaW70+CZye7NGCf1Nec3GoaN4f/aP1O+8bTW9mLjS4Rot7fEJDGFz5qq7fKrZJ7jqR35clyz5PX8Lkxd4c3p+Nj0bS/GGga34ak1/SdThu9MhjaSSeIE+WFG5gy43Agc7SM+1ch/w0H8Mf+hm/8kLn/wCN1k+EPEelaj+0ZrkXheSOXTr3RkmuJoP9VcXEcoUyKRw3DlSwyCQa1firf3etalovw90iVoptfdn1CZDhobJOZPxb7o+hHelrpbr/AJtfdpf0Hprfp/l+fT1NPxN4h0vxV8D/ABJrGg3X2uwuNGvvKm8tk3bYpFPDAEcgjkV29cn44sbbS/g34jsdPhWC1ttBuooYkGAiiBgAPwrrKbtfQSvbUKKKKQwooooAKKKKACiiigAooooAKKKKACiiigDm77/kqehf9gXUv/R9jXSVzd9/yVPQv+wLqX/o+xrpKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDm/Af/Iu3X/Ya1X/04XFFHgP/AJF26/7DWq/+nC4ooA8z1K91Oz/Zx01dCsLu+v7rRLW2ijtIWkdd8KhmwoJGFyc+uK5fwv8As56HfeF9Pu/EN3rFtqU8IkngikjQRk87drRkggYByeua7LwV4surbwD4fgXwrrM6xaZbIJY5LQLJiJRuG6cHB68gH1Arb/4TK7/6E/XP+/tl/wDJFdKp9Wuxk5bK55t8PPCOq+HPE/i/wPd2Wof2BqMDrbai9u3l8rtHzgBdxR+fdKzNA1X4kfDrw1deD7PwXdXtwskn2PVLdGkij3H73ClW55GSvuK9c/4TK7/6E/XP+/tl/wDJFH/CZXf/AEJ+uf8Af2y/+SKOSXntZ+Ycy/G/ocH478IeNfEfgPw7rF3Bb3HijRp/tElpAAFZSQcdcMw2JnBwecdsz6P41+JvirxZpcVt4Tk8PabCf+Jg+oRMVkXjJBZUbI5wFzyecgcdr/wmV3/0J+uf9/bL/wCSKP8AhMrv/oT9c/7+2X/yRVKLUr9N7CbTjb5HmviW28V+CfjleeLNJ8MXPiCy1G3ESraBiV+VQQSqttIKZ5GCD+R4D07xZc/Hy98Q+KNBuNOF5ZMciNmhjGECJ5n3S21RkZ654HQelf8ACZXf/Qn65/39sv8A5Io/4TK7/wChP1z/AL+2X/yRUxg428r/AIjlJSv52/A434KaNqmla74yk1TTbuyS5vw8DXEDRiVd0nKlgMjkcj1rlZPDl/bfFLxBd+M/BOreK5bmUnSZokMlsq7m2q7EhVXBUfNnbg8c165/wmV3/wBCfrn/AH9sv/kij/hMrv8A6E/XP+/tl/8AJFL2bsl2Vg5lr5u55X8OvAWsX3wr8Y+F9W0660u9ubgND9phZEZlAK7Wxhl3Jglc8HPem6X4p+KWjeFLPwfpfgi7g1GzKwR6mYy0OwN0+ZfL5HBbfjGTxXq3/CZXf/Qn65/39sv/AJIo/wCEyu/+hP1z/v7Zf/JFVyO99en4BzK33/icl8Y9E1C++E9tq188I1zRGiu2ltwVUNkBwuSeMkH/AICKk+BGmTv4X1DxTqSr9v8AEF7Jcu4XHyBiAPpu3n6EVk/ELRdV8fajbM9t4p07TUjCXGnwtaMk5DFt2PtYUNzjJU9BXa6Z4hbR9KtdOsPBeuRW1rEsUSebZcKowP8Al4ohFpyk1v8A0/yQpNWjG+39fqzs6x9U/wCRs8H/APYXl/8ASC7rO/4TK7/6E/XP+/tl/wDJFUbzxJqFxrmg3ieEdaEem3z3MwMtnllNtPEAv+kcndKp5xwD9CSTa2BNXPWaK4r/AIWNL/0JviD/AL+WP/yTR/wsaX/oTfEH/fyx/wDkmsPZz7GnNHudrRXFf8LGl/6E3xB/38sf/kmj/hY0v/Qm+IP+/lj/APJNHs59g5o9ztaK4r/hY0v/AEJviD/v5Y//ACTR/wALGl/6E3xB/wB/LH/5Jo9nPsHNHudrXI+P7jxZp1rp2q+D4jfJZXG/UNLRU33kBHIRmBIZeoAwT79DB/wsaX/oTfEH/fyx/wDkmj/hY0v/AEJviD/v5Y//ACTS9nPsPmj3OXvrrWPip4o8NrbeFdY0DS9F1BNRur3WrcW8rMn3Yo0ySQ2eT0/LntviVaXN/wDC/wAR2tjby3NzNp0yRQwoXeRipwAo5J9hVH/hY0v/AEJviD/v5Y//ACTR/wALGl/6E3xB/wB/LH/5JolTk4uNnqEZpSUrm14fMum+AtLNxbTmW10yLfbrGfN3LEMoFP8AFkYx61JoHiKHxH4Xg1uytLqGOdHZbe5jCTKVYqVZQTg5U8Zrn5fiHLJC6Dwh4ijLKQHSSxyvuM3PWquk+Mo9F0i202x8F+Ihb20YjTfLZMxx3J+08knknuTVTjOTk7b/APBJi4xSV9h3wX0q9074eLc6zaT2mqape3F9eRXETRyK7yEDKsMj5VXrUPj7VL6x16GLXPAv/CW+FZIMqLLT1u7mC5B/ijdsFSO4Ax61of8ACxpf+hN8Qf8Afyx/+SaP+FjS/wDQm+IP+/lj/wDJNKUJN6Iaktdd/wDhzL+HmjarfeLtU8Y6zo39gwTWkWnaVpbhRJDbIdxZ1XhSWP3e3I9Cel8L/wDIxeM/+w1H/wCm+zrO/wCFjS/9Cb4g/wC/lj/8k1kaN4xvNO1bxBdT+ENcZNS1BLqEJLZEqotYIcNm44O6Jjxngj6B8k9rC5lu2emUVxX/AAsaX/oTfEH/AH8sf/kmj/hY0v8A0JviD/v5Y/8AyTS9nPsPmj3O1oriv+FjS/8AQm+IP+/lj/8AJNH/AAsaX/oTfEH/AH8sf/kmj2c+wc0e52tFcV/wsaX/AKE3xB/38sf/AJJo/wCFjS/9Cb4g/wC/lj/8k0ezn2Dmj3O1rza/8XeLfBfizVI9d0DWfEuiXcgl0u40WzSaS2GPmhkRdp4PRiTn37an/Cxpf+hN8Qf9/LH/AOSaP+FjS/8AQm+IP+/lj/8AJNL2c73sx80bbnKaV4C1jxT4f8e3+uWQ0a68XBRa6e7Am3EaERvJjozHBI7YqjqHiXxp4j8A/wDCCr4G1mz165tlsLvULiELYRpgK8qyg4bK5O0evGcYPc/8LGl/6E3xB/38sf8A5Jo/4WNL/wBCb4g/7+WP/wAk0ezlty6aL7v61DnV7311/H/hjQm1W08EWPhzRWs764iuHi02Ge3iDRwkKFUysWG0H8Tmuf8AH2qX1jr0MWueBf8AhLfCskGVFlp63dzBcg/xRu2CpHcAY9adqHi+PU7qwnuvB3iQ/YJ/tEUazWIVpNpUFh9p5xuJA9eewq9/wsaX/oTfEH/fyx/+SabhUk7ta37f15/gJOMVZPS39foZfw80bVb7xdqnjHWdG/sGCa0i07StLcKJIbZDuLOq8KSx+725HoTP4b02+uvjh4t1zUrK4hgtrS10/T5pYmVJYyN8hRiMN8+On41d/wCFjS/9Cb4g/wC/lj/8k0f8LGl/6E3xB/38sf8A5Jp8k7p22/X+n94uZWd3v+n/AAy+40fiP/ySzxX/ANgW8/8ARD10leZ+LPGN5r3gvW9Is/CGuJcahp89rE0stkEVnjZQWIuCcZPOAa1/+FjS/wDQm+IP+/lj/wDJNL2c+w+aPc7WiuK/4WNL/wBCb4g/7+WP/wAk0f8ACxpf+hN8Qf8Afyx/+SaPZz7BzR7na0VxX/Cxpf8AoTfEH/fyx/8Akmj/AIWNL/0JviD/AL+WP/yTR7OfYOaPc7WiuK/4WNL/ANCb4g/7+WP/AMk0f8LGl/6E3xB/38sf/kmj2c+wc0e52tFcV/wsaX/oTfEH/fyx/wDkmj/hY0v/AEJviD/v5Y//ACTR7OfYOaPc7WiuK/4WNL/0JviD/v5Y/wDyTR/wsaX/AKE3xB/38sf/AJJo9nPsHNHudrRXFf8ACxpf+hN8Qf8Afyx/+SaP+FjS/wDQm+IP+/lj/wDJNHs59g5o9ztaK4r/AIWNL/0JviD/AL+WP/yTR/wsaX/oTfEH/fyx/wDkmj2c+wc0e5o33/JU9C/7Aupf+j7GukrzO58Y3k3jTTdXXwhrgt7XT7u1dTLZby0sluykD7RjGIWzz3HXnGv/AMLGl/6E3xB/38sf/kmj2c+wc0e52tFcV/wsaX/oTfEH/fyx/wDkmj/hY0v/AEJviD/v5Y//ACTR7OfYOaPc7WiuK/4WNL/0JviD/v5Y/wDyTR/wsaX/AKE3xB/38sf/AJJo9nPsHNHudrRXFf8ACxpf+hN8Qf8Afyx/+SaP+FjS/wDQm+IP+/lj/wDJNHs59g5o9ztaK4r/AIWNL/0JviD/AL+WP/yTR/wsaX/oTfEH/fyx/wDkmj2c+wc0e52tFcV/wsaX/oTfEH/fyx/+SaP+FjS/9Cb4g/7+WP8A8k0ezn2Dmj3O1oriv+FjS/8AQm+IP+/lj/8AJNH/AAsaX/oTfEH/AH8sf/kmj2c+wc0e52tFcV/wsaX/AKE3xB/38sf/AJJo/wCFjS/9Cb4g/wC/lj/8k0ezn2Dmj3NHwH/yLt1/2GtV/wDThcUVV+HF4934Pe5+xzxedqupyeXIU3Jm/nO04YjIzg4JHoT1oqCjjvBP/JP/AA9/2C7b/wBFLW5WH4J/5J/4e/7Bdt/6KWtyvVjsjie4UUUVQgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACqWs6rBoei3mqXayPBaQtNIsQBYgDJxkgZ/Grtc58Qv+Sca//wBeEv8A6CazqScYOS6IuCTkkzjv+Gg/Cn/QP1j/AL8xf/HK7zwz4p0rxdpI1DRZzJFu2OjDa8bejDsa8b8EfF3QPDfgC10K/wBNv7u5iWQMqRxmKTc7MBktnGGAPy1J4L0zWNB+E/i/Wnjn0v7ZH5lmikxugXPzL0IHzYB9qz9o1d7pK5XJey2d7HvFFeQfDy28Qy6FbeNvEPim+nsra2lYabvYrIiBhudi2CcgnkE9Oe1UPD+n+OfiZZ3HiIeLp9EgaV1tLW2LhDg9CFZeM8ZO4nmrc3e1td/kTyq17ntVxPFa20txcOI4okLu56KoGSfyrlvDPxD0/wAW6g1vpGmasbcbgL+S122zFe2/PX2IBrh9L8S6/wCK/hf4n03UNQW11XRUkS6nECv9oiCvlCOACdrLuHsetQfDjUdS8K/CK78SS6kLnT4I5Rb6Y1uqhJfMwGMo+Ygk9Pep9r7zfRK/9f1v5D5HZd72/r+tj2yivEdN8P8AxC8Q+GP+EuPjS6t7qWM3FvYR7hG6jkAgEKM46bT2zVy88d6l4g+AN5rKXMlpqltKlvLPauY2LB0+YFcYyrDIHqe1N1LJ3Wq1BQu1Z7nsVFeB6raeOoPh1a+NZfGd0rRxROtlCWVRGxCqWOcO3IJ3Kc88muh8YePtbj+HXhltKdYNW19UVplA+Xgbto7Esw57DPtTdS17rVWX37CUb27a/hud94u8W2PgzRRqmqRXEsBlWLbbKrNkgn+IgY49a2LW4S7s4bmMMEmjWRQ3UAjPNeAfEnwr4p8NeCYv7W8US65ZT3KedFcBi0Mm04KszEkdR27cemx8QPG17YzeH/DVprDaFazWMU15qEaMzopGAF2/N/D2xkkcgZqFVtzc3dL70Nwva3Zv8T2yivEvhx42uoPiBH4c/wCEmk8TaZeRsYbu4ikSRJApbH7z5uxGMkcjHcV0Hwv1bUNQ8aeNbe/1C5uYra9CwRzTM6xLvlGFBPA4HT0FaxmpNW63/AlxaTb6W/E9NoryXwXrOp3XjTx/BdajdzQ2jS/Z45J2ZYcPJjYCfl6Dp6VlfCvT/FXi62ttY1DxdqMdjp93tFt5ru11jDMHbd05A5B4zjFTCpz2st1f8bFShy3v0dvwue30VR1uR4vD+oSROyOlrIyspwVIQ4INeCaQvjbXPhhd+Ih4xvoIdLMhjgWVzJPtwzF5NwPQ4AORx2pSq8ratsriULpebsfRNFfP99feOtW+G0fjmXxTNarbFUjs7VTGJFDiMu5DYJLc4II+g4rvNX1bWta+GOi6ha65YaCbyOJ76+uZfKKqV+YR8Ebic4GR6U/aaPTa34hy7fP8D0SivDvDviprH4uadpHh7xXqPiDR7xNk/wDaErSlXwxwrMo6YU5XjnHNXPHWteIPhp40bWLe8u9R0fVIZFjtbm4d47ebGcAHIABwR7bh2pe2SjzdNV/XqP2bb5ep7LRXE/C/StYtPC66j4j1S8vr7UgJ9k9w0iwoeVVQTgEg5OPUDtXbVtr1M9OgUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAa3wz/5En/uKal/6XT0UfDP/AJEn/uKal/6XT0V5Mt2dq2ON8E/8k/8AD3/YLtv/AEUtblcr4Mt/FbeA9ANrpejPAdNt/LeTVZUZl8pcEqLcgHHbJx6mtr7N4x/6BGh/+Dib/wCRa9GNSNjlcXc0KKz/ALN4x/6BGh/+Dib/AORaPs3jH/oEaH/4OJv/AJFp+0iHIzQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFZ/wBm8Y/9AjQ//BxN/wDItH2bxj/0CND/APBxN/8AItHtIhyM0KKz/s3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWj2kQ5GaFFZ/2bxj/0CND/APBxN/8AItH2bxj/ANAjQ/8AwcTf/ItHtIhyM0KKz/s3jH/oEaH/AODib/5Fo+zeMf8AoEaH/wCDib/5Fo9pEORmhRWf9m8Y/wDQI0P/AMHE3/yLVO9uvFdheadbzaNozPqFwbaIrq8uFYRSS5b/AEbptiYcZ5I+oPaRDkkblFZ/2bxj/wBAjQ//AAcTf/ItH2bxj/0CND/8HE3/AMi0e0iHIzQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFZ/wBm8Y/9AjQ//BxN/wDItH2bxj/0CND/APBxN/8AItHtIhyM0KKz/s3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWj2kQ5GaFFZ/2bxj/0CND/APBxN/8AItH2bxj/ANAjQ/8AwcTf/ItHtIhyM0KxPGOn3Oq+CtXsLCLzbm5tJI4o9wXcxXAGSQB+NW/s3jH/AKBGh/8Ag4m/+RaPs3jH/oEaH/4OJv8A5FqZShKLi+o4qUWmYnw00a/8P/D7TtM1eD7Pdw+Z5ke9X25kZhypI6Ed6u+N9Nu9X8D6tp+nReddXFsyRR7gu5j2ySAPxq99m8Y/9AjQ/wDwcTf/ACLR9m8Y/wDQI0P/AMHE3/yLTnKE4uL6hGMou6MPwL4fudO+Gdloeu2/kzeTJFPFvVsBmbjKkjofWuF0zw78TvAKXGj+FoLDVtMlkZ4Z5mVWhz3wXUg9CR8w4r1b7N4x/wCgRof/AIOJv/kWqdldeK7+81G3h0bRlfT7gW0pbV5cMxijlyv+jdNsqjnHIP1MycJPmvYIqSVrHKeG/h7e+Hvh5r9pNKt7resQSmXYwCl2RgqAnHdjyccmn+DvA94Pg/L4X8RQmynuPOVgHWQx7mJVvlJBxwcZrtPs3jH/AKBGh/8Ag4m/+RaPs3jH/oEaH/4OJv8A5Fpfu9fNW+Q/f08nf5nk9povxZ0TQ38K2Fvp1xp5VoYtQMqhokb0ywPc9UJGeO1bOo/Di80z4KXHhjRl+36jK6SyEMqCR/MUtgsQAABjk9q7/wCzeMf+gRof/g4m/wDkWj7N4x/6BGh/+Dib/wCRaTUGmm3qNcyaaWxyOv8AhrVr34Hx+H7W036otjbRGDzEHzoU3DcTt42nvWVrfw61XWfhb4fsYClprmjIjpG7gqWAwy7hkZ4BB5HHvkeh/ZvGP/QI0P8A8HE3/wAi0fZvGP8A0CND/wDBxN/8i1UnCTbb3t+Ao80Ul2v+J474q0H4r+NfD0drrGm2MKW0isLeCaNXuGxjex3leOeMjr09Oh8XeB/EBv8AQfE/hPyv7a0y2SCW1lYASALjGScd2B5HB4Neg/ZvGP8A0CND/wDBxN/8i0fZvGP/AECND/8ABxN/8i0vc763T+4fvdvI5fwcnxBvNZlv/Gctrp9kE2x6ZbLG25v7xYbiB1P3+vYCuUXwt8QPCPjrWr3wjaWF/Z6vKZDLcuoEWWLDI3K2RuI4yD6enqf2bxj/ANAjQ/8AwcTf/ItH2bxj/wBAjQ//AAcTf/ItD5HZ3en6i96zVtzzf4feCfEuhap4qm16FZH1GIiO4SRCtxISxJAByoy3cCtz4Q+HNV8L+DZbHXbX7LctdvIE8xH+UqoBypI7Gus+zeMf+gRof/g4m/8AkWj7N4x/6BGh/wDg4m/+RacHCG3a343FJSlv3v8AhYk1eCS60S+t4F3Sy28iIucZYqQBzXnPhbwdrum/BPWNAvbHy9TuRP5UHnId25QF+YNtGcdzXoX2bxj/ANAjQ/8AwcTf/ItH2bxj/wBAjQ//AAcTf/ItJ8jbd91Ya5lbydzzxPBuvD9n1vDRsf8AibkH/RvOj/5+N/3t237vPWqHiL4feIb7wb4OFvYw3dzoqKLrS5plCy/dyN2dp+6Qeehr0bV7rxXouh32qXWjaM8FjbyXMix6vKWKopYgA2wGcD1FXPs3jH/oEaH/AODib/5FolySbd+34AuZK3r+J5gvhXxXd/Ezw/4in8OWem6fajyjZ2l1GxtUG7lvug8uT8meB61PrPgTW/iD44u7jxVBJp2iWkDxacizI7Ox4DkKxxz8xzjoo9a9I+zeMf8AoEaH/wCDib/5Fo+zeMf+gRof/g4m/wDkWlanazemr+8fv3uvL8DlvhfY+J9E0WXQ/FFlsismK2V2syOJY8/dwDuGOoyBwccYruaz/s3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWtVUja1yOR32NCis/7N4x/6BGh/wDg4m/+RaPs3jH/AKBGh/8Ag4m/+RaPaRDkZoUVn/ZvGP8A0CND/wDBxN/8i0fZvGP/AECND/8ABxN/8i0e0iHIzQorP+zeMf8AoEaH/wCDib/5Fo+zeMf+gRof/g4m/wDkWj2kQ5GaFFZ/2bxj/wBAjQ//AAcTf/ItH2bxj/0CND/8HE3/AMi0e0iHIzQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFYct14ri1y20ttG0Yz3NvNcow1eXaFiaNWBP2bOczLjjsene59m8Y/9AjQ/wDwcTf/ACLR7SIckjQorP8As3jH/oEaH/4OJv8A5Fo+zeMf+gRof/g4m/8AkWj2kQ5GaFFZ/wBm8Y/9AjQ//BxN/wDItH2bxj/0CND/APBxN/8AItHtIhyM0KKz/s3jH/oEaH/4OJv/AJFo+zeMf+gRof8A4OJv/kWj2kQ5GaFFZ/2bxj/0CND/APBxN/8AItH2bxj/ANAjQ/8AwcTf/ItHtIhyM0KKz/s3jH/oEaH/AODib/5Fo+zeMf8AoEaH/wCDib/5Fo9pEORmhRWf9m8Y/wDQI0P/AMHE3/yLR9m8Y/8AQI0P/wAHE3/yLR7SIcjNCis/7N4x/wCgRof/AIOJv/kWj7N4x/6BGh/+Dib/AORaPaRDkZ03wz/5En/uKal/6XT0VF8Mfta+B1FxDCsw1LUfMVJiyq326fIBKjIznBwM+g6UV5stzqWxn+Af+Sa+Gf8AsEWv/ola6Cuf8A/8k18M/wDYItf/AEStdBXUtjMKKKKBBRRRQAUUUUAFFFFABRRRQAUUUUAFc/4j/wCQ94S/7C8n/pDdV0Fc/wCI/wDkPeEv+wvJ/wCkN1QxmD8Tvievw3/ssvpJ1Fb9pASLjyjGE2/7Jznd7dK0PFfj+28P/DkeLrC2/tO2dYnij83yt6yMADuw2MZ6Yrzz9oizj1HWPBdlMzLHc3csLlDyAzRA49+a4HXNUvfCXgfxJ8NNfYmS1uIp9OlIOJEMqsQPYg7x/wACFYc75X3vp8rX/A05Vo/LX8bfkfT3h/Vf7d8N6bq3k+R9utY7jyt+7ZvUNjOBnGeuBWjXhXjTxJqulfB7wLo2h3LWU+t21vA9yhKlEEaDAYdMlhz6A1m+Mvho/wAJvDsPi3wr4h1AalbTxi6MrqEn3HHCgDjPVWLZBNbTkoyl2TsZxTcV3aufQ9FeAfF68uvEN98N7uwmewu9Sw8cqA7oHk8nBA65Bb9KoeKvCDfCr4h+E9R0DWtRuJtUu/Lu3u5QzSkOgbJAGVYP0OfrSu+azXWwdLrtc+jqK+cviRqc3i74wXnhzVovEF3omlxD/QdBgEsrvtU+YVPHV8biDjAAxnNdJ8Fm8QaV4m1TRJ9P8Qw+G/K83T21qzaJomBUbM/dGQTwDg7c4HNEJc4SXKe00UUVQgooooAKKKKACuf8Of8AIe8W/wDYXj/9IbWugrn/AA5/yHvFv/YXj/8ASG1oGdBRRRQIKKKKACiiigAooooAKKKKACsHxd4x0jwXokuo6zcpHhT5MG795O2OFUd/r0HU1vVwfxG8F6JqWl6z4k1C0FzqFros8NuZTlIgEdtwX+9ljyc44xioqNqLaLgk5JM1fAPjIeN/B0OvPZDT1keRTEZvM2hWIzu2r6elcFeftC28V7cT6f4V1C+0G1m8mXVkfCg5xwNu3njALAnPam/DN5I/2ZtQeEkSLa35Ur1zh8VneDooj+yfq+9FAaC7Y8YywY4P14H5ClOTTbXSKfqKKulfq2j03xZqNrq/wh13UdPlE1rdaJcyxOP4lMDEV1VeR+EpJZP2VboznJGjX6jJz8oEoH6Yr1ytZK0miIu8dQooopDCiiigAooooAKKKKACiiigBksscELzTOqRxqWd2OAoAySa8cuP2hU864u9M8H6le6DbSiOXVA5VVPHbYVHUYBcE5HSvYLu1hvrKa0uk8yCeNo5EyRuVhgjI56GvHfHWpaZoeiyfC/4b6Z9o1PUiyS28LM62qPy5ZmJwSD3OFByccA5yck9Pku7LilbX5+h2ut/FHQdH+H9t4tDSXNpeBRawoAJJXOfk56EYOfTB68ZxvBvxiXxD4nj8P6/4evPDuoXEfmWqXLlhMMZ/iVSMgHHBBwea4T4g+GT4S0n4ZeHXcTxwXreecZR5GkjZuvbLNj2roPi0Wi+Mfw8kt+JjdbWIODt81P6FqpO9S3Ryt+BL+C/W1/xPR7z/kpWjf8AYI1D/wBHWddBXP3n/JStG/7BGof+jrOugqgCiiigQUUUUAFFFFABRRRQAUUUUAcx498dad4A8PjUtSjkneSTyoLeLG6V8E4yeg45P865vwb8YR4h8Up4d1/w5eeHdSmjMlvHcsWEoxn+JFIyASOMHB5rttabQN1qviFtN3eYDbC+Med+RjZv/izjpz0rxiNNW8NfH3Sb34kMmpXGohoNKubWfEVrlioUpsXJG8Dt9/PzHpMW+dJ9f8vzKklyNrp/X3HZeM/jAvhzxM/h/QfD154i1KCPzbmO2YgQrjP8KsSQCCeABkc10vgTxxp3j7w6NU0xXhKuYp7eQgtE45xx1BBBB/8A1V578KN0nxq+IUkwzItyVDMOQvmvgfTAH5Cj4Ell8UePYY+LZNSBjAPAO+UcfgBSptySb6q/prYKis3bo7fgewfDv/kU5f8AsL6n/wCl89FHw7/5FOX/ALC+p/8ApfPRWD3NDG8A/wDJNfDP/YItf/RK10FcH4ItPFbfD/w81rrWjRwHS7YxpJpErsq+UuAWFyATjvgZ9BW59j8Y/wDQd0P/AMEk3/yVXStjI6Ciuf8AsfjH/oO6H/4JJv8A5Ko+x+Mf+g7of/gkm/8AkqmB0FFc/wDY/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVQB0FFc/wDY/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVQB0FFc/wDY/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVQB0FFc/wDY/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVQB0FFc/wDY/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVQB0Fc/4j/5D3hL/sLyf+kN1R9j8Y/9B3Q//BJN/wDJVY+r6f4rm8ReFoptb0Yu+qSCJl0eUBG+xXJyw+0ncNoYYBHJBzxgpvQCr8S/AWqeMta8MXmlz2cUekXRmnFw7KWUtGfl2qcn5D1x2qn8X/hRJ8QYrK70eW1ttVtiY2kuCVSWI84JVScg8jju1d//AMI74x/6GTQ//BFN/wDJdH/CO+Mf+hk0P/wRTf8AyXWTcGredy/eTv8AI4zXvhcnib4YaN4c1C7W21HSreEQ3cALKsiIFPBwSp/A9D2xXLn4T+PfExtNN+IHi+C70O0cOIbUEyy44G5ii847sWIya9b/AOEd8Y/9DJof/gim/wDkuj/hHfGP/QyaH/4Ipv8A5LqnKLk5PrqJJpWOL8b/AA9vvEHiXwdeaNJZ29loFwryRTOysUDRkBAFIPCEckdqX4l+AtU8Za14YvNLns4o9IujNOLh2UspaM/LtU5PyHrjtXZ/8I74x/6GTQ//AARTf/JdH/CO+Mf+hk0P/wAEU3/yXRzx/G/zCz/Cx5942+GWuXnjWPxf4B1mHSdYaPyrgXA/dyDGM/dbtgEFSOAeCK3PAHhTxHoTXl/4x8S3Gs6heEZiWV/s9uM5OxTgZPHIVcdAK6X/AIR3xj/0Mmh/+CKb/wCS6P8AhHfGP/QyaH/4Ipv/AJLpRlGOwNOW5foqh/wjvjH/AKGTQ/8AwRTf/JdH/CO+Mf8AoZND/wDBFN/8l1XtIi5WX6Kof8I74x/6GTQ//BFN/wDJdH/CO+Mf+hk0P/wRTf8AyXR7SIcrL9FUP+Ed8Y/9DJof/gim/wDkuj/hHfGP/QyaH/4Ipv8A5Lo9pEOVl+uf8Of8h7xb/wBheP8A9IbWtH/hHfGP/QyaH/4Ipv8A5LrB8PaD4rfXfFSw6/oyPHqqLKzaNKwdvsVqcqPtQ2jaVGCTyCc84C9pEOVnW0VQ/wCEd8Y/9DJof/gim/8Akuj/AIR3xj/0Mmh/+CKb/wCS6ftIhysv0VQ/4R3xj/0Mmh/+CKb/AOS6P+Ed8Y/9DJof/gim/wDkuj2kQ5WX6Kof8I74x/6GTQ//AARTf/JdH/CO+Mf+hk0P/wAEU3/yXR7SIcrL9FUP+Ed8Y/8AQyaH/wCCKb/5Lo/4R3xj/wBDJof/AIIpv/kuj2kQ5WX6Kof8I74x/wChk0P/AMEU3/yXR/wjvjH/AKGTQ/8AwRTf/JdHtIhysv1meJNOm1jwtqum2zIs15ZywRtISFDOhUE4BOMn0qT/AIR3xj/0Mmh/+CKb/wCS6P8AhHfGP/QyaH/4Ipv/AJLpSlGSaY4pxd0c38NvBt14S+HsXh7W3trmTfL5n2dmaNldicfMAeh9K88l+CXjOztbvw3ofiy3i8KXk3mSQzKfOAz0wF56DOHUNjkV7P8A8I74x/6GTQ//AARTf/JdH/CO+Mf+hk0P/wAEU3/yXScoN3foCTSsjnfEGi2vhz4LazpGngi3s9DuYkz1OIWyT7k5J+tdjXJeO9B8Vw/DrxJLda/o0sCaVdNJHHo0qM6iJsgMbohSR3wceh6Vvf8ACO+Mf+hk0P8A8EU3/wAl1TqJu7Eo2VkX6Kof8I74x/6GTQ//AARTf/JdH/CO+Mf+hk0P/wAEU3/yXR7SIcrL9FUP+Ed8Y/8AQyaH/wCCKb/5Lo/4R3xj/wBDJof/AIIpv/kuj2kQ5WX6Kof8I74x/wChk0P/AMEU3/yXR/wjvjH/AKGTQ/8AwRTf/JdHtIhysv0VQ/4R3xj/ANDJof8A4Ipv/kuj/hHfGP8A0Mmh/wDgim/+S6PaRDlZfoqh/wAI74x/6GTQ/wDwRTf/ACXR/wAI74x/6GTQ/wDwRTf/ACXR7SIcrJNVW/fR7tNHaFL9oXFs85IRZMfKWwDwDg9DXhvh/wCFHxX8LXF3caH4k0K3nvX33EzgyySHOeWeAnrzjPWvbv8AhHfGP/QyaH/4Ipv/AJLo/wCEd8Y/9DJof/gim/8Akup5o3uPW1jhdf8AhxrXjT4b2OmeKtXgbxJZzNOmoW6fuy25sDAVeNpA4A5APOOc/wAL/DDxRL42s/E3xH1621W402PZZw2wO0Hsx+RBxknoSTgk8V6V/wAI74x/6GTQ/wDwRTf/ACXR/wAI74x/6GTQ/wDwRTf/ACXT5oqXMJxbVjOvP+SlaN/2CNQ/9HWddBXJXmg+Kx8RdHibX9GM7aVfskg0aUKqiW03Ar9qySSVwcjGDwc5G9/wjvjH/oZND/8ABFN/8l0e0iHKy/RVD/hHfGP/AEMmh/8Agim/+S6P+Ed8Y/8AQyaH/wCCKb/5Lp+0iHKy/RVD/hHfGP8A0Mmh/wDgim/+S6P+Ed8Y/wDQyaH/AOCKb/5Lo9pEOVl+iqH/AAjvjH/oZND/APBFN/8AJdH/AAjvjH/oZND/APBFN/8AJdHtIhysv0VQ/wCEd8Y/9DJof/gim/8Akuj/AIR3xj/0Mmh/+CKb/wCS6PaRDlZfoqh/wjvjH/oZND/8EU3/AMl0f8I74x/6GTQ//BFN/wDJdHtIhys5n4mfD1PH+iQRw3ZsdSsZDNZ3ODhW7qcc4OByOQQDz0rmfDvws8U3njOw8RfEjxDBqkulgfY4LUHbkcgsdi4weemSQMmvTP8AhHfGP/QyaH/4Ipv/AJLo/wCEd8Y/9DJof/gim/8AkukpRT5kNptWZ5t4p+GHiePxxd+KPhzr9vpV1qMey8iuR8p4GSpCN1wDyMg5IPOK6b4aeAU8A+HpbWW6+26hdyme7ucEb27AZ5wPU9SSe+K6P/hHfGP/AEMmh/8Agim/+S6P+Ed8Y/8AQyaH/wCCKb/5LpRlGOwSTk7ssfDv/kU5f+wvqf8A6Xz0VF8OYbuLwg8dxPDJMmq6msjpCUVmF/PkhSxwCckDJx6nrRWLLMvwD/yTXwz/ANgi1/8ARK15l8Q/jXrnhvxlfaZ4c0+wvbHTI4zezTRuzI7EAjKuAPvKOh5zXoPhjU4NG+DejandnEFnoVvO/wBFgU/0r508M+O/DcHhzxdB4rtNQudT8RuzNLbwxukfVlOWcHIdienYVrKTT06K/r2RMYq2vV2/zPq7Tb+DVdLtdQs3ElvdRLLGwPVWGR/Oql14n0Gx1AWF9renW14cYt5ruNJDnp8pOa8n+DvjSaX4K6xDEd1/4egmaIHnKFGePj6hh+FYfw8+F/hrxn8LLvXvENxImqXUszvqctw3+jbT94jcFI4JO71PIrWTfM1FbK/3kRXuq+97H0LLNHBC000iRxINzO7AKo9Sao6Z4h0XWpHTR9YsNQeMZdbW6SUr9dpOK8V+K1o2leDfBPg+11e4vdKvboRzXjSAtIgZQo3DgqA5wP8AZXriurh+D3hPQPG2ialoepTaLcwZK2iXO5rwrjP3yTjBwwAxgjpQneXlewP4V3tc9Di1jTJ9Vl0uHUbSTUIV3y2iTqZUXjkpnIHI5I7ihNZ0uTV30pNSs21GNd72YnUzKuAclM7gMEdu4rybw24X9qzxMD1bTgB/3zAai0eRZP2t9a2EHbYBTjsRFFSjK/L5pv7hyVubyt+Nv8z1N/F/hqON3k8Q6UqJL5Ds17GAsn9w/Nw3t1qbUvEWiaN5f9saxp9h5ozH9quki3j1G4jNeC/CrwJoXi/xl4sufEVqb1LG/PkQNIyoGaRyWO0jP3QMHitfWLrwve/EjXf7I8L6p451lgLe4S4Ef2SzxxtRmX5MYxkjscHrUc75Yvq1f8AaV32Wh7hbXMF5bR3FnPHcQSDcksThlYeoI4NUF8T6C2qf2aut6ab/AHbfsou4/Nz6bM5z+FfPvgDWtQ0f9nvxnPYyyRywXPlxYY5i8wIrEHscEnPqM1t6B8HPB+r/AAm0nVr28bTL+4SOeXVHuOFLN9zazBB1Cg4znHXob5m3ptp+IW0131/A9uTWdLk1d9KTUrNtRjXe9mJ1MyrgHJTO4DBHbuKJtY0y31SHTJ9RtIr+dd0Vo86rLIOeVQnJHB6Dsa8g+Idn/wAIL498GeMYp5riBNmnX91K2WlXbtDuRwWKFzn1UVb8Dxt4v+OviXxVIN9npI/s6zbII3D5SR+AY/8AA6Iu7t6/h/ndCeiv6fj/AJWZ7DWPqn/I2eD/APsLy/8ApBd1sVj6p/yNng//ALC8v/pBd0S+EFud1RRRXMahRRRQAUUUUAFc34017WNF0+2j8M6LJq+qX04ghUqwggz1kmcD5UH4Z6Cukqtc6lY2d1bW13e28FxdsUtopZVVpmAyQgJyxA5wKTA4PRfGPi7S/G+n+GfiJp+kiXV45X0++0V5DEWjXc8brJ8wOOc9OQPXFr4l/E+w8BaRcR2wF/rpt2lt9PjUuVUA/vZQvKxjBJJxnBx6jltUsNY8EfFTw/4i8U6qvie31O5/sm2eSD7O+mPL90xop2MGxhiRuwBz69j8U7O2T4Y+LLxLeFbqTSZo3nCAOyhSQpbqQMnj3pTb9nzev9fdYqK/eW9P6/P+tDpNBv5dU8N6bqFwqLLd2kU7qgIUMyBiBnPGTVXxR/wk39kD/hC/7J/tHzBn+1vM8nZzn/V/Nu6Y7daPB/8AyI2hf9g63/8ARa1s1rUSU2l3MqTbgm+x4xrvjD4v6Drej6RND4Ju9Q1eYxwW1ot2zKoGWlbcwARR1P5A10fibxt4nm8bf8Ih8P8ATNPudSt7dbm/vdTdxbWyt91cJ8xY9ePyPOKfw5iPiv4geKPHV388aXDaPpQJz5cER+dgO25ufzqTX9D8W+GfiRd+L/Bek2+vwatax29/pj3S20gePhJFkb5cY4IP/wCqE9I366/etP0Le8rdNPx1/U3PB3i7UtR1i/8ADfiyxt7HxBp0aTSfZJC9vdQvwJYi3zAZBBDcjj8Lnhf/AJGLxn/2Go//AE32dcD4SPiC9/aMv73xFHbW048OrvsrWUyraK0wKRs+AHfhmJAA+bjjmu+8L/8AIxeM/wDsNR/+m+zp/ZT/AK3a/QX2mv62TOkooopDCiiigAooooAK4DWtf+IWo+JL7T/A+iaZbWen7Vkv/ECzol25GSIQgBIHTd0Jrv657WxceJtKu7Dwl4qh0u+t5vKuLm2jjumgIHMbIT8rcjrgik7jRW8BeMn8X6BdXOoWP9mahpt3JY6hbGQOsU0eN21u64IOf/11z9l8XLbXvitpnhrw3Et3pU0VwZ9TKN5cska52wvkBgv8R5HIx6mP4PsdLHiHwTqFtC2oaLdh7q8jZmGoeeCwmfeSQ5A+YZI9OKfrtrb2Xx08B21lBHbwRafqCxxRIEVBsXgAcAVf212a/wDbWyHdRfk/1X6HpdeeeKPG3iabxufCHw90ywudRt7dbm+vdUdxbWyt91SE+YsevH5HnHodeZ6/ofi3wz8SLvxf4L0m31+DVrWO3v8ATHultpA8fCSLI3y4xwQf/wBUfaV9v+Bp+JfR23/4P+RteEfGOo3uqaj4f8YWVvp+vaXEk8ptJC9vcwtnEsZb5gMggg8jj8OPj+I/xD1jQLrxl4d8P6I/ha3MskdvdTyC9uYYyQ0ikfIv3ScEZ44zxmppGo6zb/HTXNd8WxW1v9j8KmaextZfNFpH5m5Y2c4DvhWJOAPm445rJ0XwD411z4Y3N1oPiWLRdE1ZXu7bw0sZkjWGT5vKNyfnQMCchRjk+pobfLzeXy3a1+7p5+QJK9vP8LJ/r+R6d4n1u28SfAnXNZsAwt77w9czxhxhgGt2OD7jpXa15jFrNhr/AOzFqF9pFl9gtD4du4ktdxbyfLhdCoY8kAqee/WvTq0mkpNIiDbirhRRRUFBRRRQAUUUUAUda1I6Rol5qC2dzfNbRNIttaxGSWYgcKqgEkk8V5nfePPiN4X0yHxN4w8P6Inh5nj+0WtlNL9uskcgBn3fIxBIBC85PbmvUr6/s9LspLzUruCztYhmSe4kEaIM4yWPA5rzD4u+HtcvtLl8Rw61DqOhaWEv38OzQ7IbpYxuJMyMGbpuAOVyBxSuk7vbT5LqUlfQ77xL4r0fwlox1LXLtYISQsSAbpJ3PREXqzH0H8qxfhh40vfHfhu81TUbFbB4tRnto7bayvGiEYD5P3xnB6DPYVvaTc2HifQ9I1v7JGyzQx3lt50YZoS6ZBB7HDYyK474L/8AIB8Rf9jLf/8AoYqkmpyT7fqjO94xa7/oz0C9+1fYJ/7P8n7X5beR5+fL34+XdjnGcZxzivJvFHib4veEPDl1rWsP4CW2tlHyxi9LyMThUUZGWJ4Ar1+vL/E8R8Z/G7RfDknzaX4et/7YvIyfllnJ2wqR3x976E1NryS7/wDDv8C72Tb6f1+Z1GkeJLzTPh5ba78SHsNHuhF5t2IiyxxZPyrhiTuwVBAJ+bIGayvhx8RJ/HureIwdPaxstOnhSzWaJkmdHQtvcE98AjAHBHXrXb3VnbX0IivbeG4jDK4SZA4DA5Bwe4IyDXn/AMP/APkqfxI/6/rT/wBJ6payl6fqv8yHdJev6M6K+/5KnoX/AGBdS/8AR9jXSVzd9/yVPQv+wLqX/o+xrpKRQUUUUAFFFFABRRRQByXjLXvE1le2GkeC9FjvdQvQzPe3yyLZWiL3kdRksTwFBz3qh4Q8Y+IJfGF14Q8c6fY2+sQ2gvoLnTHdra5hLbSQH+ZSGOOevPTjPXXl9bNcPpMOp29rqs9u0kEZdWlUdPMEZOWAP4dq8u0C01PwP8aoLXxTfr4iu/FFrIltrDReTLB5I3mAxglAmOcqBz1oh8Vn5/rsEvhb7WNT4lfF618H/wDEt0JE1PWhNEs8YRniskdwN0xUjaTnCjIOSD06+l15n8b7O2tvhjfS29vDFJcajZvM8aBTK3nxjLEdTgAZNemUR+C73v8AohP47eX6v/I53xb/AMJn5Nt/wgn9g+Zub7T/AGz523HG3Z5XfrnPtXB2/jD4pQfErS/Cuow+ELp51+03p05bom1tgwBZi7ABm5CjBycZ4r1m6uI7O0muZ22xQxtI7eigZJ/SvOfgzYy6hpWp+OdTGdQ8T3TTruOTFbKSsUY9AAM/QiiPxen9Jf12Y5fD/Xzf9d0Jf+NvGfiDxjqmifDfS9INvoziG91LWnl8p5iM+Wix/NkdzyPpxnpfBPi6XxNb39tqdj/Z2s6TcfZtQtBIHVHxlXRu6MDkfiO2a5IaT428BeM9cu/Cnh+28S6Pr119tMJv0tJLScjDklwQynrwM/1h+EserN8S/iHc65Nby3L3Fokv2UsYo5BGxMa55O0FVz3x0FENVZ9vx0/z/IJ6arv+H9a/edt4D/5F26/7DWq/+nC4oo8B/wDIu3X/AGGtV/8AThcUUAefJ4WuPGfwI0HQ7bVDpgudKsvNmEPmkoIkJXG5epA711vhfQIPC/hfT9FtW8yOzhEfmbdu9urNjtkkn8a4bwbY6u/gXQWh8V6tBG2m25WKOGzKxjylwoLQE4HTkk+pNbX9n63/ANDlrH/fiy/+R67Y02lotzByT36EOifDNdC+I+seJbXUw1nqyMs+mNbfLlsEnfu5+YE/d/iIrlbv9n3bNd22h+MdS0vRrt902mKpdG9iQ4BHYZUnjvXYf2frf/Q5ax/34sv/AJHo/s/W/wDoctY/78WX/wAj0vY6JW2H7TfzIdT+Efh3Ufh7a+EkE0FvZt5lvcqQZVk5y5OMHOTkcD0xgYw9C+B32XxFZat4q8VX/iM6eQ1rDcKQqEHKg7nc4B5wMcgfSui/s/W/+hy1j/vxZf8AyPR/Z+t/9DlrH/fiy/8Aken7N83NbUnnXLy9DI8Y/B0eIvGH/CS6H4jvPD+ougWeS2UsXwNuVIdSpK4B5IOOnWneDfg7B4N8cN4ht9buLzfbNFJFcxZkd2wWkMm7nJBONvfr3rV/s/W/+hy1j/vxZf8AyPR/Z+t/9DlrH/fiy/8AkelGk4vRDc09xfAXw9/4QjUNduv7T+3f2vcifb9n8vyuWOM7ju+9146VkH4R3dj4p1XU/DPi280W01h919aRWqSM+SSdkjH5OWODtJGTzWt/Z+t/9DlrH/fiy/8Akej+z9b/AOhy1j/vxZf/ACPR7F6abafIPaLXzKvgv4U2nhPw/rehXV+dV03VnJMckHluilSpBYMdxxjkBeRn6csf2eSVGnN421U6AJfMGmbOBznrv2bvfZXZ/wBn63/0OWsf9+LL/wCR6P7P1v8A6HLWP+/Fl/8AI9Hsne9g9orWOT+NGp+FNA+Gj+DpGaK6+zRNp1qkTHAR8Bt+Nv8ACQcnPPvXT/B3wy3hf4Z6fb3EXl3d1m7uFIwQz9AfcKFH4VVvfCL6lfQ3mo65d3d1AMRTz6fp7vHzn5WNtkc+lX/7P1v/AKHLWP8AvxZf/I9ONOScpPd/1/XoDlFpJbI7WsfVP+Rs8H/9heX/ANILusL+z9b/AOhy1j/vxZf/ACPUMuiapNd2dzL4u1hprGYz27eTZ/I5jeMnH2fB+SRxg5HOeoFEqcmrApq567RXmOPEn/Q7ax/4DWP/AMjUY8Sf9DtrH/gNY/8AyNWPsJl+0ienUV5jjxJ/0O2sf+A1j/8AI1GPEn/Q7ax/4DWP/wAjUewmHtInp1FeY48Sf9DtrH/gNY//ACNRjxJ/0O2sf+A1j/8AI1HsJh7SJ6dXN+NvBVp400uCGW6uNPvrKYXNjqFqcSW0o6MPUeo7+xwa5XHiT/odtY/8BrH/AORqMeJP+h21j/wGsf8A5Go+rzD2sS9o/wANdSbxJY63468W3Hii50wlrCI2cdpDA5H3yiEhn9Cen5V1XirQv+Em8I6pof2j7L/aFq9v52zf5e4YztyM49MiuHx4k/6HbWP/AAGsf/kajHiT/odtY/8AAax/+RqHh5yXK9gVWKd0d1a2DaR4Sh0+O9ET2disC3hjGFKR7fM2k44xnGaoeCpdWv8AwBp8uuXbz6jcQMz3LwCJnBJ2OYwAFO0qdvauUx4k/wCh21j/AMBrH/5Gox4k/wCh21j/AMBrH/5GolQnK/N1/wCD/X9aKNSMbW6HV+AfCK+BvBVj4fW7+2m13lrjyvL8ws7MTtycfex17Vl+Kvh9e6r4mj8SeFfEs/hvWhbfZJp0tUuY54s7gGjfAyD0OayMeJP+h21j/wABrH/5Gox4k/6HbWP/AAGsf/kanKhUk7saqRSsdJ4K8CweEPt93PqFzq+sanIJL7UrrAeUgYVQo4VBzhR0z7DE3hf/AJGLxn/2Go//AE32dcrjxJ/0O2sf+A1j/wDI1VbXTtasrm9ntvGOsJLfTCe4byLI73EaRg82/HyRoMDA4z1Jo9hNiVSKPWKK8xx4k/6HbWP/AAGsf/kajHiT/odtY/8AAax/+RqXsJj9pE9OorzHHiT/AKHbWP8AwGsf/kajHiT/AKHbWP8AwGsf/kaj2Ew9pE9OorzHHiT/AKHbWP8AwGsf/kajHiT/AKHbWP8AwGsf/kaj2Ew9pE9Orz/WvhtqX/CUXmveBvFtx4XutSC/2hGLOO7huGUYDhHICv6nv7c5o48Sf9DtrH/gNY//ACNRjxJ/0O2sf+A1j/8AI1H1ed7h7WJ1PgrwVaeDLC6WO6uNQv7+Y3F9qF0cy3Mh7n0A7DtTtT8J/wBo+P8AQ/E323y/7JguIfs3lZ83zQBndn5cY9Dn2rlMeJP+h21j/wABrH/5Gox4k/6HbWP/AAGsf/kan7Cpe/8AW1vyF7SNrf1vf8zp/Ftzq8GseG49F1FrcT6iEurVbZZPtMO0s+WIPlhQpOR1JAzzWf4q+H17qviaPxJ4V8Sz+G9aFt9kmnS1S5jnizuAaN8DIPQ5rIx4k/6HbWP/AAGsf/kajHiT/odtY/8AAax/+Rqn6vP+vS39erH7WP8AXrf+vQ6Hwj8PrTwzbam9/e3Gt6nrBzqV/eAbpxjAQKOFQAnCjpn2GOXT4Qa7p9jLofh/4ialpvhmQsBp32OOSWJGOWRLgnco9OOPfJqfHiT/AKHbWP8AwGsf/kajHiT/AKHbWP8AwGsf/kam8PNgqkUbPijQrDwz8Ddf0bR4fJs7PQbuOJc5OPJfJJ7knJJ9TXa15PqWna1q+lXem6h4x1ia0vIXgnj8iyXejqVYZFuCMgnkHNWseJP+h21j/wABrH/5GpujUbuxKpFKyPTqK8xx4k/6HbWP/Aax/wDkajHiT/odtY/8BrH/AORqXsJj9pE9OorzHHiT/odtY/8AAax/+RqMeJP+h21j/wABrH/5Go9hMPaRPTqK8xx4k/6HbWP/AAGsf/kajHiT/odtY/8AAax/+RqPYTD2kT0HWdIstf0W70rVYRPZ3kRimjJxlT79j6HtXnI+D+s3Onx6DrHxB1O/8LR7VXTPskccrxqflje4HzMvY8Dj0wKlx4k/6HbWP/Aax/8AkajHiT/odtY/8BrH/wCRqPq807h7WJ6Vb28VpbRW9tGsUMKBI0UYCqBgAewFYHgvwn/wiFhqNt9t+2fbtTuL/d5Xl7PNbOzGTnHrxn0FcpjxJ/0O2sf+A1j/API1GPEn/Q7ax/4DWP8A8jU/YVL3F7SFrHT+GLnV5/FHieO/1Fr7T4LqNLLNssQgOzc8YIGXxuX5ieuRxg0uheD/AOxvG3iTxE999pk1xoMRGHb9nWJNoXduO7Oc9B+NcvjxJ/0O2sf+A1j/API1GPEn/Q7ax/4DWP8A8jUlQmvusP2kdj06uc8P+E/7C8VeJNZ+2+f/AG7PDN5PlbfI8uPZjdk7s9egrlMeJP8AodtY/wDAax/+RqMeJP8AodtY/wDAax/+RqPYTTv/AF/WgvaRZ1V9/wAlT0L/ALAupf8Ao+xrpK8nk07WpdVg1J/GOsG7t4ZIIpPIsvlSRkZxj7Pg5MSckZG3jqc2seJP+h21j/wGsf8A5Go9hMftInp1FeY48Sf9DtrH/gNY/wDyNRjxJ/0O2sf+A1j/API1HsJh7SJ6dRXmOPEn/Q7ax/4DWP8A8jUY8Sf9DtrH/gNY/wDyNR7CYe0ienUV5jjxJ/0O2sf+A1j/API1GPEn/Q7ax/4DWP8A8jUewmHtInQeNPAY8U3dhqul6tcaFr2mlvsmpW6CTarfeR0PDqfQ4/mDW8L/AA8uNM8SHxJ4q8Q3HiXXFhNvBcS26W8VvGeoSJOFJ7nv+dZGPEn/AEO2sf8AgNY//I1GPEn/AEO2sf8AgNY//I1CoTWwOpF7nV+O/Cf/AAmvhWTRvtv2LfPDN53leZjy5FfG3I67cdaseMri7tPBeq3Gnag2nXUVszw3S24nKMORiM8MT0A964zHiT/odtY/8BrH/wCRqMeJP+h21j/wGsf/AJGpPDzcXEaqxUlJnW32j3/iL4cS6PqF2bXUNQ0z7PcXAjDbJHj2u20YB5J4GKv+HdHTw94Z03R45BKthax24kC7d+xQu7GTjOM9TXB48Sf9DtrH/gNY/wDyNRjxJ/0O2sf+A1j/API1U6M22+//AAf8yVUikl2/r9C7rXw21V/FF/rngvxhc+GptVCf2hELKO6jmKjaGUPjY2O4zXQ+DPB1h4J0NtPsJZ7mWaZri6vLp98tzM33nc+vT8vqa5HHiT/odtY/8BrH/wCRqMeJP+h21j/wGsf/AJGpKhNKyB1It3Z1XgP/AJF26/7DWq/+nC4oql8Mo5z4IBmvJppP7T1HfK6oGkb7dPliAoGSeeABzwBRWGxqcj4J/wCSf+Hv+wXbf+ilrcrD8E/8k/8AD3/YLtv/AEUtblerHZHE9woooqhBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB4rpHxV1S0+L99ouvXqyaQ17LaQgxIvkHeQh3KASOADnPXPaul1PxTrNv8dtK8Ow3m3Sri0Mktv5SHc2yQ53Y3DlR0PavPLXwfH4y8U/EK0RV+3QXTTWbnqHEr/Ln0Ycfke1ReBtfvPEHxk8OSaojLeWdq9nMX6uyRy8kdjgjPuDXJRnJqCl6+qs/wBToqxSc2v6Z7l4g8Y+H/Coj/t7U4rRpBlIyGd2HrtUE498YqbQfE2jeJ7RrnQtQivI0ID7Mhkz03KcEdO4rynQLDS9e+O/iSPxdFDdXEJK2VtdYZGUHAwp4OEwcYPUn3qXSbaz0f8AaPey8LrHFZyWjfbYIOI422EkYHAwwTjsTWkKjlyt7Sv+v+RnKKV0uh3EvxS8GQW0k8uuRokUxgZTDJv3jqAu3cQPUDHvU998R/COnafaXt1rluILxd0BRWkZh0ztUFhyCOQORivMPhd4a0fW18YT6tp8F3JHM0cbTRhvLB3klc9D05HPFUfh34Z0fUfg94o1K+sILi8jWdYppEDNFshDLtJ+6cnqKzjVm4czt8KZfJHmt52PTviJ4puNN+Gc2veGL9A7GIwXMarIpVnAOAwI6H0qHRfin4ZXSdJt9b1+AapPaQtP8h2iRkBO5lXYpz1BIx7V54HZ/wBlghjkLdYHsPtGf61rXfhzwaPgCNQhtbEXH2JXW8wPNNzgZXd1zuyNucD0qnOUeeS2Vn+FyVFPlT8/zPUtb8U6N4dhtZtZvlt47uQRwPsZw7HkcqDge54qvpfjnw1rMN9Lp2rQyw6eAbqVgyJGDnB3MACODyCRXifitri7+CPgoXzMzNcsgJ67BuC/+OgV1Hxm0m18PfDe0s9BsYbK1mvI1ufIiC+ZtRtpcj7xyBye9VOpKPM+idvvt/mEYqXKu/6XO90b4i+FPEGpfYNJ1mGa6PCxsjxl/wDd3ABvwzXTV4Fq3gnU57HRbn7V4D0NUZJLK7tJ5bd7jABHzMDvPQ56578174u7aN+N2Ocetaxbad90Zu3QwfEHjjw34Wmjh13VYrWaQZWII0j49SqAkD3NclpXji91b40tpVhqkd1oL2XnRJEiFSdgOd+N3XPGawfDOm6Xrnx08Up4ogt7y4jZvssF0A6soOOFPBwm3jBxTPDNlpWn/tIXttoKxJaJbvmOE/Ij7F3qMdMHPHbpWEZyk4Sezv8Ak9zSUVFSS6W/NHUfDLxNrmsXXiYeJrwSRabdeVGXjjjEQBfcCVAzgAcmte3+Kfgq61JbGHX4DOzbF3RuqE/75UL+tXfHmo6XpfgjUrjXoJLmx8vy5II3KNLuIAXIIIyTzz0zXiHju41i7+GekSN4fsNE8PrMhsIluGluDuRiDn+6RknIznFKVR01be1r/wDDjUVN32vc921rxfoXh2+trTWtQS0muVZ4g6NtIXqSwGB+JFcD8Q/icR4Ps9W8B6v8rah9mml+zf7BYriRPocgVl/Eqyg1Txz4Cs71fMguFRJVJ+8pdMj8as/HXTbDS/BGlW2n2kFlbDUc+XbRKijKNk7RgZqpykot9pW+5oIKPMvS/wCDO5t/iT4RuNYXSo9dt2vGbYBhthb0EmNhP41oa14v0Lw7fW1prWoJaTXKs8QdG2kL1JYDA/EivL/in4d8H6d8LbW80S1sYJt8X2OeADfOD1yw5f5cnJz0ql41tjrPiL4b2+tAytd28IugeC5JTdn680+eV+XrdL7yFGPLfyv9x6tZ+O/DV9oE+tW+rRf2dbyeXJcSI0YD4B24YAk8jgDnNL4f8deG/FM7waFqsVzMgyYijRvj1CuASPcV5j8abCHT7jwvpmnWtjY6W9w7tEY/KtvMygy+zGBgnJHOCaf/AMIbq9r8QNBv7m48FaLcwSqy2umTSW73UZbnCEfMSNwGOucGnGpJytbS9v6/yHKKUb/M9F1z4ieFPDeoGy1jWI4LkDLRLG8hXv8ANsU4/GtrS9Vsda06O/0q6jurWUZSWM5B9vY+x5FeOXmj+KdI8a69qvw+vtL16C8mLX1mssUkkeSx2SKSCOdwAByccjiuk+C2qWF3ompWVnon9jXNpcD7VAs0jozkYyBISUPy4K57CilNy0l/X+fqE4qO39f5Ho1zcwWdtJcXcqQwRKWkkkYKqgdSSelee+J/irok/hPV28Ja9CdVtYw0QMRBPzgEqJFw/GemfWk+OslxH8NJBbkhHuolmwcZTk8/8CC1g+M/Dng20+CcV7YWljHN5MJtbuML5s0hIyC3VjjdkEnGD0xWdWcnGdun36lwirxv1O58OeK4ovhppmv+KdQjiMsAaa4kULuYk9FUdfYCrWgeP/DHie8a00TVo7i4A3eUyPGzDvgOBn8K81udW0e0+GXgix1HQ31y/uADYWn2hok3hsZYg4PLAYII5PSq0smvS/H3w3P4mtLKyvJIsiGzcttTEgAc5OW69OMYrT2j9py9G7f1/kZqP7u/lc9UvfH3hjTdSvbDUNXitrmxQPOkqOu0EAjBxhicjhSTU/h7xjoHitZToGpR3Zh/1ibWRlHrtYA498YrzK10LT9e/aR1uLVrSK7ht7YTCKZdyFgkSjK9D948HineHLCz0X9o/V7TToo7O0FiW8qIBEXKRscAcAZ5xUwqSfK3s7/gVKCV7dLfjb/M7rUvif4N0nUpLC+1yJLmNtrqkUkgU9CCyqQCO/PFdNa3UF7ax3NnNHPBKoaOWNgyuD3BHWvAodF8WeHdN1eLwq+l+LPDd08huFhkSbdkchtrBw+3HCk4616b8JtV07VfAMDaRpx02CCZ4mtvPaVVbO4lWY5wd2cdsmrpTctJb2v/AF/mKpFR2IPi/wCJNW8LeELe90K7+y3D3qRM/lo+VKOSMMCOoFdJq3ijSfDekwXviC/jtI5AACwJLtjJwqgk/gK4f4//APIgWn/YRj/9AkpPGetWMXjHw9YWHh3+2/EqQCWzMl0YooAQTkjO1j8pPIGMDmp5mnL1S/AbirR9H+Z23h7xl4f8Veb/AGBqcd20XLptZHUeu1gDj3xita7u7extZLm9nit4IhueWVwiqPUk8CvF/BZ1T/hoXUjrkVpBfvZFp47IkxglYyOvJOMZ9817PeWtvfWcttewRXEEi4eKVA6sPQg8GqU26XN1IaSlY8q+H3jLXfG3iOa5ufFFlYW0VyVi0VbeIyXEYGThid4GO4z0PSu01b4k+EdD1JrDU9bhjuVO140R5Nh9GKKQp9jXmvwcsol8F+JNStbKB9VtZJRaTmIGRD5XAVsZAz2FWvg74f8ACmseC7y71i1sr+/aaT7W92Fd4l7H5vujGTuGOc88VEZSsortfU0nFKTb72PVpfEGlReH31s3sT6akZlNzFmRdo6kbck/hWZpvxD8Lavqttpum6slxeXSb4olikyRgnklcKcDODg15F4RkYfC34gWtrI0mlQs32RmOeuc4/AIa6Pwbo1ppvwJn1rS7GEaxJYXLi8EQMwPzDAbGQMAcUe1esraJJ/ffQXItut2iDXpvDFz8RJNSn8fxW+t29xGLMrau0Fqi5DRMc7W3ZOTuXBz9K6f4nfEZfBejwpprQzapdgNCkisVEeDmTI4OCBxnvXlvhbwte6z8M5pYI/BsVmzOs1/qJkW6t2zgZkxhO2B0wRkcmtTx/o40/4HaB9rm0/ULy3uhBHf2b+arRfvCFWQgHbwBjpkVnJyjSaWm34/18y4pSmr+f4Hs3hjxFYeJ9Di1DS7n7TH/q5H8tk/eADcMMB6/Stes3QNPs9N0O2h060gtImjVykEQRSxUZOAOp9a0q7paM5o6oKKKKkYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAa3wz/5En/uKal/6XT0UfDP/AJEn/uKal/6XT0V5Mt2dq2ON8E/8k/8AD3/YLtv/AEUtblYHgnwVpF34A8P3E0mrCSbTLZ2Ees3iLkxKThVlAUewAA7Vuf8ACBaJ/wA9dY/8Ht7/APHq71U02Odw1H0Uz/hAtE/566x/4Pb3/wCPUf8ACBaJ/wA9dY/8Ht7/APHqftPIXIPopn/CBaJ/z11j/wAHt7/8eo/4QLRP+eusf+D29/8Aj1HtPIOQfRTP+EC0T/nrrH/g9vf/AI9R/wAIFon/AD11j/we3v8A8eo9p5ByD6KZ/wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1HtPIOQfRTP+EC0T/nrrH/AIPb3/49R/wgWif89dY/8Ht7/wDHqPaeQcg+imf8IFon/PXWP/B7e/8Ax6j/AIQLRP8AnrrH/g9vf/j1HtPIOQfRTP8AhAtE/wCeusf+D29/+PVja34Q0201fw9Db3OsJHeai8E6/wBt3h3oLW4kA5l4+aNDkc8ehNHtfIOQ3KKZ/wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1HtPIOQwNB8Fad4d8QatrFlNdSXGrSGSdZnUop3FvlAUEcsepNU4vhtolv4+/4S23a6ivizOYUdRCzMhVm27c5OSevXmur/wCEC0T/AJ66x/4Pb3/49R/wgWif89dY/wDB7e//AB6pUoq1ltsU4t3u9zk/F3wx8O+M7lbrUopoLwAKbm1cI7gdA2QQfqRn3q14R8BaH4KgkXRoHM0oxJczsGkcemQAAPYAV0X/AAgWif8APXWP/B7e/wDx6j/hAtE/566x/wCD29/+PUKUU7pCcW1Zs53wz4G03wrHqaadPdyDU5PMm891O08/dwox949c1FoPw+0rw74T1Dw9ZXF5Jaah5nmvM6mRd6BDtIUDoO4NdP8A8IFon/PXWP8Awe3v/wAeo/4QLRP+eusf+D29/wDj1HNFK1ulvkOzve/mckPhpo48Anwj9pvvsBk8zzPMTzc79/Xbjr7VjyfArwfJfx3G2+VFA3W6zgRyEDkn5cjPU4IHpivRf+EC0T/nrrH/AIPb3/49R/wgWif89dY/8Ht7/wDHqV4t3sFpLqc54m8BaR4p0zT7C7ae0ttPcPAlmVQDAwFwVPGPStjWNGsNe0ibTNVt1uLWZdro36EHsQec1b/4QLRP+eusf+D29/8Aj1H/AAgWif8APXWP/B7e/wDx6qc073W4uVq2uxwWg/BfwroOsx6lELy7lhYPEl1KrJGwOQQFUZI9816BTP8AhAtE/wCeusf+D29/+PUf8IFon/PXWP8Awe3v/wAeoU1FWSBxbd2zjvF3wr8OeMtRW/1Bbm2u8BXmtHVTKBwNwKkHHrjPA54pfDvwt8P+F/EMer6QbuOaOAwiJ5QyHPVjlc5P1x7V2H/CBaJ/z11j/wAHt7/8erG0Twhpt3q/iGG4udYeOz1FIIF/tu8GxDa28hHEvPzSOcnnn0AqVKKd0huLas2Xda0ay8QaPcaZqsPnWtwu11zg9cgg9iCAa4mT4K+HrjSlsLzUtbuoosC2M16G+zDPIjXbtAPfKn8K9C/4QLRP+eusf+D29/8Aj1H/AAgWif8APXWP/B7e/wDx6huMndoEpLZnNaj4C03VNW0PUbu6vTPogUQFXQCTaQcv8vPTtirHi7wbp3jSytbXVpLhIracTqIGUbiARg7lORzW7/wgWif89dY/8Ht7/wDHqP8AhAtE/wCeusf+D29/+PVTmmrNeYuV9zz62+CHg+21oagIbqRFfetnJMGhB6gYxuI9ix966LXPBWm6/wCItJ1m8muo7jSm3QJCyhGO4H5gVJPTsRW//wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1JSirJLbUbTe7MrxL4X0vxbpDadrUHmxbt6Mp2vG395T2NYHhT4TeG/CGqDUbEXV1dqCI5buQN5WRg7QqqM47kGu0/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMeo5o83NbUXK7Wucjqvw00jUdan1ayvtV0a9uf+PiTS7sw+d/vDBH5Yz1rY8M+FdK8Jac1no0LIsj+ZLJI5d5W/vMT/APqrW/4QLRP+eusf+D29/wDj1H/CBaJ/z11j/wAHt7/8eojKMdkDi3uyvqml2etaXPp2pwLcWtwuySNu4/oQeQexrz6L4C+EIxcZk1GQyqQhedf3Oe64Xr2+bNek/wDCBaJ/z11j/wAHt7/8eo/4QLRP+eusf+D29/8Aj1JuMndoaUkrJnI6h8MdB1Lw1pmjXD3irpYxaXccoWePnJ+bbjsO3aobX4VaLa69Ya2L/VptSs33m5uLvzXuO2JNynjHHy7eDXaf8IFon/PXWP8Awe3v/wAeo/4QLRP+eusf+D29/wDj1Pmjzc1tRcrta5g2XgzT7Hxxe+KYZro317D5MkbOvlAfL0G3OfkHc96bB4K0638eXHixJro39xD5Lxl18oDaq8DbnOFHep/F/hDTdL8Ea5qFjc6xFdWmnXE8Mn9t3jbHWNmU4MpBwQODxWz/AMIFon/PXWP/AAe3v/x6hTSsrbD5XrrucTdfCbRJLq6l07UNY0iG8Ytc2un3pjhmJ65Ug8cnjpzxXU6HoWneHNIi03R7cW9rFkhckkk8kknkk1d/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMeojKMdkJxb3Zh+L/CFh410ePTtVmuYYY5xOGtmVW3AEY+ZSMfMe1U/Enw80jxLeWV9NPfWN/ZKEivLCcRShR0GcH1POM811H/CBaJ/z11j/wAHt7/8eo/4QLRP+eusf+D29/8Aj1DlF9B2fc5LRfhnougeJ017T7nUPtnlGOXzrjzBOT1dywLFjweCBx0rryMjFN/4QLRP+eusf+D29/8Aj1H/AAgWif8APXWP/B7e/wDx6mppKyWgnFt3uYHg/wAFad4Jsbm10qa6mS5m85zcurEHGONqjjiue1j4JeEtY1R70LeWLSNueK0lVY2JOScMpx9BgV6B/wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1S3F2uth2lq77mH/whejR+DZ/DNnC1np88ZjfySN5z1bcQct7nNW/D3h+08N+HbbRrJpZba3VlUzkMzAkk5wAO/pWj/wAIFon/AD11j/we3v8A8eo/4QLRP+eusf8Ag9vf/j1Vzq97C5H3PO7n4F+D7nVje7b2GNn3m0imAiPqPu7gPow9sV1GveC9G8Q+F00C7gaKyiC+QIDtaEqMArnI6ZHIPWtz/hAtE/566x/4Pb3/AOPUf8IFon/PXWP/AAe3v/x6pvFLltoO0r3uYvhHwjYeC9FOmaVJcSwtKZS1wwZixAHYAdh2rdpn/CBaJ/z11j/we3v/AMeo/wCEC0T/AJ66x/4Pb3/49V+08ieQfRWHc+ENNj8b6Zp6XOsC1n068nkj/tu8+Z45LZUOfNzwJH46c+wrZ/4QLRP+eusf+D29/wDj1HtfIOQfRTP+EC0T/nrrH/g9vf8A49R/wgWif89dY/8AB7e//HqPaeQcg+imf8IFon/PXWP/AAe3v/x6j/hAtE/566x/4Pb3/wCPUe08g5B9FM/4QLRP+eusf+D29/8Aj1H/AAgWif8APXWP/B7e/wDx6j2nkHIPopn/AAgWif8APXWP/B7e/wDx6j/hAtE/566x/wCD29/+PUe08g5B9FM/4QLRP+eusf8Ag9vf/j1H/CBaJ/z11j/we3v/AMeo9p5ByD6KZ/wgWif89dY/8Ht7/wDHqP8AhAtE/wCeusf+D29/+PUe08g5B9FM/wCEC0T/AJ66x/4Pb3/49R/wgWif89dY/wDB7e//AB6j2nkHIbPwz/5En/uKal/6XT0Uz4aWUVv4K8iNptkWp6ki753ZsC+nAyxJJPHUkk9TRXnvc6VsZvgH/kmvhn/sEWv/AKJWugrn/AP/ACTXwz/2CLX/ANErXQV1LYzCiiigQUUUUAFFFFABRRRQAUUUUAFFFFABXP8AiP8A5D3hL/sLyf8ApDdV0Fc/4j/5D3hL/sLyf+kN1QxnQUUUUCCiiigAooooAKKKKACiiigArI8Ua8vhjw3das9nPe+QFC29uMvIzMFUD8WH/wBeteih3a0Gt9Tw3wJ4q8W6x8e7q18UNPYL9gMg0lZyYoAVRkyucF8NySM5J6dBf8dat4i8W/FiDwF4Z1ubQre3tvtF5d25IkJxu7EHABUYBGdxz0qHSv8Ak7fWP+wcP/RUVQXl9Z+Ff2p577XbqOytNR04eVPMwSMfIq8seAMxsM+uKyjZqCe2v6lu6cmvL8bGx8J/EOvW/izxB4I8U6i2qXGkkSW93Jku6ZA5J5PDKeSTyeTXceHP+Q94t/7C8f8A6Q2teZ/DaeHxB8f/ABh4g0xvP09YBAtwn3HJKAYPfPlsR7V6Z4c/5D3i3/sLx/8ApDa1pFt04N72IdlKSW1zoKKKKYgooooAKKKKACiiigArI8Ua8vhjw3das9nPe+QFC29uMvIzMFUD8WH/ANeteih3a0Gt9Tw3wJ4q8W6x8e7q18UNPYL9gMg0lZyYoAVRkyucF8NySM5J6dBf8dat4i8W/FiDwF4Z1ubQre3tvtF5d25IkJxu7EHABUYBGdxz0qHSv+Tt9Y/7Bw/9FRVBeX1n4V/annvtduo7K01HTh5U8zBIx8iryx4AzGwz64rKNmoJ7a/qW7pya8vxsXvh14w1nQ9W8V+F/GGoPqknh+FrqK7kJLvEoyQSeTwVPJJ5PJrj4Z/iH4j8Fal8SYPF9zZC2ld4dLiZvKMSHngHbxk8Mpzt5NaPh6AeM/ih8SNS0M/aLSfS5rOGdOUd3VVXB758ske1UPC/jLQrD9mvV9HutQhj1PbPAtm7gSuZD8pVepHzcntg5qOZuHM9+W/zuOy5rLbmt8rHqM3iFvFX7P2o61IqpLdaFdNKqjgOInVse2Qa7+vKPDdhNpv7LVzDcI0btod7Ntbrh1kcfowNer11S0mzCPwoKKKKkoKKKKACiiigAooooAK8S+OHiW6t/F3h7Q7XxLc+HYHjknvLy2lkGxCcAlUILfcbA7k17bXkfivVvBMfxnt9P8a+HLYSvaAw6tqE+YCuCQpjb5MZDDJ6H61E9Wl5lx0TZJ8NGi03SNY8RL8RLzxhYwWzF4rgSIbcplidsjsVJAPUDNcLDP8AEPxH4K1L4kweL7myFtK7w6XEzeUYkPPAO3jJ4ZTnbyan8Lafban8S/iBaeBwh0S40maFRb/6kysoChe2N3mYxxjOOKi8L+MtCsP2a9X0e61CGPU9s8C2buBK5kPylV6kfNye2Dms3K8XL+7det/xKSs7f3rP0t+B1HjD4oatcfC3wzPoLra6z4kdYPNXjyiCFfbnpliBnsD9DVbTLjxZ8Mvihoeia/4nuPEOma6uwtdF2McmcfLuLEYJXvghjkCuT1/TJ9C+Ffwy1S+jkjt7O8eWb5clRJIJV/NVJrqPHOsaZ40+NHgS18N3sOpfZJhcTSWsgdUXer8kcZAjJI6itV/F/wC3rP0sZf8ALr5X+d2eq3n/ACUrRv8AsEah/wCjrOugrn7z/kpWjf8AYI1D/wBHWddBVDCiiigQUUUUAFFFFABXnHxQ8b67osNzo/hPSJri+/s97ya/OBFZwjdls/3/AJDgHHbr0r0esHxz/wAk98Q/9gy5/wDRTVnVvyNmlPWSRyPwj8Q3TfBca3rl5c30lv8AaZZZriZpHZUJONzEnoK85hn+IfiPwVqXxJg8X3NkLaV3h0uJm8oxIeeAdvGTwynO3k12XwospdS/ZyurG3GZrmG9iQerNuA/U1x/hfxloVh+zXq+j3WoQx6ntngWzdwJXMh+UqvUj5uT2wc0qj1b7RTXqKGy85O/odR4w+KGrXHwt8Mz6C62us+JHWDzV48oghX256ZYgZ7A/Q1W0y48WfDL4oaHomv+J7jxDpmursLXRdjHJnHy7ixGCV74IY5Ark9f0yfQvhX8MtUvo5I7ezvHlm+XJUSSCVfzVSa6jxzrGmeNPjR4EtfDd7DqX2SYXE0lrIHVF3q/JHGQIySOoq1/F/7es/SxH/Lr5X+d2S6rdeKvib8UNb0Hw94muPD2maEuwvaswaWXODu2spOW3DrgBRxmul+C/i3VvEGjanpfiSb7Rqei3Zt5Jz1kXkDJwMkFWGepAGa5XwVrGmeDfjh46t/El/Bp32qQzwyXLhEYFi4GT32uMDvzV74Aob3UfGWuxIwtNQ1H9w5GAwDO38pF/Opo/CvNXfrcqr8T8nZelj2D4d/8inL/ANhfU/8A0vnoo+Hf/Ipy/wDYX1P/ANL56Kxe5oY3gH/kmvhn/sEWv/ola6CuD8EeCPCl38P/AA9cXXhjRp55tLtpJJZNPiZnYxKSxJXJJPOa3P8AhAfB3/Qp6H/4LYf/AImulXsZHQUVz/8AwgPg7/oU9D/8FsP/AMTR/wAID4O/6FPQ/wDwWw//ABNPUDoKK5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+Jo1A6Ciuf/4QHwd/0Keh/wDgth/+Jo/4QHwd/wBCnof/AILYf/iaNQOgorn/APhAfB3/AEKeh/8Agth/+Jo/4QHwd/0Keh/+C2H/AOJo1A6Ciuf/AOEB8Hf9Cnof/gth/wDiaP8AhAfB3/Qp6H/4LYf/AImjUDoKK5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+Jo1A6Cuf8R/8h7wl/wBheT/0huqP+EB8Hf8AQp6H/wCC2H/4msrUfA3hNPE/hWJPC+irHPqkkcyDT4gJFFlcsFYbeRuVTg91B7VMm0rgjtaKb/wrjwR/0Jvh/wD8FcH/AMTR/wAK48Ef9Cb4f/8ABXB/8TUe08iuUdRTf+FceCP+hN8P/wDgrg/+Jo/4Vx4I/wChN8P/APgrg/8AiaPaeQco6im/8K48Ef8AQm+H/wDwVwf/ABNH/CuPBH/Qm+H/APwVwf8AxNHtPIOUdRTf+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mj2nkHKOopv/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNHtPIOUdRTf+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaPaeQcpjxeENDg8XTeJ4rHbrE8flSXPnOdy4Axt3beijt2pPEvg3w/wCMLaODxJpkV6kRJjZmZHTPXDKQwBwMjPOK2f8AhXHgj/oTfD//AIK4P/iaP+FceCP+hN8P/wDgrg/+Jpc6taw7O97mb4f8NaP4W00WHh+wisrbduKx5JY9MsxyWPHUk1T8Of8AIe8W/wDYXj/9IbWt7/hXHgj/AKE3w/8A+CuD/wCJrn/DngHwfPr3iyOfwnociW+rRxwq+mwkRr9htW2qCvA3MxwO7E96ftBcp0VFN/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+Jo9p5ByjqKb/wAK48Ef9Cb4f/8ABXB/8TR/wrjwR/0Jvh//AMFcH/xNHtPIOUdRTf8AhXHgj/oTfD//AIK4P/iaP+FceCP+hN8P/wDgrg/+Jo9p5ByjqKb/AMK48Ef9Cb4f/wDBXB/8TR/wrjwR/wBCb4f/APBXB/8AE0e08g5R1FN/4Vx4I/6E3w//AOCuD/4mj/hXHgj/AKE3w/8A+CuD/wCJo9p5BymPF4Q0ODxdN4nisdusTx+VJc+c53LgDG3dt6KO3ak8S+DfD/jC2jg8SaZFepESY2ZmR0z1wykMAcDIzzitn/hXHgj/AKE3w/8A+CuD/wCJo/4Vx4I/6E3w/wD+CuD/AOJpc6taw7O97mb4f8NaP4W00WHh+wisrbduKx5JY9MsxyWPHUk1iX3wq8E6jrjave+HraW8Z97tucI7dy0YOxic85HNdb/wrjwR/wBCb4f/APBXB/8AE0f8K48Ef9Cb4f8A/BXB/wDE0e0u72Fy6WMDx6oX4Z+JVUAAaRdAADp+5auhrnfH3gHwfZ/DbxLdWfhPQ4LiHSbqSKWLTYVeNhCxDKQuQQRkEV0H/CuPBH/Qm+H/APwVwf8AxNHtPIOUdRTf+FceCP8AoTfD/wD4K4P/AImj/hXHgj/oTfD/AP4K4P8A4mn7TyDlHUU3/hXHgj/oTfD/AP4K4P8A4mj/AIVx4I/6E3w//wCCuD/4mj2nkHKOopv/AArjwR/0Jvh//wAFcH/xNH/CuPBH/Qm+H/8AwVwf/E0e08g5R1FN/wCFceCP+hN8P/8Agrg/+Jo/4Vx4I/6E3w//AOCuD/4mj2nkHKOrE8S+DfD/AIwto4PEmmRXqREmNmZkdM9cMpDAHAyM84rZ/wCFceCP+hN8P/8Agrg/+Jo/4Vx4I/6E3w//AOCuD/4mk6ie6HytbMzPD3hjRvCmm/YPD+nxWVvu3MqZJY+rMSSx9yTWLffCrwTqOuNq974etpbxn3u25wjt3LRg7GJzzkc11v8AwrjwR/0Jvh//AMFcH/xNH/CuPBH/AEJvh/8A8FcH/wATR7S7vYXLpYq6lpOn6xpcum6pZw3VnKoV4JFypA6cdsY49Kx/DXw98LeD7iSfw7o8VpPIu1pS7yPj0DOSQOBwK6L/AIVx4I/6E3w//wCCuD/4mj/hXHgj/oTfD/8A4K4P/iaPaa3sHLpYwbz/AJKVo3/YI1D/ANHWddBXO3ngHwevxJ0a1XwnoYt5NJv5HiGmw7GZZrMKxG3BIDsAe24+proP+FceCP8AoTfD/wD4K4P/AImj2nkHKOopv/CuPBH/AEJvh/8A8FcH/wATR/wrjwR/0Jvh/wD8FcH/AMTT9p5ByjqKb/wrjwR/0Jvh/wD8FcH/AMTR/wAK48Ef9Cb4f/8ABXB/8TR7TyDlHUU3/hXHgj/oTfD/AP4K4P8A4mj/AIVx4I/6E3w//wCCuD/4mj2nkHKOqvfWVvqWn3Fjex+bbXMTQypuI3IwwRkcjg9qm/4Vx4I/6E3w/wD+CuD/AOJo/wCFceCP+hN8P/8Agrg/+JpOomrNDUWtUZ3h/wAO6X4W0dNL0K1+y2cbMyxeYz4LHJ5Yk9fesO++FXgnUdcbV73w9bS3jPvdtzhHbuWjB2MTnnI5rrf+FceCP+hN8P8A/grg/wDiaP8AhXHgj/oTfD//AIK4P/iaPaa3sLl0sVdS0nT9Y0uXTdUs4bqzlUK8Ei5UgdOO2McelY/hr4e+FvB9xJP4d0eK0nkXa0pd5Hx6BnJIHA4FdF/wrjwR/wBCb4f/APBXB/8AE0f8K48Ef9Cb4f8A/BXB/wDE0e01vYOXSxz3ib4f+F/GE0U3iPSIryaIbUlDvG+PQshBI5PB4rX0rSbDQ9Ni0/SLSKztIRhIYlwB3P1JPerX/CuPBH/Qm+H/APwVwf8AxNH/AArjwR/0Jvh//wAFcH/xNCqW2QON9yL4d/8AIpy/9hfU/wD0vnopnw8sLO18KS29taQQww6tqcccUcYVUVb+cBQBwAAAAO1FZFmT4B/5Jr4Z/wCwRa/+iVr568c2l/8AEbxP4x8S6a7fZfDSRxQbT98I+GIP0Ej/AJV7A/iNfCn7POnatv2TR6FbJB7ytCqp+pB/CvNPAPgH4n/8IMJPDet6TYaZrCmaS3ukDSSBhtyxMLdVHQHofetJXk9Oi/F7CVktev5dT2/wT4mi8T+BNN1x2VDNb5nJPCOvD/hkGvO7v9oNfOurnRvCGpalolpJsm1RWKovPXGwgdRjcwPI6Vh/Cgajaab41+Gd9IF1GKGY2uHO3cyFG2k44yUYdOpNQfDv4n+GvBvwtvNB8RQSHVLWScNpstu2Lkk/dJ2lR6Hd0x0NaSnzSunZWuvP/hiIxtG1tb29P+HPUdY+K/h/Sfh/aeLFMtxbX3y2sCACSSTnKnPTaVOT044zxnC8O/Gwah4ms9F8T+F7/wAOTagQLSS5ZmWUk4X7yKQCeARkZrlPijqT694M8FeNLbSLmz0uzvPMmtGVcohZSrADjadhAJx94dM11g+M/hTV/GOiWGg6dNrdzdExi4jg2SWhbHA3gZHBLEHAC96ad5tedrfIT+BPyvf5nQ6Z4/8A7R+KuqeDP7N8v+z7YT/bPPz5nEfGzbx/rOu49PemWnxD+1fFy88Ef2Zt+y24n+2/aM7vkRsbNvH38Z3dq83ufE2n+B/2m9b1DxJJJZWV3ZKiTeSzg5SMg4UEkZQjIB5H1pvgPxDa+Kv2mNT1jT1kFpcWLCFpEKl1VY03Y9DtJqYS5uT0d/xKmlHm+Vvw/wCCb0Px3vL7VrvS9G8EX2p3ttdtC0drcFwI1bb5jER/Lz2PHqa3tX+J98nii+0Hwn4Wm8QXemRCS/YXiW6Qkj7oZgdx9h74zg1zHwFRf+Ek8dPtG7+0AN2Ocb5eKy7vxlqXiXxv4k0/xH42fwdpekSskVrb7YprhQWHyufmLYAOBnO4YFRzPkjrq1f8Asry00TseleEvido/ijwTeeI3STT4dP3C8jmO4xFVDHBH3gQeOAT6VxY/aGA2X8vgzVI/D7y+WuqFuD+Gzbng8b+1cb8PdMutb+AXjex0wNLcNcrIqDlnChHIx3JCke9b2gfGbwhovwk0vTru1bUdRs444X0ySAgMVbl9xUpx94d846datyfNvbRfiFvd+b19D0GL4nQSfEfT/DR0/Fnqtmt3YamJyVnUpuA2FRjow+96cc1Zl8f5+K8Xgqy037SVtvtF1efaNv2fgnGzac/wdx96uO+MUU83hTw54+0+0ms7vR54rgwTKFdI3Kna2CcYYKMf7Rqf4KWza9qfiXx7dI6yaveNFbCTGUhU5x/6Cv/AACqjdy5X0vf9Pz/AAJekbrra36/l+J65WPqn/I2eD/+wvL/AOkF3WxWPqn/ACNng/8A7C8v/pBd0S+EFud1RRRXMahRRRQAUUUUAFFFFABRRRQAVzPj3Rte8QeGf7L8NaimmS3M8a3V0ZGSRLfP7zyyoPzkYA6Dk8iumrnfHPjPTvAfhWfWtV+ZUIjhhDAGeU/dQE9M4OT2AJ7Um0ldjV76HmPjDwLovwxu/DmseAjdadq91rFvaSQC7kkGoo5O9XV2I6c54Az64x2fjbwFpHiXVm1bx5rBfw5Z2wVNNeZrWCJ88zSSBxuPQDoB71z3hPUvDl9r8Xizx3408OXniBl2WNjDqkJh0tG6xxjf80h6M/foOOvS67490Ww8aT+E/G1paWGnXFos9pfahKv2e8wfnQhl2qVOOpOeOmRlu9knvd/lt+vrt3FdXbW1l+e/6em5jfBo+Xe+J7TQrq6vPB1vdRpos1wzOB8p85Inblo1bAB5HHU8muu8L/8AIxeM/wDsNR/+m+zrhvh42mS/GTxC/gDyx4UWxjW6+yDFo19uHMQHy/c6leP0rufC/wDyMXjP/sNR/wDpvs6p6pPy/wCB+O4vtNLv/X9dzpKKKKkYUUUUAFFFFABXmfi/4eeF9R1TUPEPxS1pbrTyVSxt7i5ezt7FQOi7ZBvdjk5PXpivTK89uvH3he+8R6z4V+INrpulmwkV7ZdXljaG9iI+WVfMULnqNuSRz74l76b/ANf1/TGtEM+DVxqcvgO6a4mvL6xjvp10Wa+yJp7MY8osSM884JHTHbFc3bf8JbN8e/Cd94yktrY3VnfG20q1belkoQZ3Sfxu2RkgY+UY9tT4MmKTVfF0vhzevg9r9P7IUgiPftPnmIHpHuxjHFX/ABN/yX7wP/146h/6Alafbi/L/wBtf49yJfDJLv8A+3I9GrhPGPwu+H+uXd54k8XaQJpY4d9xctdzoBHGvXCOBwo7Cuxu9UsLCe2gvr62tpbuTyreOaZUaZ/7qAn5j7CuC+N11LJ4ItNAtXKT+ItSt9MDL1Cu2XP5KR+NZtN7b7L1f/Dmist9v0OR+FHhWx0Dw34i+I+j6S1i15aznSNPMjv5dsgyu4sxLM7ICcn0xgGn+EfhjoviP4dweNdZ1bUJ/E19ate/24L6RHtHwSAgB2hVxjBB6HoMAe0Q2lvp2kpaWtvm2toBFHAgByirgKM+wxzXz8JPhRb+GL3WrPX9XtLRzKzeDJNS8tHnyRsa1UluWA7lcdeOKc3uo9rLut/z8uvqKKva/fXt/S8/0O6tfE1x4v8A2YNS1q+YNdT6BerO6rgO6RyIzY7ZK5/GvUa8p0zQLjwz+yvfaZfRGC6Tw9eyzRMMGNpI5HKkdiN2MV6tWlS3O7GcPhQUUUVBYUUUUAFFFFAFHWrS9v8ARLy00u//ALOu54mSK78rzPJYjG4LkZI7c9a8N8ZeDvDXgWGx/wCEL1O7k+I5uIBC0d7JNc3rMw3maIsQIyu5iSAOBye/tfifVbvQ/DF/qmnaa2q3NpCZUs0k2NNjqAcHnGT0OcYryXx/4s+Gvi34cT6vbTabP4huoENgtrtOox3XHlqNv7wEMAPTA+lJO0uZdLevovUq11Z9b+nz/r0O/wDGvgmLxjLZf8JBq0kPh+0R5L3TYmaJbpscGSUMCEXk4x75rj/hjDp2nfE3WNN+Ht5NdeC4rBGkAnae2gvS/wB2GRic5T5mwTyfpjcuPHL+FIvC+j/EG0jit9V05Y7zVriUeSl0EG6KQFcANz8xIHXjAJrndLk0Cf49aWfhgbT7GljMdfbStv2RlI/c5KfIZN/pzj8auKtOy21/Xf8AT5dDO94Xfl+n9feexzLI0EiwOscpUhHZdwU44JGRn6ZFeE+NvAXhLwj4auNR1nxBeXXj6RGlsdRjvJEvLm4LfIsUAcjbuIXABwCeRXtLazbTw6imjz22o31gpElpDcLuWTBKxvjOwnHcV5fqPjz4Z+NfAVxqHjWLSrbUI4JIbjTrso19bSLkFI8gOSD0Kgde3NZS6tf8H5f12v0NY7pP+vUXx3ca7qmk/D/wtrN/Ppb+IXWLWbi2by3LLEC0QI6b2JHp+HBZqWgaR8HvFXhSXwe89hZ6zqS6dfaa1zJLHcBxgSgOTh1bbyMcHFVGOnL8B/Ctt8XrfUH+0zJGt+pxLYMWbyZZHJBTCbQTg+hFZL6F4Z1X4i+E9I8La/qHjC/tL9dRvdVvNRN79ktoskRiQfIoZyOBzkDPatv+XjX978NLr7vw8zH/AJd/9u/jrZ/5Hr99/wAlT0L/ALAupf8Ao+xrpK5u+/5KnoX/AGBdS/8AR9jXSVBYUUUUAFFFFABRRRQByHjfwTD4xuLMa9q0sPh2zV5LzTY2aJbpscGSUMCEUZOMe+a474Yw6dp3xN1jTfh7eTXXguKwRpAJ2ntoL0v92GRic5T5mwTyfpjr/Fvjux8L+JdM0nxJZxw6Jq0UkZ1W4kHkxyj/AJZSKVwAy9yQOvHBNcVpcmgT/HrSz8MDZmzSwmOvtpW37IykfuclPkMm/wBOcfjRD4tNtfye/wCny6BL4Xfy/NbEvi34eeDLCDUfEHxR8RSXOpXEsklnetdPbNagDKR20QcgleDjDEnnFdp8LJtcuPhjosvirzv7TaE+YbgYkK7jsL992zbnPOetc6nxA8D+J7TUbH4jWmkaVf6VcSwTadrEkcjADo8ZdRu3AA/KM9PYk+DV7/Zvw0u77U7prPQEv530qXUJNnlWOQI9zOeFznGT0x7UQ+FrpZP+vN3/AACWrXe7/r00/Kx1vi3wF4b8dQ20XirTftyWrM0I8+SLaWwD9xhnoOteR+Gvhl4P1T41zP4X0g2Wj+EnUTzLczP9qvs5CZdjhY8ZOOp65Br2fX9dg0jwbqOuxSJNDa2Ul1G6MGVwELKQehB4/Oud+Dejf2P8LNJebm71JDqF1Ieskkx35PvgqPwojpJtdPze35P52CWsUu/5Lf8ANfiM+I/iK/DW3g/wrIE17WI3Zpxz9gtRxJcHHf8AhUcZbvxUPwJGPgroAJyQkvPr++euet/CfxW0XxB4g1ixm8HXkuqzMxuL9rppkgHEcS7QAqqOw7k5Jq/+z3/bv/CrrP8AtX+z/wCzsN/Z/wBm3+djzH3+bu4zu6be3WiHwv5frp/XmE90dh4D/wCRduv+w1qv/pwuKKPAf/Iu3X/Ya1X/ANOFxRQB514a8Q+BL74a+HtN8Q6v4duBDptqJLW+uYH8uRYlByjnhhyOmRXRweOPBNtbxwW3ifQIoY1CJHHqEKqigYAADcAelFFbqTsZ2KieI/hxHq76rHrHhZdRcbWvFurcTMMYwXzuPAA61Deav8L9Qvvtt/qHhG6uxj/SJprZ5OP9onNFFHMFjSl8c+Cp4Whm8UaBJE42sj6hCVYehG6qGm658M9FleTR9U8J6fI4w72txbRFh6EqRmiinzPcLdB2peIPhtrLRnWNX8K35i5jN1c20uz6bicUsPiP4cW+pf2hBrHhaK98sRfaUurcSbAAAu4HOMAce1FFLmCw6w8S/DrSpJ5NL1rwvZPctvna3u7eMytzyxUjJ5PJ9aiudd+Gl5qSajeap4UuL6PGy6luLZpVx0w5ORiiijmCxLY+Jvh3pc1xLput+GLOS6ffO9vd28Zlbk5Yg/MeTyfU1XGrfC8an/aQ1DwiL7dv+1eda+bu9d+c5980UU+YLHEfFnxfea/D/wAI/wCE9b8LS6PfwBbu6m1W3V4m38jmX7uAOiE9ea7Pwjrvgjwn4R07RLfxdoTLZwhWcajCN7nlm+93Yk0UUou1/Mb1sbP/AAn3g7/obND/APBlD/8AFVlaj458Jv4n8Kyp4o0Vo4NUkkmcahERGpsrlQzHdwNzKMnuwHeiilKTsCWp2f8AwsfwR/0OXh//AMGkH/xVH/Cx/BH/AEOXh/8A8GkH/wAVRRWJYf8ACx/BH/Q5eH//AAaQf/FUf8LH8Ef9Dl4f/wDBpB/8VRRQAf8ACx/BH/Q5eH//AAaQf/FUf8LH8Ef9Dl4f/wDBpB/8VRRQAf8ACx/BH/Q5eH//AAaQf/FUf8LH8Ef9Dl4f/wDBpB/8VRRQAf8ACx/BH/Q5eH//AAaQf/FUf8LH8Ef9Dl4f/wDBpB/8VRRQAf8ACx/BH/Q5eH//AAaQf/FVQ1bxV8Mdet0g1zXvCWpQxtvSO8vLaZVbGMgMSAcE80UUAZaP8Eo3V428AqynKspsgQfWtbVPF3w01y1FrrXiDwpqNuGDCK7vbaVAfXDEjNFFAEtj43+Hel2aWmmeJ/DFnbRjCQ2+oW8aL9FDACsfw54+8Hwa94skn8WaHGlxq0ckLPqUIEi/YbVdyktyNysMjupHaiijcDoP+Fj+CP8AocvD/wD4NIP/AIqj/hY/gj/ocvD/AP4NIP8A4qiigA/4WP4I/wChy8P/APg0g/8AiqP+Fj+CP+hy8P8A/g0g/wDiqKKAD/hY/gj/AKHLw/8A+DSD/wCKo/4WP4I/6HLw/wD+DSD/AOKoooAP+Fj+CP8AocvD/wD4NIP/AIqs3VvEvwt19YhruteENTEJJjF5d2s2zPXG4nFFFAF6D4geAraBILbxb4chijXakcepQKqj0ADcCopfG3w6n1CC/m8TeF5Ly3VlhuHv7cyRBvvBW3ZAPfHWiigDK8ReJfA+vahokr+L/C2zTb4XbSSajA0o2qcLGd3y5bbk56DHetS88afDnUHt3v8AxL4XumtZRNAZ7+3cxSDo65b5WHqOaKKNvz/r7g3/AK/ruWv+Fj+CP+hy8P8A/g0g/wDiqyz4h+FTaz/a7av4OOpZz9tNza+dn/fzu/WiijzDfQp+PvH3g+8+G3iW1s/Fmhz3E2k3UcUUWpQs8jGFgFUBskknAAroP+Fj+CP+hy8P/wDg0g/+KoooAP8AhY/gj/ocvD//AINIP/iqP+Fj+CP+hy8P/wDg0g/+KoooAP8AhY/gj/ocvD//AINIP/iqP+Fj+CP+hy8P/wDg0g/+KoooAP8AhY/gj/ocvD//AINIP/iqP+Fj+CP+hy8P/wDg0g/+KoooAP8AhY/gj/ocvD//AINIP/iqyoNe+FFrqz6rbar4Nh1FyWa8jubVZmJ6kuDk5+tFFAFy/wDG/wAO9VspLPU/E3hi8tZBh4Li/t5Ef6qWINR6X4u+GmiWv2bRfEPhTT7fO7yrS9tokz64VgKKKAM7Q/EvgfStf17VD4v8LRvqs8bhLfUYF+VEwGc7vmcksSfoOcVZn174UXOrjVbnVfBs2oqQReSXNq0wI6fOTu4+tFFC0A0Lnx74AvbWS2vPFfhu4glXbJFLqMDK49CC2CKq6V4q+GOhQNDoeveEtNic7mjs7y2hVj6kKRRRQBnXnj7we3xJ0a6XxZoZt49Jv43lGpQ7FZprMqpO7AJCMQO+0+hroP8AhY/gj/ocvD//AINIP/iqKKAD/hY/gj/ocvD/AP4NIP8A4qj/AIWP4I/6HLw//wCDSD/4qiigA/4WP4I/6HLw/wD+DSD/AOKo/wCFj+CP+hy8P/8Ag0g/+KoooAP+Fj+CP+hy8P8A/g0g/wDiqP8AhY/gj/ocvD//AINIP/iqKKAK1/43+Heq2UlnqfibwxeWsgw8Fxf28iP9VLEGo9L8XfDTRLX7NoviHwpp9vnd5Vpe20SZ9cKwFFFAEGpeIPhTrN5Hd6vq3g2/uYgBHNdXNrK6DOeGYkjmk8SeMvBOseFr/S4PFvhV2ubdoUW71CB4gSMAsu7kDrj27UUUmrrlew02ncmt/F3w7i8PQ6LceK/Dd1ZR2y2zRT6jbusiBQuGUtgggdKtweP/AAFa28dva+LfDkMMShI449SgVUUDAAAbAAHaiiqbbd2SkkrIefiN4HZSG8Y+HyDwQdUg5/8AHqgsfG/w70uyjs9M8T+GLO1jzsgt9Qt40TJycKGAHJJoopDD4eX9ndeFJbi2u4JoZtW1OSOWOQMrq1/OQwI4IIIIPeiiigD/2Q==)\n",
        "\n",
        "* Pour les réseaux de neurones, on a également crée des dataloaders avec des images de taille 256\\*256 pour faire la comparaison avec les 32\\*32 mais aussi car AlexNet ne fonctionne pas sur des images de trop petite taille. De plus on remarque que les réseaux préentraînés étaient entraînés sur des images de taille 256\\*256. On voit effectivement que changer la taille de l'image a un impact sur la performance des réseaux préentraînés mais ne change rien à ceux qui ne sont pas préentraînés. Enfin le learning rate a un impact sur la performance des réseaux et notamment sur AlexNet qui n'apprenait pas pour un learning rate au dessus de 0.01. On peut le baisser mais jusqu'à un certain seuil, en effet trop le baisser ne le fait pas apprendre assez vite. Enfin les réseaux de neurones avaient un temps d'exécution quasi-similaire et WideResNet 28-2 est celui qui obtenu les meilleurs résultats sur les différents tests.\n",
        "\n",
        "![Neural Network.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RDuRXhpZgAATU0AKgAAAAgABAE7AAIAAAAMAAAISodpAAQAAAABAAAIVpydAAEAAAAYAAAQzuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEFudG9pbmUgWGllAAAFkAMAAgAAABQAABCkkAQAAgAAABQAABC4kpEAAgAAAAMxOQAAkpIAAgAAAAMxOQAA6hwABwAACAwAAAiYAAAAABzqAAAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMjAyMzowMToyNCAxNTowNDoxMwAyMDIzOjAxOjI0IDE1OjA0OjEzAAAAQQBuAHQAbwBpAG4AZQAgAFgAaQBlAAAA/+ELHmh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjMtMDEtMjRUMTU6MDQ6MTMuMTkwPC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPkFudG9pbmUgWGllPC9yZGY6bGk+PC9yZGY6U2VxPg0KCQkJPC9kYzpjcmVhdG9yPjwvcmRmOkRlc2NyaXB0aW9uPjwvcmRmOlJERj48L3g6eG1wbWV0YT4NCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgPD94cGFja2V0IGVuZD0ndyc/Pv/bAEMABwUFBgUEBwYFBggHBwgKEQsKCQkKFQ8QDBEYFRoZGBUYFxseJyEbHSUdFxgiLiIlKCkrLCsaIC8zLyoyJyorKv/bAEMBBwgICgkKFAsLFCocGBwqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKv/AABEIATkDCgMBIgACEQEDEQH/xAAfAAABBQEBAQEBAQAAAAAAAAAAAQIDBAUGBwgJCgv/xAC1EAACAQMDAgQDBQUEBAAAAX0BAgMABBEFEiExQQYTUWEHInEUMoGRoQgjQrHBFVLR8CQzYnKCCQoWFxgZGiUmJygpKjQ1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4eLj5OXm5+jp6vHy8/T19vf4+fr/xAAfAQADAQEBAQEBAQEBAAAAAAAAAQIDBAUGBwgJCgv/xAC1EQACAQIEBAMEBwUEBAABAncAAQIDEQQFITEGEkFRB2FxEyIygQgUQpGhscEJIzNS8BVictEKFiQ04SXxFxgZGiYnKCkqNTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqCg4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2dri4+Tl5ufo6ery8/T19vf4+fr/2gAMAwEAAhEDEQA/AM//AIWZ49/6G26/8ArT/wCM0f8ACzPHv/Q23X/gFaf/ABmuZor6T6rR/lPK9tU7nTf8LM8e/wDQ23X/AIBWn/xmj/hZnj3/AKG26/8AAK0/+M1zNFH1Wj/KHtqnc6b/AIWZ49/6G26/8ArT/wCM0f8ACzPHv/Q23X/gFaf/ABmuZoo+q0f5Q9tU7nTf8LM8e/8AQ23X/gFaf/GaP+FmePf+htuv/AK0/wDjNczRR9Vo/wAoe2qdzpv+FmePf+htuv8AwCtP/jNH/CzPHv8A0Nt1/wCAVp/8ZrmaKPqtH+UPbVO503/CzPHv/Q23X/gFaf8Axmj/AIWZ49/6G26/8ArT/wCM1zNFH1Wj/KHtqnc6b/hZnj3/AKG26/8AAK0/+M0f8LM8e/8AQ23X/gFaf/Ga5mij6rR/lD21TudN/wALM8e/9Dbdf+AVp/8AGaP+FmePf+htuv8AwCtP/jNczRR9Vo/yh7ap3Om/4WZ49/6G26/8ArT/AOM0f8LM8e/9Dbdf+AVp/wDGa5mij6rR/lD21TudN/wszx7/ANDbdf8AgFaf/GaP+FmePf8Aobbr/wAArT/4zXM0UfVaP8oe2qdzpv8AhZnj3/obbr/wCtP/AIzR/wALM8e/9Dbdf+AVp/8AGa5mij6rR/lD21TudN/wszx7/wBDbdf+AVp/8Zo/4WZ49/6G26/8ArT/AOM1zNFH1Wj/ACh7ap3Om/4WZ49/6G26/wDAK0/+M0f8LM8e/wDQ23X/AIBWn/xmuZoo+q0f5Q9tU7nTf8LM8e/9Dbdf+AVp/wDGaP8AhZnj3/obbr/wCtP/AIzXM0UfVaP8oe2qdzpv+FmePf8Aobbr/wAArT/4zR/wszx7/wBDbdf+AVp/8ZrmaKPqtH+UPbVO503/AAszx7/0Nt1/4BWn/wAZo/4WZ49/6G26/wDAK0/+M1zNFH1Wj/KHtqnc6b/hZnj3/obbr/wCtP8A4zR/wszx7/0Nt1/4BWn/AMZrmaKPqtH+UPbVO503/CzPHv8A0Nt1/wCAVp/8Zo/4WZ49/wChtuv/AACtP/jNczRR9Vo/yh7ap3Om/wCFmePf+htuv/AK0/8AjNH/AAszx7/0Nt1/4BWn/wAZrmT0Ncp4b8R3F3qDWmoyhzIP3TbQMEduBWUqeHjNQcdy4yqyi5J7HqP/AAszx7/0Nt1/4BWn/wAZo/4WZ49/6G26/wDAK0/+M157Y6jdTeLL2zklzbxJlE2jg/L3xnuauXWu6bZ3HkXF2qyd1AJx9cDiiNPDOPM0l6g5VU7XO2/4WZ49/wChtuv/AACtP/jNH/CzPHv/AENt1/4BWn/xmuRnv7a2svtcswEGAfMUFgc9OlEt/bQ2AvZJNtuVDb9p6Hpx171boYdXuloT7Sr3Ou/4WZ49/wChtuv/AACtP/jNH/CzPHv/AENt1/4BWn/xmuNl1exht4J5Z9sVwR5bFT82fw4/Gkg1nT7mOaSG5Vkg/wBYxBAX8TS9jhr2sg9pVtfU7P8A4WZ49/6G26/8ArT/AOM0f8LM8e/9Dbdf+AVp/wDGa4m117TLy4ENvdq0h6KVK5+mRzVS71C6i8W2dkkuLeSLc6bRyfm74z2FS6eGsmknd20KUqut2eg/8LM8e/8AQ23X/gFaf/GaP+FmePf+htuv/AK0/wDjNczXKWniO4j8TTWl7KGtjK0aZUDYc8cgfhzROnh6coxlHcIyqyTaex6j/wALM8e/9Dbdf+AVp/8AGaP+FmePf+htuv8AwCtP/jNeezajdJ4xgsVlxbPHuZNo5OG74z2FX73WbDTpAl5crG5524LH8gOKFTwzTbSVnbUHKqmlc7JfiV48UYXxZdAZJ/48rTvz/wA8aX/hZnj3/obbr/wCtP8A4zXFXesWttpTXySrJHjEZGSGbsOOlZ+l+J7abT2m1CYJKrEuqxsQoJwOgocMKpcrS7gpVmro9F/4WZ49/wChtuv/AACtP/jNH/CzPHv/AENt1/4BWn/xmuOutUs7K1juLmYJFJjY20nORnsKLnVLO0tY7m4nCxS42MFJ3ZGRwBVuhh1e6WhPtKr6s7H/AIWZ49/6G26/8ArT/wCM0f8ACzPHv/Q23X/gFaf/ABmuNvNWsdPCm8uFiLDIUgliPoOaks7+11CIyWcyyqOuOo+o6ij2GHb5bK4e0q2vc67/AIWZ49/6G26/8ArT/wCM0f8ACzPHv/Q23X/gFaf/ABmuGbxHpSZ3XYBDlCNjZz9MfrVXT9TuZvEt/bTTZt4VyilQNvTvjNZ8mF5kkk7lc1azbZ6H/wALM8e/9Dbdf+AVp/8AGaP+FmePf+htuv8AwCtP/jNcba6tZXkUslvOGjh++5Uqo/EjFQw+IdKuLgQxXil2OACrAE/UjFX7LDaaLUXPW8zuP+FmePf+htuv/AK0/wDjNH/CzPHv/Q23X/gFaf8AxmuZoq/qtH+Un21TudN/wszx7/0Nt1/4BWn/AMZo/wCFmePf+htuv/AK0/8AjNczRR9Vo/yh7ap3Om/4WZ49/wChtuv/AACtP/jNI3xK8eMMN4suiMg/8eVp25/541zVFH1Wj/KHtqnc6b/hZnj3/obbr/wCtP8A4zR/wszx7/0Nt1/4BWn/AMZrmaKPqtH+UPbVO503/CzPHv8A0Nt1/wCAVp/8Zo/4WZ49/wChtuv/AACtP/jNczRR9Vo/yh7ap3Om/wCFmePf+htuv/AK0/8AjNH/AAszx7/0Nt1/4BWn/wAZrmaKPqtH+UPbVO503/CzPHv/AENt1/4BWn/xmj/hZnj3/obbr/wCtP8A4zXM0UfVaP8AKHtqnc6b/hZnj3/obbr/AMArT/4zR/wszx7/ANDbdf8AgFaf/Ga5mij6rR/lD21TudN/wszx7/0Nt1/4BWn/AMZo/wCFmePf+htuv/AK0/8AjNczRR9Vo/yh7ap3Om/4WZ49/wChtuv/AACtP/jNH/CzPHv/AENt1/4BWn/xmuZoo+q0f5Q9tU7nTf8ACzPHv/Q23X/gFaf/ABmk/wCFlePAxb/hLLrJABP2K0/+M+9c1RR9Vo/yh7ap3Om/4WZ49/6G26/8ArT/AOM0f8LM8e/9Dbdf+AVp/wDGa5mij6rR/lD21TudN/wszx7/ANDbdf8AgFaf/GaP+FmePf8Aobbr/wAArT/4zXM0UfVaP8oe2qdzpv8AhZnj3/obbr/wCtP/AIzR/wALM8e/9Dbdf+AVp/8AGa5mij6rR/lD21TudN/wszx7/wBDbdf+AVp/8Zo/4WZ49/6G26/8ArT/AOM1zNFH1Wj/ACh7ap3Om/4WZ49/6G26/wDAK0/+M0f8LM8e/wDQ23X/AIBWn/xmuZoo+q0f5Q9tU7nTf8LM8e/9Dbdf+AVp/wDGaP8AhZnj3/obbr/wCtP/AIzXM0UfVaP8oe2qdzpv+FmePf8Aobbr/wAArT/4zR/wszx7/wBDbdf+AVp/8ZrmaKPqtH+UPbVO503/AAszx7/0Nt1/4BWn/wAZr6B8E3V3qvw/8PahfXTyXN3pdtPM4VBudolZjgLgck9K+WK+o/hx/wAks8Kf9gWz/wDRCV5uOpQp8vIrb/odWHnKV7s+XKKKK9s4AooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAA/dP0rz6w01rrQp7u2GLq1n3qV6kYBI/rXoJ5qjpekwaTDJFbNI6yNuPmEHnHsBXJWoOrNdrP7+htTqckX8jmvDl4994ivLrbiR7cnA9flH86raLaXF7aXbrHpsh3HzWvA29eOoI6DrzXVWGg2mnX8t3bGQNICChI2qCc8DHtVa88J6beXTTt5sTMcssbAAn8Qa5/q1TljfV6/izX2sLu3kZU1s9p4GuInuILhRKCrwSb1A3DjP1zVrU54/8AhA4gXXLxRqoz1IIz/I1uf2Zaf2abAQgW23bs/rn1z3rKXwbpio4JnYsMBi4yv04/nVzo1EnGK3SX3ExqRum+juZOsqG8L6Mp6HA/StjWl0zS9FEclkrxyOAIozs3sB1JFWrjQbW5sbW1kkmCWuNhVhk49eKs6jptvqdp9nulJXOQVOCp9RVOjO02kru35E+0j7t+lzk9Va9bUNKa9tobVRIBFHG2WABXr2rSv/8AkfLD/rj/APFVabwvZuYmkuLt5YmBWV5dzADoORjH4Vdl0qCbVodRZ5BNCu1VBG0jnrx70o0Zp3f8yY3Uja3k0Xa4eLSxqt9rcagedHKWiPvubj8a7iqNlpMFheXNzC8jPctucMRgck8ce9a1qPtZRvtr+RFOpyJ230OT0a9lvvFVk1wCJY4jG5PUkK3NPsoLm917UdsVjNMHOVvVY4GT90D8P0rpU0G0j1n+04zIsxJJUEbSSME4xn9ai1Lw1YancefL5kch+80TAbvrkGub6vU5VfVpv53NvawvppojKsdO+z6HqqyzWdzGUZ1WB94jYKfUcdvyp+i6dFeeDpFWJBNKrjftG4kHIyfqBW9a6XaWdg1nDF+5cEOCclsjByaraXoFppNxJNatKWddpDsCAM59K1WHakk1py2IdVNPve5ykbya5Dp+mAkNbxvvPuOn6AD8alsp21ifSNPO7FrlpfwPH6AD8a6ix0K00/UJryAyGSXOQxBC5OeOKWx0O00++mu4DIZJs5DEELk544rKGGqXTl13+WxUqsbNL5fqYljDb3vjDUBqapJIpxFHJyCPoevGKdaJFa+Onh08BYmjPmon3VOP8cVr6n4esdVkEs6ukuMGSM4JHv2qTTNGs9JRhaoSzfekc5Y1pChNSimlo279WTKpFpvutjC8MWVvcX+oy3EKSskuF3qDt5PIz3rN1GK9n1/VIrEE5BMuO6jBxXYadpMGmPO0DyMZ23NvIODz0wPei30mC21Se+RpDLOMMGI2j6ce1R9Vbpwg9LXuP2yUpSMqAWd/4L8qGWK0QqFZnbAVwQeSfU/zrIuTqFnYQx6rZQ3thGR5ciPjjHGGU/zFdRBoNnALpF3tDdHLwsRtH04yPzqBfC9n8qST3csCHK27zZjH4U50akrO1nZemnl+QRqQjfsasEizW0ciZCugYZ64IqSgAKoCjAAwAO1FeicwUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABX1H8OP+SWeFP+wLZ/+iEr5cr6j+HH/JLPCn/YFs//AEQleRmX2fn+h24XqeZ/8Kx8Kf8APldf+DK5/wDjlH/CsfCn/Pldf+DK5/8AjldbRTEcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW0UAcl/wrHwp/z5XX/gyuf/jlH/CsfCn/AD5XX/gyuf8A45XW15fp+rai/wC0ZqemvqF01glkGS1MzGJT5cZyEzgHJPbvUuVpKPcpK6b7f5nR/wDCsfCn/Pldf+DK5/8AjlH/AArHwp/z5XX/AIMrn/45XW15/rvxn8KaDrT6bK13dyxNslktYlZI2BwQSWGce2aHKMd2CTexp/8ACsfCn/Pldf8Agyuf/jlH/CsfCn/Pldf+DK5/+OVoyeMdCj8JnxL9vRtL2bhMoOTzjbjruzxjrmsPTvixol7q1nYXdhq2lNf4+yS6haeXHPngbSCcg5HPTnrRzJS5eorO1y3/AMKx8Kf8+V1/4Mrn/wCOUf8ACsfCn/Pldf8Agyuf/jlQeJvinoHhPXJdK1aO8E0duJ90casr56KPmzu/DHvUVx8WtAs9N0a/vYL+3ttY3mF5IlHlqjAFnG7pzkYzkVPtIdx8suxc/wCFY+FP+fK6/wDBlc//AByj/hWPhT/nyuv/AAZXP/xys3RfjN4V1zxBHpNs15DJM/lwzTwhY5WJwACGJGe2QKbr2o+V8atBsv7Z1ODzbUt9giTNtN/rPmc+YMHj+4eg59Gpp2t1dg5Xrfoan/CsfCn/AD5XX/gyuf8A45R/wrHwp/z5XX/gyuf/AI5VXWfiz4b0DXdQ0rVPtcVxYorMREGWUkAhUw2c4PcAcdateDfiRoPjeaaDSTcQ3MK72gukCsVzjcMEgjJHfvRGcZOyYOLW4f8ACsfCn/Pldf8Agyuf/jlH/CsfCn/Pldf+DK5/+OVQ1/4xeFvD2utpVzJdXE0b7J3tog6Qt3DEsMkd9oOMEdeK1vDXj3R/FurahY6N50n2EKzTsq+XIG6FSCT27gURnGTsmDi47kH/AArHwp/z5XX/AIMrn/45R/wrHwp/z5XX/gyuf/jlb2t6vBoGh3eq3iSPBaRmR1iALED0BIGfxrldA+Lfh7xJrttpWmQ37TTxGUu8ShIQFLEOd3GAO2RzjNPminy31Cztcuf8Kx8Kf8+V1/4Mrn/45R/wrHwp/wA+V1/4Mrn/AOOVmT/GTw9D5kyWOsT6dHN5L6nDZ5tg3+/uz+may/it8TH0PQrGHw1cMLnU4xPFdrGGQQEHkZOQ2cdvXvUSqxUeYag27HT/APCsfCn/AD5XX/gyuf8A45R/wrHwp/z5XX/gyuf/AI5VTTvihoDeA08RXstxb26P9m2zIDLLKqjIUAnOfr9cU7wn8V/Dfi/Uv7PsWubW7YExw3caqZcDJ2lWIJ9s5rTmjzcqZNna5Z/4Vj4U/wCfK6/8GVz/APHKP+FY+FP+fK6/8GVz/wDHK62imI5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyj/hWPhT/AJ8rr/wZXP8A8crraKAOS/4Vj4U/58rr/wAGVz/8co/4Vj4U/wCfK6/8GVz/APHK62igDkv+FY+FP+fK6/8ABlc//HKP+FY+FP8Anyuv/Blc/wDxyutooA5L/hWPhT/nyuv/AAZXP/xyvSPhzCp+FvhUkvzo1n0kb/ninvWJW/8ADj/klnhT/sC2f/ohK48T0N6XUwKKKK7DAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8aj1Kx0r9pbVrjVL23soPsSr5txKsa5MceBliBmvZa5XWvhr4S8Q6tLqWsaT9ou5tu+T7TKmcAAcKwHQDtWU4yclKPQuLSTT6/5mgnirQNRY2mma/plxdyqViihvY2dmx2AOTXg3gEyW+k63aXfje08NSCZlvLS70+GZpwBg8uQWOdw2DOPxr2bSvhf4P0TVINR0vSPIu7dt0Un2mZtpxjozkHg9xU2sfDjwlr+pnUNV0aKa6Y5aRZHj3n1YKwBP1qJU5Sd36dSlJLQ8zW/wBJ8D/Bzdp72vi20vdSItmvtPaKFH28ko+SwGw88ck88Vm+Nk19PE3g9vE2r6fdyyXKPDZ2EQVLZC8eDu6sD2zx8vFe43vhvRtQ0IaLd6bbvpwUKtsE2qmOm3GNp9xg1iR/CrwVFbxxRaFEgilEySLNIJAw6fPu3Y9s49qbpy5r9Lr8Bcy5fv8AxOP1S3iuP2ndNE8ayBLMOoYdGCOQfwNO+MVtHeeNvA9tcIrxTXhR1YZDAyRAgjuK9Gfwto8niiPxE9nnVY4/LS481+FwRjbnb0J7UureGNI1zULC+1S08+506TzbV/NdfLbIOcKQDyo656U1TaSXZ3/EObVvyt+B5r8ZbeGPxV4JeOJEb7YUyox8oeLA+gyas+J/+TjvC/8A15H/ANrV6BrXhbR/EN1Y3GsWf2iWwk8y2bzXTy2yDn5SM8qOuelLdeGNIvfElrr1zab9TtE8uCfzXGxeeNoO0/ePUd6Iwaaf96/4A5Lla8rfieb6LaQ3P7TGuPPGkht7MSR7lztbbEMj0OCeaTSIkh/ad1dYUVA1luIAxkmOMk/nXpNv4Y0i08S3PiC3tNmqXUflTT+a53L8vG0naPur0Haki8LaPD4ol8RR2e3VZo/LkuPNflcAY2529FHbtRGm0oeV/wAbhKSfN52/Cx5R8JdY0TQb/wAT2/ia8tLLUjdsJHu2Ee9QSGUFv9rPHuKm+C01jceO/F82kIEsJHDW6hcAIZH24HYY7dqqeKIdWHjW6uvEfwxi17a3+jXWmidBIoPytJtLqxxgYZQfwrpfhL4a1ix1LXdf1vT/AOzDqsoaGz6FF3Mx47D5gADg8dOlZUL80fJNfhYqra0vNpnTfEn/AJJpr3/Xm9c/8Pbi00P4Ex6i9os0cdrPcTRAf64hmyD16gAfSu+1LTbXV9Mn0/UYvOtbhCkse4ruU9sggj8Ki0zRNO0fRY9J0+2WOwjVkWBmLjaSSQSxJOcnrWzg7ya6q35kcytFPo7ng2s6hrutfCO51Q3GiaLoMkuyHSbC2VWlYSjg5+6eN3HJA6AGtHx3/wAm6+F/+ukH/oqSvR4/hT4Ije4ZfD9uTcKVfc7sAD/dBb5D7rgjtWtJ4Q0Kbwunh2bT1l0qMYSCSR2285GGJ3A89c1k6UnFrvb8C1USkn6/ieRfFm9t9Rt/B99ZalA+mQuYprqALcxwyfuz8yg4YgAnaeuMVc/s+y1f4gaDPffEu11nVIJVe2jtNJU71DbijPE2F6H73QZNemWvgfw3Z+HZdCh0qL+zJXMj28jM4LcfNliSDwOc8U3w/wCA/DPhe5e40PSYradxgyl3kcD0Bckj8K15H7Tm87/1/WxHMuTl8rHQ0UUVqQFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFb/wAOP+SWeFP+wLZ/+iErArf+HH/JLPCn/YFs/wD0QlceJ6G9LqYP/CA+Dv8AoU9D/wDBbD/8TR/wgPg7/oU9D/8ABbD/APE10FFFkUc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAc//wAID4O/6FPQ/wDwWw//ABNH/CA+Dv8AoU9D/wDBbD/8TXQUUWQHP/8ACA+Dv+hT0P8A8FsP/wATR/wgPg7/AKFPQ/8AwWw//E10FFFkBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRRZAcH4R8EeFLnRLh7nwxo0zjVNQjDSafExCreTKq5K9AoAA7AAVuf8ID4O/6FPQ//AAWw/wDxNHgr/kA3P/YX1L/0unroKSSsBz//AAgPg7/oU9D/APBbD/8AE0f8ID4O/wChT0P/AMFsP/xNdBRTsgOf/wCEB8Hf9Cnof/gth/8AiaP+EB8Hf9Cnof8A4LYf/ia6CiiyA5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+JroKKLIDn/8AhAfB3/Qp6H/4LYf/AImj/hAfB3/Qp6H/AOC2H/4mugri/irrF7pXgvyNJuDbX2qXcOnwTL1jMrYJHvtDdOR1FS9Og1qan/CA+Dv+hT0P/wAFsP8A8TR/wgPg7/oU9D/8FsP/AMTXnvinwRpnwv0q08WeE5bu1u7G6hF+z3LyC+idwr+YGOM/NnjA68dCPYQdygjoRmmrNC1MD/hAfB3/AEKeh/8Agth/+Jo/4QHwd/0Keh/+C2H/AOJriIPDmn/FHxx4kn8Uma80vR7kafY2SzvHGjquZJDtIy2T1z7HtWr8N57vS77xP4TmuZr9dCuVNm875fyZU3ohY9cYIz/+oKLTV2ul/l/TG1bbvb+vyOi/4QHwd/0Keh/+C2H/AOJrD8XeCPCltolu9t4Y0aFzqmnxlo9PiUlWvIVZchehUkEdwSK563/4SiX42+GLzxY9vbm5tLw2+mWzb1s1CDq/8bnIyQMcDFd741/5ANt/2F9N/wDS6CjeN/63sK+tg/4QHwd/0Keh/wDgth/+Jo/4QHwd/wBCnof/AILYf/ia6CiqsgOf/wCEB8Hf9Cnof/gth/8AiaP+EB8Hf9Cnof8A4LYf/ia6CiiyA5//AIQHwd/0Keh/+C2H/wCJo/4QHwd/0Keh/wDgth/+JroKKLIDn/8AhAfB3/Qp6H/4LYf/AImj/hAfB3/Qp6H/AOC2H/4mugoosgOf/wCEB8Hf9Cnof/gth/8AiaP+EB8Hf9Cnof8A4LYf/ia6CvMNb0uD4h/Fa88P61JNJoWh2MUsllHK0az3EpyC5XBICjgZ69OpqXukuv8Aw4+jb/rodf8A8ID4O/6FPQ//AAWw/wDxNH/CA+Dv+hT0P/wWw/8AxNcv4Ktj4P8AiTqvgy0uJpdIexj1GwhmkLm2G7Y6KSc7c4IH/wBcnpvH2vS+GPAOr6vbMFnt7c+SSM4kYhVOD15IobShz/1/VwSblyjv+EB8Hf8AQp6H/wCC2H/4mj/hAfB3/Qp6H/4LYf8A4mvONV+GVr4f+Hz+KtOvL6PxbZWov5dTa6dmndQHdGUnBU4Ixj0znnKfFDX9L1yx8B2+twTT6dqr/b7i2tkZ5JQIhtjUIc5ZpMcH8aJaO1tbpff/AMM/uEtVdbWb+7+kekf8ID4O/wChT0P/AMFsP/xNYdp4I8KN8QNWt28MaMYI9LsZEiOnxbVZpboMwG3AJCqCe+0elZPwyg+H0HiS7TwzoGoeH9djtystnqnnJMYSVO4K7sMZA967Kz/5KVrP/YI0/wD9HXlOysmF9w/4QHwd/wBCnof/AILYf/iaP+EB8Hf9Cnof/gth/wDia6CinZAc/wD8ID4O/wChT0P/AMFsP/xNH/CA+Dv+hT0P/wAFsP8A8TXQUUWQHP8A/CA+Dv8AoU9D/wDBbD/8TR/wgPg7/oU9D/8ABbD/APE10FFFkBz/APwgPg7/AKFPQ/8AwWw//E0f8ID4O/6FPQ//AAWw/wDxNdBRRZAc/wD8ID4O/wChT0P/AMFsP/xNH/CA+Dv+hT0P/wAFsP8A8TXQUUWQHP8A/CA+Dv8AoU9D/wDBbD/8TR/wgPg7/oU9D/8ABbD/APE1g/E65ubyfw94Vs7yWzGvXxjuZYG2yfZ413SBT2J4Gf6E1iXvhjT/AIW+LvDV74UM9np+qXo06/smneSOUup2SYdjhgR1/wDr5lWb262+en+dhvRfK/y/pHc/8ID4O/6FPQ//AAWw/wDxNH/CA+Dv+hT0P/wWw/8AxNdBXkHxjPiq60m4aQ2+neH7S8tlVEfzJtQLSJy2OERSenJJX6Yel0rbi6N9jv8A/hAfB3/Qp6H/AOC2H/4mtr4cwQn4W+FSYkJOjWeSVH/PFKmpvw4/5JZ4U/7Atn/6ISsqnQqI6iuf/wCE+8Hf9DZof/gyh/8AiqP+E+8Hf9DZof8A4Mof/iq2uiToKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+KougOgorn/+E+8Hf9DZof8A4Mof/iqP+E+8Hf8AQ2aH/wCDKH/4qi6A6Ciuf/4T7wd/0Nmh/wDgyh/+Ko/4T7wd/wBDZof/AIMof/iqLoA8Ff8AIBuf+wvqX/pdPXQVwfhHxv4UttEuEufE2jQudU1CQLJqESkq15Mytgt0KkEHuCDW5/wn3g7/AKGzQ/8AwZQ//FUk1YDoKK5//hPvB3/Q2aH/AODKH/4qj/hPvB3/AENmh/8Agyh/+Kp3QHQUVz//AAn3g7/obND/APBlD/8AFUf8J94O/wChs0P/AMGUP/xVF0B0FFc//wAJ94O/6GzQ/wDwZQ//ABVH/CfeDv8AobND/wDBlD/8VRdAdBXBfGG0lfwTDqdvE8zaLqFvqLRp1KRt835KSfwrd/4T7wd/0Nmh/wDgyh/+KpD4+8GkEHxXoZB6g6jD/wDFVL12/qw15nD/ABH8W6D4z8KWXhzw1qVvqd9rl3AkcNs4dokDh2dwDlMBehwfyOPT21CxgvodOkvLdLyVC0Vs0qiSRR1IXOSB6iuXsNc+GelXUlzpeqeE7K4l/wBZLbXFtG79+SpBNV73xD4NvPGGmay3inw2osIJVV/t8Pmuz4AG7dwgG447kj0pp2+b/T/gCd38jH8M65pXgnx94v0bxFfQaZ9svRqdpLdyCNJkkX5trNgZDDGM/Toau/DOVNb8TeL/ABXaK32DU7yOC0lZSPOSFNpcZ7Ek1rap4i+G+toi61rHhbUFjOUF3dW8oU+24nFXIfHHgm3hSG38UaBFEg2oiahCqqPQANxSjpv0Vvy/yHLX5u/9fPUxPEP/ACXDwd/15X3/AKCtb3jX/kA23/YX03/0ugqvJ4v8BTX0N7L4h8OSXVurLDO17AZIw33grbsgHvjrWX4u8b+FLnRLdLbxNo0zjVNPkKx6hExCreQszYDdAoJJ7AE0aKNvX82xfav/AFskd5RXP/8ACfeDv+hs0P8A8GUP/wAVR/wn3g7/AKGzQ/8AwZQ//FVV0B0FFc//AMJ94O/6GzQ//BlD/wDFUf8ACfeDv+hs0P8A8GUP/wAVRdAdBRXP/wDCfeDv+hs0P/wZQ/8AxVH/AAn3g7/obND/APBlD/8AFUXQHQUVz/8Awn3g7/obND/8GUP/AMVR/wAJ94O/6GzQ/wDwZQ//ABVF0B0FeZSapYeDPjhqc+u3MdhZeINPheC6uH2RebD8rIWPAO0g8nHT1Fdb/wAJ94O/6GzQ/wDwZQ//ABVVNR8U/D7WLX7Nq2u+Gb6DO7yrq8t5Fz64YkVL3TQ+jX9dzB8L3tt4r+M2s+IdIkFxpun6bHpq3acxzSl/Mba3cDgZ/wDrZ1vH8Fv4y+FuvWuhXMOoN5TBfssokBljIfZ8ufmyoGPerdl4w8B6baJa6d4i8O2lvGMJDBfQIi/QBsCs3wv4h8G6BYXUX/CU+G43uryW6aO2v4VjTeeFA3dlAye5ye9Jq8eS/R/fe/6sabUufzX5f8BHP+IfiX4e1b4PSQ6fqENzqup2Is4tNjcNcedIoQqU6jBJ5xg44zkVqSavpXgS+8IaZ4k0y1hjXTxbQ67MV/0aVUAMWSpKhh33Afqa1Itb+GcGqtqcGp+E479iS12lxbCUk9cuDn9atXvjDwHqVm9pqPiLw5d20nDwz30Do31Utg1Tbbcur/4P+bJSVlHov+B/kcvJqth4u+OGgzeF7mO+i0WzuG1C8tzviCyLtSPeOCc5OAfX0OOws/8AkpWs/wDYI0//ANHXlVNO8VfD7R7X7NpOu+GrG33FvKtry3jTJ6nCkDNZ1p438KL8QNWuG8TaMIJNLsY0lOoRbWZZbosoO7BIDKSO24etGiSX9dw1bbO8orn/APhPvB3/AENmh/8Agyh/+Ko/4T7wd/0Nmh/+DKH/AOKp3QHQUVz/APwn3g7/AKGzQ/8AwZQ//FUf8J94O/6GzQ//AAZQ/wDxVF0B0FFc/wD8J94O/wChs0P/AMGUP/xVH/CfeDv+hs0P/wAGUP8A8VRdAdBRXP8A/CfeDv8AobND/wDBlD/8VR/wn3g7/obND/8ABlD/APFUXQHQUVz/APwn3g7/AKGzQ/8AwZQ//FUf8J94O/6GzQ//AAZQ/wDxVF0BzfxRddG1jwl4quFb7HpOoNHdyKCfKimXYXIHYED86o+LNe0nxr4w8IaJ4cvrfVHt9SXU7mS0kEqQRRA/eZTgEkgY/wARnr5fHPgqeF4p/FGgSRuNrI+oQkMPQgtzVLS/EPw30RXXRdX8K6eJDlxaXNtFu+u0jNStH5Xv+X6q43qvlb8/8zp01Kxk1KTT47y3a9iQSSWyyqZEU9GK5yB71xXxo/5JtN/1+2v/AKPSpIPEPg1PG11rzeKfDaGSzS1Ty7+ESPhtzM7bueigDnAB9a0r3xf4C1K2NvqPiHw5dwFgxinvYHUkHIOC2MgjNO97N9/yf+Qmt15fmv8AM6im/Dj/AJJZ4U/7Atn/AOiErB/4T7wd/wBDZof/AIMof/iq2vhzcQj4W+FQZUBGjWeQWH/PFKyqdCojLvUrGwkgjvry3tnuZBFAs0qoZXP8Kgn5j7Clvr+z0yzku9SuoLO2jxvmuJBGi5OBljwOSBXF/GKxlm+H8mp2gzdaLcxalCc4wY2+b/x0tVL4jXcXie18JeH7Zg8HiG+inlUMPnto181x+Py1pd7Le6X3/wBP7hWS18m/u/pHodrd299ax3VlPFcW8qho5YXDo49QRwRVUa/o7SIi6tYl3uDaqouUy0w6xjnlx/d61wPgDWI/C/gPxJp14cf8Ipd3UYViSTCMyRn8QSB9KoaaJfCXhn4fWd3p1jd3eq6kJLmS7g3yQSS5kZ0OflcZxnnpTTTattp/5NsS9E7+f4b/AKHrtV0v7OW+lsorqB7uFVeW3WQGSNT0JXqAexNcRqXi3xVrHivUNE8AafpbLpJVLy/1aR/KMjDPlosfzEgdT65HHGcbwRrV3P8AFPxfeeJLNdLurPTrZbyMSb412BiXVu6lcMO4zip51ddtfus3cpqy/ruj1iqep6xpmi26z6zqNpp8LNsWS6nWJS2M4BYgZ4PFefW3i74i61pf/CR6DoGjjRWBlgsrueQXtzEOjAj5FLDkA/rxnI+JniXR9f8AAvgzxBcoBpM+tW81xHPHv2xgP5isoB3YwwIwc03L5arfzYJa/f8AgejR+OvCM0ixxeKdFd2OFVdRiJP4bq3q8Wv/ABZ8ELzT57a00rTryeWMpHb2WiPHNIxHCowjXDHscit7w7rOo+APgjpc3iC0muNTVRBbWBbEjs8hEMRJ6EKR9AMY4xTUlZ/1uK2qX9evoel0V5tceLvHXhY2+peN9K0U6JNKkUzaXLIZrLeQFZ9/DgEgHb9asa34x8SXnjq58LeCYNFW5sbdJ7ibWJZAJN4yFjROTgYJbkduO5zf1+IW/r8Dvbi4htLaS4u5o4IIlLySysFVFHJJJ4A96baXltf2kd1Y3EVzbyjdHNC4dHHqGHBrgtR1vV9Z+EnioeI9HfStRtLW5t5Uw3lTYjOJImI+ZDn36Vy/wq1G68DSaNoGsTNJo/iKzjvNKuX6RTsgaSAntknI+o7k0J3lb0/G/wDl+gNWjf1/C3+Z7FFqFlPfT2UF5BJd2wUzwJKpkiDDK7lByuR0z1qzXm/h24is/jN8QLm5cRww21lJI56KohJJ/Korbxd8Rda0v/hI9B0DRxorAywWV3PIL25iHRgR8ilhyAf14yuZcqb7XG4629PyTPR7m7t7KES3k8cEZYKHlcKCScAZPcmpq8W+Juv6l4o8E+FdZ8OixXTbzULdwl2H85LjeQinbxsBDBu/HFevaX/aH9lW39tfZv7Q8sfaPsm7yt/fZu5x9aavrfo7E9vNFuiiimAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBB8O/+RTl/7C+p/wDpfPXU1y3w7/5FOX/sL6n/AOl89dTXK9zYKKKKQBRRRQAUUUUAYmo+NPC2kXz2WreJdHsbuPG+C5v4o5FyMjKswIyCDWjYanYarYJfaXe217aSZ2XFtKskbYODhlJBwQR+FfPmlXsus+LPGmrxfC+PxsTrEkZurowKkMMQCKsXmKxdsDJVR/d9a6Txb4n0jWfgjp9t4Kg/sa01zU4tIa2ghWBrUvIfOjKLgKcBs+ob3oV3FPq7fj/w43ZSa6K/4f1seq6d4n0HWLyW00jW9Ov7mHPmQ2t3HK6c45VSSOa1K8b+KHgzw74F8G2PijwrpVtpOoeH7y3kjntUCPLGXCOkjAZcFW5LZP5nPsatuQMO4zT0tdd7fl/mTqnqMuLiG0tpbm7mjgghQvJLIwVUUDJYk8AAd6WGaK4gjmt5ElikUOkiMGV1IyCCOoI715d8bNC1/WPCOtynWlsfD9lpr3BtLVCJ7uZQTtkc8CMYXgcnnPau58J7/wDhAdE8rb5n9mQbd3TPlLjPtSWzfa36/wCQ3ul3v+n+ZqS31pBeQWk11DHc3IYwQPIA8oUZbavU4BGcdM1hePP+Rdtf+w1pX/pwt685ttC1zTPj94Tv/FWtDU9Tv7K+MkcCbLa1VUG2OJTzj5jknk8V6N48/wCRdtf+w1pX/pwt6Psp/wBbtfoK+rXb/JP9TpKKKKBhRRRQAUUUUAFR3FxDaW0tzdzRwQQoXklkYKqKBksSeAAO9SVwHxx1RtK+DeuvESJLmJbVAo5PmOEIH/ASamTaWhUVd2Zv2/j7wdeXUVtaeLNDnnmcJHFFqULM7E4CgBskk9q1NT1jTNEtPtWs6jaafb7gvnXc6xJk9BuYgZrxnR9S0Twxd6K/if4QW/h/TpHhhs9clhtpZUl42PMqruiYkZyTkGtyXStP8dfH3VrXxDbR6jp/hrTYEt7K5TfCJp/naQoeCdoA5BHT0FaNapLz/BX/AK9UQndNvy/F2PTrHULPVLNLvTLuC8tpBlJreUSI30YEg0X1/Z6XZSXmpXcFnaxDMk9xII0QZxkseBzXmnhKwtPB3x01zw1okYtdK1LSo9VSzj4jhlEnltsXGFBGDj+gGPS76ws9UspLPUrSC8tZRiSC4jEiOM5wVOQeal/Cmuv/AAw9pWf9dTD/AOFj+CP+hy8P/wDg0g/+KrZfVtOj0kapJqFqmnGMSi8aZRCUPRt+cYORznFePeOvB/hjXfHWj+AvD/hnSLIyr/aGr3lpYRRyQWqtwiuq5VnYY9cY7E1F8Q73w4nxU0Tw34ht3l0DRtLFza6JaQNJ9suWfy4o1iX7+1VOB0HOeCaFql5v8t/ysvMez9P12/zfkex6Vrmk67btPomp2epQo21pLO4SVVPoSpIzWTY/8lT13/sC6b/6Pvq4n4fy+Br74iXF14e0rVPCOuR2Xl3Gh3VotktxETkSmEAgkHuCD6iu2sf+Sp67/wBgXTf/AEffU+iZK3Z0lFFFIYUUUUAFFFFABRRXFfELxJf2a2Xhnwuy/wDCRa4xjt3IyLOEf6y4b2UdPVsdcEUvJDXmdZZ6jZaisx0+8t7oQStDKYJVfy5F+8jYPDDuDyKpzeKvD1vqw0qfXtMi1EkKLN7yMTEnoNhOf0rzr4K6NLYeBfFWi6dfyRTQa3e2sF7KokdWCqqyEcbiDg44zUXiH4ZeBfB3wb1FdfsrO6ubezkaTV5YFW6nuCDhlcksGLkYXcR255ok1Fc3kn96uEVzPl82vuZ6/VbUNSsdJs3u9UvLeytk+/NcyrGi/VmIArE+HaanF8NvD6a6XOoLYRCbzM787eN2ed2MZz3zVTxH8PrTxZ4z0zVtfnS90vTYHWPR5oN0TzMf9axJw2F42lT65q5LllykxfNHmOj0vWdM1u1+06LqNpqFvnb5tpOsqZ9MqSKnubmCytZbm8njt7eFC8ksrhURQMkkngAeteUaJpOl6T+0bPbeCrWGzsotG/4nUFmoSBJS/wC6G1flV8c444z6mqfxe1O88ZWXiHw5os7Q6RoNhJd6zdx/8tZwhaK1U9OoDP8AQDg1nKVoqS8/wv8A5FxjeXK/L8bf5nskFxDdW8dxaypNDKoeOSNgyupGQQRwQR3rn/hx/wAks8Kf9gWz/wDRCVL4E/5J34d/7Blt/wCilqL4cf8AJLPCn/YFs/8A0QlaTjyycexnCXNFMh1Cyi1LTbmxuBuhuYXhcY6qwIP868Y+Ei3mseNwmpRuv/CHaadJG/vMZXG4f8AQD2r0/wD4TXS/+fXXP/BBff8Axmj/AITXS/8An11z/wAEF9/8ZrdWUub+uq/VkPWNv6/rRHmvjrTJ0+LDaJbxubXxpFarcFO32eTMn0Hlj9a6b4lKE8SeAVUAKuuIAB2G010n/Ca6X/z665/4IL7/AOM0f8Jrpf8Az665/wCCC+/+M0RSSS7O/wCN7BK8m/NW/C1ziLXxHZfDDxt4lh8Wia003WLz7fZaitu8kbllAeMlASGBHT0544zT0K5fxx448d+RazWUeo6LDBa/aV2O6MjqshXqoJORnnGDXof/AAmul/8APrrn/ggvv/jNH/Ca6X/z665/4IL7/wCM1PKmkm9tPwaK5mndev43PC9H074W6XoceneNfDF/B4qtl8qWxBuy93IOA0ZRtmG7dB6cc12HiDT49M8G/Dy2h0U6Ev8AwkVq/wDZxuGnMG5nbBduSecnPTOO1eif8Jrpf/Prrn/ggvv/AIzR/wAJrpf/AD665/4IL7/4zVre/mn9zuT6ef4qxnfETwe/iTRhe6OxtfEWm/v9Nu4+HDjnyyf7rdMHjnNcX4mvpPir8GbPULTT2u7zTb6OXUdLRiJGaPKyxjHIyGJGOcH14r0X/hNdL/59dc/8EF9/8Zo/4TXS/wDn11z/AMEF9/8AGalxWq+fz/rcpPZ/1b+tjxuOw+EeqyW1n4Q8H3ms6xNIqvYG4u4Pswz8zSuxKqF9s8/nXSfEeXwTP4oks/iRoc+mxpAn9n69bmVvOHdDsXhlOcBt3rxkZ9A/4TXS/wDn11z/AMEF9/8AGaP+E10v/n11z/wQX3/xmhpNWF1PMtAk1GT4YeO9l9qd/wCG1s3XRrnVQfOkTyW3kEgEpnbg4A64A5FdXbeE7fxn8D9D0yZvJnGmW0tpcj70Eyxja4P14PsTXRf8Jrpf/Prrn/ggvv8A4zR/wmul/wDPrrn/AIIL7/4zTsmmvT8L/wCYJtWt5/jb/I8q+Hi6z4o1z4hWOvxC21efT4bC4yeDIIni3/jgNxxzxWBo+nfC3S9Dj07xr4Yv4PFVsvlS2IN2Xu5BwGjKNsw3boPTjmvdP+E10v8A59dc/wDBBff/ABmj/hNdL/59dc/8EF9/8Zpcq/C3/DfeO/8AXyS/Q888Xaeuj/Bnw9JFoMui2tjqlveXFisr3JtI/MZmLMRuP3sn0JxXq2kavY69pFvqekzi4s7ld8UoUruGcdCAR07isz/hNdL/AOfXXP8AwQX3/wAZo/4TXS/+fXXP/BBff/Gaq6u/N3/T9CO39f1udBRXP/8ACa6X/wA+uuf+CC+/+M0f8Jrpf/Prrn/ggvv/AIzTuhnQUVz/APwmul/8+uuf+CC+/wDjNH/Ca6X/AM+uuf8Aggvv/jNF0B0FFc//AMJrpf8Az665/wCCC+/+M0f8Jrpf/Prrn/ggvv8A4zRdAdBRXP8A/Ca6X/z665/4IL7/AOM0f8Jrpf8Az665/wCCC+/+M0XQHQUVz/8Awmul/wDPrrn/AIIL7/4zR/wmul/8+uuf+CC+/wDjNF0B0FFc/wD8Jrpf/Prrn/ggvv8A4zR/wmul/wDPrrn/AIIL7/4zRdAdBRXP/wDCa6X/AM+uuf8Aggvv/jNH/Ca6X/z665/4IL7/AOM0XQHQUVz/APwmul/8+uuf+CC+/wDjNH/Ca6X/AM+uuf8Aggvv/jNF0B0FFc//AMJrpf8Az665/wCCC+/+M0f8Jrpf/Prrn/ggvv8A4zRdAdBRXP8A/Ca6X/z665/4IL7/AOM0f8Jrpf8Az665/wCCC+/+M0XQHQUVz/8Awmul/wDPrrn/AIIL7/4zR/wmul/8+uuf+CC+/wDjNF0B0FFc/wD8Jrpf/Prrn/ggvv8A4zR/wmul/wDPrrn/AIIL7/4zRdAdBRXP/wDCa6X/AM+uuf8Aggvv/jNH/Ca6X/z665/4IL7/AOM0XQHQUVz/APwmul/8+uuf+CC+/wDjNH/Ca6X/AM+uuf8Aggvv/jNF0B0FFc//AMJrpf8Az665/wCCC+/+M0f8Jrpf/Prrn/ggvv8A4zRdAdBRXP8A/Ca6X/z665/4IL7/AOM0f8Jrpf8Az665/wCCC+/+M0XQGz8O/wDkU5f+wvqf/pfPXU15v4D8aaXa+GJI5bXW2Y6pqL5i0G+kGGvZmHKwkZwRkdQcg4IIrpP+E80j/nz8Qf8AhOah/wDGK5XuanSUVzf/AAnmkf8APn4g/wDCc1D/AOMUf8J5pH/Pn4g/8JzUP/jFIDpKK5v/AITzSP8Anz8Qf+E5qH/xij/hPNI/58/EH/hOah/8YoA6Siub/wCE80j/AJ8/EH/hOah/8Yo/4TzSP+fPxB/4Tmof/GKAOOg+NNt4clv9K+JdtLpmt21w620VpZStHfxZ/dtCfmBJ6ckDPpyBzX/CGeIJPgzqGr/2VNHrEniE+JbbSmU+ZGokBEeByGKAnHXnGM8V6t/wnmkf8+fiD/wnNQ/+MUf8J5pH/Pn4g/8ACc1D/wCMULRX66fhZ/mkPd+X/Dr8mzzTxf4+0n4taPZ+DfB0V5d3uoXcB1FZLV4xp8KOHcyMy4z8uMDIznnoD61P4j0my8SWXh2e62apeQtNb2/lud6J947gNoxjoSKof8J5pH/Pn4g/8JzUP/jFZl14j0e88R2GqTR+ItthFKsVuPDN/jzHwC5Pk9lBAH+0afl6v8P+Au/+U6/16lr4q/8AJI/FH/YLn/8AQDWp4P8A+RG0L/sHW/8A6LWqn/CeaR/z5+IP/Cc1D/4xR/wnmkf8+fiD/wAJzUP/AIxSWl/O34X/AMxvVryv+Nv8jnfE3/JfvA//AF46h/6AldF48/5F21/7DWlf+nC3o/4TzSP+fPxB/wCE5qH/AMYrn/GnjTS7nQbZI7XXARq2muTJoF8gwt9Ax5aEDOAcDqTgAEkCj7KXr+bf6h1b7/5JfoeiUVzf/CeaR/z5+IP/AAnNQ/8AjFH/AAnmkf8APn4g/wDCc1D/AOMUAdJRXN/8J5pH/Pn4g/8ACc1D/wCMUf8ACeaR/wA+fiD/AMJzUP8A4xQB0lFc3/wnmkf8+fiD/wAJzUP/AIxR/wAJ5pH/AD5+IP8AwnNQ/wDjFAHSVzfjzVtf0LwtJqfhbTo9TuraVHmtGRneSHPz+WFIJfHI69DwaP8AhPNI/wCfPxB/4Tmof/GKP+E80j/nz8Qf+E5qH/xikxnmnjXx5pPxb8Pw+DvAsd5f3+oXEJupDaPGumxpIrM8jMAARjHBPPfOAdTXNXtvhj8YbzxFr0VxH4f17ToYpdQigeRYLmE7QHCgkAqeDjOenQ12/wDwnmkf8+fiD/wnNQ/+MUf8J5pH/Pn4g/8ACc1D/wCMU9rW7v8AFWFvv/WtzkvAl0fG3xT1jxzZ2s8Wipp8emadPPEYzdjf5jyKpGducAH+uQO98P8AiXSfFFjLeaFd/areGd7d38t0xIn3lwwB4z16Vn/8J5pH/Pn4g/8ACc1D/wCMVmaF4j0fRba5Vo/EVzPd3Ul1PKfDN+u53PQAQ8AKFUeyijy6Jfjf/hwffrf8Lf8ADGV8LANY8XeO/E8wzLPq7adEW5Kw26hQB6Ak5x7VT8bAeC/jFpvj7ULGe40WTTH068uIITK1k+4sshUc7SDtyB6+ortP+E80j/nz8Qf+E5qH/wAYo/4TzSP+fPxB/wCE5qH/AMYo1XLbp/lZ/ePR3v1/zuvu0OF07WrX4mfGbQde8JRzzaNoFrcLc6o0DwpO8q7VhXcAWx1Ixx+We6sf+Sp67/2BdN/9H31H/CeaR/z5+IP/AAnNQ/8AjFc/Z+NNLX4k6zcG11zZJpNggA0C+LgrNeE5TydwHzDBIweQCdpwdEl/WtxdbnolFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0lFc3/AMJ5pH/Pn4g/8JzUP/jFH/CeaR/z5+IP/Cc1D/4xQB0leZaj8MvFTePNW8TeH/iB/ZMupKkZjfRorkxRoOI1Z34GcngDJ65rqf8AhPNI/wCfPxB/4Tmof/GKP+E80j/nz8Qf+E5qH/xijrcOljzf4Q/2n4a07xnrfiHxL9q0qw1O9+1QfYUj3zIVZ7jcDkFgCPLHAzxWBpPxV8EeKtfTxH8RvESxrazM2l+H1s55IbTBwJZSsZWSXHTkhc8c9PZ/+E80j/nz8Qf+E5qH/wAYo/4TzSP+fPxB/wCE5qH/AMYoV00+yS/4P9bdAdtfNv8A4b+twl+IHhmHwlaeJpNT26PeSLHBc/Z5fnZmKgbdu4cg9RXF/F74pw+FdSsfC9rqsej3eoJ5t1qkkDzCygyRlUQEtIxBA4wMc4zmuh8QeI9H1/STp0kfiKGCWWNp9vhm/JkjVgxTmHjdjBPoTWn/AMJ5pH/Pn4g/8JzUP/jFJq/3/h/X/DArr+upyHw48W/DdoP+EV8Ba5JcandJJK9xNazefcS7SWmkd0UM3fkj0Fc1rPwv8YeD/hfrtva/EbzdMjtLm4uLQ6FCGuSyln3Sly+W6bskj8BXqn/CeaR/z5+IP/Cc1D/4xR/wnmkf8+fiD/wnNQ/+MUSXMn5qw4uzV+9yl8KrHVLH4baQusav/ajS2sUsDfZlh8iIxrtiwv3tv948mrvw4/5JZ4U/7Atn/wCiEo/4TzSP+fPxB/4Tmof/ABio/hzMo+FvhUEPxo1n0jb/AJ4p7Vcpc0myIx5YpFTXde03w1o82q63c/ZrKDb5kvls+3JAHCgnqR2rkB8cvh0WAHiLqe9lcD/2nTfjkcfCDVj/ALUH/o5KpX3xq0/ToIItS8HeK7c3JEMK3WmrGszkcKCz85/GtubcTWiZ6JpeqWOtabDqGk3UV3aTrujmibKt2/MHgjseKt15d4XN58Nvhfr+u67YJYmW7mv4NKjcbbYPtWOLI4HOOnTPTtWFP438RabpH/CRSfEbwvqE8aCebw5H5AUr1aNJQ5cuB09/XvTkk/u+VyUm1p5/M9upGYIpZuAoyTXlfi/4gXk2q+HrDStdtvC1jrFh9u/te8t1mHONsShjsBweSfUYPr0Xg+58Tvb6lb+Iru01iyRA+n61aeWi3akHcCiMdpB7gYNKUmk/K/4ArXXy/E3fDnijRvFunNfeHr5by3SQxMwRkKsOoKsAR1HapW17TV8SJoDXONTe2N2sHltzFu27t2NvXjGc14J8PWuPh94c0TxpCZJND1R5LXW4hk+SwmdY5wPQcA//AF69GklSX9ouzlidXjfwyWVlOQwM5wQaq+qXrf5Jv+vIGrc3l/nY9GqpqmqWWi6XPqOqXC21pbrullfOFH4V5InjvVPFdxe39h8RNA8J2UNw8VnZXCwSy3Cqcb5fMYFAxHGB0/M1fFviTUvHHwG1O/TULe0l06drbUo7RFmhvCrKBscnKqdysCMnt05rKU/ccl2v/X9XLUffUX3t/X9WPbYZUngSaI5SRQynGMgjIqlY65pup6lf2FhdLPc6c6x3SKD+6ZhkDOME49CcdDWFp2g67c/Dy30y48UzC+lRCdSgtEikWI4OxVHAO35d3Xv1rn/hXo1p4f8AF/jfS9PEn2e3u7YKZXLsxMWSSx6kkk/jWz0m4/10/wAzJP3U+/8Awf8AI6rxN8QPC/g+aKHxHq8VnNKNyRBHkfHqVQEgcHk8Vr6Vq1hrmmxahpF3FeWkwyk0TZB7H6EHtXld1r0PhD4z+IZ/7JvPEs2o2sL7dJg+0XFgFXaY3X+FW4PX0yDxWx8FhFNoOs6lbtBDHqGqzXC6fCxP2HOB5TLgbW4yQBjpUQlzfd+trFyVn/Xa56RRXF/FjxBqfhj4e3eqaHMYbyKaFUYIr5DSKCMMCOQcdKwNWn+Jmg6HJ4suNZ0+6jgj+0XWgfYlVIourKs332YD14znrwCcy1vsgs7pdz1OivMvFPizX77xL4SsPBl/Haw+IrKaUSzwLIIhtRxJgjJKqWwMgEkZqLxH4o1zw7caR4Sn8WabDqt1FJcXmv6jDFAkUIYhdkRIUuemM/wn8G3bf0/r7hJXPUqo6frOn6pdXtvp9ys8lhN5FyFB/dyYztz689q868M+M9Rh8YQ+F77xdpPihNSt5XtNTsViWS3lRclZI0JXGOR64P4Z/wALdP16y8QeM7i68Rfa47a/mjuIvsMafaZ9oImyD8n+4OKlztr0s39zt/XyHa+nW6X3/wBfmex0V5b8NtQ8c+KND07xPqmuxNZGN1OlxWUYe7K7l3mU42EuOgGMAe5qvrFx8RrDw/ceIdX8YaVoFwkbTLob2kLx4GSIzMWLFiB2zz0qpPl3/r+v+HEve2PSdT17TdHurC31K58mXUZxb2q+WzeZIRnbkA4+pwK0a8yn8d6te6T8PdRtZFs/7dvY472JEVldSp3KNwJAyOxz71E2q+N/EPxK8TeHdD1u30uw08wOLuSzSd4N0YOxFOA245JLE4xxRfVrzf4W/wA/66paq/kvxbR6lRXnXhHxZrVjqPirRvGl5DfyeHY0uDqEMIiM0TIX+ZBwCAO3/wBeuXtvG/iHWtL/AOEgj+I3hfRpXBlg8PzeQ42/wpLKW3qxHXA49uyc0tfmVys9tqhrGt6foNrFcatcfZ4pp0t0bYzZkc4UYUHqe/SuDvPiVf6r4I8N3Phi3t49Z8STfZoFuGLR2xXPmucfeC7ePqD2xXPePbDxro9jo0PiHXbfxDp9zrNpumFkttLbSB8gAJwyHBGTznFNtqVvNL8v0Yvs38r/AJ/5HtlUtQ1ex0prVL6fy3vJ1t7dAjO0khyQAFBPQEk9AAScCrtcDpU3/CR/GbWJ5hut/DVtHaWqnoJphukf64AX6U+qX9f10+YdGzY8SfEXwp4Ru0tfEOsRWlw67hCI3kcDsSEUkD61tWWrafqWlJqdjewT2LoZFuEcFNo6nPbGDn0xWJqkOm+Dl1LX7Dw/falf6jIv2lbGNp5pSBgcM3yoAOg4HpXG/DrQLDxP8Mdc0yW7ayj1XUZ5LmysG8t9ODMv+j4dflIC4Py4IJx61Kbd11/r+rjaWj6XOosviz4G1DWV0u08RWz3TPsUFXVGb0EhUIc9sHmuxrzP4r2ulW/w6g8JWNlHNf3rR22k2UajerKw+cY+6FAJLcDsetWfF2v634CvdE1i9u2u/DYRbPVY/KUtC54W4BA3HngjJ9hk0+Zde9r/ANf1qvMVn+F/6/roegu6xxs8jBEUEszHAA9TXJ6b8VPBOra2ukaf4gt5bxm2Im11V29FcqFYntgnPaqnhP8AtHx14c1O/wDFHmjR9aYix03AiMdr0DM6YfLjk/NjHTg1zPxYubKHQrTwfDok+naek9uq63NbEWdgoIOVdQTux8vOB8xyetF2mr9bfj/kNJNO3mek+IfFOieFLAXniHUYrGBjtUvks59FUAlvwFQeGvGnh7xhDJJ4c1SK9EX+sQBkdPcowDAe+KSfwrpuo+LNP8TXEstxcWVsYbWMsrQruOTIBjO8jjOelclpwt9b+Pdzqmgxr9l0zTTZ6jdxj5J52bIjz0YqACTzjAB6ChX5rPz+Vv6/EX2bry/H+vwO+03V7HV1uG0+fzfs0728ylGRo5F6qQwBHY+4II4NXa4K6l/4R742WIh+W38T2UiTIBwZ7cblf67CV/AV3tNaxT/rsD0dgooooEFFFFABRRRQAUUUUAFFFFAEHw7/AORTl/7C+p/+l89dTXLfDv8A5FOX/sL6n/6Xz11Ncr3NgooopAFFFFABRRRQBxuu/FzwL4a1k6VrPiK3gvVO14kjkl8s+jFFIU+xIrpl1fTn0b+1kvrdtO8rz/tYlHleXjO7d0xjvXL22ieFvhd4F1R7+ZpNPd5bm/uL/bJJdO5JIbCgOTnaBjnpXnUfhm7tf2ULyy1S5j0QTF7yKG8cqsURnEiQseuWHGOuWxik2lFt9La9P6/y9CkryS7v+n/Xc9J8P/FfwR4p1o6ToXiCC5vskLCY5I/MxnOwuoD9CflJ45rsK+e9Z8XWvje58CaUnhi98IeXqMFxDqGqW/2aFVQZ8m2cD5t2QB90HA46Y+hKtqy+djNO/wB1zl/FfxI8I+CJ4oPE+tQ2U8y7khEbyuV5+YqikgcHkjHFbOla7pet6NHq2k38F1YSKWW4jcbMDrk9sYOc9K8hu/EUPgr46+Jbj+xr3xVNqdpA+3Rrf7Tc6cEXaYpF42q3DdfTIPFZGi2l1qnwB8fXvh7ZHNqt7PcJpVoxZrFMrvgZcDa5UNkAYwR9Kz5vccvK/wCNrf8AB8jS3vqPml+F7nqOm/F3wHq/iEaJp3iW1mv2fYibXVJGzjCyFQjE9sE57Vf8ef8AIu2v/Ya0r/04W9eY+JfFnw6uf2fZdN0a60+Vjpw+x6bAytcRThchjGPmUqQWLkdic889lPqE2rfB/wAL6hdsWnurnQ5pGJ6s15bEn8zWrja67f8AB/yM072ff+v1PQKKKKgoKKKKACiiigAqvf39ppdhNfalcxWtrAu+WaZwqoPUk1YrB8XeENP8a6TDpmsS3C2kd1HcvFAygT7DkI+QcoT1HB4HNAzM8PfFrwN4p1f+y9D8QwXF6SQkLxyRGQ+il1AY8ds110sscELyzusccalndzgKByST2FeWfFmOz1nWvCXhfR4Y5NfTU4byJoV+awtozl5CR91eAAOMkcciuo8eeDz4utEhv9Wu4NHhika6062IQXjYyoeQfNtGD8oxnPtUydocy8/w6/p6oaV58r8vx/q5v6Jren+I9Ft9W0a4+02NypaGUIy7wCR0YA9Qe1X64L4H/wDJFPDf/Xu3/ox6m+Mupy6R8HvEV1bsVka18kMvUeYyxk/k1XV9xtLoRS/eKPnYfZ/GDwDf+IRolp4ltZL5pPLVdriN26ALIV2MSTgYbmtzxN4t0Lwdpg1DxLqUNhbM21WfJZ29FVQWY/QGuM8Z+EdJtv2e7zSo7OJItO0nz7cqoyksabhICMfMWGSe+TnrWxodlpuu+GvDXjTVtPkvtVtNJSeBlLOyl4gz7I920uemevvRJWuu3/B/yBO6T7/8D/M1vC3jXw741spLrwvqsN/HE22QKGR4z23IwDDODjI5qCx/5Knrv/YF03/0ffVwXgfVYPEPx41nWJrCbw5df2UlsmlX8Jhurxd4Y3DLjaQMBBhmOB24rvbH/kqeu/8AYF03/wBH31DWifcOrR0lFFFIYUUUUAFFFFABXO+K/H3hfwRHE3ijWIbAzcxxlWkkceoRAWx74xXRVz9v4P0uz8b3/i+SSabULq2S3zOymO2jQciPgFQepyTz6Uhlnw34r0Pxfpn9oeG9Sh1C2ztZoyQUPoynBU+xArB1P4w+AdG11tH1HxLaxXqP5bqqO6RtnBDSKpRSD1yRjviuCsdRWK++KXjrwtH5GkGw8m1niXal3cxRtvmT1AY43Dg5Jz1qn4V1+TSvhHa2ulfDG81nwy1kDqt+88cL3LFR50iwnLyjJOG46ccDNF+u2i/G/Xpt+KC1tP60t0+dvkz3yORJoklhdZI3UMjqchgehB7isnxN4t0Lwdpg1DxLqUNhbM21WfJZ29FVQWY/QGo/BU2iT+CdJk8K7ho7Wy/ZFZmYonZSWJOR05PGKfq2g6RPqlv4jvtOe91DSYZDalSzsmRltkedpc4wDjPQZpz91tExd1cj8LeNfDvjWykuvC+qw38cTbZAoZHjPbcjAMM4OMjmsvXfi14G8Na5/ZGteIbe3vgQrxCOSTyyezsqkL1/iIrj/A+qweIfjxrOsTWE3hy6/spLZNKv4TDdXi7wxuGXG0gYCDDMcDtxXQ+J/wCyvhz4Vv49D8Gahrf9qvNLcwWkLXIlkYfM07MS205x/FxnApSfKlL+t/69Coq8nH+tjvLe4hu7aK5tJUnglQPHLGwZXUjIII4INc/8OP8AklnhT/sC2f8A6ISsn4MW9vafCLQ7e01OHU0SNyZoC2xWZ2YoAwBG0ttwQDx0rW+HH/JLPCn/AGBbP/0QlXJcsmiIu6ucR8Y9PvNU+Fup2mmWk95cu0OyG3iMjtiVScKASeBmui8QeHbHxT4YuNG1aLfBcRbScfNG2OGHoQeRVb/hI9U/6EvXP+/1j/8AJNH/AAkeqf8AQl65/wB/rH/5JrdpNNPqTd3TXQ4bTtI8ReKfhVrngfxFbzw6rYf6Nb308TiG8VGDROHIw33cHGTjBPXFZcLo2lR6XF8F4h4kCCIy3GkQ/YN44MhmHVe+B9M969N/4SPVP+hL1z/v9Y//ACTR/wAJHqn/AEJeuf8Af6x/+SaLXd31tf8Ar8w2Vkcz4tN/pcWl2eq+C7TxJ4cFmI7i30ux8yW1nAAzHGxx5eOAAAR69Acr4b+HJbTxVrGraHoOpeG/DlxZeUmnaizCSe43ZMnlliUAAxye/HfHd/8ACR6p/wBCXrn/AH+sf/kmj/hI9U/6EvXP+/1j/wDJNDV7v1/EOiXp+Bz3wv8AD7P8GbPRPEWnSxCZbiO4tbqIo21pX6qcEcEEfga5fwF4V8R+HfjE1lqsNzc6Vp2lSWlhqLRNseEyB0Qv03DcRj29MV6T/wAJHqn/AEJeuf8Af6x/+SaP+Ej1T/oS9c/7/WP/AMk03Zz5v6/rUXRr+t7nluk6LbeBftei+JPhlJ4kC3Ej2Op2GlRXZmjY5CyFuUIzjnP6ZPQal4b1m/8AgfrVinhvTdJ1G+3TRaXpcSxhVDKQGwcNJtXkjGeBjtXZf8JHqn/Ql65/3+sf/kmj/hI9U/6EvXP+/wBY/wDyTUOKcHF9rFc3vc3nck8H6u2s+GbaeTTNR0x41ELW+o25hkyoAztP8J7GsXwbYXlr8QPHFxc2k8MF1d2zQSyRlVmAhwSpPDAHjitb/hI9U/6EvXP+/wBY/wDyTR/wkeqf9CXrn/f6x/8AkmtG7y5v66f5GajZJf11/wAzjLe91f4deLvELXfhnVdb03Wbz7bb3mkQCeRWIAMciZGAOx/nnjX+HWl6sdX8ReJ9ZsG0o65PG8OnO2XiSNSoZ8dGbOSPatz/AISPVP8AoS9c/wC/1j/8k0f8JHqn/Ql65/3+sf8A5JqYrl+639fcU9fzOb+Om8/Ci98ogP8AaLfaT6+cuKztb8T+KPE/hy48K23gnVbTVryE2t1d3KKtjCrDDyJNn5xg5AHP1xg6njiHVPGfhaXRv+EX1yy8yWKTzs2MmNjhsbftQ64x1roB4i1QKB/wheucD/ntY/8AyTStdNPZv9EO7TTXRfqcvceG7nS/iN4Ags7a4uLHStPuLaS6ERKJiJVXcw4UnHGTUXxF8Nzr400zxYvhuLxPYwWrWd9pxhWWRULFlkjRgQxBJ46/nkdd/wAJHqn/AEJeuf8Af6x/+SaP+Ej1T/oS9c/7/WP/AMk1T1t8399/8xLT8F9xynhGKPU/F0F7ovw5tPDWlWsT+Zd6jpaW148hGAsSryowTknOQccUzwsNR0Xxn4w0i+0PUwuq3k17a36W+62ZCnCmQHhjjpXXf8JHqn/Ql65/3+sf/kmj/hI9U/6EvXP+/wBY/wDyTUuKat5NfeNNp380/uOe+HenazY/A20sYreWx1hbOdYY7lDG0cpZ9m4MMjkg8155pfhqGbw7Npo+GWqz+K5IGjutT1dd1v5hBDTCVmO49wFXPoT1Psn/AAkeqf8AQl65/wB/rH/5Jo/4SPVP+hL1z/v9Y/8AyTTmudt9xRvFJLoecWOjaqfCXwuibSr5JbDUVN3G9s4a3UbgWcY+Ue5x1rrPCWn3tt8WPHN5cWc8VtdGy8ieSJlSbbGwbaxGGweuOlbf/CR6p/0Jeuf9/rH/AOSaP+Ej1T/oS9c/7/WP/wAk1V/eb73/ABt/kJL3bei+53OXs/Dt3qHxG+IUV1bXEFnqtjbW8Ny8TCOTMBVtrdGxnnBrlNHtY/Dmhx6DrnwhOq63ar5MV7baXDNbXeOFd5iPlzxnOT3OOg9T/wCEj1T/AKEvXP8Av9Y//JNH/CR6p/0Jeuf9/rH/AOSajlVreVv6+8tyv/Xkl+hyOteGdftvDHhfV9N0jTk1nQLg3Muk6YghgdJARLHGM4DYPvk5xnIFZXjHxBr/AI3s9Kg0rwbrljZ22q2s13JqFoY5Dh+iIMkqOpfgAD3r0P8A4SPVP+hL1z/v9Y//ACTR/wAJHqn/AEJeuf8Af6x/+SafW/nf8v8AInpbyt/X3nQV5/4SjbSvi94zsLj5Tfrbahbk/wAabSjfkwxXQf8ACR6p/wBCXrn/AH+sf/kmsTWDqepa5pOsWvhTXLS+02Rh5m+xcTQuMSRMPtQ4OAQexAODyC/tJ/L+vnYOlv6/roQ3vijxP4R8T6lHrOh6t4h0e6cS6bPpFokr24x80ToMHg9GJOfftm6R/wAJB4e03xd44uPD9x/aOsSxNZ6JAhlkUINiM4QHk7tzY6AV2f8Awkeqf9CXrn/f6x/+SaP+Ej1T/oS9c/7/AFj/APJNTbS1+lh31PNPCPiX+xZ5dY1zwX441XxJeJi6v20bhF6+VEN/yRj2Az1PYDqfFdvf+PdV0zw0tlqFjoUkK32rTywtF5i8FLYN03Z5YA8Y69a6L/hI9U/6EvXP+/1j/wDJNH/CR6p/0Jeuf9/rH/5Jp2TVnsLVao5Tw1D4usvC+ueD43uLbU9JGzSNXmg3Q3EJ5jG5lKlgPlI5xkehqhq/irxN4o8I3Hhb/hBdXh1u8g+y3NxdQqtjGSMPIJs4YdwAPpnHPdf8JHqn/Ql65/3+sf8A5Jo/4SPVP+hL1z/v9Y//ACTQ1dWlr3/rz6jTs7r+v66HBeNb3XNC07QvBumad4iudNis401LU9HsWmldFXb5SNwFLbck5yAR16V0PgbxLp4Np4c0fwT4l0Kzijby5L/TfJhXAz8z7iSx9Tkkmtz/AISPVP8AoS9c/wC/1j/8k0f8JHqn/Ql65/3+sf8A5Jppu7b6k20SXQwNfQat8bvC1rCN39kWd1fXBB+4JAI0B+pFd/XCaGdT0rVNV1S58Ka5eX+pzB5Jt9igSJRiOJR9qOAo755JJ9ht/wDCR6p/0Jeuf9/rH/5JojpFL+tf6sN6v+v68zoKK5//AISPVP8AoS9c/wC/1j/8k0f8JHqn/Ql65/3+sf8A5Jp3A6Ciuf8A+Ej1T/oS9c/7/WP/AMk0f8JHqn/Ql65/3+sf/kmi4HQUVz//AAkeqf8AQl65/wB/rH/5Jo/4SPVP+hL1z/v9Y/8AyTRcDoKK5/8A4SPVP+hL1z/v9Y//ACTR/wAJHqn/AEJeuf8Af6x/+SaLgdBRXP8A/CR6p/0Jeuf9/rH/AOSaP+Ej1T/oS9c/7/WP/wAk0XA2fh3/AMinL/2F9T/9L566mvN/AfiLVIPDEiReDNbuF/tTUW3xTWIAJvZiV+a5BypJU8YyDgkYJ6T/AISjV/8AoRPEH/f/AE//AOSq5XuanSUVzf8AwlGr/wDQieIP+/8Ap/8A8lUf8JRq/wD0IniD/v8A6f8A/JVIDpKK5v8A4SjV/wDoRPEH/f8A0/8A+SqP+Eo1f/oRPEH/AH/0/wD+SqAOkpGbYhYgkAZ4GT+Vc5/wlGr/APQieIP+/wDp/wD8lUf8JRq//QieIP8Av/p//wAlUAeRQ+K77W/Gb6/468A+OL2Oxnzo2l22is1tagdJn3Mu+U+4wvbtjsvGA1X4lfDaK90DQtSsL/TtTiu49L1u3Fs915JyUIJPynPByMkV1f8AwlGr/wDQieIP+/8Ap/8A8lUf8JRq/wD0IniD/v8A6f8A/JVGyS7fn3B6tvv+XY868W63r3xV0OHwnpvgfXtGkubiJ7zUNXt/Ihs1RwxaNs/vDwQMY/WvT7vxJBp/ivTPD01nfPNqEUjxXaxA24KAkqz5+9gZwAaq/wDCUav/ANCJ4g/7/wCn/wDyVVCbUb641y21WbwN4kae0heKFDc6fsTeRubH2r72FAz2GfU0/L5/h/wEJ6/15nK299rXwx8a+JnvPCmsa/peu3v2+1vdFthcSoxUAxSJkEAY4P8APJxc8FaV4sVfGfi4aZFpWqa8ySadpN6SwQxRlVMu0jBcnkZBHeut/wCEo1f/AKETxB/3/wBP/wDkqj/hKNX/AOhE8Qf9/wDT/wD5KqVoreVvl/SRW7v53PLdQuNW8U6NdaDoXwuuPD/iTVoha6tq8+nx29tEjYErLMMmUHnA6855xz6R4osItK8C6Tp1v/qrTU9HgTP91b63Ufyq1/wlGr/9CJ4g/wC/+n//ACVXP+NPEeqTaDbLJ4L1yADVtNYPJNYkEi+gIX5bknLEBR2yRkgZIrpYm2up6JRXN/8ACUav/wBCJ4g/7/6f/wDJVH/CUav/ANCJ4g/7/wCn/wDyVSGdJRXN/wDCUav/ANCJ4g/7/wCn/wDyVR/wlGr/APQieIP+/wDp/wD8lUAdJRXN/wDCUav/ANCJ4g/7/wCn/wDyVR/wlGr/APQieIP+/wDp/wD8lUAdJXH/ABP8Sa34Z8GyT+FtIvNV1W4cQQLaWrTmDIJMrKoPAA4B4JIFXP8AhKNX/wChE8Qf9/8AT/8A5Ko/4SjV/wDoRPEH/f8A0/8A+SqTV1YadmeceCPFVj4VjdU8A/EK81XUJFbUNWvNF/eXMnTcx3/Kg7KOAPU5J9kv1Z9OuVQFmaJgABkk4NYX/CUav/0IniD/AL/6f/8AJVH/AAlGr/8AQieIP+/+n/8AyVRP3o2FH3ZXM74O2F5pnwh0Cz1K1ns7qGBhJBcRmN0PmMcFTyODTdSkg+Knw58Q6Xa2l5p8jmaw8vUIhG6zIAVYgE/Lkqc9cdq0/wDhKNX/AOhE8Qf9/wDT/wD5KqhpOo32jWskFr4G8SP508lxLJLc6ezSSOxZiT9q98AdgAO1Op+8bv1v/X5ih7iVulv6/I4TUPEvjTxH4B/4QVfA2s2evXNsthd6hcQhbCNMBXlWUHDZXJ2j14zjB6vxBJ4o8CyeH5/D9lc654csLQWeoaXZxI1wNoASaPPzMRjBUH+pG/8A8JRq/wD0IniD/v8A6f8A/JVH/CUav/0IniD/AL/6f/8AJVNtt36vf+vm/wCrBZJW6L+v0X9XOP0tNX8f/FTR/FMvh7UPD2kaDbzpEdUiENzdyyrtKmPJIRRzk9T9eOwsf+Sp67/2BdN/9H31H/CUav8A9CJ4g/7/AOn/APyVXP2fiPVB8SdZlHgvXGdtJsFMImsd6ATXhDH/AEnbg7iBgk/KcgcZOiS/rqPrdnolFc3/AMJRq/8A0IniD/v/AKf/APJVH/CUav8A9CJ4g/7/AOn/APyVSA6Siub/AOEo1f8A6ETxB/3/ANP/APkqj/hKNX/6ETxB/wB/9P8A/kqgDpKK5v8A4SjV/wDoRPEH/f8A0/8A+SqP+Eo1f/oRPEH/AH/0/wD+SqAOkrxX4neINW1Txn/wjl74Z8W3PhK2QNeHRNNeQ6m5APlmTK4iGcHack5HoR6N/wAJRq//AEIniD/v/p//AMlUf8JRq/8A0IniD/v/AKf/APJVK2o76GBpOrWXjzw1qfhK38I+IvDVm2nPbxtqemC2hVSuwKnzEEjOcegrndF8W+LfCPg2DwddeANavtasbf7Ha3VlCr2M4A2o7TZAQYwTkfXGePQf+Eo1f/oRPEH/AH/0/wD+SqP+Eo1f/oRPEH/f/T//AJKokua9+u/4/wCYLT5bf18jB8Pp/wAKg+D+lW2sW13qD2mFuv7PiEhR5XLMxyR8ilsFqt+NtV8WeHNe03WdGsbnWtASN4tS0uyiRrgE/dmjyNz46FQf8RJq+o32t2K2l74G8SeR50crolzp6+ZsYMFb/Svu5AyO/TpV/wD4SjV/+hE8Qf8Af/T/AP5Kqm3J8z7kpWVjj9LTV/H/AMU9H8Uy+HtQ8PaRoNvOkR1SIQ3N3LKu0qY8nCKOcnqfrwtt448Y+Ebi+0jxX4V13xJcC4dtP1PSLNHhnhJ+QSbdoiI6HIPrz1PX/wDCUav/ANCJ4g/7/wCn/wDyVR/wlGr/APQieIP+/wDp/wD8lUuyX9a3H5sy/hR4Z1Lw54XvJNdijtr/AFbUZtSms4mDJamQjEYI64AGfc1qfDj/AJJZ4U/7Atn/AOiEo/4SjV/+hE8Qf9/9P/8Akqo/hzIw+FvhUCFz/wASaz5BXn9ynvTYGZ4r8T2fg/w3c63qcVxLbW5UOluoZzuYKMAkDqfWuX/4W0oXc/gTxsqYyXOj8Aev36T45f8AJINWxz80H/o5Kydc+KfjDwzp8FxrPw6+x28rrCly+tRvGjHgFyqHaPckD3rfm3Ia0XzPQ/DfiXTPFmhw6tok/nW0pK8qVZGHVWB6Ef8A1xkEGtWvL7NdR+GPwp8Q+INTltrnVby4k1F1t8mBJZiqoq+qgkE/5NcDP440qx0j+2bD4raxeeJY0ErWc8ExsZ36mIRGMBQegOeOvHZymk7Pyv8A11sJRurrzsfR1NdxHGznooJOK8c8c+MJ7qTwxc6rqmreHfC2p6eLme+0gESCdgCsbOFJVQD2Bzk8enSfDu4mms9WFp4ti8T6JtVrKaacyXkBKnck3yg+4zz7UpSaUvK/4CVtPO34m34J8e6N4902e70QzIbeXy5oLhVWRD2JAJGD2Oex9KuP4osk8bR+FzFP9tksTfCQKvl7A+zGc53Z9se9eHeDbO58G+B9B+IejRPJCpmt9ctY/wDltb+e4EoH95OPwA7Zr0CK9ttR/aA069splmtp/C5likQ5DKZsgiqvql63+5v8bfp0G1bm/D70j0us3xDrtn4Z8P3esan5n2W0TfJ5a7mPIAAH1IrwtfiBofie5vdQ8TfEbWvD8v2h1sdO0pJUSCIHCmQrGRITjJ59vYWtb1u48efs+6rf3mr3Ms+jXTQNPaEwR6gAyBWkjI6FXB28YIz7VnKb5HJdrlKNpqL72Pd7edbm1inQELKgcA9QCM1j6B4v0rxNqWrWejyNP/ZUqwzTDBjdmBPyEHnGCDwORxms/TvBsFx8PLfQbzV9YubeZEeSeW8PnupwxjLgA7P4cenFYnw002z0fxv450/TLaO1tLe6tUihjGFUeT/k571s9KjX9br/ADMk/dT/AK2f+Rs+JPiRpXh3WRpCWGq6zqQjEstrpNp57woejPyAB+OeR61s+GvE2meLNGTU9FmaSBmKMrqVeNx1VlPQivOH1PWNH+LXiWXwNoreJxdxw/2lG0y2y2kyLhVEz/K2VOSvUfnWv8Hislhr9zdsYtautUkn1OxaEx/ZJGHCAE8jHIbvn2qIPm+6/wCP5ef+di5aP5/oejUVw/xi1G90n4Xale6XdTWt1G8OyWGQowzKoIyCDyOK5PxnoniXwh4PfxjH421m41a1MUtxbSyD7FJudVKLCBhR83qenqaOb/IOVuyXU9korznxZqGs+IvGmk+D9G1ObRoLiwOo6hd2v+u8vdtCI38JJ79f5GvZRav4L+IGneGbjxBqWsaR4gt5xDLqEvmXNrNGu4kS45BB6Y4/m7v8/wAP+GYtLX/r+up3GjeJLHXb7VbWw80tpdz9lnZ1wDIBk7fUc9a1q8i+EXhv7B4u8WXH9s6vc/Y9TktfKuLrek/CnzJBj5pP9qu6+IV1cWXw41+5s55Le4isJXjlicqyMFOCCOQfep5rU1N9r/gNRvPl87HR0V5JpHg/xXrPgmx8QT+OdYttbezSa3himH2RRsyiyRkHzCR95iep74qprfjHW/EfgPwJqWkX0mmX+q6olpcPCSF3YeNyVzhgGBYKcjgVbunbrdL73YlWav0/yVz2aivIPG2oy/DXRNM0QeLdVX+2LxjPrGpO11Nawqq7wgC5ySRjjjJ+oxtF8eaRovjLRbfwt471bxNa6ldraXllq6yyNHv4WWORkXbg4BXvn8kpJy5V6fMbVo3fqexWviSxvPFV/oEHmm8sIY5pyVwgD/dAPc8VrV4/4X8LeT8fPET/ANu61J9jiguNsl5kT+YD8knHzIuflHbAp/gLS9Z8V6lqmpap4q1qK20rXLiG2tLe6KpKqybiJc5LLghQvAAHHWlTbklfrf8AB2CSs38vyueu1na3q/8AYmnfa/7Pv9Q/eLH5NhB5snzHG7bkcDqT2FeW6+kKXuoXHjj4qT6NfLM/2bT9E1HYlvH/AAB4wu927nIH1rPPjLXNT+AFtqsmqz/b49VjtvtsDGF5UEwAJ246qcH170RkpPTy/FpfqEvdTfr+Cb/Q9zoryzxImu618bF8P6d4gvtK0+TRBPc/ZZMNgSkHy88I5JUb8ZAFTeGRq3hX4tS+FZtf1DWtLudK+3xHU5fNmhcSbMb8cjg8dOn4ilffrf8AC/8AkNq1/K342/zPTaK+eV+IGh+J7m91DxN8Rta8Py/aHWx07SklRIIgcKZCsZEhOMnn29h0Vj8TdXvfhFJdWV3Fd6ydUGjW1+ICqyszDbOUI4Oxs4x17dqIyuvu/HT9UEo2dn/X9WPUfEeu23hjw7eazfpNJb2cfmSLCAXIyBwCQO/rV+3mW5tYp0BCyoHUHrgjNeMfEXwRrfh/4b6tfweMdY1ZmgC39tqUokhlQsMmNf8AlkQeRgngYr2DSv8AkDWX/XvH/wCginFtuV+lv1E+nz/Qra/r9p4d05Lq8WWVpZkt4LeAAyTyucKiAkAnvyQAASelZfibx9pvhm+g097LUtU1KeMyrYaXbGeYRg43kZAAz71kXcza18drLT5ubXQ9La9RD0M8rbA2PZc49Mmur1K3+wRXmraNotvfau8aoAGSF7gA8K0pHAHXnNK75eb1/DT819w9L2/rXX8vxKvhjxjpXizT57nTnlhe1cx3VtdR+VNbOOqup6H9ODzwa5uX4z+H42eePTdcuNJjco+sw6ezWa4OCd+c4B9BWd4AVdV8TeMbbxdbPZa/qgT7Zpn3US1CFEMcisd+QxywIOewrZ8Y32l+EfA6+GNGshPeXts1jpmkxZd5NylckE52KCSzE9utEm0rrtt59v0Gkuaz/pf1/Wp2lpdQX1nDd2cqzW86CSKRDlXUjII9iKlJABJOAOpNeX634f1/wh8NNCvNDv52v/DMKyXVokzeTeRAfvUKjg45KkjIA45rQ+H93feNrjUPF+pPcR6TfKbXTdLklzGIFOGkeMHaXZgeucDjpiqfxNLp/S+//MhfCm+v9MWX4y+Ho5mkFhrUmkpL5T61HYM1kpzt/wBZnOM8ZArpPEHi/R/DWiw6pqFwXguGVLZbdfMe5ZhlVjA+8SPwrmPiSdb07wfcaN4T8MxSaVJaNHcXFu0Y+yRHIcR2/wAu87ckYI5rW8N6L4a1vw54X1KxBv4dJt1Gm3DsylPkCElQQC3y45BwRxUxu0/l/wAH/gFOya+f/A/4Izw/8StK13XF0afT9W0TUpEMkNrq9mYHnUckpyQcYP5H0rctNftLvxDfaLslhvbJElKSgATRt0kTBOVyCp6EEcjkZ4rUJ08cfFXRV0RfOsPDEsst7qKfc85lAECN/Ee7AdPrVv4gSnRfFng/X4Plc6kNMnIx88M4PB9QGUH2pp3Sfd2/yf3/AIa9hNWuuyv/AJr7jvqKKKYgooooAKKKKAIPh3/yKcv/AGF9T/8AS+euprlvh3/yKcv/AGF9T/8AS+euprle5sFFFFIAooooAKKKKAPPtY+MmhaVql7aW+la9q0OnOY7++0zTzNbWjDlhI+RjaOTjOMGuln8Z+H7bwb/AMJVLqcQ0XyRMLsAkFScDAAznPG3Gc8YzWV4sbW/DHhx4Phx4Rs76aYyM8ccsdtHCxGd5TjzCSeQCCcda8xfSYdQ/Zw0aHwrFdayuhalHc6hYyQbJpGjkZp4mjycEFydoJ4A60l8P3fju/RDe9/X/gfN/wBefoXh/wCL+h67qVpZz6Zrei/bztsLjVrEwQ3p6gRvkgkjkA4zkY5rva8C+KvxU0Lxb8M5o/CEd5fXVvc2000hs5I109lkUjezADeT8oCk9T2Fe9xktGpbqQCau2l/P/InVNHG+J/ijo3hvXP7EhsNW13VljEs1jotmbmSBD0Z+QBnI4znkHGCK0/DfjnQvFHhubW7C6MNral1u1ul8p7RkGXWQH7pA5Pb3rybwHqfjO/1rxq/grStJN5Jr85u9T1maTyiqnbHCixjcSFBOTgDPvUHjLxebv4PeNbTUNCt9D8R213b2+tR2YUC48yRcShhywZAQN2frUK/L5tJ/fb8Nf12Lsua3RO33X/y/Tc7aP47eGHlSZtO16LRpJREmuy6ay2LEnAPmE5xnjla6bx0wfw1aMpDKdZ0ogg8Ef2hb1wWr67460rwgNS1LwX4em8Gw26edojSNLeR2wHVsjyjhQCVwcfhmuy8S3lnqHgLSLzTNv2K41LR5bfaAAI2vrcrgDpwRxV238v6/r/gGad7PudhRRRUlBRRRQAUUUUAFZ2va9p3hnQ7nV9auVtrK1TdJIQT3wAAOSSSAAOpNaNVr/TbHVIFg1Oyt7yJXWRY7iJZFDryGAIPI7GkNHGaH8XNF1jXbXSb3Stc0G4vsixbWbA26Xh9I2ycnGOuOo7nFWPEfxH/AOEc1uTTv+EN8Xar5aq32rS9L8+BsjOA+4ZI6HjrXIfEbVNVl8a+Hx4u0dtH8I6brEdxHq0UqXBnmXIi3gEGFCSckhu3SvRfG/ieLwf4I1TXpQrmzgLRIejyHhF/FiBQ37nN/X/D+X+YJPn5TF8HfFPT/GfiS80O20HX9MvLGES3A1OzWER5I2qcOSGIOQCBkAmuzubmCytJbq7lSCCFDJLLI21UUDJJJ6ACuR+Fvhefw34Njl1YmXW9Vc3+pzOPmeaTnaf90ELj2NZfx8vXsfgxrJQsBM0MLlDg7GlUMB9RkfjTn7qt12+f+QoWk79P0I4/jt4YeVJm07XotGklESa7LprLYsScA+YTnGeOVrpvGfjiw8FabZXd5ZX+pNfXK2ttbaZCJpZXZSw2qWGeF7c8iuC1fXfHWleEBqWpeC/D03g2G3TztEaRpbyO2A6tkeUcKASuDj8M1c8aaL4i8Y634F1PwCLS20u1ikuhfzqjR2wkjURkRZyzBc7QBgHGeKbWtl3/AKv92gk+r7HUeFfH/wDwlOqSWX/CJ+KNG2QmX7Rq+m/Z4mwQNobcctznHoDVqx/5Knrv/YF03/0ffVy+ha34t8LfEax8J+NdXt9ft9Zgll0/Uo7RbaRZIwC0bovy4xyCMn+nUWP/ACVPXf8AsC6b/wCj76h2smg6tM6SiiikMKKKKACiiigArk/FnxF0rwnqNvpj2WqaxqlxGZk0/SLQ3E4jBwXK5AC59TXWVk6rbf2dFe6xoehW1/rTxKgAZIJLgA8I0xHAHXnNJjRU8I+NtH8Z6dPdaU00MlrIYru0u4jFPayDqsiHoevqODzwa5eb45eGop3lGna9Lo0cvlPr0WnM1gpB2n95nJGeMhT1rP8AhfM17428ZDxbafYPE+pNFJd6S8amJLVVKRlHBIlBBwzccnGKvfFM6/pfgi50Lwb4Uhk0eWyeK5uLZox9jiOQ4jtsrvIXJGCOcdaJO1n5f8Pr5BFXbj5/1p/X46ekQTxXNvHPbyLLDKoeORDlWUjIIPcEVgeMfG+keCLCC41b7RNNdS+TaWdnEZZ7l/7qJ3/EgcjnkU/wLNpU/gHRD4eumutNSyjit5mGGZUULyOx4wR2NcR8V7iex8d+DtQ8OQNqvia0kn+z6OF+WeB1CyOz9ItvZjxz7Gqmkp8vn/X9dNyYO8OZ9jqvCHxF0nxhe3WnwWuo6XqlmoebTtVtjBOqHo+3JBH0PcZ6isnVfjNoWnaleWtlpOv61Fp8hivb3StPM1vauPvB3yOnfGa5/wALX2o6z8eGv/G+lHw3q0ekG303TNwnW4i3bnf7Qvysy5+6BwD7Guyvrrwx8JPBxjs7cwQNK32WxidpZry4c52JuJZ2Yn8PoKT0in/V72/rz0KWraX9aX/ryOg0LXdO8S6Hbavolyt1Y3S7opVBGecEEHkEEEEHoRWX8OP+SWeFP+wLZ/8AohKzfhJ4avvCvw6tLPVo1gvZ5ZLua3T7tuZGLeWPoCB9c1pfDj/klnhT/sC2f/ohKqSsyVqjkPiroWo+JPhzqGl6Lb/abyZojHFvVM7ZFY8sQOgPeuk1HSrXWNEn0zU4VmtrmExSxnuCMfn79qzPtnjH/oBaH/4Opv8A5Fo+2eMf+gFof/g6m/8AkWt7Jpp9SLu6fY4/Q/BWvXfw51rwH4mBW1hJh0vU9yN5sIO6MlQ24FSBwQOMAdM0+G9+K/8AZUehLoOnW12qCH/hIPtyPEAOPMEBG4tj14z2xxXW/bPGP/QC0P8A8HU3/wAi0fbPGP8A0AtD/wDB1N/8i0f8D52AyvESeONMvLG50JIPEtiLX7PfaZcNFbNNJ/z2VyuBnnKnj0HPGR4K8H6pD4u1PxRqGg2Phlbqx+yRaTZSrJuO7cZJCgCZ4GMevPTnrPtnjH/oBaH/AODqb/5Fo+2eMf8AoBaH/wCDqb/5FoaT38/x/wCHC+lv60Mz4ZeHLzRPhhZaJ4is1jnUTrPbuyyAq8jnBKkggqw7965bwT8ONa8JfFq4uMNP4bisJILCZ5VJhV5A/lbc7uCW5xj37V3n2zxj/wBALQ//AAdTf/ItH2zxj/0AtD/8HU3/AMi03Zy5hdGv67nG6Tp/jr4eLdaNoHh+28SaO87zWMv25LV7YOclHDfeAJ7f1wNTWPDHirXvhHquka3f215rl8rOojQRwxfMGWJSAMgAY3HnJ5Pet77Z4x/6AWh/+Dqb/wCRaPtnjH/oBaH/AODqb/5FqXFOPK+1iuZ83MvUl8I3Or3Hhy3/AOEg0f8Ase8iHlG3+0pPkKAA25eOfTtWX4U0PUdN8b+MNQvbfyrXUrqCS1k3qfMVYtrHAORg+uKv/bPGP/QC0P8A8HU3/wAi0fbPGP8A0AtD/wDB1N/8i1bd5c39dP8AIi1lb+v61OVOm+MfBHijWbrwzocHiTStZuTeGA3y201tMQA2WfIZTjjH6d9bwF4b1fT77WvEPifyI9W1yWN5ba2O6O3SNSqLnucE5Nan2zxj/wBALQ//AAdTf/ItH2zxj/0AtD/8HU3/AMi1MbR/L5DepnfFXQtR8SfDnUNL0W3+03kzRGOLeqZ2yKx5YgdAe9L8TtD1HxD8MdS0nR7f7RfTrEI4t6pu2yIx5YgdAe9aH2zxj/0AtD/8HU3/AMi0fbPGP/QC0P8A8HU3/wAi0WTVvmUpNNPsc/4q8OeILbX9I8W+EoILzUrG0+x3WnTyCMXMJOcK54Vgcnnj+RZo2i+J/Efjyy8U+L9Og0WHSoJIrHTY7lbhy8gw0juvHToB+nfo/tnjH/oBaH/4Opv/AJFo+2eMf+gFof8A4Opv/kWmtHf1/Ei2lv60MDwlpPiLw74+8Qw3GkJNo+r3r3yanHdoPKJXhDEfmJ4xkcfWtf4l/wDJLvEn/YOm/wDQTVj7Z4x/6AWh/wDg6m/+Raoa5aeKfEGg3ukXmiaOlvewtDI0WuShgrDBwTaEZ/A1Eo/u+RdrFxdp8z73OR8P3vxLTwLpujadoWn3CzWEa22uPfBI4o2Qbd8ON5ZRxkZGcHnmtHUPh9eaboXgXSNDiN3FouqxXF3KXVML8xeTBIz8zHgZPNdFpaeLNJ0m00620TRmhtIUhRpNblLFVUAZxaDnirX2zxj/ANALQ/8AwdTf/ItaO3Ndd0/ud0ZpPlSfb80Zvj/wxqusNpGseGZYF1nRLhp7eO5/1c6sMPGT2yB1/l1FbTr34ia9rlj/AGhpFv4V0y2fzLv/AEuK8lvBjhFwMIvqevoa2/tnjH/oBaH/AODqb/5Fo+2eMf8AoBaH/wCDqb/5FqVo/wAS3qjAXSfEWj/GO91iz0hNQ0nWYIIZrlbtI2s/LGCSjcv9F/8ArVc+G+g6loGn65Fq1v8AZ3utZubqEeYr7onI2t8pOM+h5rT+2eMf+gFof/g6m/8AkWj7Z4x/6AWh/wDg6m/+RaIpJW9fxdxPV/d+Csed+G/C/jDww1zpsHg3Rb69kuJZF8T3F0nzb2JDOmDISM9BgfqTFF8P/E8Pwdn8OtY+dqCa2J0xNGomiEobzB82FyMnaTn2r0n7Z4x/6AWh/wDg6m/+RaPtnjH/AKAWh/8Ag6m/+RaEkrPtb8Gn+gSvK/nf8b/5mYNB1IfG06/9m/4ln9h/ZPP8xf8AW+cG27c7unOcY96JtA1J/jZBrwts6YuiNaNP5i8SmUtt253dOc4xWn9s8Y/9ALQ//B1N/wDItH2zxj/0AtD/APB1N/8AItPTTyv+N/8AMbbd/O34W/yON0nT/HXw8W60bQPD9t4k0d53msZftyWr2wc5KOG+8AT2/rgampeDfEfiX4cvYeIdXt28QfaRe200UQWG1kVtyRjAyyjpuIJ5PXFb32zxj/0AtD/8HU3/AMi0fbPGP/QC0P8A8HU3/wAi0rK1v60C+tzgvFcfxO8Y+Db7QpfDFnpbNEPOuF1COX7YQQdkS5GzJGcueB716rp8TwaZaxSja8cKKwznBAANY/2zxj/0AtD/APB1N/8AItH2zxj/ANALQ/8AwdTf/ItNaX8/+D/mJ628jAu4W0X47WWoTcWuuaW1kjnoJ4m3hc+65x64NTeIbbxnovi5td8Lwf2/YXUCw3GjT33keS69JIi3yDPcdT79pdf0zxN4i05LW80TSImimS4guINclEkEqHKuhNoQD25BBBI71pi88Ygf8gLQz/3Gpv8A5FpJaJdr/j/w7/Ab39f0/wCGRzmjaN4oOuax431vTYI9YfTzaabo8FwreWgO8K8vCli2OegH5DnPC8fj/Qby61XUvhw2r67eMfP1GbXbdSEzxHGuD5aDj5Qf6Y9H+2eMf+gFof8A4Opv/kWj7Z4x/wCgFof/AIOpv/kWiyvdf1/w4b7mD4jsfE3jXStH0e80l9Gsr5zJrZW8jkMUak4gUqcsXwMsBgD15pvh7wrqnhnxNrWi6fA8fhTU4muLWeCZUbT52GGjVc7gD94EDAOPeug+2eMf+gFof/g6m/8AkWj7Z4x/6AWh/wDg6m/+RaLL77/j/X9aiu7HH2snxT0jR28OLotpq0qK0MHiGfUgFKn7ryRNl2YDr7+vU1tf8K+K/D3w60Xwj4MsptSgG7+1LmC8jtZGUtuZEZz8u8s3IBwBjvXc/bPGP/QC0P8A8HU3/wAi0fbPGP8A0AtD/wDB1N/8i0NJrX+rf18+o07HO+FdR8VaZ9g0aL4YR6LpKMEaWPWoJBCvd9oGWPc9yak8fJ/bXjDwf4fhAdl1D+1Lj/YigB5P1ZgB71vfbPGP/QC0P/wdTf8AyLWXaaZ4mtPEN9rX9iaRNe3qJEXl1yUiGNekaYtBhcksepJPJ4GHfVX73/y/EVrJ29P8/wADtKK5/wC2eMf+gFof/g6m/wDkWj7Z4x/6AWh/+Dqb/wCRadwOgorn/tnjH/oBaH/4Opv/AJFo+2eMf+gFof8A4Opv/kWi4HQUVz/2zxj/ANALQ/8AwdTf/ItH2zxj/wBALQ//AAdTf/ItFwNn4d/8inL/ANhfU/8A0vnrqa838B3njBfDEgtNC0SWP+1NRJaXWpkO77bNuGBatwGyAc8gA4GcDpPt3jf/AKF7w/8A+D6f/wCQ65XuanSUVzf27xv/ANC94f8A/B9P/wDIdH27xv8A9C94f/8AB9P/APIdIDpKK5v7d43/AOhe8P8A/g+n/wDkOj7d43/6F7w//wCD6f8A+Q6AOkorm/t3jf8A6F7w/wD+D6f/AOQ6Pt3jf/oXvD//AIPp/wD5DoA5C2PxP8GXF9pen6KnjKwmuHmsdSutWEUtsrnIjlEmS4U9Nvb8ha0bwP4q8OfDXUbfRdYtofFuo3j6nPceUGt2mdgWjAZThSo25xnPPFdL9u8b/wDQveH/APwfT/8AyHR9u8b/APQveH//AAfT/wDyHRsrfL+vuDr+Jxd9pnj74kXWnaZ4q8PWvhjQrS6jub7bqCXUl8YzuVECcIpYc7uenpg91qHiC7sfGukaKNK8yz1KKVjf/aAPKdFLbPLxk5GPmyAM1D9u8b/9C94f/wDB9P8A/IdVXTxY+qR6k/hfw613FE0Mcp1+clEYgsB/omBkqM/QUeX9bf8ADf1urf1/XzOaOjeM/h94o1u78G6Fb+JtH1y6N61m1+tpNaTsPnIZ8qVOAfXt25jsvhZqPiDwp4tbxlNBba14sdJJEtfnjshEP3Kg/wARUgZ7Ht612f27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0raW8rfL+kir6387/M4PUYviv4h8MSeDL/w7ptotzCLS68RDUVkjaLGHZYPv7mGevc9u3X+JNMh0TwBo+l2pJhstS0e3jJ6lUvrdR/Krv27xv8A9C94f/8AB9P/APIdc/40vPGLaDbC60LQ40/tbTSGj1qZyW+3QbRg2o4LYBOeAScHGDV3r5k2Wluh6JRXN/bvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h0hnSUVzf27xv8A9C94f/8AB9P/APIdH27xv/0L3h//AMH0/wD8h0AdJRXN/bvG/wD0L3h//wAH0/8A8h0fbvG//QveH/8AwfT/APyHQB0lc5470TWNe8LyW/hnVpNK1WGVJ7aZZGRHZDny5NvJRuhHP0PSk+3eN/8AoXvD/wD4Pp//AJDo+3eN/wDoXvD/AP4Pp/8A5DpPUDhtZ0/4h/EvT4PDfiXwxZ+GtJaaN9RvBqKXLXKIwbbEi8pkgcseB+vR/E/w5qniaw8P6Zplr59kus282pDzFXbbIST94jPOOBk1rfbvG/8A0L3h/wD8H0//AMh0fbvG/wD0L3h//wAH0/8A8h1V9vW/z0/yF/lb7zpK4K7tpfit8PfEGiazp50Sf7TJZACcT7HjKskmVAB5xkD0IzWz9u8b/wDQveH/APwfT/8AyHVXT08WaVa/ZrDwv4dhiLvIVGvznLOxZmJNpkkkkkn1qWr7/wBbalJtWa7nG6jF8V/EPhiTwZf+HdNtFuYRaXXiIaiskbRYw7LB9/cwz17nt23Ne8N+KvDj+Hr/AMASHUYNGsxY3Gh3F2YY7yIABXU/cWQY6nt+R6D7d43/AOhe8P8A/g+n/wDkOj7d43/6F7w//wCD6f8A+Q6d3v1/r/Nistun9f5I5rQNB8VeJ/iDZ+L/ABxpttocWkwSQ6bpUVyLiQPIAHlkkX5TxwAP0xz0tj/yVPXf+wLpv/o++o+3eN/+he8P/wDg+n/+Q65+zvPGP/CydZZdC0M3B0mwDxnWpgir515tIb7LkkktkYGMDk5ID6WDrc9Eorm/t3jf/oXvD/8A4Pp//kOj7d43/wChe8P/APg+n/8AkOkB0lFc39u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHQB0lFc39u8b/8AQveH/wDwfT//ACHR9u8b/wDQveH/APwfT/8AyHQB0lef+JrXxzoXjRvEPhK3/wCEj067t1gudDn1D7P5Lr0liZ/kXI+8MZPvnjc+3eN/+he8P/8Ag+n/APkOj7d43/6F7w//AOD6f/5Do63DpY5zwz4T8Q6v4q1bxf4ySPR76+0/+zbOxsbjzHsoCdxZpRw0m7kEcD+WZaS/F3RdFbwumhWWsyorQ2/ia41QBSh+68sTZkZgOvv69T2327xv/wBC94f/APB9P/8AIdH27xv/ANC94f8A/B9P/wDIdDs9On9f5sNb36mJbWtx8IvhLYWmm2J1ttPKrcf6QIM+Y5MkgyDwGbhQMngU3xv4e8SW/jXTPGvgu3t9SvLO1eyutLuJvK+0ws275HPyqwPc+3XGDp36eLNThjiv/C/h2eOOVJlRtfnxvQ7lJH2TnBAPPcCrX27xv/0L3h//AMH0/wD8h0223zPe/wCn/D/1skrK39b3OV0nRfF/ir4had4s8ZaNb6Bb6HBMthpsV2tzNLJIu1meRcLjHQcVy+lQ/EqDxjd+KPEHwxOtaozlbF5Nfto49Ph7JEnzYY/xPnJ9snPqX27xv/0L3h//AMH0/wD8h0fbvG//AEL3h/8A8H0//wAh0tmrdBvXcueF9S1rVdH+0eJNA/sC88xl+yfbEuvlGMNvQAc88e1U/hx/ySzwp/2BbP8A9EJR9u8b/wDQveH/APwfT/8AyHUfw5ab/hVvhXCIR/Y1njLn/nintTEYnjrxV/whfg+710Wf237MUHkeb5e7c4X72DjrnpXPf8Jl8Q9u9vhc2zGSV1+3Jx7Dbz9KPjln/hUGrY67oP8A0clYfifxP8WPCehpqN/a+FpbEFUmns4rmQ2ynjzGUsDgewP0rZytdv8ArRE20VvM9A8H+LLXxjof9oWsE9pLFK1vc2lwuJLeVfvIw/EH6HseK3q8rkR/h18E9a1vTdVGrajfk3z6iqgLJLOyqHUdMDIIHt+FcJLZadDowvdD8IfESLxYkYkj1t7OUtLN1y48wqUJ4I29PWqlKzs1ta/r1sJK6uut7H0fTZH8uJ3xnapOPWvGvHkeqat/wjWqeKvDurat4dbTg+oaZp+9JIbkgEtJGCCQOwyMEHJ9dT4VXfhyRNah8Ia5cyaeyK6aHeI4l04gENhmY5UnHTIBxzSlJpSXa/4CVtH3t+JufDb4m2PxEsrsx2v2C+tHxLaNN5h2H7rhsDIPI6cH8K1ZPFez4kReFPsefM003/2rzemJNmzZj8c5/CvHfDGjXulfC/w74+8NRF9S0n7Qt7br/wAvlp5771PuvUf/AFhXY6brNlr/AMdNL1bS5RNa3XhYyRt7eeeD6EHgj1FVe0kn0vf7m0/nb77obVub8PvSPU6xvFviKPwn4Tv9cmt2uUs4w5iRtpfJAAz25NeFaffaR4zW71vxh4R8Z+ILu5uZDbTadbSNb2kYYhUiKyAEjHJI6/jnS1u0u9c/Z91WXxbYamLvRLphpsuqxvDcGLcgR3GQGO1ypJyOPXms5Sfs21o7X/rzKUUpqL72/ryPc476L+y0vrl0t4jCJXZ3AVBjJyT2HrXO+DPH9h441DWo9IjJtNMmSKO638XG4ElguOACCBycjnil0jwR4dXwHZ6CdMR9LYJcNbSSO6s+Q+Tkkn5ucdPasjwDFHB8Q/HsUEaxxx3dqqIi4CgQcAAdBWz0qNf1ujFP3E/62Za17x/f23ia40Hwl4Yn8RX1nGsl7tukto7cMMqpdgQWI5x/ga2PB/i218X6TLdQW81nc20zW13Z3AxJbyr1U/4//qrgceJLr4o+I7z4ZpYpF+7t9Vk1gt5Elyi8eUE+fIU854J/Ctf4Rn7PDr9hqizJ4kj1Az6uJGUq0kgyrR7eNhUcDqOaim2/uv8Aj08v+AaTsnp3/T87no1Fed/HQOfhReiIhXNxb7Sex85cVj+JvhhYaD4PvPEum3+oReKbC2N2+rfanL3DqNzBlJ27TjGABxjr3OaybeyDlu1Fbs9corxnxHGPHXjD4dretJb22saXPLdxwSFC6NGjtHuHIBIAOO2areN4tO0LxFongWz0nXLjw5BZyXs+m6IHmmuS0hAVzuDeWCCTz3A9MNtrfu191/8AISs/uT+89vrA8OeKY/EWpa5axWzQjSL02ZZmz5rAAlsdhzXmXgtBY+PbbTvC/hbxXo/hrUbeWLULTVrWRYI3CkrIjFmKk4KnnnI/Cf4Y+END0zXPGt3Y2PlT6ffT2Vs/nO3lw7AduC2Dz3OT71Dk1r5N/c/6+/yGlfTzX4nstFePfB7wVps/gjSPFd28kmtJDKttdTSuUtUBdFUR5ClQOee5JzXJ6pb/AA7l0O+ljvtb8V+KYo5HbWbKO43LKMkMOfLVBx0zgd6qcuTfp/X9fqKK5tj3zU7zUrW6sE03Svt8U84S6l+0rF9ljx/rMH7/APujmtGvFZNQutV8OfCW91CZp7mXUojJK5yzkKRknueOtT2vg+w8Y/GTxtba7JcS6bbm0Z7GOdokmdovlZ9pBO3acDPenrzOK7v8Ev8AP+uiWq5vJfi2j2OivIvCkv8Awgmu/EHSdNkml0nRLWK9s7SaUuIiYWdlUnnBIH5VxWmx6TrWgxarrfhTx/qfiO6TzhrlpayYjc8qYcSBdg7fL09O08+l12v/AF9xfLbf+tn+qPpKsDxf4n/4RTTLW8+yfa/tF9DabPN2bfMbbuzg5x6d/WvO7zVvEWv+DvA+ga1JfaTfa7dPBqUhQ285ihDZGCMqXAU+/wBDiq3j34c6R4QsdGu/CxuLG3fWbRLu0Ny8kU/z/K5Dk4cEDkEcE023zW6XS/L/ADJ+z52b/P8AyPbKxNY8RjTdc0nR7W2+132pSMfL8zYIYUGZJWODwMgAdyQMjkjbrz/wlI2q/F7xnf3HzGwW20+3B/gTaXb82Oaf2kvn/XzsHS/9f1uybVPiFqT6/faT4M8Kz+IpdNYJezC8jtoonIzsDPncw7gdK1fCvjay8UaDd6gIJrCXT5HhvrW5AD28iDLA+2O9O13WtA8B6bNey28UEt7OWS2tIQJr64bsFUZdyccn8TXN6H4P10+BfE73n2e11/xO00zRNIfLtd67UQsoOdo6kDr+dTeXK7a6fj2/P8CrK6v3/Ai0j4jeNte0u31PSfhqZ7K5XdDMddhTcucZ2soI6dxXSeLvGqeGXsbG10241bWdRJFpp1sQC+37zMx4RR/e/oCRw174E8SeCfAY1ix8a6o+p6NZiQ2hcGxdI15jEWB/CMbjyevB6VZNV1zxL8YNMuPDhtrOe+8LxTLdXMZkFpG77nZU43NkhRnA9ab35V3/AEbXl0JW3M/61Xz6nc+G/HV3qXiJ/D/ibw9P4f1YwG4hhe4W4jnjBwSsigDI7iuyrzrSdW8T+HPHll4X8Yanb69a6zBK9nfLarbyK8a5eN41+XGO/wD+quI1Gzv9E8ZTfCnTr+GDQ9enW5ikMoElpA25pYFH+0Vwvse+SQcz0Xf87/19wWtdvp+R6l4s8anw/qFlpGlaVPret36s8FjDIsYCL1d3bhF7ZNQeGPHk+reIZvD3iHQrjQNajg+0rbSTLOksWcbkkXAOD1H+BxtNY+H/AA5ZrqMltY2EWn2ggW7aNVMMC/wb+u32z1rk/DEd14y8fHxxJbva6Pb2Zs9JWVdslyrNlpyvVVPRQeo54pr4rev/AAP0/EH8N/T/AII+9+IPiKbxRq2k+FfBf9uQ6VKkM10NVjtxvZA2Nrr2yRwT07Vt3Hi9tD8Dt4g8Y6a+jyxg+ZYxzrcvu3bUVWXAYtx9M89Ca5DTvhRrr3Wt3Wo+MdR0x7/UJbyCHRZzGi7jwZCVBfgAbeAMcHmuU13xRrmreDtCt75IdR1XTPFy6fKzDZHdSRZ8stjoCSM49KhN8qT3dvxaT/FlO12+mv4Xa++x3cPxM1azvLFvFfgu80PS9QmWCC+a7Sba7fcEsYAMeffpXU3XiMWPjCz0S9tvKj1CFns7vzMiSVOXiIx8p24YHJzz0xzxGv6h488A28XiTWvEFlreliZEv9PSwWD7OjkLuicEs2Cf4vy9NT4xsbb4enWbc4udJvLa9t3zghhIq/qGI/GqT0T87fl/nfQmzbsuu39fhqd9RTIpBLCki9HUMPxp9WJO6uFFFFIAooooAKKKKAIPh3/yKcv/AGF9T/8AS+euprlvh3/yKcv/AGF9T/8AS+euprle5sFFFFIAooooAKKKhu3aOyneP76xsV474qZPlTY0rux57efFPVr7VtQtvAfgm88TWmmStBd3wvI7WPzF+8sW4EyEd8d/YgnUt/Ht7r3gO38Q+CPDsutXEsvlSabPdpaSQFSQ4ZnyMqRjHfNea/CTS/iBrnwrsJvD3iOx8NWkbzGFf7PW6kvZPMYu0rOfkG7gbQTgfhXp3w08XXvi3w1cPrVvFb6tpl7Lp9+sBJjMseMsvsQQavlavHqv6+7y3Jvrdbbfn+P4HJav8WvHGg3Wn2+q/C7yZtSuBbWkS+IIJHlc9gqoTgdyeB3Ir1xSSoJGDjkeleX+Do28afFrX/F90S9horto+kKfuhl/18g9yTjPocdq9RoXwp99fl0/z+dhv4mu359f8jgdd+JN/F4ouvD3gnwrc+KNQsFVr8rdJawW24ZVTK4IL452/rwQNDwz8RNP17w1qeqahbT6PNozSR6pZ3XL2rIu48j7wxyCOteafD+z8a+IL7xknh3W7Tw5AviK6ae/axF3PPJuACBHIVUVQOeTk1u23jOSbwX440H4oKk8/h+Hyb6ewXb9shmQ+Wyr0Vz0x0BI6VF2qd+tr/l+Gvr1Ktedul7f1/VuhKnxo1KKxt9e1XwJqNh4SuHQJrD3UbOqOQFkeADcqHPXJ4xjORXY+OXWXwzZyRsHRtY0plZTkEHULfmvG9W0v4lx/CG2tPE8Nk/hK3jja8t7R/8AiaCyQghWYjyiQqrnbycfWvWvE13aX3gPSLvTGD2c+paPJbsO8Zvrcr+mK0aWvk/n8/67md9vP7vl/XY7CiiipKCiiigAooooAKyPFXifTvB3hu61vWXdba3A+WJdzyMThUUd2JIA/XA5rXryj483N5Bp3hFdPto7qV/EdtsglJCSOA2xWI7bsZpPdLu0vvY11fqW4PitrVle6e/jHwJfeH9I1KdYLfUHvI5tjv8AcEsagNFn36Gtjxh4/n0HXbTw94c0CfxHr11Cbn7FFOsCxQg43vIwIUE8D3HbIzy3iPUviJ8ObaHxRr3iSw17SFnjTUdNj05bf7MjsF3QuCWfBP8AF+XppeGCZv2hPGsk4+aPT7FLckf8sipJ/wDHqa1aXr+Cvb/hunoLa79Pzsb3gnx2viybUdO1DSp9E1zS3Vb3TbiQOUDDKsrjh1PrgfqM9FquqWeiaRdanqcwgtLSJpppCM7VUZPHf6VwEBZP2nbtYsBJPDCNNg9WFxhcj6Zo/aAnkt/gtq5jUsGkt1kUd1MyZGe2elJv3U11/wA7f8EqK99rt/lcpt8ZNYg09PEF98PtTtvCblW/tR7qMzLExwJGth8wXnOc4xzk103jjx3L4X0/Rn0TSRr17rV2ttZ2i3aweYChbdvIIxwOuBz1rkta/wCFpeHfDT+Lf7f0p4bKAXE/htNPVYUhUZZFnJ3lgvsBkfgb3ibwvq3xOvvBniPQtZ/sXTIbZ7qSWIn7UPPjXAjBXaDtyNxPGcgGqa1su/8AV+mtuhCel31T+/8APr1Oh8K+IvGOrapJB4n8C/8ACPWiwl1uv7Xhutz5ACbEAIyCTn296tWP/JU9d/7Aum/+j76uN0ldZ+HvxV0jw1ceI9S1/RfEEE7Q/wBrS+dcW00Shj+8xkqR24A/n2Vj/wAlT13/ALAum/8Ao++o0smv61DW7TOkooopDCiiigAooooAK4rxb8QpdF8QQeHPDegXPiTX5oftDWcEywxwRZxuklbhcnoMflkZ7WvD7GLxZq/xy8fWfhm/tdHYfYxPqk9t9okiQQ/IkcZIU5OSSTjjpS3lb5j2i2eg+C/Hb+Jr/UNI1jRbjQdd03a1zYTyrKNjfddJF4dfcVD4l+J+keH/ABnonhaLZfarql2kMkMcuPsqN/G/B56YXgkc5Heh4K8ReJLLx3qHgfxreW+qXcNmuoWWpwQiE3EJbYQ8a8Kwb0/XrWV478N6P4e17wT/AGLp8No154rjuLh0HzSyMshLMx5PJP07VS1lHs2vzt8iHdRl3Sf5XPWa5TxZ4g8XaRfwxeF/BP8AwkVu8e6Sf+1orTy2yfl2uCTxg5966us/X9Yt/D3h3UNYvP8AUWNu87jOMhRnH49KiTsrvoWld2Rwnhv4m+JdW+Ii+E9Y8Cf2VKkH2i7nTWI7kW0ZB2lgiYyxwAuQec4xSTfFbWdRub2XwT4FvPEWkWEzwTagt9HAHZPveUjAtKB7dat/B3Q7qz8IP4g1rL614kl/tG8dhyA/+rT2AQjjtk1e8S+JdI+H2l2+kaBpkEmq3pZdL0SwiWMzSHJLFVACIDks5wOveqleOj3/AF/4G3nuKNparb9O/wA9zZ8I+KtP8aeF7TXdI8wW9yD8kq7XjZSQysPUEGqvw4/5JZ4U/wCwLZ/+iEqD4a+FLjwb4GtdM1CVZr93e5vHT7pmkYswHsM498Zqf4cf8ks8Kf8AYFs//RCVUtxLY5j4j+Gbzxh4EvdF0yWCK5uGjKPcMVQbZFY5IBPQeldFNaw3Vi9pdxpNDLGYpY2GVdSMEEehFY32Pxj/ANB3Q/8AwSTf/JVH2Pxj/wBB3Q//AASTf/JVdHRq25nfbyOc8P8Aw6vbPwfrfg3XLuO60G4dxpskcrGeCJjkKwKgZU4I5POe3FVo/DHxPOmJ4fl8TaTFpiqIv7VgilXUPLHoPuBscZznvnNdZ9j8Y/8AQd0P/wAEk3/yVR9j8Y/9B3Q//BJN/wDJVK39eg7mXr/hvxVDqGn6j4L15Vmtbb7LNZaxJJLb3KjpI205EnqwGT6jnMXhrwdraeJ77xT4vvNPl1i5sxZRw6bGywQx5z1b5mJIHXpz17bP2Pxj/wBB3Q//AASTf/JVH2Pxj/0HdD/8Ek3/AMlUWvv5/juH9fcV/h14Zu/CXgKx0PVJIJri3Mu9oGLIQ0jMMbgD0Ydq5vwr8K5vCfxVvdd0+5g/sOa2eOC0Lt5kDOwYqoxt2ZBI579O9dZ9j8Y/9B3Q/wDwSTf/ACVR9j8Y/wDQd0P/AMEk3/yVVby5uoujRytv4O8b+Erq8tvAeqaPJo93O06W2rpKWtGY5YRlPvDPPP8AiTp3fgK/vvhfqPhvUNfuL/Ub8M8l9dZZRIWDYVc/KgwAAOn6Vr/Y/GP/AEHdD/8ABJN/8lUfY/GP/Qd0P/wSTf8AyVUcq5eX5fIfM+bm+ZP4Ug1628Pw2/ik6cb6L5A2nFzGUAAU/OM7vXtVHw54bvNH8XeKNUuZIGg1e4hlgWNiWUJHtO4EAA59Can+x+Mf+g7of/gkm/8Akqj7H4x/6Duh/wDgkm/+Sqttt3/r+tCbK1jnLvwj4u0DxLqep/D/AFDSfs2ry+fdWGrpJ5cc2OZEaPnLdwf14xseCPCN14ebUtS1y/XUdb1eVZbyeNNkYCjCIg/uqCee9W/sfjH/AKDuh/8Agkm/+SqPsfjH/oO6H/4JJv8A5KpRXLsN6nN/HRBL8KL2MkgNcW6kjtmZar3XhD4ga5p//CO634i0r+wWASa8toJBfXUQx8jg/IpI4JH65Irb1zwrr/iTS307WtV0O5tHdXaP+yLhMlSGByt2D1A71oCy8YgYGu6H/wCCWb/5KqVHe/V/ogb1VuhQvvB0z+O/C2q6cbeHTdEtp7doSzb8OgVAowQQMc5I/Gm+MfB+paprWn+IvCuoxafrmno0S/aULQXETcmOQDkDPcf4EaX2Pxj/ANB3Q/8AwSTf/JVH2Pxj/wBB3Q//AASTf/JVU9QWhmeH9D8YzeIk1jxprVqot4mjg0zRzKlsxbq8m/lz6A8DqKraL4S8RaH4v1+S3udMm0LWppLpw4kW5ilZMADA2lc/jW59j8Y/9B3Q/wDwSTf/ACVR9j8Y/wDQd0P/AMEk3/yVScU/xX3jTa/rsZ3hTwZc6T8KI/Ceq3MYnNrNbyz2rEhfMLcqWAPAbuK57T/BPj9PDA8J3Wt6Ja6JFAbdbqyt5PtcseMbSD8i5HBYAn6nmuy+x+Mf+g7of/gkm/8Akqj7H4x/6Duh/wDgkm/+SqJLmbb6ij7trdDlbT4eazF4e8C2M09j53h29E90UkcrIgzjZ8uScEdcV0Hh/wAL3uleP/FGuXEsDW2sG28hI2YuvloVbcCAByeME1a+x+Mf+g7of/gkm/8Akqj7H4x/6Duh/wDgkm/+Sqrq33/W3+QraW9Pw1M/T/Bs8fjrxXquoNby6drtvBAkSM3mAJGUfcMADOeME/hWDYeEfiN4c00+H/Dmv6NJoy5S2u76GQ3drGeyhfkYr2z+g4rrvsfjH/oO6H/4JJv/AJKo+x+Mf+g7of8A4JJv/kqp5Va3yKu/6+4yda+H89/4R0qxtdcuv7Z0aVbiz1W6YyyNKOu/JyVbJGOcDHXGDhaz4L+IPixdPPiTVdDhXT76G5jtdPWVY5QrZZnZgTuAyAoGMnJPFdn9j8Y/9B3Q/wDwSTf/ACVR9j8Y/wDQd0P/AMEk3/yVTtrfzv8AMXS3yOgrgdKh/wCEc+M2sQTHbb+JbaO7tWPQzQjbIn1wQ30re+x+Mf8AoO6H/wCCSb/5KqlqHhzxHqrWr32r6HI9nOtxbuNHnRo5BkAgrdg9CQR0IJByKOqf9f11+QdGjlrjwj8Rk+IF94ltW8KXcjkxWP8AaD3LtZwZOFQKoCkg/MeTnPODXSx6F4k8TeFdW0b4hHR1W8j8uFtH835R/ebzO4O0jHpzWj9j8Y/9B3Q//BJN/wDJVH2Pxj/0HdD/APBJN/8AJVTyrl5eg7+9zdTjpvBfxD1bR08Ma34h0ldBCiGa8tIJBe3MI/gYN8ikjgkfrzna8SeBbt7/AErWfBd3b6Zq+k2/2SFbiMvBPBj/AFT45AHUEf8A1xr/AGPxj/0HdD/8Ek3/AMlUfY/GP/Qd0P8A8Ek3/wAlVT19RLQw9F8JeJbjxSvijxreabcalZ27wafZacHS2h3D5mLOCxLdOhx78YzpPhXc6h4R1NtVu4D4sv7r7eNRiZtkE6E+SqEjcI1Hy9M8n2rrfsfjH/oO6H/4JJv/AJKo+x+Mf+g7of8A4JJv/kqlbS39b3/Md9f69DjvF/hHx/4muNCd38NzwafEstzZXck5guLoZBcqqAlRwQCe5yDXR+Hx8RRq0Y8Ujwv/AGbtbf8A2b9o87OPlxv+XGetXvsfjH/oO6H/AOCSb/5Ko+x+Mf8AoO6H/wCCSb/5KprRsT1OUh8G+OfC0l7Y+BdW0YaNeTvPGmpxSGayZzlhHtyGHcbvy6k3W+FVm3w7Hh06hMb4XP2/+1Cg8w3e7d5u368Yz0755re+x+Mf+g7of/gkm/8Akqj7H4x/6Duh/wDgkm/+SqXKrW/rTYd9bnKXPg7xz4ra107xzq2jf2JbzLNKumRSCa9KHKrJu4UZGTt/+uL/AMUkOsafpPhK25n1u+jVwBnZbxESSuR6AKB+Nbn2Pxj/ANB3Q/8AwSTf/JVUh4c8RjXG1f8AtfQzftALfzm0ec7Y87toBu8Lk8nAGcDOcCjt63/r7l8hefyOsAAAA6Clrn/sfjH/AKDuh/8Agkm/+SqPsfjH/oO6H/4JJv8A5KqriOgorn/sfjH/AKDuh/8Agkm/+SqPsfjH/oO6H/4JJv8A5KoGdBRXP/Y/GP8A0HdD/wDBJN/8lUfY/GP/AEHdD/8ABJN/8lUAdBRXP/Y/GP8A0HdD/wDBJN/8lUfY/GP/AEHdD/8ABJN/8lUAbPw7/wCRTl/7C+p/+l89dTXm/gOz8YN4YkNpruiRR/2pqIKy6LM53fbZtxyLpeC2SBjgEDJxk9J9h8b/APQw+H//AAQz/wDyZXK9zU6Siub+w+N/+hh8P/8Aghn/APkyj7D43/6GHw//AOCGf/5MpAdJRXN/YfG//Qw+H/8AwQz/APyZR9h8b/8AQw+H/wDwQz//ACZQB0lFc39h8b/9DD4f/wDBDP8A/JlH2Hxv/wBDD4f/APBDP/8AJlAHH2/gbx74MkvLD4c6tof9h3c7zx2+rxSeZYs5ywjMfDDPIDf4k9b4J8Hf8IV4TfTYbxr2+nkkurq8lXb59w/LPgdBnHHoKf8AYfG//Qw+H/8AwQz/APyZR9h8b/8AQw+H/wDwQz//ACZSt7tvl8ht3d/n8yv8MvCd34L8BWej6pLBNfo8stzNAzMsjvIzZywBPBA5HarGpaxq1p8QdE0q3WxfTL6Cd5wwc3KNGMhhztCZZQcgnLCj7D43/wChh8P/APghn/8Akyo/7K8ZfaftH9ueHPO2bPN/4R+bdtznGftmcZ5xVN3dybaHPX3gnxf4d8U6prHw11HR1h1mUT3unazHJ5SzYwZEaP5snuD3/AB+mfClZvCPiKx8Waj/AGhqvidvM1G8hjCKjAfuxGp7JgYz1x+FdF9h8b/9DD4f/wDBDP8A/JlH2Hxv/wBDD4f/APBDP/8AJlTZWt8vkVd3v8/mcRceC/ipqug/8Ipq/iXQRobILefUbeCX7fPB0IKt+7BK8Eg59zzXW+KNOttH8DaVptihS2s9T0eCFSc4Rb63A/QVa+w+N/8AoYfD/wD4IZ//AJMrn/Gln4xXQbY3Wu6HIn9raaAseizIQ326Dacm6PAbBIxyARkZyKu/vJsj0Siub+w+N/8AoYfD/wD4IZ//AJMo+w+N/wDoYfD/AP4IZ/8A5MpDOkorm/sPjf8A6GHw/wD+CGf/AOTKPsPjf/oYfD//AIIZ/wD5MoA6Siub+w+N/wDoYfD/AP4IZ/8A5Mo+w+N/+hh8P/8Aghn/APkygDpK5vx34Og8ceGG0uW5ezuI5UubS7jXLW8yHKuB37gj0J6UfYfG/wD0MPh//wAEM/8A8mUfYfG//Qw+H/8AwQz/APyZSauNOxx914H+IHjBrTS/iDrGh/2DbTpPMmkwyrPflDlVk3/KgyATt/wI1vFvg3xEfGVv4u8A6hp9rqwtPsV1a6nG5t7qLduXJT5gyn068DI5ztfYfG//AEMPh/8A8EM//wAmUfYfG/8A0MPh/wD8EM//AMmU/wCv0/LQX9fr+Zm+BvB2r6Rq+q+I/F+o29/r+qhI5PsistvbRIPlijDckZJOT1+uSWWNrc/EbwNr2jeMVs9kl5PYiTTd2wqjDa6lySWVgc9sr0rV+w+N/wDoYfD/AP4IZ/8A5MqODSvGVtCIrbXPDkMa5wkfh+ZVGTk8C89aTSas9rW/r+uo02ndb3v/AF/XQ4y58DfE3VtDHhLWPEuiHw8yCCa/t7eQX80A42FT+7BIGCc5+vfb8T/D7UPtuh614CvrbTdX0O2+xwx3qM9vc2+APKkx8wxjORz+hG59h8b/APQw+H//AAQz/wDyZR9h8b/9DD4f/wDBDP8A/JlPXfr/AF/wfvYtDD8M+C/Ec/jJPFvxC1KwutStYGt7Cy0yN1trRW++4L/MzN056c9eMblj/wAlT13/ALAum/8Ao++o+w+N/wDoYfD/AP4IZ/8A5Mrn7Oz8Y/8ACydZVdd0MXA0mwLyHRZijL515tAX7VkEENk5OcjgYJL6WDrc9Eorm/sPjf8A6GHw/wD+CGf/AOTKPsPjf/oYfD//AIIZ/wD5MpAdJRXN/YfG/wD0MPh//wAEM/8A8mUfYfG//Qw+H/8AwQz/APyZQB0lFc39h8b/APQw+H//AAQz/wDyZR9h8b/9DD4f/wDBDP8A/JlAHSV5/wCJPBPiG38ZyeLvh7qOn2up3dutvf2eqRs1vdKv3GJT5lYDjjqPTnO59h8b/wDQw+H/APwQz/8AyZR9h8b/APQw+H//AAQz/wDyZS63HfoZfgvwZq+n+ItQ8V+M9Qtb7X7+FbbZYoy29rApyI493zHJ5JPP6k3PGvha98R6n4XuLGW3jTR9XjvpxMzAtGqsCFwDluR1wPerH2Hxv/0MPh//AMEM/wD8mUfYfG//AEMPh/8A8EM//wAmVXby/wCHJte/n/wweO9Y1bQfC7ahoC2L3STxIUvg5WRWcLtUKQS5LADnGag+JnhnUvGPgC/0HRriC3uLxo1Z53ZV2CRWYZUE8gEdKfLpXjKfZ5+ueHJPLcOm/wAPzHaw6EZvOCPWpPsPjf8A6GHw/wD+CGf/AOTKn17/AORV7O6N+KEW1mkFuiqsUYSNOgGBgD2FeN6H4L+Leha9qetxv4IvdU1OTM17evdvIqfwxIVUBUGOgHpnOBXov2Hxv/0MPh//AMEM/wD8mUfYfG//AEMPh/8A8EM//wAmU/tcwtOXlLnhf/hJf7H/AOK0/sr+0vMb/kE+Z5OzjH+s+bd1z26VT+HH/JLPCn/YFs//AEQlH2Hxv/0MPh//AMEM/wD8mVH8ORN/wq3wrh0A/sazxlD/AM8U96YHOfEjxNe+D/Ad9rWlxW8tzbmMIlwrMh3OqnIBB6H1rGD/ABh2B9vglxjO0G7BPtzxR8cv+SQatjj5oP8A0clc/wCLtO+KHhrw22q2vjptUtYAGu4otHt4pY4f4nTruIHOMj1zWzdk2+/6Ii2iS8zvPAniyXxZos8t9ZfYNSsLp7K+tg+9Y5Uxnae4OR+o5xk6kfiTQ5tVOmQ6zp8moAkG0W6Qygjr8mc/pXnF+LHwl+z1qeo+DL24uhexfaDfytmaV5nVHkY9mAJ+hHrzXNT+FNZuvB0em6Z8H7azuVhU22rRa3bfaEkHKy7wAxOecZx2qpSabVtrX9etiYpON+97f18z3PUdV0/R7X7Tq1/a2MGdvm3Uyxrn0yxAottTs9Q043ul3dveQFSUlgkEiNj3U4ry7xX4Z8UXl14a8Q3fh2z8TPZaZ5N/o13KgCTEAvIucozdu/QYB7T/AA3vtA/tzXrbT9H1PwzqtzbrcXOiXcYSBAuV8yEBRwcjPTPGBSk3aS9fw/q410foW/hP8U5PHcdzZ61bwWeqw5ljSFWVJ4c7d6hiTwwIPPp746CXxRep8WofC4ig+xSaQb4yFW8zeJdmM5xtx7Z968v8M+Gr27+DPh3xR4ZXb4h0OS4lgAH/AB8xefJvhPqCM4H1Het3w74msvFvxq0rWtNP7qfwwxaMn5onE53IfcHj9aq9pJPpe/3Oz/rqDVlJ/wBbpf15Hpeo+ItE0i4jg1bWLCxmk5SO5ukjZ/oGIzWV8QPGEXgzwbd6uklq1yqD7LDPKFE7kjgDOWwDnA7CvIfCEera9pt/rFz8LrXxVPqV3M0uo3mpwIwwxXYiSKWjCgY4x0+mNDVfD+p2H7POu2vivR1tZbC4Z9LhuJo7p7WBnTaFkGemWXPBx7VlKUvZt7aXLUUqij52PWYvFuir4TTxBdatZCwWMGW5jmDRhu6ggnJzxjrnisXwB48n8banr4Ni1nZ2E0SWqyxskzoyE7nBPfAIwBwR161u6LoulQ+GLGyh0yzjtRHHKIFt1CB8Bt23GM55z1zzXNeBv+Sk/ED/AK/bX/0RW8lao16/mjBP3E/62Y3VvFvivU/GGoeH/AVjpTHSUjN7eas8nl73GVjRU5zjv069OM7HgXxbN4p028XUbIWGqabdPZ31urbkWRe6t3BH+e9cVHpmteLfiR4i1PwZrK+F4rOQadeXCwi5a+mQD5jGxCrtBwG6/nWv8Js6W/iDw1fxq2sadeCa+vFkZxemZdyyktyCQMFe2Pes6bb37X/Hf0t/XU0npt3/AE/zO+vb+0021a61G6gtLdSA0s8gRAScDJPHJIFVV8R6G2rf2Wus6edQzj7ILpPNz6bM5/SuQ+OWR8IdV2kg74MEdv3yVz/xO8CeG9A+EFzd6VpNtb39gIJIr6NAJy/mICzSfeYnJ6mnzPfpe35DUbtLuetXl7a6daPdahcw2tvGMvNPIERR7k8CobDWtL1Wze70zUrO9toyQ81vOsiLjk5YEgV51r9jB4s+L2gaJr4Nzplto7aiLVyfLnn37csOjYHOD/U5W90TTfCvxo8OReHrOGxttctbqG/s7dAsUixpuVig+UcnHT+fL1vbvf8AC/8AkTpa/o/6+TN3wX8QbTxZrmuWC3enk2V20VmkFwHe4hUDMo5+YZPUDFdfc3VvZWslzeTx29vEpeSWVwqoo6kk8Ae9eafCnRdLtfE/jSa102zhlttZkggeOBVaKPaPkUgcL7Diuo+Jf/JLvEn/AGDpv/QTUc1qSl5X/ApRvPl8/wBTUbxPoC3kFo2uaaLm5VXghN3HvlVhlSq5yQR0I61cutQs7FoVvbuC3M7+XEJpAnmNgnauepwCcD0rzfw38MfCl98KbJb/AE23urm809J5dQkUGfeyBsrJ1AHAABxgfWuRuppvFfwu+GqazI8v2nWUtZnLENLGDJHyevzIME+9aO6k49bpfe7EJpxUuln+Cue32Wu6TqNlLeafqlld2sJIknguEdEx1ywOBSaZr2ka35n9jarY6h5WBJ9kuUl2fXaTivLvijpsOlzeF/DXhzw3bz2Go30k9xpdpIlml48aLtVnxjHc567R3qvBoPiY+MtB1PR/hlbeFTa3Srd3FlqdsVltm4kV40C7uOc8njipjK8rdL2KkrK/z/P/ACOz0n4iWOp/ErVPDa3um+RaxRC2dLlS9xKcl0HPJXGCByOc10TeJ9BSaKJtb05ZJpWhiQ3ceXkU4ZAM8sDwQOQa4Lw1oWkx/HrxS0el2SNbWtrNAVt0BidlO5l44Y55I5NVvhR4Y0e/n8RavqOn295exeILlYJriMO0AR9w2Z+78xJyMUqbbUb+b/GwSsm7eX5XPRtR8TaFpFytvq2t6dYzsMrFc3aRsR7BiDUHiXVLqy0FbzSL7R7d3ljCz6rMUt2ViM4ZT94j7vqa8utx4VubnVo9C8Cap42ubm7lM2q31vEY3kJwypO+NoXoNoGOOvWsC1kkb9muGOUMoh1xY0jL7vLUTg7QfYk0RlzNfL8Wl+opLlTfr+T/AMj3651rS7KaWG81Kzt5YYfPkSWdVZI843kE8LnjPSjTNY0zWoGm0fUbTUIlO1pLWdZVB9CVJrzXWvD+neI/2ioLfWbdbu2g0EXH2eQZjkYTEDcvRgNxODxUunaPp/hz9oU22hWkWn2134fM01vbIEjZxNgHaOBwO3v601LZvrf8L/5DkrXt0t+Nv8z0DUfEWiaRcRwatrFhYzScpHc3SRs/0DEZrRDKV3AjbjOc8Yr578IR6tr2m3+sXPwutfFU+pXczS6jeanAjDDFdiJIpaMKBjjHT6Y0by08R6H8GhoWu202kRXmuR2MUZvFnaCxkcHZ5iE5A+Zee3bFJSbX3fjZfr+Y5JJ27X/D/hj0TxV4+0/TvCOtah4c1PS9R1DTYPMNutwsu07gPnVGyBz7V1NlM1zp9vO4AaWJXYDpkjNeV/FX4d+F9N+FmoXOk6Ta6bc6fCrQ3Fsmx2G4KVdhy4IJHzZ65r1DSv8AkDWX/XvH/wCginHVyv0t+v8AXyJfT5/oZHizxDcaQdO0/SI4ptX1W4EFqkoJRFHzSSuAQSqrzgEZJA71j654t8R3fi+fwx4FstOlvLGBJ7681R3EEW/7qBU+YsRz6VXhZr39oa4WY5TTtBXyF/utJKNzfXAxXT+KPFmneE9OW41AySzzN5drZ2675rqTsiKOSeR7DNF/dUn5/nb81f8AAfVpf11/LT8TI8GeLtU1XWNU8P8AinT4LLWtLCPIbVy0E8bjh0zyB7H1+oGDpPiX4leK1vNQ8MxeFY9KW9mgtWv1uRLIiOVDHaSDnHXjvwK2PCegajaPrfirxVNDZ6tq8YLRhsx6fAinYhY4yQOWOQMj8a5rSfgl4ZXwdHKur3OpXyRtLZ6zb3TIsWSWUxKrFQuee+Tk59FK61l0Wv8AXp8r3sCs9F1f9fj+B13ibxbqPhjQdKhewh1LxLqbJbQ2ds5SF5tuXbc3IjXrzz06ckVNJ1zx5YeIrKw8Y6Lp9xZ3+5UvdDEzrasBkCYPnAPTdwK84TV9f8V3PwwuV1AWd/dw3sDXzxhyrL8jSKDwXKrx7mutv7PV/hx4p0Ce28TatrWnaxfrYXVnq04nZWfO2SM4G0DHI/yK15r+dv0/pie1vK/9f13PSrPVNP1FZzp99bXQt5DFMYJlfynHVWweCPQ1y3ifx6llaaVF4TW11vUdauGt7EJcAwfL992dc8L3A5rzr4pj/hGvHbx6Lqw0638UW6x64qoX+zR+YqfaeOFyGK5Pqe5yPY4v7H8JeF4x5sNjpWnwACR2AVEAwDnuT+pPvSTvHmen/A3/AK/yG1aVl/Xb+v8AM5LT/F3i3RfF2maJ490/SvL1culnfaQ8nlrIozsdZOcn1/nzh2ueJfGN34/uvDvgiLQyljZRT3UuqrNw7scKDGf7oBxj15qPSIL34geL9P8AFV5bSWOgaUHOlW867ZbuRhg3DKfupj7o6nr3qCT4XeG/FPjLX9W1nVv7ZS4lSOTT7ecxpauiBQJNj5ZwOmcYyeOaPedr+f3dL/12vqGmtvL7+v4HRQ63rXhvwdqOsfEI6WJLPdKBpAk2NGAML+853lsj05Fc2PFXxNTTY/EEvhfS5dKk2yHS7aSV9QWJu/8AcLYOcAZ9hXDeJpb3R/AXjzwpFdT3thod5ZG1e5feyRSMreUW7hSBx711/iDw14k0bwpP4tg8dapJq1nb/a5IHkX7BIqjcYxCBgDHAOT+vEuWjn0Vvyv8/wDgDs9I9df6/rujsvEXiW40CTSL+WFf7GuplgvXkRlltjJgRuecBd3ysCMjcDnjB6WuL8TXCeJ/gjqF7cQ+ULzRWuvLI+43leYPyIFbHgq9l1LwHod5c5M0+nwu5I6sUGTWtmnKL6frf/L8SN0n3/S3+ZuUUUUgIPh3/wAinL/2F9T/APS+euprlvh3/wAinL/2F9T/APS+euprle5sFFFFIAooooAKKKKAPNLvxL8TtUu7+78K+G9KttJspnjjh1szRXd8E6tGowEDdFL+xrQPxLhuvgrceO7K38llspJUt7jLBZlJTYcYyN4xkYyPSrfirT7/AMd+G/L8E+NI9LhfzI5rmyijuRN2Kbw2UIOclTn8q4LTLbT/ABl8DLjwde3lj4QOn6kNHuHVt8TzRSK2I97gkucHkk5J60rNxceun+Tf4rT7itFJSe13/wAN+D/Xy6fQrn4w3sunXWqR+C4tPnMUlxHELsTpEcFgAcrvAJ68Zr0avDvHvgHS/hd4dj8aeD7jULbWdPuYPtE0t5JKdRRpFVklDHBznPGP8PcFbcgbGMjOKt2auu/+Rmrp69jznWfGXi/V/Geo+Hfhvp+kSHR0j/tC+1h5PK8xwSsSCM5JxyT06jjgm74a+IV1qnhPWbvVNDuYtb0GV7e+0uzVpmklUZXysDLBwRj+o5rP+FG5PEvxChuDm5HiKR2GefLZAY+PpUHhG+tdN+K3xN1G/u7e006KaxWS4ncRxo4hIbLHAHUDrULWNu8b/PT/ADLe7fZ2/Nf8ErX3jz4jeF9Mh8TeMPD+iJ4eZ4/tFrZTS/brJHIAZ93yMQSAQvOT25rtfHRDeG7QjodZ0oj/AMGFvXG/F3w9rl9pcviOHWodR0LSwl+/h2aHZDdLGNxJmRgzdNwByuQOK6TX9Vh134d6Lq1sjRw32oaNcIjdVD31swB/OqWsX5P8On5Ml7rzX9fmjs6KKKQwooooAKKKKACsXxbrl34e8Nz32maRdaxegrHb2VshZpHY4GSAdqjqWPAAraqtfalY6XFHJqV7b2ccsixRtcSrGHdvuqCTyT2HU0ho86Txn478L65pEXxC0vQ20zWbtLKG40aWUvazP9xZBJ94HpleBgn0B0PF3jLxEnjO28IeA9P0+51d7Q31zc6pI629tDu2jIT5mJPp044POOa+Jun6z4Z1qy8eazqqa/oek3yyLo0sHkizDsEEsbIf3jrkY3g9T07P8S2Wp+MfjQYPBeop4d1HQbBBfazs855UmyyQeSflZRjdljwT7DLWqXq/yv8A1924NWv6L87f15nVeBPGeq6zq+r+HPFmn29jr+jmNpvsbs9vPHIMrIhPI+h5/UDtWZUUs5CqoySTgAV5R8N7e78MfE/xD4d8TTrqmvX9umpf20CQbuAN5YRo+kZUngLxg+wr1dlV1KuAysMEEZBFD+FPyF9po82svi5ba98VtM8NeG4lu9KmiuDPqZRvLlkjXO2F8gMF/iPI5GPU6vj3xlqmhaho+g+FdPt77X9aeQWy3chSCFI13PI+OSBkcDBPP0OTrtrb2Xx08B21lBHbwRafqCxxRIEVBsXgAcAVU+JsF14l+Ifhvw34clTTdetYpNTXWSxLWUGQjKsY4k39CrcYHvwdIed/wb/y+7zDW8vL/JfqzX8KeM/EY8bS+D/H2n6fb6q1p9ttLrSndre4iDbWGH+ZWB9evPTjO3Y/8lT13/sC6b/6Pvq4Hw/Y6p4P+N1rF411JfEl/wCILGSHT9X8vyGgWIB3hMC5RVPXcO/1Nd9Y/wDJU9d/7Aum/wDo++p/ZT/rdi+01/W3+Z0lFFFIYUUUUAFFFFABXE+Kde8aP4jXQ/Ami2bNHAJ7jVNZWVLRcnAjQoMu/c4PHeu2rJ1O4/tSG/0fQ9egsNYjjUl4xHPLahuQzRMe4zjcMUmMwvAfjHUtevdY0PxPp8Nhr2hyRpdi1cvBMsilkkjJ5AIB4PI4+g5jRvFXxU8YLfal4Uh8IR6Ol/Pb2jait0JZEjcqHOwkHOOvHIPAqPwILnwd458TeFfEN5Ddald2f9sN4ibKNPHnZ+9VmITYegUhdo7VU0b4B+FF8ERTLrV3qmoJE81lrltdvGsJJLK0Kq5QLnnvk5OeeBuy5ntb8ev5PsFteVb3/D+mu/mewab9u/su1/tj7P8Ab/JX7T9l3eV5mPm2buduc4zziuQ8Z+M9ZsfE2n+E/BlhaXmvX0D3TSX8jLb2sKnG99vzNk8ACpvhL4gvvE/wr0TVNVcyXkkTRyykcyFHZN/4hc5963vEfiTSvCmiy6rrt2ttax8ZPLOx6Iq9WY9gKqouWTuTDVaHJeFvGniVPHDeD/H2m6fb6lJaG8tLzS3c29wgbDLh/mDD39O3Gc+TxV8RvEPjHxDY+BofC66Zo10lp52rLch5JNgZwDGcHBJHQdutXvB+j6t4g8ZS+P8AxPaNppe0+yaTpco/eW0BbcXl9JG9B0HB5rD0j4JeD9fGr6nqusyeJf7R1Ce6imtLpo4bV2b5tgjcguDwSc/dHAxS1ur9n+en4fiPTW3dflr+P4Hpvh7+3P7Dg/4Sv+z/AO1fm8/+zd/kfeO3bv8Am+7jOe+azfhx/wAks8Kf9gWz/wDRCVg/BrVNQvfCupadqt5LfyaJq1xpsd5MdzzRxkbSzdzg4z7VvfDj/klnhT/sC2f/AKISm+666/eJX2ZgeOfC3/CZ+ELvQ/tn2L7QUPn+V5m3a4b7uRnpjrW8Ix5PluAy7dpBHUVhf8I5qn/Q6a5/35sf/kaj/hHNU/6HTXP+/Nj/API1dPSxn2Mrw98N7XRNH1vQbi8+3eH9Tld4bB4iptFf7yK+45HQjgYIz1NZI+FWsvp40O68eajN4aA8s6f9ljEzRD/lmbj723tjHTiur/4RzVP+h01z/vzY/wDyNR/wjmqf9Dprn/fmx/8AkalZdv6Q7sy9f+Hv2zUNP1PwtrE3hzU7C2+xxTwwrMjQdo3jY4YDHHP58Yl8NeBZtJ1S81rXtcn13W7u3+ym8kgWFIogc7UjXhecE8847c5v/wDCOap/0Omuf9+bH/5Go/4RzVP+h01z/vzY/wDyNRb+vXcVw8D+F/8AhDPB9noX2z7b9mMh8/yvL3bnZ/u5OMbsde1YuifC+x8P/E6+8W6bdeVHewsj2Ah+VXYqWYPnoSuduO557Vtf8I5qn/Q6a5/35sf/AJGo/wCEc1T/AKHTXP8AvzY//I1V9rm6h0aOdm+GmqadqV7N4I8YXPh60v5TNcWX2OO5jDn7zR7iNmfb+gFaI+G2lp8O73wnHcXPl3wZ7i8kbfNLMxDGRiepyBx6D8a0f+Ec1T/odNc/782P/wAjUf8ACOap/wBDprn/AH5sf/kao5Vy8ttNvkO7vcseF9K1PRdCjsda1n+2biI4W5+yrB8mAFXapI4x171Bofhj+xfEniDVvtfnf2zNFL5XlbfJ2JsxnJ3Z69BSf8I5qn/Q6a5/35sf/kaj/hHNU/6HTXP+/Nj/API1Xd3uTZWsYuq/DzUB4jvNb8G+Kbjw7c6hg30f2RLqKZgMBwjkBW9T/Lmtfwf4Ot/CVpdH7XPqOoX0vnXt/cn95O/QfQAdB2p//COap/0Omuf9+bH/AORqP+Ec1T/odNc/782P/wAjUkrbDeu4njnwt/wmfhC70P7Z9i+0FD5/leZt2uG+7kZ6Y60vjTwv/wAJf4LvNA+2fY/tSoPP8rzNu11b7uRnO3HXvR/wjmqf9Dprn/fmx/8Akaj/AIRzVP8AodNc/wC/Nj/8jUW0sNNpp9ij4q8Bp4h/s68sNTn0jWtLG201G3QMVBGCrIThlPoT+hIMfhvwFNpviFvEPiXXZ/EOteSYIriSBYI4IyeQka8Anuf8TWl/wjmqf9Dprn/fmx/+RqP+Ec1T/odNc/782P8A8jUbO4uliho3gm80HxtqWr2GvONM1OVri50uS1VszEY3CXOQPbFT/Ev/AJJd4k/7B03/AKCasf8ACOap/wBDprn/AH5sf/kaornwle3trJbXni3WLi3lUpJFLbWDK6nqCDbYI9qmUbw5F2sVF2lzM4nw78ONYvvBWmWdt441G08P3llE82nJbxtIA6AsqTn5lUk9MHjI5rr9W8BWl7a+GrTTp10+18P3sV1FEsW/zFQEbM5GM5+9z9KsQeFb+2t44LbxfrMUMahEjjt7BVRQMAAC24A9Kk/4RzVP+h01z/vzY/8AyNVu17pdb/dt9xmlpZ9rf5ieMPB9n4x02GC5nns7q1lE9ne2zbZLeQdGB/mP64NYunfD3U5dcsdS8Z+LLjxEdNfzbK3+yJaxRyYwHZUJ3sOxPStv/hHNU/6HTXP+/Nj/API1H/COap/0Omuf9+bH/wCRqSVncp6qxQm8E3kfxFPinSNeeyS5SOPULJrVZVuVTgAOSCnHcZ/pV3wf4U/4RS01OA3n2v7fqM19nytmzzCDs6nOMdeM+lO/4RzVP+h01z/vzY//ACNR/wAI5qn/AEOmuf8Afmx/+RqSSSsl3/HUHrv/AF0OYsfhbqulJLpeleONRs/Dkkjt/Z0dtGZUDHLKtwcsoyew9e5zSp8JUh+H83hWDWNludT+3Qym2yYkDhhGRv8Am6Y3Z/Cum/4RzVP+h01z/vzY/wDyNR/wjmqf9Dprn/fmx/8AkahK39ej/QHrv/V/+HGjwpj4knxZ9s66Z9g+y+V/00379+fwxj8aJPCm/wCJEXiv7Zjy9NNh9l8rrmTfv35/DGPxp3/COap/0Omuf9+bH/5Go/4RzVP+h01z/vzY/wDyNT2t5frf/Nhvfz/S3+Rzs3w01TTtSvZvBHjC58PWl/KZriy+xx3MYc/eaPcRsz7f0ArUg+G2hx+A7jwrP9ouba7Zpbm5lkzNLMTuMpb+9kA9O3er3/COap/0Omuf9+bH/wCRqP8AhHNU/wCh01z/AL82P/yNSUUlaw7u9zkNT+E+ua9ok2keIPH17qFkExaxNZImxh91pSrBpsehI55r0m0g+y2cNvu3eVGqbsYzgYzWL/wjmqf9Dprn/fmx/wDkaj/hHNU/6HTXP+/Nj/8AI1NaC3MPxHAPD3xO0XxUwIs76E6Pev2iLNuhc+xf5c9sj1qvr3w58Q6n48k8T6X4zXTZhEILaJtJjuPsyYG4KXfAJOSSADzjpW9d+ELu/tJLW/8AFmr3NvKMSQzWtg6OPQg22DUo8N6oBgeM9cA/642P/wAjUrfhf8f6f3jv/X9fL7iv4e8PeJbKa5HirxaviG0nhMYtm0uK2Ck9SShOeMjB9a50fCfVLezk0XTPHOo2fhmRiDpq28bSqjHLIs5+ZV9sdOucmur/AOEc1T/odNc/782P/wAjUf8ACOap/wBDprn/AH5sf/kaiy7f1+or2Kms/D3SdT8M6dpFm02mHSSj6ddWrYktnUYBBPXPfPX681Q0n4e6gfEFnq/jLxRceI5tOybGJrRLaKFj/GVQnc3oT0/LG1/wjmqf9Dprn/fmx/8Akaj/AIRzVP8AodNc/wC/Nj/8jU+vMHSxQsvh9aMviGTxBcDVbrX2K3E3k+V5cOMJEg3HAXrnOScHtWDqvwr1zVPCuh6JL4z+TSJC4kk0xZRcYI8oOjSbW2DI5yD3Fdb/AMI5qn/Q6a5/35sf/kaj/hHNU/6HTXP+/Nj/API1LlXbt+Gw7/16mTpfhfxzaapbT6l8RPt9pHIGmtf7Egi81e67wcrn1FR6v8PdQPiK71rwd4ouPDlzqGPt0YtEuYpmAwHCMRtb1P8ALnO1/wAI5qn/AEOmuf8Afmx/+RqP+Ec1T/odNc/782P/AMjU7CKmjfDzSNL8LX+i3bTan/ahZ9Rurp8y3LsMFie2O2On1yawD8KtWuLOPRdT8c6jeeGkKj+zTbIsjovSNpx8xXjGMdPSuq/4RzVP+h01z/vzY/8AyNR/wjmqf9Dprn/fmx/+RqVk3ew7u1jJ+JDNF4Lj8M6Mipea0y6baRIOEQj52x/dWMMT6V1un2UWmaZa2NvnybWFIUz12qAB/KsF/B91Jex3knivVmuokZI5za2BdFbGQG+zZAOBkd8Cp/8AhHNU/wCh01z/AL82P/yNTV9W+v8AX+f3i008v6/y+46Ciuf/AOEc1T/odNc/782P/wAjUf8ACOap/wBDprn/AH5sf/kamBs/Dv8A5FOX/sL6n/6Xz11Neb+A/DmqT+GJHi8Z63br/amorsihsSCRezAt81sTliCx5xknAAwB0n/CL6v/AND34g/78af/APItcr3NTpKK5v8A4RfV/wDoe/EH/fjT/wD5Fo/4RfV/+h78Qf8AfjT/AP5FpAdJRXN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi0AdJRXN/8Ivq/wD0PfiD/vxp/wD8i0f8Ivq//Q9+IP8Avxp//wAi0AczP8K9Y07Ur5/A3ji88N6bqMzT3OnrZR3KrI33jEzEGLPtnn6ADV/4VT4e/wCFct4OP2n7Izec135n+kGfdu87fj7+e+MY46Vo/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItHSwdbnM2vwq1a+1Kwk8deN73xLYabKs1rYNZpbIZF+60pUky49+/sSD0ep3Orr8StEtrHUW/s2S1ne9sRbKRhQAkhlxlfmZQFGM4J7Gn/APCL6v8A9D34g/78af8A/ItH/CL6v/0PfiD/AL8af/8AItO4rGL4i+G+o3Xiu48R+DPFlx4Y1G+iSK+22iXUVyEGFYo5ADAcbvT0yc3dB+Gmj6R4M1Dw/evNqq6s0kupXVyf3t1I/wB5yR07Yx0x681d/wCEX1f/AKHvxB/340//AORaP+EX1f8A6HvxB/340/8A+RamytYq7vc5AfB/WbnT49B1j4g6nf8AhaPaq6Z9kjjleNT8sb3A+Zl7HgcemBXV+NLeK08J2FvbRrFDDq+kpGijAVRf24AHsBUn/CL6v/0PfiD/AL8af/8AItc/408OapDoNs0njTXJwdW01QkkNiACb6ABvltgcqSGHbIGQRkGrsmyPRKK5v8A4RfV/wDoe/EH/fjT/wD5Fo/4RfV/+h78Qf8AfjT/AP5FpDOkorm/+EX1f/oe/EH/AH40/wD+RaP+EX1f/oe/EH/fjT//AJFoA6Siub/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWgDpKxfFvhXTvGfhu40bVxIIJsMssLbZIXU5V0PZgaq/wDCL6v/AND34g/78af/APItH/CL6v8A9D34g/78af8A/ItJq4HMQfCrWNSu7JfHXji88SaZYSrNBp5so7ZXdfumVlJMuPfqfqa0/FXw7udV8TJ4m8K+I7nw1rvkC2muI7dbiK4iByA8TkAkdj/gMan/AAi+r/8AQ9+IP+/Gn/8AyLR/wi+r/wDQ9+IP+/Gn/wDyLTApeDPAB8Nanfa3rOs3Gv6/fqI59QuIxGFjHIjjjXhFzzgVa8B3Or3Wj30mt6i2pEajOlrdG2WDfCrbVwqjoCGAPORg55p//CL6v/0PfiD/AL8af/8AItH/AAi+r/8AQ9+IP+/Gn/8AyLR/lb+v66sP8/6/ryF1Pwn/AGj4/wBD8TfbfL/smC4h+zeVnzfNAGd2flxj0OfaqfjXwCPFN9p+r6Xq9zoWvaZuFpqNugkwrfeR424dT6HH8xVv/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWjt5f1+od/MyfDPw6utO8T/8JL4u8SXHibWY4jBbTSW6W8Vsh+9siQkBj0J71rWP/JU9d/7Aum/+j76j/hF9X/6HvxB/340//wCRa5+z8OaofiTrMQ8aa4rrpNgxmENjvcGa8AU/6NtwNpIwAfmOSeMHSweZ6JRXN/8ACL6v/wBD34g/78af/wDItH/CL6v/AND34g/78af/APItAHSUVzf/AAi+r/8AQ9+IP+/Gn/8AyLR/wi+r/wDQ9+IP+/Gn/wDyLQB0lFc3/wAIvq//AEPfiD/vxp//AMi0f8Ivq/8A0PfiD/vxp/8A8i0AdJXEeKvh5c6t4kj8SeFvENx4a10Q/ZprmK3S4juIs5CvE2AxHY5498DGn/wi+r/9D34g/wC/Gn//ACLR/wAIvq//AEPfiD/vxp//AMi0eYFLwn8PYdBuNS1HW9Tm8Q61qqCK9vrqNUDRgY8tIxwif7Irmx8HNXtbGTQdJ+IGqWPhSViDpS2sbSpGxy0aXB+ZV68YPB5zk57H/hF9X/6HvxB/340//wCRaP8AhF9X/wCh78Qf9+NP/wDkWgDP8U2V14X+H1np3gi7OlS2stvbWiJbrOZQWC+Xhs9c5L8kYJqh47+G+t+LvFul63pni5dIGlp/o1s+lpdqkpJzLh327sYAO3jGQa3/APhF9X/6HvxB/wB+NP8A/kWj/hF9X/6HvxB/340//wCRaHq7ve9w2Vl2sZ/hvwz440zW47nxD8Qv7csVVg9l/YsFtvJHB3ocjB596x7n4UavY6hf/wDCE+Ob3w5pmpTNPdaelnHOFdvvGF2IMWfbofoAOo/4RfV/+h78Qf8AfjT/AP5Fo/4RfV/+h78Qf9+NP/8AkWgC34U8Lad4N8OW+i6Osn2eHLGSZt0krscs7t3Ynn+WBVT4cf8AJLPCn/YFs/8A0QlH/CL6v/0PfiD/AL8af/8AItR/DmNj8LfCpEzj/iTWfAC8fuU9qbdw2Jq8k8K/EXWtS+I6/wBozJ/wjOszXNrpC+Wo2vBt+beACd/zcEnnpXWfFHX5PD/w/vpLMt9vvMWVmqfeaWT5Rj3Ayfwry/xBbeNbD4aabYReADpi+GzFexagurwSlGiBLuY1GTuyxIB79625rSu9l+u/3LX5kWvGy3f9L73+R6Z8SNe1LQLPQH0m5+ztea3bWk58tW3xPu3L8wOM4HI5rY8S+MvD/hC3jm8R6pFZLKcRqwZ3f1wqgsR74rhviHrEHiDwf4I1a0/1N5rtjMoPUZDHB9x0rOvh4qu/j3rreG10F7uzsLdYDrXmkxwsuWMXl9PmJyfcetVqny9bv8En/XzYaNKXkvzaPSNM8Z+H9a8PT63pOopeWFurNM8Mbs8YAycxgbwcc4xmibxr4eg8MW/iF9SQ6XclVhnSN2MjMcBQgBYtnjGMjBz0Nch4O0TX7P4o6lqHiS78Mx3F7pwFxYaPLIHkIcbZnjcZ6bl3fQetcT4Wh0qL4wxWwmum8JLqNw2iIygW328Ku8Kc8gZbb2z075E25Jd/0ev39PPQl6Jvt/l+nXy1Om8c/EfW/CXxVs4Y98/h2PT0udQt1hXdGjSFDLnG7glOM49u9dV8SfEd3o/wt1DXfDl4sc6xwyW9yirICrSIMgMCCCrenese6tIL/wDaEuLS8iWa3n8LNHLG4yHUz4IP4VwHjK6uPBPgjxF8PdXleS1ZY7nQbmQ58yHz0LQk/wB5efwz2xU3fKl3vb/wJ6fdt8zRJe0Xyv8Actf8/wDhz3DVfE+k+G9Ci1LxFqEVlCyr88nV2IzhVHJPsBUHh/x34a8U2VzdaDq0V3HaqWnARleMepRgGxwecc1554vGu3Xxe8MW2hrpEk8GjtPZprPmGESbsOyhOd4VVx7Amr9hoviz/hbGjax4pvPCVpcCCaFodNlmS4vI9vTa4+cK20+3PtV3bk/n+F/8jJWUV6ItfDn4oWfi/wAT65pzaks7C6Z9NiW3dM2qgfNkr1yf4jn2r0HUL+20rTbm/v5PKtbWJpZpNpbaqjJOBknj0rhfhj/yMPjv/sPSf+giug+IX/JNvEX/AGDZ/wD0A1Dk1SUvK/4Fxjepy+f6mdP8XvAdteQ2s3iO3WWZVdf3chVQwyNzBcKfUMQR3xXTahrWm6TpL6pqN9Bb2KKHNw7jZg9MHvntjrXA2Wj6fB+zYYI7OERyeH2uXXYPmlMO8uffdzmudkigv9L+EFjq4WTTJkzLHLyjyrAvlKQeDySMfhWkrqTh1ul99/8AL5kx1ipeT/BXPSfDXxD8K+L7qS28PaxFdzxruaIxvE5HqFcAke4ziuX0L4q6fqvxb1PQDqitZ7Y4NPiFs4LzjPmgnb2xjJwOOKk+J8NtbeJPA95aIkeqf23FBGyAB2gIIkXPXbjHHTn3qbw7/wAl48Yf9eNn/wCgmpTvOPq1+F/1+/UHpF+if42/ryPQZJFijaSQ4VAWY+gFcZN8YPAdvDaSzeIYVW8XdD+5lJxnGWAXKcg/ex69K62//wCQbc/9cX/ka85+BWlaSPhFatDbwStfNL9t3KG8xg5Xa3sFA4PY+9GrbS6W/UNEk+53N74m0fT9Di1m5v4/7OlaNY7mPMitvYKuNoPBJHPSqWkePvC+vLqL6VrEM8emc3cpVkjiHPO9gFI+U8gkcV4zeop+AviaygJOmQeJGgsNpyog89OFPcZLV3Hxoiay+HWm2Omx2sNrJqVrbyxzArB5QJIV9vITcFzjtRze7zLra3zS/K47WfK/P8G/zt8jpdE+J/g3xFq/9l6PrsE94chYijx7yOyllAY/Qmud1X4q6fp3xhtfD0uqLFYJAYrhPszlvtbMAiZ29MEcjjnk1jeMNA+IGp+H4IteuPAWl2lnNFJb3aSXEBtnVht2OwwueBjvnFdFe5/4aG0jOCf7Alzj/rrRq5Rv3f5X/r5MT2fy/P8Ar8Ta1j4meENBup7bV9ajtp7ecQSRmGRmDlQ2MBTkYI5HAyMmneIviR4S8KXEdvr2sxWs8ihxCI3kcA9CVRSV/HFc74Isrd/jF8QLuSJWnWW1iV2UEqpiyQPrgZ+gqG31i7/4THxCfh54NivZ/tXkalrF7f8Alo06qMoFOWKrkcLge3Skm7Lu1f8Ar/P5Ddrvydjqb7xXpWq+Ab/W9C8RRWtrHCx/tKKDz/sxHcxEZJGfukZ5qSXxloei2GlDXNbjV72086K5liMazqqBmc8YTOQdpx1wK8f0cXC/Dj4qpeJZxzLcyeZHY58hX28hM9s10OqWFrqfi34TW1/Ak8P2KVzHIoKkrboy5B9wDTi3J6deX8U3+nzE1bfpzfhY7vw38RvCfi69ez8P6zFdXKLuMJjeNiO5AdRu/DNP8S/EDwt4Qmjh8RaxFaTSDcsQR5Hx6lUBIHua5vxrBFH8ZPh/cRxqszveRtIBhmURDAJ9OT+ZrmvDg8bXXxA8a3nhlfDLXK6m0Ez6v55nWNRiNV8vgJtH4kH0pczdref4f8OVZLV+X43/AMj1/SdZ07XdLj1LSLyG7s5RlZo2yPcH0I7g8iuTvfiz4Pm+3adpXiO2fU0glMOFbYzhSQFcrsY56DJzXD3Wla7oHgX4jvd3uhG5uo45JbHQpXZbVmGJSyMMpuTn35Nd1qWjeHpPgpLaCC1/sldJMsbBVCqfK3CQHpuzznrmpqN8kmuiX4p/lYcV7yXn+Vv8zY8B6nea14A0XUtTm867urRJJpNoXcxHJwAAPwFR+N/EFxoWixRaUEfV9SnWy09H5Hmv/GR/dUZY/THeoPhd/wAkr8Of9eEf8qyPE5M3xx8FwTE+THbXkyLngybMZ9+K2mvf5fP/AIP6GUHaHN5f1+Ja8RXHjCTVtK8M+G53t2e1M194huLISKm35QFUARmRjk7eMDoKq+HtZ8T6J8Ql8JeLNRt9aS7smu7PUY7YQPlWwyOi8fQj9c8dN4q8V2HhPTUuL0ST3Fw4htLO3XdLcynoiL/XoKyPCPhrU21y58XeLdi61eQiCKzibdHp8GciIN/ExPLN69OKlO8vvv8Aovy+W5T+H7rfr+pyd34i13WfFuviD4jWPhTTLG+Fjaw3VpbSGZ1RfMwZCD94+/XtXU67rur+B/AFu1zep4j125nS0tJmgWBLiaVzsyiHAAX0PO3qM5rP8K+A/h7rFrqmp2NtHr32+8mNxc6hFueOTcdyKGVSmCT0APPU8V5pci7Pw/0u3tdQmg03TPGbWlpfBtxht+QrgnPCljg1Eb8qj3t+aT/Mp7t9Ff8AJtflqemw6f8AE/RryxvbjW7PxHDLMq3umraR23kIfvNFJkFtv+1jPpXYWviPSrzxBeaHBdZ1KyRZJrd43QhG6MCwAYe6k4ry/wAd+DNL+HeixeLPCk15aa1bXUKvI93JKdQ3MFZJA5IOeTwB349G/G9Gj1HSbvw1Jcw+KPs84cWagubLY3mFueAOdvfOcc9Hzcq+f6fl3v0uJRu/679v6/M7LXPHEtz4XnuvANs+tXpvRp8bLbyGGOTOGdjgZRe7D5c45rB1S/8AHXgC40zUtd8R2viHS7u9itLu3+wJbNb+YcBo2U/Ng+vtxzkdX4ZvvDeifDWwvtMuEt9Bt7MSJNIei45Lf7Wc5HXOawLG0v8A4la3Ya5qltJp/hnTphc6bZyjEt9IPuzyD+FBn5V6nOTxirtadu1r+nX79bdfuuTe8L/d6/8AA0v0+8b4/wDEGrp410zQdG8TweGYfsUt7fX1xBDKipuCoD5mAPmyOo6961/DM2oaVoOoa1rvjaHxVp6wmaOe2s4YViVAxfBjJDZ4+mPeql74X8F+JfilcT6rnUtasbKNX0+6j3QRxkkq4Urhj8x7sBnoDiuL1rSItF8UeOtB8KwiGwuvDLXc9pB/q4rjkDCj7pKZ4H+FZOTjBvq7/hd/krGllKVumn42/wAzc05/id4q0JfFGna5Y6Slwnn2OiGxWVZI+qCSZvmBYdxxyOnQdNr2qeI7TwJb66lr9k1GxVLrUNMBSRZY1H72MMM44yykHqBnPIrifDvw18PeIvhjp2uapf3s+qNp6yxamLx1NmVXhY1BChU24xjsea7P4card+JfhXpl7rbGSe4t3SWRusoVmTcfcgA/jVyvFSS6f8H/AC16ERd+Vvr/AF/wz+86nT7+31TTba/sZBLbXMSyxOP4lYZBqxXB/BWSWT4SaR52fk85EJ7oJXC/pxXeVpKyegldaMKKKKkAooooAg+Hf/Ipy/8AYX1P/wBL566muW+Hf/Ipy/8AYX1P/wBL566muV7mwUUUUgCiiigAooooA8zvbH4q6zcahqdtr1l4Wt7eVxY6XLZRXX2iNfutNNuOzdj+HOAfWmSfFa7HwBXx2NPjW/eLYsBJ8rzvN8rdnOdmfm69OM961tY0zQvjD4XK6b4i1SCxSWW3lOnStb+Y4+VklR1+YD0IxzXng8YXn/CjbnR7i30yRo9a/wCEZW8NqBaNHuA+0GMYUAD0wNwB9qlX5eVeVvPpv53X5orS6k/O/wCe3lZ+fQ3b3VfiF8P7zQtS8UeJLLxFp+q38Vjc2MVgkDWzS52mJ15cAj+LkgdOcj1+vBPFngAfCvRtI8XQa/qWvnQp4UGn61IJ4WDsqHyF48pxnK9cYHpXvSncobpkZ5rTS2nd/oZ6pq/b/M8wn1fxp498Xazp/g3W7bw1o2h3H2OS/ayW7murgAF1Cv8AKqrnHr9c4Gla67440DwDrVx4m0X+1dY01mSxbTk3/wBpqcBH8tMsnJ+YYGACRXA/D/4e6T4x1bxra+MpLq+isvEFyE0v7VJFFGXbcJiEKliw4BJIwtdX8K7iTQ9c8Z+Fm1GW70Xw9cxfY7i7l3GBHQs8RY9kx36c1C+HV/ZT/K/pv6WLfxX7O35/f+fyMzXbr4qeDfCzeMtS8TafqcduqT3ugnTUhjjRiAypMDvJXPf369D3Pi+6S+8G6bdw5Ec+q6RKueuGv7cj+dcrdyXXxpnWzskltPAkE6vcXjjbJrDI2fLjB5WIMOX6kjA6Guw8dKE8NWioAFXWdKAA7D+0Ler6a/L+v6/Enrp8zpaKKKkYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVzdj/wAlT13/ALAum/8Ao++rpK5ux/5Knrv/AGBdN/8AR99QB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXN/Dj/klnhT/ALAtn/6ISukrm/hx/wAks8Kf9gWz/wDRCUAYuu+FLLxFqmj3uoTXGNIuftUNujKI3k/hZwVJOO2CK2ZoY7i3kgnQPHIpR1PRgRgisL/hCtL/AOfrXP8Awf33/wAeo/4QrS/+frXP/B/ff/Hq6raWMr63Mu3+F+j23hnTNCW91J7PS9RXULbfKhZXUkhM7PuZY8dferninwBpPiq9t7+ea907U7ZSkWoabcGCdV/u7sHI5PUdz61Y/wCEK0v/AJ+tc/8AB/ff/HqP+EK0v/n61z/wf33/AMeotf8Ar5AnYpaV8OtL0fS9St7O91I32qR+XdavNcCS8cYxxIwIGB6D364NP1D4d6Hf+CbPwxtntrSxMbW09uwWaF0ORIrYIDHnJxzuNWv+EK0v/n61z/wf33/x6j/hCtL/AOfrXP8Awf33/wAeot/XpsBJF4Vs4vGK+JTcXUl+NPFgQ7LsZN+7cQFB3ZHrj2qt428CaP4+0mKx1sTIIZPMint2CyRnuASCMEdRj09Kl/4QrS/+frXP/B/ff/HqP+EK0v8A5+tc/wDB/ff/AB6hq6t/Xf8AME7O6/roN8TeB9H8V2NrBqQnjmsiGtLy2l8ueBuOVcdOg7Y4HpVfw18PdL8N6pJqhu9S1fU3j8oX2rXRuJkT+4pwAB+Gatf8IVpf/P1rn/g/vv8A49R/whWl/wDP1rn/AIP77/49R1uHSxDp/gWw0vxld+ItPvtSge8Yvc2K3P8AosrkYLlCM7u+c1s6zpcOt6Je6XdtIkF5A8EjREBgrDBIJBGefSsz/hCtL/5+tc/8H99/8eo/4QrS/wDn61z/AMH99/8AHqVvd5baBezv1LCeGrNPBY8MCSf7ELD7B5m4eZ5ezZnOMbse2M9qo3ngDQ9Q8E2vha/iluLKziSOCV3AmjKDCuGAGG9wMe2OKm/4QrS/+frXP/B/ff8Ax6j/AIQrS/8An61z/wAH99/8epu7bb6gtLW6Gd4f+Gek6FrMerT3+q63qEKFLe41e789rdSMEJwAPyzVu78C2Fx42i8U299qVjfBUWeO1udkN2q9BKpB3DHGARU3/CFaX/z9a5/4P77/AOPUf8IVpf8Az9a5/wCD++/+PUdvIO/mbF//AMg25/64v/I1418M/hnpevfDXSb86nrOmm7jcXsGnXxhivMSMv7xcHPyjHGOK9N/4QrS/wDn61z/AMH99/8AHqP+EK0v/n61z/wf33/x6ly6ttf1r/mF9iLU/AWiaj4Kj8Kxxy2OlxGMxpasAy7GDDlg2ckck5Jya19X0bT9e0efS9XtlurO4XbJG/f0OeoIPII6Gs3/AIQrS/8An61z/wAH99/8eo/4QrS/+frXP/B/ff8Ax6m9bp9QWjTXQw9O+EWiWd7azXmpa3q1vZOHtbDUr4zW8DD7pVMDp2zmtbxH4FsPEetWOrtfalpuoWKlEuNOufKZ0JyUbIIK57VN/wAIVpf/AD9a5/4P77/49R/whWl/8/Wuf+D++/8Aj1AE+k+GLLR/EGs6xbSzvcaw8b3CyMpRSi7RtAAI49Sawb/4VaPea7d6naanrelG+fzLy202/MEN03cuoGecnOCOprX/AOEK0v8A5+tc/wDB/ff/AB6j/hCtL/5+tc/8H99/8epW20AzLX4W+H7HR9d0qwa6tbHW0VZoY3XEO1duY8qSCepLbsmtFvBenNqvh6/M115vh6F4bUb12urRhDv+Xk4HbHNO/wCEK0v/AJ+tc/8AB/ff/HqP+EK0v/n61z/wf33/AMep7O/9f1qH9ffuTar4XstY8RaNrNzLOtxo7StbrGyhGMihTuBBJ4HGCKyfEPw10nXtbOsQXuqaLqboI5rvSLs27zKOgfgg9B2zwPStD/hCtL/5+tc/8H99/wDHqP8AhCtL/wCfrXP/AAf33/x6iw7j/D3g3RvDWjT6bYW7Sx3RZruW5bzZLpmGGMjH72fy9q5pfgx4eXdbnUNbfSjuMekPflrSInoRGR2PIySM9c10X/CFaX/z9a5/4P77/wCPUf8ACFaX/wA/Wuf+D++/+PUnFPdAm0aGg6Nb+HfD9lpFk8slvZQrDG0xBcgepAAz+Fc38RNOmjTSvFWnwtPd+Hrg3DxIMtLbsNsyj32/MP8Ad961P+EK0v8A5+tc/wDB/ff/AB6j/hCtL/5+tc/8H99/8epyu9eolZadDH17wBpfjnVrDxLF4h1q0kS1C2kul3axKEbJ3KdhOWDcnPIxVrw/4A/sDWI7/wD4SzxRqexWX7NqWpedC2RjJXaMkdqvf8IVpf8Az9a5/wCD++/+PUf8IVpf/P1rn/g/vv8A49Raz0DfcxdV+Euialql3eWuo6zpC37Fr2202+MMN0x6l0wc574xW+fB+gHwj/wjH9mw/wBj+X5YtecYznOeu7PO7Oc85zUX/CFaX/z9a5/4P77/AOPUf8IVpf8Az9a5/wCD++/+PUrK1raDu73MXS/hNoun6pa3l3qOtauti2+ztdTvjNBbN2KJgcjtnNb9h4WsrHxNqWvNLcXV9qCJEzXDKwhiXpHGABtXPJHOTyai/wCEK0v/AJ+tc/8AB/ff/HqP+EK0v/n61z/wf33/AMepiMG7+EGiXXhy40FNT1e20ya/N+tvBPGFiY5+RMocJk5288gHNEXwq8qZH/4Tzxs+xgdr6xlTjsRs6Vvf8IVpf/P1rn/g/vv/AI9R/wAIVpf/AD9a5/4P77/49QlbYHruV/FHgDSvFN/b6jJc6hpmp26eXHqGmXJgmCHqmcEEc+lWPC3gvSfCNrcR6as0892++7vLuQyz3LersevU8DA5PHJo/wCEK0v/AJ+tc/8AB/ff/HqP+EK0v/n61z/wf33/AMeoStsD13OfuPg14emmmW3v9astNuH3z6RaX5jtJcnJBjxnB9AR7YrV8ZXY8O+CP7M0C3RLy7UadpdrEMfOw2jA7BVyxPYKat/8IVpf/P1rn/g/vv8A49R/whWl/wDP1rn/AIP77/49UuPu8vT+v68h82vN1LfhnQ4fDXhfTtGtjuSygWLd/fYD5m/E5P41q1z/APwhWl/8/Wuf+D++/wDj1H/CFaX/AM/Wuf8Ag/vv/j1aNtu5KSSsdBRXP/8ACFaX/wA/Wuf+D++/+PUf8IVpf/P1rn/g/vv/AI9S1GdBRXP/APCFaX/z9a5/4P77/wCPUf8ACFaX/wA/Wuf+D++/+PUagbPw7/5FOX/sL6n/AOl89dTXm/gPwXpd14YkklutbVhqmopiLXr6MYW9mUcLMBnAGT1JyTkkmuk/4QPSP+fzxB/4Ueof/H65XuanSUVzf/CB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wAKPUP/AI/SA6Siub/4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+gDpKK5v/hA9I/5/PEH/hR6h/8AH6P+ED0j/n88Qf8AhR6h/wDH6AMPV/g7oepa1eajY6rr2hnUG331tpGoGCG7Y9WdMHkjg4xnJ7kmt4+AvDR8E/8ACInSof7E8vZ9myfXO7dnO7PO7Oc803/hA9I/5/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/AB+jpy9A63MDS/gvoVjqlleajq+v66mnuJLK01fUPPgtmHQom0dOMZz0Fbmp2GoTfErRLy0udSSzgtZ/tcSykWjggBNy/wAUm5sjrgKfan/8IHpH/P54g/8ACj1D/wCP0f8ACB6R/wA/niD/AMKPUP8A4/RdisjO8S/C3R/EWuNrVvqGsaDqkiBJ7zRbw2zzqOgfgg49cZ6elKfhX4fT4fXfhCxkvbGyvm33dzBMDcXDZBZndlOS2MHjpwMCtD/hA9I/5/PEH/hR6h/8fo/4QPSP+fzxB/4Ueof/AB+lZWsVd3uctB8E4bW3jt7X4g+PIYYlCRxx60FVFAwAAI8AAdq6PxhbfY/B2nW3nTT+TqukR+bO26STF/bjcx7scZJ9am/4QPSP+fzxB/4Ueof/AB+uf8aeCtLttBtnjutcJOraahEmv3zjDX0CnhpiM4JweoOCCCAaq7Jsj0Siub/4QPSP+fzxB/4Ueof/AB+j/hA9I/5/PEH/AIUeof8Ax+kM6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Siub/4QPSP+fzxB/wCFHqH/AMfo/wCED0j/AJ/PEH/hR6h/8foA6Subsf8Akqeu/wDYF03/ANH31H/CB6R/z+eIP/Cj1D/4/XP2fgrS2+JOs25utc2R6TYOCNfvg5LTXgOX87cR8owCcDkgDccgHolFc3/wgekf8/niD/wo9Q/+P0f8IHpH/P54g/8ACj1D/wCP0AdJRXN/8IHpH/P54g/8KPUP/j9H/CB6R/z+eIP/AAo9Q/8Aj9AHSUVzf/CB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wAKPUP/AI/QB0lFc3/wgekf8/niD/wo9Q/+P0f8IHpH/P54g/8ACj1D/wCP0AdJRXN/8IHpH/P54g/8KPUP/j9H/CB6R/z+eIP/AAo9Q/8Aj9AHSUVzf/CB6R/z+eIP/Cj1D/4/R/wgekf8/niD/wAKPUP/AI/QB0lFc3/wgekf8/niD/wo9Q/+P0f8IHpH/P54g/8ACj1D/wCP0AdJXN/Dj/klnhT/ALAtn/6ISj/hA9I/5/PEH/hR6h/8fqP4cwqfhb4VJL86NZ9JG/54p70ASswRSzkKqjJJ7CvFfCXi3XJPH1n4g1S+uG8PeKLq5s7K3d2MVuYyBCQp4UvtYcdck12nxb1ibTfAc1lYZOoazKmm2ig9Xl4P/ju79K4TxP4S+JMfw4i02VfCy2ehxJc27WDXP2lTAuQULDaWIB+uTW/NaXM9l/T+5bepFrrlW7/pfj+R2/xU1C906x8Ntp95PambxBawymCVk8xDuyhweVPcHitXxR470vwteW9jNb3+palcoZItP0y2M87IOr7eMDr1PY+lcV4116LxP4D8CazCABea7YyMoOdrfMGX8CCPwqpf2et3Px81y20zxYnhy6ubG3a1MlhHcm5iC/MqbyMYYEkDr+FVqny+b/CKDRpS8l/6U0d9onj3TNf0rULnT7W/F5pqk3WlTQCK7jOMhSjEDJA45x71X/4WZoL+ELDxBai6uotRnW2trSFFNw8zHHl7SwAYYOecYHXpnC8I6S2n/FPUrjWPHEev6xDpgiuYE0xbcRR7wyl3QlMjn5T82DnpXF+HH0y0+LUPit7CSLwvq1/Pb6VLJJ+7iuiFBnCYwokKsAf8BgTu0u/+dvx/B9yXom+3+V/w/I2PiD4o8SeH/i9b3mjyXU+nafpCXt/polOx4fNKOwTO3cAwOe230FdT8TPEJm+Ct/rnhzUJYhLFBLb3VtIY3AaVOhHIOCQfxFQsiyftHSJIodG8MEMrDIINwOK86+Ikc/w88O694PkWR9B1jbdaNJgkW8gmRpID6DGSP8Sai9oJd2//AEp6fdt/wTVL94n2tf7lr/n/AMA9n13xlpvhTSbCTUzc3F1eAJbWlrEZZ7l8AkKo69ep9R61B4e+Iel+Ibi6s1stT07U7WLzm03UbUw3DR/3lXJDA9ODXC+MYdSf4veGRZeIk8PGfR2itLyW0S4Uy7vmQB8AMylec56DvWjZaDe2nxY0N/E3xBTWNWt4J2gsE0dIWMTIQxZ4zhRnBG7rjA71pduXq3+F/wDL7vvMVZRXovx/q3qO+GHji+8Q+K/Edpf2GuKrXrvA93bbY7ONQAIXOfkfnO39a9D1zV7fw/oN7q14kj29lC00ixAFiqjJwCQM/iK4v4Ykf8JF47Hf+3pOP+Aitv4l/wDJLvEn/YOm/wDQTWbk1RUl2/QtK9Sz7/qYZ+NXh7yUu49O1ybTCqmbU4rAvbW5IBKu4PUZAO3PPrW/4h8faH4a0vTdSv5ZJLHUpAkFxbqHXBQuGPOSCBxjJJI4rJ8Jat4eh+Cdhc/aLVNLh0wR3G5htVtmHRh/eLE8dST715/a2dxH8N/hZBqcbBjrsTqknURlpGT/AMdK1q9JOPmvxdv+GIT91S8n+Cv/AMOemJ8SdKi8Ly67q1hqujwRzi3SDUbQxzzuQCojQEls54+h9DSaD8SdL1vWk0i507V9Dv5lL28GsWZtzcgddnJBx6da5n4yLdr4g8FzQ6sujQLfSqdQlt1mjt5Sg8tirfL2YZPTOe1Qat4c1SHxN4ZHi/4mJeyLqMc9hZrocaPM69QGjOVUjILH5RnntUxbcvK9vy/EqSsvlf8AP/IseHfHt9f/ABq1nTJ9N14WbRxQQRS2uI7QgNukcZ+VXx8rc54rctPivpGo6z/Zmm6VrV7Ol21pcNb2YdLVhJsDSMGwqkgkHrgZIFVfDpH/AAvjxgO/2Gz4/wCAmmfB1ETTfE7hcM3iK8LH1wRSpv3Y37N/+TWCe7t5f+k3Lmp/FnSLLULu1sNI13WlsXMd3c6XYGaGBx95WckDI74zTPEfjHQdW+HFvr1vqerRadPcxKs2kuIrgP5m3Yd2MDPDD06Vz2h674k1/QLzVvDNz4Z8JeGlnmxJ5G+dMMQzuuRGCeuDzz34J4+xbf8As2q3mebu19T5mMb/AN+Ocds0RbbSfk/xX+YpqybXmvuT/wAj1/xF8StF8M+If7EvoL+a/e2W4gitbfzWuMsVEaAHJfgnoBgdal8K/ELSvFepXOmRWuo6ZqdqgkksdTtvJm2cDdjJ45HfvWGYkf8AaUDOoLR+G9yE/wAJ8/GfyJpbgf8AGSFttGCfDbc/9tzTi3o31v8Ahf8AyHJb26W/G3+Ze1b4qaRpuq3VhZ6XrWtPYtsvJdKsTPHbN3DtkAEd8Z6GtyPxjoMvhE+J01KL+xxF5puTnAGcYx13Z424znjFeR/DLSfFV94fvYtK+IUejTWl7OL2wbSIJnhk3nLu7kMc9cn6dqivtPtbD4Q3E9rr3/CRacviaO71G5isjbps3r5gC8hl3YOV+XnjpUpu2vW34tfhr/VxySUnbo3+F/x0Nzxn8XLK88Caolja6/odxcW5OnX91atbJcNkH91ID125I6cV6tpjtJpNo7sWZoELMTkk7RzXCfGbU9Hf4O6i09zbyR3kafY9rg+a+5SpTHX147V3Wlf8gay/694//QRVR3l8v1/H/gEy+y/X9DmfGGpXV54g0fwlpVzLbT6gxub2eFyjw2kZBbaw5VnbCgjoN3tVbXPD/ibxT4vntJtV1HQPDdpAnkS6XcpHPeTHliW5ZVXpgjmq1n/ycXqPnfe/4R+PyM/3fO+bH41q+K/F13Z6lD4c8KWqX/iG6jMirIcQ2cfTzZiOQPQDk/llfZTfW/5tfpf8R9Wu1v0f62/AyvAl7qul+NPEPhLVNWn1m00yKG4try5IaZFcEmORu57gnnv7DzrR/EPh3XWlvfE/xO8R6Re6hfTNBZWWpSJDBF5hCBvkZU49SBjHSvXtA8K2/hHw/qMty9xquoXivcaldY/e3b7TkKMjA6hVB4/WsjQpPAJ+EM1xpdra2fhySCRp4bggsjc5WTJYl88DJJ6Y7UpaK7d7L+vytf8AzGtdF1f6f07CeMNS1Kws/DXhTwzq8iXWrZjOr3DCaRLeKMM8u7oXIx83uehwRX8L6TdWfia3l8K/EF/EunruTVbPUtSW7dBj5WjKA7SD2OAfWvPIdIWfRPhXP4vLppUguLWdpHKrsc7oVdsjCsoUemB6V2njDRtD8O+O/Bc3hCztNO1e41FYnhsUWMTWhB8wuiYyAO5/pxf27/3rf15dfvfYh/Dbyv8An/X3HZ2fj7Rrm416C58/T5tAJN5HdqqkRgZEi7ScoR079OORWTq2o+I/Geg6E3hKG90ax1SQve303lJcW1uBwVXceX7EZIHXGa4P4uW9trHjhrvTNOmvYvD9tHJ4i8mXYs8BkV1gOB8zAAv7AeoGPUtX8b6RovhOz1e2DXkd8qJp1rajMl0zD5URf5+mPwqYu8by8v6+f+Zb0lZf1/w3+Ryf2XVvh/8AEDw5Y23iXVdb03XJJYJ7XVpxPLGypuEiPgEAdx0/PjF8beItLm+KGqWniLxrrHhvTdMtIIo49Lu5I2mmfLk7FVsgKQCcenNdx4Y8LalPrn/CWeNGjfWmjMdrZwtuh06I/wAC/wB5z/E/4Dil8Ny+E7jx14lOn6ebXX4ZVS/e6P7yVdow6ZY4jIx0C9sjpRZuyfm/+B8v60QrrVryX9fkZceuWHg/4Salr3h/xBf+KI/9ZbXGpXf2h/NbaipnAIAYgleDyaxx4f1hHiMHxSlbxqdsrabc36C0ZjyY/swBIGOMge+BXLa7YjUfC3xPfwwFbRo7+1ngNt/q/MTa05THHHByPT6V1Hivw14Bt/gxNq2n21lG62oms9SjKi5e4xlcy/eZi3UEnv6cS5aOfkvutfT+tbDtqoep1/jm91HQNNsPFEMsgXS3U6laRSMYprd8LIQvQshwytjPB9SK66GVJ4UmhYPHIoZGHQgjINcbrUtxN8DLyXXP+Pp9AZrneCP3hg5z77q1vAgnX4eeHxdZ84abBuycn/VitrWlKPa343/y/EzveMX3/S3+Zv0UUUhhRRRQAUUUUAFFFFABRRRQBB8O/wDkU5f+wvqf/pfPXU1y3w7/AORTl/7C+p/+l89dTXK9zYKKKKQBRRRQAUjMFUsxwAMk0tRXURns5olODJGygntkYqZNqLaGrN6niFldS+PLOTxR4q+JN54Rsr64lj0SwstRjslESOVDPu5lJIyR+uCAOxu4fiPB8MbXT7O6stQ8RzTrbtqtsy7I7ct/x8FX2gsEx8ozycjNcX8E/Bfgy++Hl1H4l0ywvtXs557bUhqKq8loEZgFXdkxqFOcjHOT2rW+Fniew8LfCbWNS1K8kPh/TtVuYdKkcl3ltwwEaJn7xLZAx/Sr91adLJ+u34u/TfXyFq3fza/P8v8AIi8SaRrvwtm0TW9N8aa7rSXWpwWV7p+sXIuEuFkJB8oYGxhyQB+fGD7NXnWheHdY8ZeILPxd46t/sUNm3m6NoW7P2bI/10/96XHQdE+ucei0a2s9/wDhtP67i0butv6/r5Hk0lprHxO8feIbVfE+raDofh+VLKGPRrjyJbifbukd35OBkDHQ8dCDm34NfV9f0zxT4G8Sa7f/AG/RrpYF1exk8i5kgcB433YwHwCCef6k+Gc0GkePvH+gXUqx3baudSjjcgGSGZAdw9QCMH0yPWl+GckOrfEf4g+ILBxNYXN7b2kMynKyNDFhypxgjLdQaUbNJd43+en+bKlo2+z0/H9NTkfHXg290TUNG0Dw38QfG9z4g1q42QJc62zRwQrzJM4VQcAZxyMn6Yr0zxRZHTfA2lWLXVxeNbanpERuLl98spW+txudu7HGSfWsDwOg8S/F7xh4pn/eJpsi6HYZ6IIxumx9WI/M11Xjz/kXbX/sNaV/6cLemm+Reev+X4fmJ/E/LT/P8dPkdJRRRSAKKKKACiiigAooooAK8m8Vane+KfH+qaFJ4rm8J+GvD9vC+oXtrcLbzTzygsiiZvuKF/XOc5GPWa8R07wvoF7+0f4st/F9rb3b3MNvd6Za3oDQzAx7HcI3yuwIxyDj5qSV5Jev9fm/kO9ot+n5/wBL5na/Dyx1XTft/wDxVsXirw0+19OvZboT3MZH30eRRtcehzn2FeP6J4l8MeIHmv8AxZ8WfFGiX2pahO9vYWGqSpDbwmQhFb92yx8epAxjgV2vh620zw/8afFuneFbYnQk0VbjUbCw+4l3uICRqCArlM/KMc+mONvw7L8OW+Cs9zpFpaWPhiWCRriG5ILI3OVkJZiZM4AySfu47Um7Ln7L9X/lowS15PP9P+DqjvdItks9FsraG8mv44oERLq4l82ScBQA7P8AxE9Se+areJvEdh4T8OXmtas5W2tU3FVGWkY8KijuzEgAeprmfgml6nwZ8OjUg4l+zkx7+vlF2Mf/AI5t/CsP4h2fjW9+ImlXFh4P/wCEj8PaUguYLf8AtOG1V7zJxI+/JbYOgxjJzntWlRWm4+f9f13JhrG/9f1+gvwh1nxPqvi7xmPF8siXCS2ssdj5rNHZLJGzCNQeAQpUNjqQetdlY/8AJU9d/wCwLpv/AKPvq86+Get+J7v4y+LxqXhL+zxdvbG/P9pRS/YCsB8scD95v9V+73r0Wx/5Knrv/YF03/0ffUPZei/IOr9TpKKKKkYUUUUAFFFFABXi/wAXPEdlH8RtH0bWfF+p+FtJt9NmvbufTLt4ZZmZwkaAKG3HKk4weM9K9orhkm8Hz/GmeC501o/FcGno0N3dH5ZYCTxCCxGQc5IUHryRmla8l8/yf/DjvaL/AK6oi+Fcegy6beX/AIZ8ba14rt5yiudWvjO1uVzwEZVZCc85HOBXJ/Gzx3q6W91o3g24lt/7Ka3m1jUIJTGYRJIqxwKy872zuPT5R15Ipxmu4/jT4zuPhzb293cR6Aq3EcTKsTah5h8sMchd23OcnsR61xnidPGnh/4N32lav8P2tBc3MVzqOsya3BM9xcNMjF2jUZ+ZgFAz8ox1xVJ3lF9NPzt+l/u3uK1rr+tr/rb7z6aTlF+leZ+PbzXNf+Iuj+BNE1m40K2uLKTUL+9tflneNW2iONv4TnqRzz6cHu/D95qWoaDa3Ot6V/ZF9Ip82y+0LP5XJA+deDkYPHrXG/EPRtI1fxd4fSHxJP4b8XYl/sm7ihMglUD95GwI2MO+0kH65IpPSS/ro/8AhxRfuFfR5dS8BfEjS/Cd54gv9d0vXLaaS0k1WUS3VvNEAzAyAAsjKTwRwRxWT8YfFvi+3sbiDw/YXOkaVY3lsl3q0khikuS8iYS3C87fmG5jjoR9aNjoc7/tCeHo73xLceJdY0mxubjU7po0ijgVl8uKMRJ8sZyxJHU5BPauq+O3/JLJ/wDr+s//AEoSmt4N9/8A26wpaKaXb/23+mejVzfw4/5JZ4U/7Atn/wCiErpK5v4cf8ks8Kf9gWz/APRCUijO1Lw9per6np1/qNsZ7nTZDLaMZXCxuRjdtB2k8dwcdq0mUOpVwGVhggjqK/P+itfaK1rEcvU+3YPh/wCGLbSLXS4NM2WVnei/t4ftEuI5wchh82ccn5fu+1WfEvg3w/4vt44fEelxXqxHMbMWR09cMpDAe2a+GaKOdNWaHZrW59waf4D8NaV4dutD03S0tdPvFKXCRSOryg8ENIG3njjr0OKsX/hLQ9T8Lp4dvdPSTSo0REtgzKFCY24YEMMYHOc18L0Ue08g5bH3dF4d0uHX11tLZv7RW0FkJ2ldj5IbdtIJweRnJGfemeI/DGjeLdMGn+IbFby2EgkVC7IVYdCGUgjqehr4Uoo9pfoJRtsfdmt+GNG8SaSNN1zT4r20XG1JM5QgYyrDkHHcHNVfDPgbw34OEv8AwjmlRWTTcSSBmd2Hpuck49s4r4doo9prewculj7jh8FeHrfxa/ia301ItYkUq9ykjruBGDlAdpJ9cZqL4hWtxe/DjX7azgkuLiWwlSOKJCzOxU4AA5J9q+IaKmUk48tioq0uY+vvD/wp8I3OlaNqer+GoDqi2UHnCYOoLiMA74s7S2euVznrXY6n4f0zWHsH1G1Ep064W5tcOyeXIowDhSM9ehyK+EKKt1bvREKFla5966ppNhremy2Gr2kV5aTDDxSrlT/9f3rE8OfDjwl4SvWvNA0WK1uWG3zmd5WUdwpdjt/DFfEtFL2ivexXK7Wufcd/4K8Pal4mtPEN5pqPq1oQYbpZHRhjpkKQG/4EDV3R9B03QIrmPSbb7Ol1cvdTDzGbdK/3m+YnGcdBxXwfRQqltkLlufacnwr8ES682sSeHbV7xn8xiSxjLepjzsz/AMBq43gPw2+jT6U2m/6DcXn26SHz5ADNuDbs7sjkDgce1fEFFCmlsgcb7n3h/YOmjxJ/b/2b/iZ/Zvsnn+Y3+q3btu3O3rznGfehtB01vEia+1tnU0tjaLP5jcRbt23bnb15zjNfB9FHtPIOU+1tf+GPg7xPqf8AaGt6HDcXZxulWR4i/wDvbGG78c1vw6Rp1tpA0qCxt009YzELURDy9h6rt6EH9a+CqKOdJWsOzve59mQfCDwHbfa/I8PQr9rQxynzpT8pPIXLfJ/wHHHHSuyiiSCFIohtSNQqjOcAcCvgGihVLbIXLfU+0PGGm3Vn4g0fxbpVtLcz6extr2CFC7zWkhAbao5ZkbDADqN3tRrfwo8F+JNYm1XWtGa6vbjBklN3OucAAcBwBwB0FfF9FLnXYdn3Ptvwx8PPC/g28mu/Del/Y554/Lkb7RLJuXOcYdiOoqrc/CjwPea4dWuPDlq92z725YRs3qYwdhz3yvPevi6in7TbTYXKfemp6Rp+s6XJp2qWcN1ZyAK0MiAqcdPpjsR0rH8NfDzwr4QupLrw9o8VpcSDa0pd5HA9AXJIHsMV8R0Ue0V72Hy6WPu7SvDmlaJb3cGnWgjS9ne4ud7tIZpH+8zFySc1z918JfBV7pVnpt1o7SWdiZGtoTez4iLkFsfP3Ir4xopc67BZ9z7L0v4P+BdG1W21LTdD8m7tZBJDJ9rnbaw6HBcg/iK0fEvw88KeL7qO58Q6NDdXEY2iYO8TkehZCCR7HOK+I6KftFa1g5dbn3ppukafo+lx6bpdnDa2ca7VgiQBcHrx3z3J6965y2+FHgez1xdWt/Dtql2r71O5zGreojJ2DHbA4r4uoo9pre2ouXSx9o/ECxvPENnZeF7OGbyNTmBv7oIdkNshDON2Mbm4UDryT0Brroo0hiSKJFSNFCqqjAUDoBXwBRQqlugON/6/r+rH6A0V+f1FP2nkHKfoDRX5/UUe08g5T9AaK/P6ij2nkHKfoDRX5/UUe08g5T9AaK/P6ij2nkHKffXw7/5FOX/sL6n/AOl89dTX5uUViWfpHRX5uUUAfpHRX5uUUAfpHRX5uUUAfefiL4UeCPFerf2nr3h+C5vTjdMskkRfHTdsYbunfNXde8AeGPEvh+10PV9JSTS7N1e3tIZHgSMgFRgRsvQE8e9fn/RSsrWHd3ufbsPwB+GkEyTReGtrxsGU/b7k4IOR/wAtK39T8NfbviVomvraqp061nR7oynLbwFWIJnHdmLY7Ad6+A6Kfb+vImyPvvxX8N/CPjeeKfxPosN7PCu1JhI8TheflLIwJHJ4JxzW3o+jad4f0qHTdFs4bKzgGI4YVwo5yT7knknqa/OmihaKyG9dz9ENE8O6X4chuotGtfsyXl093OPMZ98r8s3zE4zjoOPas7x5/wAi7a/9hrSv/Thb18AUUAfpHRX5uUUAfpHRX5uUUAfpHRX5uUUAfpHRX5uUUAfpHWB4p8D+G/G1tFB4o0mG/WEkxsxZHTPXDqQwB9Aea/PuilZMabWx+hfhrwnoXg7S/wCz/DWmw2FsW3MseSzt6szEsx9yTWDd/Bz4f32vnWbrwxZves/mNy4jdvUxBthz3yvPevhKiqu73F0sfffj/wAML4q8KrpKWizE3MDRkyGNbfa4zJwedq5wvOTjiuor83KKQH6JWOgaZpusalqtlbeXe6oY2u5fMY+aUXavBOBgccAVmWP/ACVPXf8AsC6b/wCj76vgCigD9I6K/NyigD9I6K/NyigD9I6K/NyigD9I657xX4D8M+N4Yo/FGkQ3/knMblmSRPYOhDAe2cGvz9ooA/Q3w54X0TwjpQ07w5p0Nhag7ikQJLt6sxyWPbJJPFS69oGm+JtHl0vW7b7TZysrPF5jJkqwZeVIPUA9a/O2im227sFpsfffxA8MjxX4WGlLarO7XULozSlBBtcEycH5tq5wvOTir/ifwhoPjLTVsfE2mQ6hbq25A+VZD6qykMv4EV+etFTbSwH6D+F/Bnh7wXYvaeGNKh0+KQgyFMs8hHTc7Es2MnGTxmreu6BpnibSm03W7b7TaNIkhj8xkyyMGU5Ug8EA9a/O2iqu73FZJWP0jrm/hx/ySzwp/wBgWz/9EJXwBX3B4B/5Jt4Z/wCwTa/+iVpDP//Z)\n"
      ],
      "metadata": {
        "id": "6elfjnTG6apG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5 : Explications de FixMatch\n",
        "\n",
        "FixMatch est une méthode d'apprentissage qui a été pensé par Google Reasearch en 2020. Il a été pensé car en DL il est nécessaire d'avoir une grande base de données pour pouvoir effectuer l'apprentissage or créer cette base de données (et surtout poser des labels sur chaque élément) est très coûteux.\n",
        "\n",
        "FixMatch a été originellement pensé sur la classification d'images à partir de réseaux de neurones tel que ResNet. Imaginons qu'on possède des images avec un label et d'autres non. Le réseau de neurones traditionnel ne peut apprendre que sur les images avec un label or FixMatch est une méthode qui vise également à apprendre sur les données sans label d'où le fait que c'est une méthode d'apprentissage semi-supervisé car il apprend également sur des données non annotées. \n",
        "\n",
        "FixMatch utilise la data augmentation, technique utilisée pour augmenter la taille d'une base de données en utilisant des propriétés sur les objets sur lesquels on travaille. Par exemple si on souhaite classifier des images d'animaux, alors effectuer une symétrie horizontale, une faible rotation ou une faible translation ne change que très peu l'image et le réseau de neurones doit être capable de toujours donner le même animal en sortie peu importe le changement sur l'image. On distingue alors deux types de data augmentation :\n",
        "- **Weak augmentation :** On retrouve des des techniques telle que la symétrie horizontale, la translation, le zoom/dezoom. Ces techniques sont catégorisées comme weak car on ne change qu'assez peu l'image et qu'un bon réseau de neurones entraîné serait capable de classifier l'image avec une accuracy qui varierait assez peu. Dans FixMatch, ils ont choisi de n'utiliser que la symétrie horizontale et des translations (qui ne vont que jusqu'à 12.5% de la taille initiale)\n",
        "- **Strong augmentation :** Les techniques utilisées effectuent des changements plus drastiques sur l'image et il est bien plus compliqué de classifier l'image, parmi ces techniques on retrouve des changements sur la couleur, le contraste, la luminosité, etc... Parmi les techniques de strong augmentation, FixMatch utilise le CutOut qui consiste à enlever un carré (de taille raisonnable) de l'image. FixMatch effectue également un AutoAugment qui consiste à choisir un certain nombre de transformations parmi un set prédéfini, de choisir une magnitude qui définit la \"puissance\" de la transformation et d'effectuer ces transformations sur l'image. FixMatch utilise le RandAugment ou le CTAugment pour effectuer l'AutoAugment\n",
        "\n",
        "L'apprentissage de FixMatch s'effectue en plusieurs étapes :\n",
        "- Il faut tout d'abord créer la base de données avec des données avec label et des données sans label avec μ fois plus de données sans label que données avec label (il a été prouvé que plus μ est grand, meilleurs sont les résultats). Il faut également choisir une architecture pour les réseaux de neurones.\n",
        "- On commence à travailler uniquement sur les données ayant un label, la fonction de perte à minimiser est *lₛ* qu'on calcule à l'aide de l'entropie croisée\n",
        "- Après avoir fait cette étape, on va effectuer une weak augmentation sur les données sans label. Et on va demander au réseau de neurones de classifier les images. Si la classification est donnée avec une certaine confiance supérieuse à un seuil (pour éviter d'avoir des pseudo label aberrant), on va poser un pseudo-label sur l'image en fonction de ce qu'a donné le réseau de neurones.\n",
        "- On va maintenant effectuer une strong augmentation sur les données avec un pseudo-label et demander au réseau de neurones de classifier les images qui ont subi cette augmentation. A partir du pseudo label et de la sortie, on détermine l'entropie croisée et la fonction de perte *lᵤ*  uniquement sur les données ayant un pseudo label\n",
        "- On calcule la fonction de perte totale *lₛ + λᵤlᵤ* avec *λᵤ* un paramètre de régularisation (qui sera fixé contrairement à d'autres algorithmes de SSL). A partir de cette fonction, on va remettre à jour les poids\n",
        "\n",
        "Le fait d'introduire un seuil pour créer le pseudo label fait qu'au début le réseau de neurones ne pourra mettre aucun pseudo label sur les images. Donc au début l'entraînement s'effectuera comme si on entrainait traditionnellement un réseau de neurones sur des des données avec label, puis petit à petit il va être capable de créer quelques pseudo label et ainsi les données sans label vont commencer à avoir de plus en plus d'impact sur les poids du réseau\n"
      ],
      "metadata": {
        "id": "qL_PbGDf6i7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6 : Implémentation de FixMatch\n",
        "\n",
        "On choisit un réseau de neurones WideResNet 28-2 comme dans le papier originel (https://arxiv.org/ftp/arxiv/papers/2001/2001.07685.pdf)\n",
        "\n",
        "On commence par définir tous les hyperparamètres qu'on devra utiliser (les valeurs seront prises à l'identique au papier originel)\n",
        "\n",
        "On va utiliser 100 images avec label par classe (on peut choisir une autre valeur mais il faudra reconstruire les données avec label qu'on a fait au tout début). On possède donc 1000 images avec label et 47000 images sans label"
      ],
      "metadata": {
        "id": "6FlCd27K8pQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "\n",
        "num_class = 10 #number of classes\n",
        "seed=111 #seed for the algorithm\n",
        "batch_size = 32\n",
        "num_train = 100 # number of labeled image by classe\n",
        "cutout = 16  # parameter for the cutout\n",
        "num_epochs = 100\n",
        "#Validation set size\n",
        "valid_size = 200\n",
        "\n",
        "threshold = 0.95 # Threshold to set pseudo label = tau\n",
        "lambda_u = 1 # scalar that decides how much both the unlabeled image loss contribute relative to the labeled loss\n",
        "mu = 7 # Relative size between labeled and unlabeled data\n",
        "lr = 0.03 # Learning rate\n",
        "bn_momentum = 0.9 # Used in the BatchNorm2D layer in WideResNet\n",
        "momentum = 0.9 # In SGD optimizer\n",
        "weight_decay = 5e-4 # In SGD optimizer\n",
        "nesterov = True # In SGD optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "torch.manual_seed(seed) # Set the seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5sg0BWn99yd",
        "outputId": "c0bffb94-0ee7-45d0-aa20-dc26285c5095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7a5aa53550>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit les différentes transformations qu'on fera subir à nos données (weak, strong augmentation), on construit les dataloader ainsi qu'une fonction **unlabeled_loader** qui permettra de créer 2 dataloader à partir dun set d'images: un pour le weak augmentation et l'autre pour le strong augmentation (les images sont dans un ordre aléatoire mais dans le même ordre pour les 2 dataloader ce qui nous permettra d'itérer sur chacun des dataloader à chaque étape de l'algorithme)"
      ],
      "metadata": {
        "id": "OLl3-zBrdPQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create shuffled dataloader with weak and strong augmentation\n",
        "def unlabeled_loader(x_unlabeled, y_unlabeled, seed = None) :\n",
        "    if seed==None :\n",
        "        permutation = np.random.permutation(len(x_unlabeled))\n",
        "    else :\n",
        "        permutation = np.random.RandomState(seed=seed).permutation(len(x_unlabeled))\n",
        "    x_unlabeled = x_unlabeled[permutation]\n",
        "    x_unlabeled = x_unlabeled[:len(x_train)*mu]\n",
        "    y_unlabeled = y_unlabeled[permutation]\n",
        "    y_unlabeled = y_unlabeled[:len(x_train)*mu]\n",
        "    unlabeled_loader_weak = torch.utils.data.DataLoader(\n",
        "        Dataset_sub_CIFAR(x_unlabeled, y_unlabeled, transform=transform_weak),\n",
        "        batch_size=batch_size*mu,shuffle=False, num_workers=2) \n",
        "    \n",
        "    unlabeled_loader_strong = torch.utils.data.DataLoader(\n",
        "        Dataset_sub_CIFAR(x_unlabeled, y_unlabeled, transform=transform_strong),\n",
        "        batch_size=batch_size*mu,shuffle=False, num_workers=2) \n",
        "    return unlabeled_loader_weak, unlabeled_loader_strong\n",
        "\n",
        "\n",
        "#Dataset loading\n",
        "CIFAR10_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=None, download=True)\n",
        "CIFAR10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=None, download=True)\n",
        "np.random.seed(seed=seed)\n",
        "permuation=np.random.permutation(len(CIFAR10_train_dataset.targets))\n",
        "\n",
        "Original_train_data_x = (CIFAR10_train_dataset.data)\n",
        "Original_train_data_y = np.array(CIFAR10_train_dataset.targets)\n",
        "Original_train_data_x = Original_train_data_x[permuation]\n",
        "Original_train_data_y = Original_train_data_y[permuation]\n",
        "\n",
        "Original_test_data_x = CIFAR10_test_dataset.data\n",
        "Original_test_data_y = np.array(CIFAR10_test_dataset.targets)\n",
        "\n",
        "\n",
        "\n",
        "#Selection of 250 labeled images for training and 2000 for validation\n",
        "incr_class = torch.zeros(num_class)\n",
        "train_idx_dico = {} #labeled images index dictionnary\n",
        "\n",
        "for i in range(num_class):\n",
        "    train_idx_dico[str(i)] = []\n",
        "\n",
        "valid_idx = np.zeros(num_class * valid_size, dtype=np.int32) #validation images indexes (2000)\n",
        "incr_t = 0\n",
        "incr_v = 0\n",
        "incrtotal = 0\n",
        "\n",
        "for idx in range(len(Original_train_data_y)):\n",
        "    class_y = Original_train_data_y[idx]\n",
        "    incrtotal += 1\n",
        "\n",
        "    train_idx_dico[str(class_y)].append(idx)\n",
        "    incr_class[class_y] += 1 #count the number of image per class\n",
        "    incr_t += 1\n",
        "\n",
        "\n",
        "train_idx = np.zeros(num_class * num_train, dtype=np.int32) #train labeled images indexes (1000)\n",
        "list_train_id = []\n",
        "list_unalabel_id = []\n",
        "valid_idx = []\n",
        "unlabel_idx_dico = {}\n",
        "for i in range(num_class):\n",
        "    unlabel_idx_dico[str(i)] = []\n",
        "for i in range(num_class):\n",
        "    list_train_id = list_train_id + train_idx_dico[str(i)][0:num_train]\n",
        "    valid_idx =valid_idx + train_idx_dico[str(i)][num_train:num_train+valid_size]\n",
        "    list_unalabel_id = list_unalabel_id + train_idx_dico[str(i)][num_train+valid_size::]\n",
        "    unlabel_idx_dico[str(i)] = train_idx_dico[str(i)][num_train::]\n",
        "\n",
        "#Get labeled and unlabeled data\n",
        "\n",
        "x_train = Original_train_data_x[[int(i) for i in list_train_id]]\n",
        "y_train = Original_train_data_y[[int(i) for i in list_train_id]]\n",
        "\n",
        "x_unlabeled = Original_train_data_x[[int(i) for i in list_unalabel_id]]\n",
        "y_unlabeled = Original_train_data_y[[int(i) for i in list_unalabel_id]]\n",
        "\n",
        "#Get validation set data\n",
        "x_valid = Original_train_data_x[[int(i) for i in valid_idx]]\n",
        "y_valid = Original_train_data_y[[int(i) for i in valid_idx]]\n",
        "\n",
        "# Printing the size of the training, validation and test sets\n",
        "print('Number of training examples: ' + str(x_train.shape[0]))\n",
        "print('Number of unlabeled examples: ' + str(x_unlabeled.shape[0]))\n",
        "print('Number of validation examples: ' + str(x_valid.shape[0]))\n",
        "\n",
        "transform_weak = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "# We choose to use RandAugment\n",
        "transform_strong = transforms.Compose([\n",
        "    transforms.RandAugment(),\n",
        "    transforms.ToTensor(),\n",
        "    CutoutDefault(cutout),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "transform_normalize = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "# Dataloader creation\n",
        "\n",
        "labeled_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_train, y_train, transform=transform_normalize),\n",
        "    batch_size=batch_size,shuffle=True, num_workers=2) #num_workers = 2 ou 1\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=transform_normalize),\n",
        "    batch_size = batch_size,\n",
        "    shuffle=False, num_workers=2)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    Dataset_sub_CIFAR(x_valid, y_valid, transform= transform_normalize),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "67V160pEVMdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736caa47-e131-4498-91a5-ea485af108e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Number of training examples: 1000\n",
            "Number of unlabeled examples: 47000\n",
            "Number of validation examples: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On crée le réseau de neurones qui est un WideResNet 28-2\n",
        "\n",
        "On crée également la fonction d'entraînement. Cette dernière affichera en plus des performances et de la fonction de perte, des informations sur le nombre de pseudo label posé sur les images sans label (plus ce nombre est grand plus le réseau est \"confiant\" dans ses prédictions), le nombre de pseudo labels correct (information qu'on ne devrait pas avoir mais qu'on dispose ici et qui permet de voir la performance du réseau de neurones sur des données) ainsi que le nombre de fois où le réseau de neurones donne la même sortie pour une image avec une strong augmentation que son pseudo label (cela mesure sa consistance)"
      ],
      "metadata": {
        "id": "LnuNeNbSdvZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Networks creation\n",
        "net = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class)\n",
        "net = net.to(device)\n",
        "net_save = WideResNet(28, 2, dropout_rate=0.0, num_classes=num_class) # model where to save the results\n",
        "net_save = net_save.to(device)\n",
        "\n",
        "# Training\n",
        "def train_fixmatch(epoch,net,trainloader,log_interval=15):\n",
        "    net.train()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    total_pseudo_label = 0 # nb of unlabeled images\n",
        "    nb_pseudo_label = 0 # nb of pseudo label (higher than threshold)\n",
        "    same_pseudo_label = 0 # nb of same output between weak and strong augment\n",
        "    correct_pseudo_label = 0 # correct pseudo label\n",
        "\n",
        "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate_scheduler(lr, epoch)))\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate_scheduler(lr, epoch), momentum=momentum, weight_decay=weight_decay, nesterov = nesterov)\n",
        "\n",
        "    unlabeled_loader_weak, unlabeled_loader_strong = unlabeled_loader(x_unlabeled, y_unlabeled, seed=epoch)\n",
        "    iterator_strong = iter(unlabeled_loader_strong)\n",
        "    iterator_weak = iter(unlabeled_loader_weak)\n",
        "    for batch_idx, (inputs_train, targets_train) in enumerate(trainloader):\n",
        "        optimizer.zero_grad()\n",
        "        # Labeled inputs\n",
        "        inputs_train, targets_train = inputs_train.to(device), targets_train.to(device) # GPU settings\n",
        "        inputs_train, targets_train = Variable(inputs_train), Variable(targets_train)\n",
        "        outputs_train = net(inputs_train)               # Forward Propagation\n",
        "\n",
        "        # Get pseudo label\n",
        "        inputs_weak, targets_weak = next(iterator_weak)\n",
        "        inputs_weak = inputs_weak.to(device)\n",
        "        targets_weak = targets_weak.to(device)\n",
        "        outputs_weak = net(inputs_weak)\n",
        "        outputs_weak = nn.Softmax(dim=1)(outputs_weak) # Softmax = Normalization -> To get probabilities so it can be compared to threshold\n",
        "        outputs_weak_max, pseudo_label = outputs_weak.max(dim=1) # Get max and pseudo label\n",
        "\n",
        "        mask_targets = outputs_weak_max>threshold # Used to know if we take the pseudo label in the loss, mask on targets\n",
        "        mask_inputs = mask_targets.view(-1,1) # Mask on inputs/outputs\n",
        "\n",
        "        # Strong augmentation (only on pseudo label higher than the threshold)\n",
        "        inputs_strong, _ = next(iterator_strong)\n",
        "        inputs_strong = inputs_strong.to(device)\n",
        "        inputs_strong = Variable(inputs_strong)\n",
        "        pseudo_label = Variable(pseudo_label)\n",
        "        outputs_strong = net(inputs_strong)\n",
        "\n",
        "\n",
        "        # Loss and backpropagation\n",
        "        outputs_strong_masked = (torch.masked_select(outputs_strong, mask_inputs)).view(-1, num_class)\n",
        "        pseudo_label_masked = torch.masked_select(pseudo_label, mask_targets)\n",
        "        targets_weak_masked = torch.masked_select(targets_weak, mask_targets)\n",
        "        # loss_u = loss on unlabeled\n",
        "        if outputs_strong_masked.numel() > 0 :\n",
        "            loss_u = criterion(outputs_strong_masked, pseudo_label_masked)\n",
        "        else :\n",
        "            loss_u = 0\n",
        "        loss = criterion(outputs_train, targets_train) + lambda_u * loss_u # Loss\n",
        "        loss.backward()  # Backward Propagation\n",
        "        optimizer.step() # Optimizer update\n",
        "\n",
        "\n",
        "        _, predicted_train = torch.max(outputs_train.data, 1)\n",
        "        correct_train += predicted_train.eq(targets_train.data).cpu().sum()\n",
        "        total_train += targets_train.size(0)\n",
        "\n",
        "        total_pseudo_label += mask_inputs.size(0)\n",
        "        nb_pseudo_label += mask_inputs.cpu().sum()\n",
        "        _, predicted_strong = torch.max(outputs_strong_masked.data, 1)\n",
        "        correct_pseudo_label += pseudo_label_masked.eq(targets_weak_masked.data).cpu().sum()\n",
        "        same_pseudo_label += predicted_strong.eq(pseudo_label_masked.data).cpu().sum()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%% \\nPseudo labeled: %.3f%% (%d/%d)    \\tCorrect pseudo label: %s (%d/%d)    \\tSame output weak and strong augmentation: %s (%d/%d)'\n",
        "                %(epoch, num_epochs, batch_idx+1,\n",
        "                    (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct_train/total_train,\n",
        "                    100.*nb_pseudo_label/total_pseudo_label, nb_pseudo_label, total_pseudo_label,\n",
        "                  ('{:.2f}%'.format(100.*correct_pseudo_label/nb_pseudo_label) if nb_pseudo_label!=0 else 'Undefined'), correct_pseudo_label, nb_pseudo_label,\n",
        "                  ('{:.2f}%'.format(100.*same_pseudo_label/nb_pseudo_label) if nb_pseudo_label!=0 else 'Undefined'), same_pseudo_label, nb_pseudo_label))"
      ],
      "metadata": {
        "id": "0lBnTl0XUaOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entraînement et évaluation"
      ],
      "metadata": {
        "id": "z2TfCScTasSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc=0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_fixmatch(epoch,net,labeled_loader)\n",
        "    acc =test(epoch,net,valid_loader)\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
        "        net_save.load_state_dict(net.state_dict(), strict=True)\n",
        "        best_acc=acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNKOfZHs9KcV",
        "outputId": "e140b5aa-bd36-4c5c-d028-e0ebeb26b4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0, LR=0.0300\n",
            "| Epoch [  0/100] Iter[  1/ 32]\t\tLoss: 2.3109 Acc@1: 9.375% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  0/100] Iter[ 16/ 32]\t\tLoss: 2.1104 Acc@1: 17.969% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  0/100] Iter[ 31/ 32]\t\tLoss: 1.7244 Acc@1: 21.976% \n",
            "Pseudo labeled: 0.000% (0/6944)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "\n",
            "| Validation Epoch #0\t\t\tLoss: 2.1608 Acc@1: 22.70%\n",
            "| Saving Best model...\t\t\tTop1 = 22.70%\n",
            "\n",
            "=> Training Epoch #1, LR=0.0300\n",
            "| Epoch [  1/100] Iter[  1/ 32]\t\tLoss: 2.1796 Acc@1: 21.875% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  1/100] Iter[ 16/ 32]\t\tLoss: 1.8590 Acc@1: 25.781% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  1/100] Iter[ 31/ 32]\t\tLoss: 1.7217 Acc@1: 27.621% \n",
            "Pseudo labeled: 0.000% (0/6944)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "\n",
            "| Validation Epoch #1\t\t\tLoss: 2.6429 Acc@1: 29.15%\n",
            "| Saving Best model...\t\t\tTop1 = 29.15%\n",
            "\n",
            "=> Training Epoch #2, LR=0.0300\n",
            "| Epoch [  2/100] Iter[  1/ 32]\t\tLoss: 1.9760 Acc@1: 25.000% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  2/100] Iter[ 16/ 32]\t\tLoss: 1.9438 Acc@1: 31.250% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  2/100] Iter[ 31/ 32]\t\tLoss: 1.9391 Acc@1: 32.460% \n",
            "Pseudo labeled: 0.000% (0/6944)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "\n",
            "| Validation Epoch #2\t\t\tLoss: 2.3037 Acc@1: 27.20%\n",
            "\n",
            "=> Training Epoch #3, LR=0.0300\n",
            "| Epoch [  3/100] Iter[  1/ 32]\t\tLoss: 1.7047 Acc@1: 34.375% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  3/100] Iter[ 16/ 32]\t\tLoss: 1.3130 Acc@1: 37.500% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  3/100] Iter[ 31/ 32]\t\tLoss: 1.8187 Acc@1: 37.097% \n",
            "Pseudo labeled: 0.000% (0/6944)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "\n",
            "| Validation Epoch #3\t\t\tLoss: 2.2976 Acc@1: 23.35%\n",
            "\n",
            "=> Training Epoch #4, LR=0.0300\n",
            "| Epoch [  4/100] Iter[  1/ 32]\t\tLoss: 1.7668 Acc@1: 31.250% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  4/100] Iter[ 16/ 32]\t\tLoss: 1.5631 Acc@1: 39.258% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  4/100] Iter[ 31/ 32]\t\tLoss: 2.5066 Acc@1: 35.685% \n",
            "Pseudo labeled: 2.463% (171/6944)    \tCorrect pseudo label: 30.41% (52/171)    \tSame output weak and strong augmentation: 93.57% (160/171)\n",
            "\n",
            "| Validation Epoch #4\t\t\tLoss: 3.4777 Acc@1: 29.40%\n",
            "| Saving Best model...\t\t\tTop1 = 29.40%\n",
            "\n",
            "=> Training Epoch #5, LR=0.0300\n",
            "| Epoch [  5/100] Iter[  1/ 32]\t\tLoss: 2.9021 Acc@1: 25.000% \n",
            "Pseudo labeled: 8.482% (19/224)    \tCorrect pseudo label: 42.11% (8/19)    \tSame output weak and strong augmentation: 94.74% (18/19)\n",
            "| Epoch [  5/100] Iter[ 16/ 32]\t\tLoss: 1.9783 Acc@1: 32.031% \n",
            "Pseudo labeled: 2.985% (107/3584)    \tCorrect pseudo label: 28.04% (30/107)    \tSame output weak and strong augmentation: 97.20% (104/107)\n",
            "| Epoch [  5/100] Iter[ 31/ 32]\t\tLoss: 1.4627 Acc@1: 32.863% \n",
            "Pseudo labeled: 1.541% (107/6944)    \tCorrect pseudo label: 28.04% (30/107)    \tSame output weak and strong augmentation: 97.20% (104/107)\n",
            "\n",
            "| Validation Epoch #5\t\t\tLoss: 2.5675 Acc@1: 29.65%\n",
            "| Saving Best model...\t\t\tTop1 = 29.65%\n",
            "\n",
            "=> Training Epoch #6, LR=0.0300\n",
            "| Epoch [  6/100] Iter[  1/ 32]\t\tLoss: 1.8189 Acc@1: 37.500% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  6/100] Iter[ 16/ 32]\t\tLoss: 1.3214 Acc@1: 39.648% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  6/100] Iter[ 31/ 32]\t\tLoss: 2.4530 Acc@1: 38.105% \n",
            "Pseudo labeled: 0.677% (47/6944)    \tCorrect pseudo label: 23.40% (11/47)    \tSame output weak and strong augmentation: 93.62% (44/47)\n",
            "\n",
            "| Validation Epoch #6\t\t\tLoss: 4.2510 Acc@1: 25.05%\n",
            "\n",
            "=> Training Epoch #7, LR=0.0300\n",
            "| Epoch [  7/100] Iter[  1/ 32]\t\tLoss: 2.5094 Acc@1: 28.125% \n",
            "Pseudo labeled: 8.036% (18/224)    \tCorrect pseudo label: 22.22% (4/18)    \tSame output weak and strong augmentation: 100.00% (18/18)\n",
            "| Epoch [  7/100] Iter[ 16/ 32]\t\tLoss: 2.7568 Acc@1: 31.445% \n",
            "Pseudo labeled: 2.651% (95/3584)    \tCorrect pseudo label: 20.00% (19/95)    \tSame output weak and strong augmentation: 94.74% (90/95)\n",
            "| Epoch [  7/100] Iter[ 31/ 32]\t\tLoss: 1.6117 Acc@1: 31.552% \n",
            "Pseudo labeled: 1.397% (97/6944)    \tCorrect pseudo label: 20.62% (20/97)    \tSame output weak and strong augmentation: 94.85% (92/97)\n",
            "\n",
            "| Validation Epoch #7\t\t\tLoss: 2.6490 Acc@1: 25.50%\n",
            "\n",
            "=> Training Epoch #8, LR=0.0300\n",
            "| Epoch [  8/100] Iter[  1/ 32]\t\tLoss: 1.8038 Acc@1: 31.250% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  8/100] Iter[ 16/ 32]\t\tLoss: 1.4864 Acc@1: 34.570% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  8/100] Iter[ 31/ 32]\t\tLoss: 1.6435 Acc@1: 40.121% \n",
            "Pseudo labeled: 0.000% (0/6944)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "\n",
            "| Validation Epoch #8\t\t\tLoss: 2.4512 Acc@1: 31.70%\n",
            "| Saving Best model...\t\t\tTop1 = 31.70%\n",
            "\n",
            "=> Training Epoch #9, LR=0.0300\n",
            "| Epoch [  9/100] Iter[  1/ 32]\t\tLoss: 1.7976 Acc@1: 31.250% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  9/100] Iter[ 16/ 32]\t\tLoss: 1.7166 Acc@1: 42.578% \n",
            "Pseudo labeled: 0.000% (0/3584)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [  9/100] Iter[ 31/ 32]\t\tLoss: 1.6555 Acc@1: 38.407% \n",
            "Pseudo labeled: 1.915% (133/6944)    \tCorrect pseudo label: 43.61% (58/133)    \tSame output weak and strong augmentation: 95.49% (127/133)\n",
            "\n",
            "| Validation Epoch #9\t\t\tLoss: 1.8215 Acc@1: 35.05%\n",
            "| Saving Best model...\t\t\tTop1 = 35.05%\n",
            "\n",
            "=> Training Epoch #10, LR=0.0300\n",
            "| Epoch [ 10/100] Iter[  1/ 32]\t\tLoss: 1.8126 Acc@1: 53.125% \n",
            "Pseudo labeled: 1.339% (3/224)    \tCorrect pseudo label: 33.33% (1/3)    \tSame output weak and strong augmentation: 100.00% (3/3)\n",
            "| Epoch [ 10/100] Iter[ 16/ 32]\t\tLoss: 2.5167 Acc@1: 40.039% \n",
            "Pseudo labeled: 2.846% (102/3584)    \tCorrect pseudo label: 38.24% (39/102)    \tSame output weak and strong augmentation: 92.16% (94/102)\n",
            "| Epoch [ 10/100] Iter[ 31/ 32]\t\tLoss: 2.2334 Acc@1: 34.476% \n",
            "Pseudo labeled: 2.074% (144/6944)    \tCorrect pseudo label: 27.08% (39/144)    \tSame output weak and strong augmentation: 93.75% (135/144)\n",
            "\n",
            "| Validation Epoch #10\t\t\tLoss: 2.3545 Acc@1: 33.75%\n",
            "\n",
            "=> Training Epoch #11, LR=0.0300\n",
            "| Epoch [ 11/100] Iter[  1/ 32]\t\tLoss: 1.6941 Acc@1: 46.875% \n",
            "Pseudo labeled: 1.339% (3/224)    \tCorrect pseudo label: 66.67% (2/3)    \tSame output weak and strong augmentation: 100.00% (3/3)\n",
            "| Epoch [ 11/100] Iter[ 16/ 32]\t\tLoss: 1.4317 Acc@1: 39.062% \n",
            "Pseudo labeled: 3.348% (120/3584)    \tCorrect pseudo label: 40.83% (49/120)    \tSame output weak and strong augmentation: 98.33% (118/120)\n",
            "| Epoch [ 11/100] Iter[ 31/ 32]\t\tLoss: 1.4938 Acc@1: 40.323% \n",
            "Pseudo labeled: 1.728% (120/6944)    \tCorrect pseudo label: 40.83% (49/120)    \tSame output weak and strong augmentation: 98.33% (118/120)\n",
            "\n",
            "| Validation Epoch #11\t\t\tLoss: 3.3933 Acc@1: 32.75%\n",
            "\n",
            "=> Training Epoch #12, LR=0.0300\n",
            "| Epoch [ 12/100] Iter[  1/ 32]\t\tLoss: 1.6521 Acc@1: 43.750% \n",
            "Pseudo labeled: 0.000% (0/224)    \tCorrect pseudo label: Undefined (0/0)    \tSame output weak and strong augmentation: Undefined (0/0)\n",
            "| Epoch [ 12/100] Iter[ 16/ 32]\t\tLoss: 1.8903 Acc@1: 45.312% \n",
            "Pseudo labeled: 1.869% (67/3584)    \tCorrect pseudo label: 40.30% (27/67)    \tSame output weak and strong augmentation: 85.07% (57/67)\n",
            "| Epoch [ 12/100] Iter[ 31/ 32]\t\tLoss: 2.1678 Acc@1: 35.181% \n",
            "Pseudo labeled: 1.800% (125/6944)    \tCorrect pseudo label: 38.40% (48/125)    \tSame output weak and strong augmentation: 88.00% (110/125)\n",
            "\n",
            "| Validation Epoch #12\t\t\tLoss: 1.3992 Acc@1: 27.35%\n",
            "\n",
            "=> Training Epoch #13, LR=0.0300\n",
            "| Epoch [ 13/100] Iter[  1/ 32]\t\tLoss: 2.1529 Acc@1: 25.000% \n",
            "Pseudo labeled: 1.786% (4/224)    \tCorrect pseudo label: 50.00% (2/4)    \tSame output weak and strong augmentation: 100.00% (4/4)\n",
            "| Epoch [ 13/100] Iter[ 16/ 32]\t\tLoss: 1.8251 Acc@1: 33.984% \n",
            "Pseudo labeled: 1.730% (62/3584)    \tCorrect pseudo label: 37.10% (23/62)    \tSame output weak and strong augmentation: 93.55% (58/62)\n",
            "| Epoch [ 13/100] Iter[ 31/ 32]\t\tLoss: 1.8094 Acc@1: 33.266% \n",
            "Pseudo labeled: 2.779% (193/6944)    \tCorrect pseudo label: 44.04% (85/193)    \tSame output weak and strong augmentation: 92.75% (179/193)\n",
            "\n",
            "| Validation Epoch #13\t\t\tLoss: 3.2373 Acc@1: 32.45%\n",
            "\n",
            "=> Training Epoch #14, LR=0.0300\n",
            "| Epoch [ 14/100] Iter[  1/ 32]\t\tLoss: 2.0931 Acc@1: 34.375% \n",
            "Pseudo labeled: 2.679% (6/224)    \tCorrect pseudo label: 50.00% (3/6)    \tSame output weak and strong augmentation: 100.00% (6/6)\n",
            "| Epoch [ 14/100] Iter[ 16/ 32]\t\tLoss: 2.2053 Acc@1: 38.867% \n",
            "Pseudo labeled: 3.906% (140/3584)    \tCorrect pseudo label: 65.00% (91/140)    \tSame output weak and strong augmentation: 96.43% (135/140)\n",
            "| Epoch [ 14/100] Iter[ 31/ 32]\t\tLoss: 2.0073 Acc@1: 37.802% \n",
            "Pseudo labeled: 3.384% (235/6944)    \tCorrect pseudo label: 62.55% (147/235)    \tSame output weak and strong augmentation: 95.74% (225/235)\n",
            "\n",
            "| Validation Epoch #14\t\t\tLoss: 2.4981 Acc@1: 35.00%\n",
            "\n",
            "=> Training Epoch #15, LR=0.0300\n",
            "| Epoch [ 15/100] Iter[  1/ 32]\t\tLoss: 1.5375 Acc@1: 46.875% \n",
            "Pseudo labeled: 4.018% (9/224)    \tCorrect pseudo label: 88.89% (8/9)    \tSame output weak and strong augmentation: 100.00% (9/9)\n",
            "| Epoch [ 15/100] Iter[ 16/ 32]\t\tLoss: 2.4474 Acc@1: 45.117% \n",
            "Pseudo labeled: 3.739% (134/3584)    \tCorrect pseudo label: 54.48% (73/134)    \tSame output weak and strong augmentation: 96.27% (129/134)\n",
            "| Epoch [ 15/100] Iter[ 31/ 32]\t\tLoss: 1.3824 Acc@1: 43.448% \n",
            "Pseudo labeled: 3.255% (226/6944)    \tCorrect pseudo label: 58.41% (132/226)    \tSame output weak and strong augmentation: 94.69% (214/226)\n",
            "\n",
            "| Validation Epoch #15\t\t\tLoss: 1.3117 Acc@1: 41.95%\n",
            "| Saving Best model...\t\t\tTop1 = 41.95%\n",
            "\n",
            "=> Training Epoch #16, LR=0.0300\n",
            "| Epoch [ 16/100] Iter[  1/ 32]\t\tLoss: 1.5048 Acc@1: 62.500% \n",
            "Pseudo labeled: 0.446% (1/224)    \tCorrect pseudo label: 100.00% (1/1)    \tSame output weak and strong augmentation: 100.00% (1/1)\n",
            "| Epoch [ 16/100] Iter[ 16/ 32]\t\tLoss: 1.7543 Acc@1: 43.164% \n",
            "Pseudo labeled: 4.353% (156/3584)    \tCorrect pseudo label: 67.95% (106/156)    \tSame output weak and strong augmentation: 96.15% (150/156)\n",
            "| Epoch [ 16/100] Iter[ 31/ 32]\t\tLoss: 2.1029 Acc@1: 43.952% \n",
            "Pseudo labeled: 4.983% (346/6944)    \tCorrect pseudo label: 61.27% (212/346)    \tSame output weak and strong augmentation: 96.24% (333/346)\n",
            "\n",
            "| Validation Epoch #16\t\t\tLoss: 2.7789 Acc@1: 34.50%\n",
            "\n",
            "=> Training Epoch #17, LR=0.0300\n",
            "| Epoch [ 17/100] Iter[  1/ 32]\t\tLoss: 1.9630 Acc@1: 43.750% \n",
            "Pseudo labeled: 10.268% (23/224)    \tCorrect pseudo label: 60.87% (14/23)    \tSame output weak and strong augmentation: 100.00% (23/23)\n",
            "| Epoch [ 17/100] Iter[ 16/ 32]\t\tLoss: 1.7117 Acc@1: 49.023% \n",
            "Pseudo labeled: 5.329% (191/3584)    \tCorrect pseudo label: 70.16% (134/191)    \tSame output weak and strong augmentation: 93.19% (178/191)\n",
            "| Epoch [ 17/100] Iter[ 31/ 32]\t\tLoss: 1.3537 Acc@1: 46.875% \n",
            "Pseudo labeled: 5.487% (381/6944)    \tCorrect pseudo label: 68.24% (260/381)    \tSame output weak and strong augmentation: 92.39% (352/381)\n",
            "\n",
            "| Validation Epoch #17\t\t\tLoss: 1.4285 Acc@1: 40.75%\n",
            "\n",
            "=> Training Epoch #18, LR=0.0300\n",
            "| Epoch [ 18/100] Iter[  1/ 32]\t\tLoss: 1.9148 Acc@1: 37.500% \n",
            "Pseudo labeled: 2.679% (6/224)    \tCorrect pseudo label: 50.00% (3/6)    \tSame output weak and strong augmentation: 100.00% (6/6)\n",
            "| Epoch [ 18/100] Iter[ 16/ 32]\t\tLoss: 1.7465 Acc@1: 49.414% \n",
            "Pseudo labeled: 6.417% (230/3584)    \tCorrect pseudo label: 69.57% (160/230)    \tSame output weak and strong augmentation: 93.91% (216/230)\n",
            "| Epoch [ 18/100] Iter[ 31/ 32]\t\tLoss: 2.2135 Acc@1: 50.403% \n",
            "Pseudo labeled: 6.855% (476/6944)    \tCorrect pseudo label: 70.80% (337/476)    \tSame output weak and strong augmentation: 91.39% (435/476)\n",
            "\n",
            "| Validation Epoch #18\t\t\tLoss: 3.0178 Acc@1: 33.25%\n",
            "\n",
            "=> Training Epoch #19, LR=0.0300\n",
            "| Epoch [ 19/100] Iter[  1/ 32]\t\tLoss: 1.4033 Acc@1: 56.250% \n",
            "Pseudo labeled: 9.375% (21/224)    \tCorrect pseudo label: 76.19% (16/21)    \tSame output weak and strong augmentation: 95.24% (20/21)\n",
            "| Epoch [ 19/100] Iter[ 16/ 32]\t\tLoss: 1.9629 Acc@1: 50.977% \n",
            "Pseudo labeled: 5.943% (213/3584)    \tCorrect pseudo label: 70.89% (151/213)    \tSame output weak and strong augmentation: 95.31% (203/213)\n",
            "| Epoch [ 19/100] Iter[ 31/ 32]\t\tLoss: 1.7361 Acc@1: 50.101% \n",
            "Pseudo labeled: 6.020% (418/6944)    \tCorrect pseudo label: 72.97% (305/418)    \tSame output weak and strong augmentation: 95.22% (398/418)\n",
            "\n",
            "| Validation Epoch #19\t\t\tLoss: 2.3800 Acc@1: 41.25%\n",
            "\n",
            "=> Training Epoch #20, LR=0.0300\n",
            "| Epoch [ 20/100] Iter[  1/ 32]\t\tLoss: 1.9527 Acc@1: 50.000% \n",
            "Pseudo labeled: 3.571% (8/224)    \tCorrect pseudo label: 75.00% (6/8)    \tSame output weak and strong augmentation: 87.50% (7/8)\n",
            "| Epoch [ 20/100] Iter[ 16/ 32]\t\tLoss: 1.2693 Acc@1: 54.883% \n",
            "Pseudo labeled: 6.278% (225/3584)    \tCorrect pseudo label: 70.22% (158/225)    \tSame output weak and strong augmentation: 94.22% (212/225)\n",
            "| Epoch [ 20/100] Iter[ 31/ 32]\t\tLoss: 2.1992 Acc@1: 52.823% \n",
            "Pseudo labeled: 7.388% (513/6944)    \tCorrect pseudo label: 63.16% (324/513)    \tSame output weak and strong augmentation: 92.40% (474/513)\n",
            "\n",
            "| Validation Epoch #20\t\t\tLoss: 1.1490 Acc@1: 42.45%\n",
            "| Saving Best model...\t\t\tTop1 = 42.45%\n",
            "\n",
            "=> Training Epoch #21, LR=0.0300\n",
            "| Epoch [ 21/100] Iter[  1/ 32]\t\tLoss: 1.5819 Acc@1: 59.375% \n",
            "Pseudo labeled: 4.018% (9/224)    \tCorrect pseudo label: 44.44% (4/9)    \tSame output weak and strong augmentation: 100.00% (9/9)\n",
            "| Epoch [ 21/100] Iter[ 16/ 32]\t\tLoss: 1.6696 Acc@1: 55.469% \n",
            "Pseudo labeled: 5.999% (215/3584)    \tCorrect pseudo label: 64.65% (139/215)    \tSame output weak and strong augmentation: 93.02% (200/215)\n",
            "| Epoch [ 21/100] Iter[ 31/ 32]\t\tLoss: 1.5244 Acc@1: 54.536% \n",
            "Pseudo labeled: 6.207% (431/6944)    \tCorrect pseudo label: 71.46% (308/431)    \tSame output weak and strong augmentation: 90.49% (390/431)\n",
            "\n",
            "| Validation Epoch #21\t\t\tLoss: 1.4541 Acc@1: 37.40%\n",
            "\n",
            "=> Training Epoch #22, LR=0.0300\n",
            "| Epoch [ 22/100] Iter[  1/ 32]\t\tLoss: 1.3373 Acc@1: 62.500% \n",
            "Pseudo labeled: 3.125% (7/224)    \tCorrect pseudo label: 57.14% (4/7)    \tSame output weak and strong augmentation: 85.71% (6/7)\n",
            "| Epoch [ 22/100] Iter[ 16/ 32]\t\tLoss: 1.4386 Acc@1: 56.055% \n",
            "Pseudo labeled: 8.203% (294/3584)    \tCorrect pseudo label: 75.85% (223/294)    \tSame output weak and strong augmentation: 93.54% (275/294)\n",
            "| Epoch [ 22/100] Iter[ 31/ 32]\t\tLoss: 2.3102 Acc@1: 55.343% \n",
            "Pseudo labeled: 8.511% (591/6944)    \tCorrect pseudo label: 79.53% (470/591)    \tSame output weak and strong augmentation: 90.86% (537/591)\n",
            "\n",
            "| Validation Epoch #22\t\t\tLoss: 2.1284 Acc@1: 38.20%\n",
            "\n",
            "=> Training Epoch #23, LR=0.0300\n",
            "| Epoch [ 23/100] Iter[  1/ 32]\t\tLoss: 1.1879 Acc@1: 71.875% \n",
            "Pseudo labeled: 5.804% (13/224)    \tCorrect pseudo label: 92.31% (12/13)    \tSame output weak and strong augmentation: 92.31% (12/13)\n",
            "| Epoch [ 23/100] Iter[ 16/ 32]\t\tLoss: 1.5133 Acc@1: 59.375% \n",
            "Pseudo labeled: 8.259% (296/3584)    \tCorrect pseudo label: 83.11% (246/296)    \tSame output weak and strong augmentation: 89.19% (264/296)\n",
            "| Epoch [ 23/100] Iter[ 31/ 32]\t\tLoss: 1.5580 Acc@1: 58.871% \n",
            "Pseudo labeled: 8.252% (573/6944)    \tCorrect pseudo label: 81.33% (466/573)    \tSame output weak and strong augmentation: 89.01% (510/573)\n",
            "\n",
            "| Validation Epoch #23\t\t\tLoss: 1.0281 Acc@1: 45.60%\n",
            "| Saving Best model...\t\t\tTop1 = 45.60%\n",
            "\n",
            "=> Training Epoch #24, LR=0.0300\n",
            "| Epoch [ 24/100] Iter[  1/ 32]\t\tLoss: 1.5428 Acc@1: 71.875% \n",
            "Pseudo labeled: 9.821% (22/224)    \tCorrect pseudo label: 68.18% (15/22)    \tSame output weak and strong augmentation: 77.27% (17/22)\n",
            "| Epoch [ 24/100] Iter[ 16/ 32]\t\tLoss: 1.2956 Acc@1: 66.016% \n",
            "Pseudo labeled: 12.667% (454/3584)    \tCorrect pseudo label: 84.14% (382/454)    \tSame output weak and strong augmentation: 88.77% (403/454)\n",
            "| Epoch [ 24/100] Iter[ 31/ 32]\t\tLoss: 2.1188 Acc@1: 64.315% \n",
            "Pseudo labeled: 11.780% (818/6944)    \tCorrect pseudo label: 84.35% (690/818)    \tSame output weak and strong augmentation: 88.63% (725/818)\n",
            "\n",
            "| Validation Epoch #24\t\t\tLoss: 1.1846 Acc@1: 43.10%\n",
            "\n",
            "=> Training Epoch #25, LR=0.0300\n",
            "| Epoch [ 25/100] Iter[  1/ 32]\t\tLoss: 1.1042 Acc@1: 68.750% \n",
            "Pseudo labeled: 12.500% (28/224)    \tCorrect pseudo label: 82.14% (23/28)    \tSame output weak and strong augmentation: 85.71% (24/28)\n",
            "| Epoch [ 25/100] Iter[ 16/ 32]\t\tLoss: 1.2876 Acc@1: 65.430% \n",
            "Pseudo labeled: 13.644% (489/3584)    \tCorrect pseudo label: 80.57% (394/489)    \tSame output weak and strong augmentation: 89.37% (437/489)\n",
            "| Epoch [ 25/100] Iter[ 31/ 32]\t\tLoss: 1.7768 Acc@1: 66.028% \n",
            "Pseudo labeled: 13.710% (952/6944)    \tCorrect pseudo label: 80.78% (769/952)    \tSame output weak and strong augmentation: 88.13% (839/952)\n",
            "\n",
            "| Validation Epoch #25\t\t\tLoss: 2.7624 Acc@1: 43.55%\n",
            "\n",
            "=> Training Epoch #26, LR=0.0300\n",
            "| Epoch [ 26/100] Iter[  1/ 32]\t\tLoss: 1.0774 Acc@1: 59.375% \n",
            "Pseudo labeled: 10.268% (23/224)    \tCorrect pseudo label: 86.96% (20/23)    \tSame output weak and strong augmentation: 91.30% (21/23)\n",
            "| Epoch [ 26/100] Iter[ 16/ 32]\t\tLoss: 1.1334 Acc@1: 67.383% \n",
            "Pseudo labeled: 13.142% (471/3584)    \tCorrect pseudo label: 80.47% (379/471)    \tSame output weak and strong augmentation: 87.05% (410/471)\n",
            "| Epoch [ 26/100] Iter[ 31/ 32]\t\tLoss: 1.3820 Acc@1: 66.935% \n",
            "Pseudo labeled: 14.070% (977/6944)    \tCorrect pseudo label: 79.43% (776/977)    \tSame output weak and strong augmentation: 87.10% (851/977)\n",
            "\n",
            "| Validation Epoch #26\t\t\tLoss: 3.2391 Acc@1: 41.15%\n",
            "\n",
            "=> Training Epoch #27, LR=0.0300\n",
            "| Epoch [ 27/100] Iter[  1/ 32]\t\tLoss: 1.2719 Acc@1: 75.000% \n",
            "Pseudo labeled: 11.607% (26/224)    \tCorrect pseudo label: 69.23% (18/26)    \tSame output weak and strong augmentation: 76.92% (20/26)\n",
            "| Epoch [ 27/100] Iter[ 16/ 32]\t\tLoss: 1.2152 Acc@1: 71.289% \n",
            "Pseudo labeled: 12.863% (461/3584)    \tCorrect pseudo label: 85.90% (396/461)    \tSame output weak and strong augmentation: 87.42% (403/461)\n",
            "| Epoch [ 27/100] Iter[ 31/ 32]\t\tLoss: 1.1434 Acc@1: 67.742% \n",
            "Pseudo labeled: 14.372% (998/6944)    \tCorrect pseudo label: 83.17% (830/998)    \tSame output weak and strong augmentation: 87.17% (870/998)\n",
            "\n",
            "| Validation Epoch #27\t\t\tLoss: 0.9888 Acc@1: 49.10%\n",
            "| Saving Best model...\t\t\tTop1 = 49.10%\n",
            "\n",
            "=> Training Epoch #28, LR=0.0300\n",
            "| Epoch [ 28/100] Iter[  1/ 32]\t\tLoss: 0.8523 Acc@1: 81.250% \n",
            "Pseudo labeled: 13.839% (31/224)    \tCorrect pseudo label: 87.10% (27/31)    \tSame output weak and strong augmentation: 90.32% (28/31)\n",
            "| Epoch [ 28/100] Iter[ 16/ 32]\t\tLoss: 1.3001 Acc@1: 73.438% \n",
            "Pseudo labeled: 16.211% (581/3584)    \tCorrect pseudo label: 82.62% (480/581)    \tSame output weak and strong augmentation: 85.54% (497/581)\n",
            "| Epoch [ 28/100] Iter[ 31/ 32]\t\tLoss: 1.1923 Acc@1: 70.262% \n",
            "Pseudo labeled: 15.783% (1096/6944)    \tCorrect pseudo label: 81.39% (892/1096)    \tSame output weak and strong augmentation: 85.49% (937/1096)\n",
            "\n",
            "| Validation Epoch #28\t\t\tLoss: 1.0213 Acc@1: 45.95%\n",
            "\n",
            "=> Training Epoch #29, LR=0.0300\n",
            "| Epoch [ 29/100] Iter[  1/ 32]\t\tLoss: 1.5300 Acc@1: 56.250% \n",
            "Pseudo labeled: 16.071% (36/224)    \tCorrect pseudo label: 66.67% (24/36)    \tSame output weak and strong augmentation: 88.89% (32/36)\n",
            "| Epoch [ 29/100] Iter[ 16/ 32]\t\tLoss: 1.4244 Acc@1: 73.242% \n",
            "Pseudo labeled: 13.588% (487/3584)    \tCorrect pseudo label: 84.80% (413/487)    \tSame output weak and strong augmentation: 85.42% (416/487)\n",
            "| Epoch [ 29/100] Iter[ 31/ 32]\t\tLoss: 1.0615 Acc@1: 74.294% \n",
            "Pseudo labeled: 15.697% (1090/6944)    \tCorrect pseudo label: 83.39% (909/1090)    \tSame output weak and strong augmentation: 86.24% (940/1090)\n",
            "\n",
            "| Validation Epoch #29\t\t\tLoss: 1.9487 Acc@1: 41.35%\n",
            "\n",
            "=> Training Epoch #30, LR=0.0300\n",
            "| Epoch [ 30/100] Iter[  1/ 32]\t\tLoss: 1.3664 Acc@1: 62.500% \n",
            "Pseudo labeled: 17.857% (40/224)    \tCorrect pseudo label: 80.00% (32/40)    \tSame output weak and strong augmentation: 87.50% (35/40)\n",
            "| Epoch [ 30/100] Iter[ 16/ 32]\t\tLoss: 1.1173 Acc@1: 78.906% \n",
            "Pseudo labeled: 18.610% (667/3584)    \tCorrect pseudo label: 82.01% (547/667)    \tSame output weak and strong augmentation: 83.21% (555/667)\n",
            "| Epoch [ 30/100] Iter[ 31/ 32]\t\tLoss: 1.2131 Acc@1: 76.109% \n",
            "Pseudo labeled: 18.548% (1288/6944)    \tCorrect pseudo label: 82.76% (1066/1288)    \tSame output weak and strong augmentation: 83.23% (1072/1288)\n",
            "\n",
            "| Validation Epoch #30\t\t\tLoss: 0.3296 Acc@1: 49.50%\n",
            "| Saving Best model...\t\t\tTop1 = 49.50%\n",
            "\n",
            "=> Training Epoch #31, LR=0.0300\n",
            "| Epoch [ 31/100] Iter[  1/ 32]\t\tLoss: 1.4417 Acc@1: 65.625% \n",
            "Pseudo labeled: 20.089% (45/224)    \tCorrect pseudo label: 82.22% (37/45)    \tSame output weak and strong augmentation: 80.00% (36/45)\n",
            "| Epoch [ 31/100] Iter[ 16/ 32]\t\tLoss: 0.8731 Acc@1: 82.422% \n",
            "Pseudo labeled: 19.950% (715/3584)    \tCorrect pseudo label: 82.38% (589/715)    \tSame output weak and strong augmentation: 85.73% (613/715)\n",
            "| Epoch [ 31/100] Iter[ 31/ 32]\t\tLoss: 1.0045 Acc@1: 79.839% \n",
            "Pseudo labeled: 19.052% (1323/6944)    \tCorrect pseudo label: 81.03% (1072/1323)    \tSame output weak and strong augmentation: 85.03% (1125/1323)\n",
            "\n",
            "| Validation Epoch #31\t\t\tLoss: 1.0986 Acc@1: 50.40%\n",
            "| Saving Best model...\t\t\tTop1 = 50.40%\n",
            "\n",
            "=> Training Epoch #32, LR=0.0300\n",
            "| Epoch [ 32/100] Iter[  1/ 32]\t\tLoss: 1.0893 Acc@1: 90.625% \n",
            "Pseudo labeled: 19.643% (44/224)    \tCorrect pseudo label: 81.82% (36/44)    \tSame output weak and strong augmentation: 84.09% (37/44)\n",
            "| Epoch [ 32/100] Iter[ 16/ 32]\t\tLoss: 1.4605 Acc@1: 80.859% \n",
            "Pseudo labeled: 19.336% (693/3584)    \tCorrect pseudo label: 81.53% (565/693)    \tSame output weak and strong augmentation: 86.00% (596/693)\n",
            "| Epoch [ 32/100] Iter[ 31/ 32]\t\tLoss: 1.1881 Acc@1: 79.536% \n",
            "Pseudo labeled: 19.643% (1364/6944)    \tCorrect pseudo label: 82.84% (1130/1364)    \tSame output weak and strong augmentation: 85.63% (1168/1364)\n",
            "\n",
            "| Validation Epoch #32\t\t\tLoss: 0.7131 Acc@1: 48.80%\n",
            "\n",
            "=> Training Epoch #33, LR=0.0300\n",
            "| Epoch [ 33/100] Iter[  1/ 32]\t\tLoss: 0.8185 Acc@1: 81.250% \n",
            "Pseudo labeled: 18.750% (42/224)    \tCorrect pseudo label: 69.05% (29/42)    \tSame output weak and strong augmentation: 85.71% (36/42)\n",
            "| Epoch [ 33/100] Iter[ 16/ 32]\t\tLoss: 0.5114 Acc@1: 83.203% \n",
            "Pseudo labeled: 20.647% (740/3584)    \tCorrect pseudo label: 83.24% (616/740)    \tSame output weak and strong augmentation: 86.62% (641/740)\n",
            "| Epoch [ 33/100] Iter[ 31/ 32]\t\tLoss: 1.1210 Acc@1: 82.560% \n",
            "Pseudo labeled: 19.888% (1381/6944)    \tCorrect pseudo label: 82.55% (1140/1381)    \tSame output weak and strong augmentation: 85.08% (1175/1381)\n",
            "\n",
            "| Validation Epoch #33\t\t\tLoss: 1.2842 Acc@1: 48.15%\n",
            "\n",
            "=> Training Epoch #34, LR=0.0300\n",
            "| Epoch [ 34/100] Iter[  1/ 32]\t\tLoss: 0.8382 Acc@1: 87.500% \n",
            "Pseudo labeled: 16.964% (38/224)    \tCorrect pseudo label: 63.16% (24/38)    \tSame output weak and strong augmentation: 84.21% (32/38)\n",
            "| Epoch [ 34/100] Iter[ 16/ 32]\t\tLoss: 0.6395 Acc@1: 88.086% \n",
            "Pseudo labeled: 22.266% (798/3584)    \tCorrect pseudo label: 80.08% (639/798)    \tSame output weak and strong augmentation: 84.09% (671/798)\n",
            "| Epoch [ 34/100] Iter[ 31/ 32]\t\tLoss: 1.0834 Acc@1: 85.081% \n",
            "Pseudo labeled: 23.041% (1600/6944)    \tCorrect pseudo label: 81.31% (1301/1600)    \tSame output weak and strong augmentation: 84.81% (1357/1600)\n",
            "\n",
            "| Validation Epoch #34\t\t\tLoss: 0.1326 Acc@1: 54.90%\n",
            "| Saving Best model...\t\t\tTop1 = 54.90%\n",
            "\n",
            "=> Training Epoch #35, LR=0.0300\n",
            "| Epoch [ 35/100] Iter[  1/ 32]\t\tLoss: 0.6716 Acc@1: 96.875% \n",
            "Pseudo labeled: 20.982% (47/224)    \tCorrect pseudo label: 80.85% (38/47)    \tSame output weak and strong augmentation: 87.23% (41/47)\n",
            "| Epoch [ 35/100] Iter[ 16/ 32]\t\tLoss: 0.9882 Acc@1: 89.062% \n",
            "Pseudo labeled: 24.665% (884/3584)    \tCorrect pseudo label: 82.35% (728/884)    \tSame output weak and strong augmentation: 85.41% (755/884)\n",
            "| Epoch [ 35/100] Iter[ 31/ 32]\t\tLoss: 1.4551 Acc@1: 87.298% \n",
            "Pseudo labeled: 24.352% (1691/6944)    \tCorrect pseudo label: 81.90% (1385/1691)    \tSame output weak and strong augmentation: 83.68% (1415/1691)\n",
            "\n",
            "| Validation Epoch #35\t\t\tLoss: 1.9653 Acc@1: 49.80%\n",
            "\n",
            "=> Training Epoch #36, LR=0.0300\n",
            "| Epoch [ 36/100] Iter[  1/ 32]\t\tLoss: 1.4965 Acc@1: 68.750% \n",
            "Pseudo labeled: 22.321% (50/224)    \tCorrect pseudo label: 78.00% (39/50)    \tSame output weak and strong augmentation: 80.00% (40/50)\n",
            "| Epoch [ 36/100] Iter[ 16/ 32]\t\tLoss: 0.9309 Acc@1: 85.352% \n",
            "Pseudo labeled: 23.661% (848/3584)    \tCorrect pseudo label: 80.42% (682/848)    \tSame output weak and strong augmentation: 83.02% (704/848)\n",
            "| Epoch [ 36/100] Iter[ 31/ 32]\t\tLoss: 1.0183 Acc@1: 85.988% \n",
            "Pseudo labeled: 24.093% (1673/6944)    \tCorrect pseudo label: 80.16% (1341/1673)    \tSame output weak and strong augmentation: 82.67% (1383/1673)\n",
            "\n",
            "| Validation Epoch #36\t\t\tLoss: 0.3410 Acc@1: 53.20%\n",
            "\n",
            "=> Training Epoch #37, LR=0.0300\n",
            "| Epoch [ 37/100] Iter[  1/ 32]\t\tLoss: 1.0676 Acc@1: 84.375% \n",
            "Pseudo labeled: 23.214% (52/224)    \tCorrect pseudo label: 78.85% (41/52)    \tSame output weak and strong augmentation: 78.85% (41/52)\n",
            "| Epoch [ 37/100] Iter[ 16/ 32]\t\tLoss: 0.7067 Acc@1: 90.039% \n",
            "Pseudo labeled: 22.824% (818/3584)    \tCorrect pseudo label: 81.30% (665/818)    \tSame output weak and strong augmentation: 83.74% (685/818)\n",
            "| Epoch [ 37/100] Iter[ 31/ 32]\t\tLoss: 1.1991 Acc@1: 87.298% \n",
            "Pseudo labeled: 24.525% (1703/6944)    \tCorrect pseudo label: 80.15% (1365/1703)    \tSame output weak and strong augmentation: 84.32% (1436/1703)\n",
            "\n",
            "| Validation Epoch #37\t\t\tLoss: 1.0924 Acc@1: 44.00%\n",
            "\n",
            "=> Training Epoch #38, LR=0.0300\n",
            "| Epoch [ 38/100] Iter[  1/ 32]\t\tLoss: 1.0044 Acc@1: 84.375% \n",
            "Pseudo labeled: 30.357% (68/224)    \tCorrect pseudo label: 85.29% (58/68)    \tSame output weak and strong augmentation: 79.41% (54/68)\n",
            "| Epoch [ 38/100] Iter[ 16/ 32]\t\tLoss: 1.0698 Acc@1: 91.016% \n",
            "Pseudo labeled: 26.507% (950/3584)    \tCorrect pseudo label: 80.42% (764/950)    \tSame output weak and strong augmentation: 82.74% (786/950)\n",
            "| Epoch [ 38/100] Iter[ 31/ 32]\t\tLoss: 0.7107 Acc@1: 92.540% \n",
            "Pseudo labeled: 26.671% (1852/6944)    \tCorrect pseudo label: 79.97% (1481/1852)    \tSame output weak and strong augmentation: 83.05% (1538/1852)\n",
            "\n",
            "| Validation Epoch #38\t\t\tLoss: 0.5774 Acc@1: 50.90%\n",
            "\n",
            "=> Training Epoch #39, LR=0.0300\n",
            "| Epoch [ 39/100] Iter[  1/ 32]\t\tLoss: 0.8917 Acc@1: 84.375% \n",
            "Pseudo labeled: 28.571% (64/224)    \tCorrect pseudo label: 81.25% (52/64)    \tSame output weak and strong augmentation: 84.38% (54/64)\n",
            "| Epoch [ 39/100] Iter[ 16/ 32]\t\tLoss: 1.1312 Acc@1: 93.750% \n",
            "Pseudo labeled: 27.818% (997/3584)    \tCorrect pseudo label: 76.13% (759/997)    \tSame output weak and strong augmentation: 82.15% (819/997)\n",
            "| Epoch [ 39/100] Iter[ 31/ 32]\t\tLoss: 0.9210 Acc@1: 91.230% \n",
            "Pseudo labeled: 27.578% (1915/6944)    \tCorrect pseudo label: 77.86% (1491/1915)    \tSame output weak and strong augmentation: 81.98% (1570/1915)\n",
            "\n",
            "| Validation Epoch #39\t\t\tLoss: 0.6559 Acc@1: 54.10%\n",
            "\n",
            "=> Training Epoch #40, LR=0.0300\n",
            "| Epoch [ 40/100] Iter[  1/ 32]\t\tLoss: 0.5640 Acc@1: 87.500% \n",
            "Pseudo labeled: 29.911% (67/224)    \tCorrect pseudo label: 74.63% (50/67)    \tSame output weak and strong augmentation: 89.55% (60/67)\n",
            "| Epoch [ 40/100] Iter[ 16/ 32]\t\tLoss: 0.5769 Acc@1: 93.750% \n",
            "Pseudo labeled: 28.181% (1010/3584)    \tCorrect pseudo label: 80.99% (818/1010)    \tSame output weak and strong augmentation: 86.93% (878/1010)\n",
            "| Epoch [ 40/100] Iter[ 31/ 32]\t\tLoss: 0.8382 Acc@1: 93.044% \n",
            "Pseudo labeled: 28.125% (1953/6944)    \tCorrect pseudo label: 80.44% (1571/1953)    \tSame output weak and strong augmentation: 84.54% (1651/1953)\n",
            "\n",
            "| Validation Epoch #40\t\t\tLoss: 2.7712 Acc@1: 51.15%\n",
            "\n",
            "=> Training Epoch #41, LR=0.0300\n",
            "| Epoch [ 41/100] Iter[  1/ 32]\t\tLoss: 1.0195 Acc@1: 96.875% \n",
            "Pseudo labeled: 27.232% (61/224)    \tCorrect pseudo label: 73.77% (45/61)    \tSame output weak and strong augmentation: 72.13% (44/61)\n",
            "| Epoch [ 41/100] Iter[ 16/ 32]\t\tLoss: 1.3650 Acc@1: 93.359% \n",
            "Pseudo labeled: 31.920% (1144/3584)    \tCorrect pseudo label: 77.71% (889/1144)    \tSame output weak and strong augmentation: 83.48% (955/1144)\n",
            "| Epoch [ 41/100] Iter[ 31/ 32]\t\tLoss: 0.7316 Acc@1: 92.137% \n",
            "Pseudo labeled: 31.351% (2177/6944)    \tCorrect pseudo label: 78.69% (1713/2177)    \tSame output weak and strong augmentation: 83.37% (1815/2177)\n",
            "\n",
            "| Validation Epoch #41\t\t\tLoss: 0.4980 Acc@1: 50.40%\n",
            "\n",
            "=> Training Epoch #42, LR=0.0300\n",
            "| Epoch [ 42/100] Iter[  1/ 32]\t\tLoss: 0.9651 Acc@1: 84.375% \n",
            "Pseudo labeled: 19.196% (43/224)    \tCorrect pseudo label: 81.40% (35/43)    \tSame output weak and strong augmentation: 81.40% (35/43)\n",
            "| Epoch [ 42/100] Iter[ 16/ 32]\t\tLoss: 1.4145 Acc@1: 92.969% \n",
            "Pseudo labeled: 28.181% (1010/3584)    \tCorrect pseudo label: 77.72% (785/1010)    \tSame output weak and strong augmentation: 84.46% (853/1010)\n",
            "| Epoch [ 42/100] Iter[ 31/ 32]\t\tLoss: 1.2160 Acc@1: 91.129% \n",
            "Pseudo labeled: 27.938% (1940/6944)    \tCorrect pseudo label: 76.80% (1490/1940)    \tSame output weak and strong augmentation: 82.89% (1608/1940)\n",
            "\n",
            "| Validation Epoch #42\t\t\tLoss: 0.0902 Acc@1: 55.70%\n",
            "| Saving Best model...\t\t\tTop1 = 55.70%\n",
            "\n",
            "=> Training Epoch #43, LR=0.0300\n",
            "| Epoch [ 43/100] Iter[  1/ 32]\t\tLoss: 0.8713 Acc@1: 84.375% \n",
            "Pseudo labeled: 27.232% (61/224)    \tCorrect pseudo label: 72.13% (44/61)    \tSame output weak and strong augmentation: 88.52% (54/61)\n",
            "| Epoch [ 43/100] Iter[ 16/ 32]\t\tLoss: 0.5256 Acc@1: 94.727% \n",
            "Pseudo labeled: 28.544% (1023/3584)    \tCorrect pseudo label: 78.79% (806/1023)    \tSame output weak and strong augmentation: 84.95% (869/1023)\n",
            "| Epoch [ 43/100] Iter[ 31/ 32]\t\tLoss: 0.7552 Acc@1: 93.548% \n",
            "Pseudo labeled: 28.687% (1992/6944)    \tCorrect pseudo label: 78.77% (1569/1992)    \tSame output weak and strong augmentation: 83.23% (1658/1992)\n",
            "\n",
            "| Validation Epoch #43\t\t\tLoss: 0.7189 Acc@1: 53.70%\n",
            "\n",
            "=> Training Epoch #44, LR=0.0300\n",
            "| Epoch [ 44/100] Iter[  1/ 32]\t\tLoss: 0.7507 Acc@1: 96.875% \n",
            "Pseudo labeled: 28.125% (63/224)    \tCorrect pseudo label: 74.60% (47/63)    \tSame output weak and strong augmentation: 82.54% (52/63)\n",
            "| Epoch [ 44/100] Iter[ 16/ 32]\t\tLoss: 0.9466 Acc@1: 96.094% \n",
            "Pseudo labeled: 30.190% (1082/3584)    \tCorrect pseudo label: 80.13% (867/1082)    \tSame output weak and strong augmentation: 82.53% (893/1082)\n",
            "| Epoch [ 44/100] Iter[ 31/ 32]\t\tLoss: 0.7126 Acc@1: 94.456% \n",
            "Pseudo labeled: 30.991% (2152/6944)    \tCorrect pseudo label: 76.81% (1653/2152)    \tSame output weak and strong augmentation: 81.51% (1754/2152)\n",
            "\n",
            "| Validation Epoch #44\t\t\tLoss: 0.4303 Acc@1: 58.45%\n",
            "| Saving Best model...\t\t\tTop1 = 58.45%\n",
            "\n",
            "=> Training Epoch #45, LR=0.0300\n",
            "| Epoch [ 45/100] Iter[  1/ 32]\t\tLoss: 0.7370 Acc@1: 96.875% \n",
            "Pseudo labeled: 34.375% (77/224)    \tCorrect pseudo label: 81.82% (63/77)    \tSame output weak and strong augmentation: 75.32% (58/77)\n",
            "| Epoch [ 45/100] Iter[ 16/ 32]\t\tLoss: 0.8304 Acc@1: 96.680% \n",
            "Pseudo labeled: 30.525% (1094/3584)    \tCorrect pseudo label: 79.34% (868/1094)    \tSame output weak and strong augmentation: 80.90% (885/1094)\n",
            "| Epoch [ 45/100] Iter[ 31/ 32]\t\tLoss: 0.6163 Acc@1: 95.464% \n",
            "Pseudo labeled: 29.522% (2050/6944)    \tCorrect pseudo label: 78.73% (1614/2050)    \tSame output weak and strong augmentation: 81.76% (1676/2050)\n",
            "\n",
            "| Validation Epoch #45\t\t\tLoss: 0.2580 Acc@1: 55.90%\n",
            "\n",
            "=> Training Epoch #46, LR=0.0300\n",
            "| Epoch [ 46/100] Iter[  1/ 32]\t\tLoss: 0.8055 Acc@1: 93.750% \n",
            "Pseudo labeled: 32.589% (73/224)    \tCorrect pseudo label: 69.86% (51/73)    \tSame output weak and strong augmentation: 79.45% (58/73)\n",
            "| Epoch [ 46/100] Iter[ 16/ 32]\t\tLoss: 0.4971 Acc@1: 96.680% \n",
            "Pseudo labeled: 32.840% (1177/3584)    \tCorrect pseudo label: 78.16% (920/1177)    \tSame output weak and strong augmentation: 82.50% (971/1177)\n",
            "| Epoch [ 46/100] Iter[ 31/ 32]\t\tLoss: 0.8814 Acc@1: 95.262% \n",
            "Pseudo labeled: 31.984% (2221/6944)    \tCorrect pseudo label: 79.15% (1758/2221)    \tSame output weak and strong augmentation: 83.39% (1852/2221)\n",
            "\n",
            "| Validation Epoch #46\t\t\tLoss: 0.1794 Acc@1: 57.60%\n",
            "\n",
            "=> Training Epoch #47, LR=0.0300\n",
            "| Epoch [ 47/100] Iter[  1/ 32]\t\tLoss: 0.6393 Acc@1: 96.875% \n",
            "Pseudo labeled: 33.482% (75/224)    \tCorrect pseudo label: 80.00% (60/75)    \tSame output weak and strong augmentation: 82.67% (62/75)\n",
            "| Epoch [ 47/100] Iter[ 16/ 32]\t\tLoss: 0.6126 Acc@1: 96.289% \n",
            "Pseudo labeled: 33.147% (1188/3584)    \tCorrect pseudo label: 81.73% (971/1188)    \tSame output weak and strong augmentation: 84.26% (1001/1188)\n",
            "| Epoch [ 47/100] Iter[ 31/ 32]\t\tLoss: 0.6095 Acc@1: 94.657% \n",
            "Pseudo labeled: 33.324% (2314/6944)    \tCorrect pseudo label: 80.12% (1854/2314)    \tSame output weak and strong augmentation: 83.66% (1936/2314)\n",
            "\n",
            "| Validation Epoch #47\t\t\tLoss: 0.0160 Acc@1: 53.50%\n",
            "\n",
            "=> Training Epoch #48, LR=0.0300\n",
            "| Epoch [ 48/100] Iter[  1/ 32]\t\tLoss: 0.4784 Acc@1: 93.750% \n",
            "Pseudo labeled: 29.018% (65/224)    \tCorrect pseudo label: 73.85% (48/65)    \tSame output weak and strong augmentation: 92.31% (60/65)\n",
            "| Epoch [ 48/100] Iter[ 16/ 32]\t\tLoss: 0.7271 Acc@1: 96.875% \n",
            "Pseudo labeled: 32.896% (1179/3584)    \tCorrect pseudo label: 80.75% (952/1179)    \tSame output weak and strong augmentation: 84.48% (996/1179)\n",
            "| Epoch [ 48/100] Iter[ 31/ 32]\t\tLoss: 0.6951 Acc@1: 96.169% \n",
            "Pseudo labeled: 32.013% (2223/6944)    \tCorrect pseudo label: 80.93% (1799/2223)    \tSame output weak and strong augmentation: 83.90% (1865/2223)\n",
            "\n",
            "| Validation Epoch #48\t\t\tLoss: 0.0752 Acc@1: 56.90%\n",
            "\n",
            "=> Training Epoch #49, LR=0.0300\n",
            "| Epoch [ 49/100] Iter[  1/ 32]\t\tLoss: 0.7545 Acc@1: 93.750% \n",
            "Pseudo labeled: 33.036% (74/224)    \tCorrect pseudo label: 74.32% (55/74)    \tSame output weak and strong augmentation: 83.78% (62/74)\n",
            "| Epoch [ 49/100] Iter[ 16/ 32]\t\tLoss: 0.5952 Acc@1: 95.898% \n",
            "Pseudo labeled: 34.180% (1225/3584)    \tCorrect pseudo label: 80.73% (989/1225)    \tSame output weak and strong augmentation: 84.57% (1036/1225)\n",
            "| Epoch [ 49/100] Iter[ 31/ 32]\t\tLoss: 0.7122 Acc@1: 93.649% \n",
            "Pseudo labeled: 33.482% (2325/6944)    \tCorrect pseudo label: 78.62% (1828/2325)    \tSame output weak and strong augmentation: 83.57% (1943/2325)\n",
            "\n",
            "| Validation Epoch #49\t\t\tLoss: 0.4232 Acc@1: 52.40%\n",
            "\n",
            "=> Training Epoch #50, LR=0.0300\n",
            "| Epoch [ 50/100] Iter[  1/ 32]\t\tLoss: 0.9386 Acc@1: 90.625% \n",
            "Pseudo labeled: 26.339% (59/224)    \tCorrect pseudo label: 81.36% (48/59)    \tSame output weak and strong augmentation: 76.27% (45/59)\n",
            "| Epoch [ 50/100] Iter[ 16/ 32]\t\tLoss: 0.6530 Acc@1: 95.508% \n",
            "Pseudo labeled: 31.445% (1127/3584)    \tCorrect pseudo label: 80.12% (903/1127)    \tSame output weak and strong augmentation: 83.41% (940/1127)\n",
            "| Epoch [ 50/100] Iter[ 31/ 32]\t\tLoss: 0.5792 Acc@1: 96.573% \n",
            "Pseudo labeled: 32.733% (2273/6944)    \tCorrect pseudo label: 81.79% (1859/2273)    \tSame output weak and strong augmentation: 84.87% (1929/2273)\n",
            "\n",
            "| Validation Epoch #50\t\t\tLoss: 0.7160 Acc@1: 56.50%\n",
            "\n",
            "=> Training Epoch #51, LR=0.0300\n",
            "| Epoch [ 51/100] Iter[  1/ 32]\t\tLoss: 0.3093 Acc@1: 96.875% \n",
            "Pseudo labeled: 33.036% (74/224)    \tCorrect pseudo label: 79.73% (59/74)    \tSame output weak and strong augmentation: 94.59% (70/74)\n",
            "| Epoch [ 51/100] Iter[ 16/ 32]\t\tLoss: 0.7784 Acc@1: 97.461% \n",
            "Pseudo labeled: 35.686% (1279/3584)    \tCorrect pseudo label: 79.05% (1011/1279)    \tSame output weak and strong augmentation: 85.77% (1097/1279)\n",
            "| Epoch [ 51/100] Iter[ 31/ 32]\t\tLoss: 0.5474 Acc@1: 95.665% \n",
            "Pseudo labeled: 34.764% (2414/6944)    \tCorrect pseudo label: 77.63% (1874/2414)    \tSame output weak and strong augmentation: 85.09% (2054/2414)\n",
            "\n",
            "| Validation Epoch #51\t\t\tLoss: 2.3434 Acc@1: 45.90%\n",
            "\n",
            "=> Training Epoch #52, LR=0.0300\n",
            "| Epoch [ 52/100] Iter[  1/ 32]\t\tLoss: 0.6045 Acc@1: 90.625% \n",
            "Pseudo labeled: 35.268% (79/224)    \tCorrect pseudo label: 79.75% (63/79)    \tSame output weak and strong augmentation: 86.08% (68/79)\n",
            "| Epoch [ 52/100] Iter[ 16/ 32]\t\tLoss: 0.5134 Acc@1: 97.461% \n",
            "Pseudo labeled: 36.300% (1301/3584)    \tCorrect pseudo label: 81.86% (1065/1301)    \tSame output weak and strong augmentation: 84.09% (1094/1301)\n",
            "| Epoch [ 52/100] Iter[ 31/ 32]\t\tLoss: 0.6987 Acc@1: 97.177% \n",
            "Pseudo labeled: 35.397% (2458/6944)    \tCorrect pseudo label: 81.53% (2004/2458)    \tSame output weak and strong augmentation: 84.30% (2072/2458)\n",
            "\n",
            "| Validation Epoch #52\t\t\tLoss: 0.5821 Acc@1: 58.65%\n",
            "| Saving Best model...\t\t\tTop1 = 58.65%\n",
            "\n",
            "=> Training Epoch #53, LR=0.0300\n",
            "| Epoch [ 53/100] Iter[  1/ 32]\t\tLoss: 0.6138 Acc@1: 100.000% \n",
            "Pseudo labeled: 34.375% (77/224)    \tCorrect pseudo label: 77.92% (60/77)    \tSame output weak and strong augmentation: 80.52% (62/77)\n",
            "| Epoch [ 53/100] Iter[ 16/ 32]\t\tLoss: 0.6627 Acc@1: 98.047% \n",
            "Pseudo labeled: 34.403% (1233/3584)    \tCorrect pseudo label: 81.18% (1001/1233)    \tSame output weak and strong augmentation: 84.27% (1039/1233)\n",
            "| Epoch [ 53/100] Iter[ 31/ 32]\t\tLoss: 0.6802 Acc@1: 97.480% \n",
            "Pseudo labeled: 34.015% (2362/6944)    \tCorrect pseudo label: 80.44% (1900/2362)    \tSame output weak and strong augmentation: 84.29% (1991/2362)\n",
            "\n",
            "| Validation Epoch #53\t\t\tLoss: 0.5260 Acc@1: 56.60%\n",
            "\n",
            "=> Training Epoch #54, LR=0.0300\n",
            "| Epoch [ 54/100] Iter[  1/ 32]\t\tLoss: 0.4203 Acc@1: 96.875% \n",
            "Pseudo labeled: 37.500% (84/224)    \tCorrect pseudo label: 84.52% (71/84)    \tSame output weak and strong augmentation: 88.10% (74/84)\n",
            "| Epoch [ 54/100] Iter[ 16/ 32]\t\tLoss: 0.6465 Acc@1: 97.656% \n",
            "Pseudo labeled: 35.045% (1256/3584)    \tCorrect pseudo label: 81.61% (1025/1256)    \tSame output weak and strong augmentation: 84.63% (1063/1256)\n",
            "| Epoch [ 54/100] Iter[ 31/ 32]\t\tLoss: 0.5533 Acc@1: 97.077% \n",
            "Pseudo labeled: 34.317% (2383/6944)    \tCorrect pseudo label: 81.37% (1939/2383)    \tSame output weak and strong augmentation: 84.52% (2014/2383)\n",
            "\n",
            "| Validation Epoch #54\t\t\tLoss: 0.0254 Acc@1: 60.15%\n",
            "| Saving Best model...\t\t\tTop1 = 60.15%\n",
            "\n",
            "=> Training Epoch #55, LR=0.0300\n",
            "| Epoch [ 55/100] Iter[  1/ 32]\t\tLoss: 0.5732 Acc@1: 100.000% \n",
            "Pseudo labeled: 30.804% (69/224)    \tCorrect pseudo label: 76.81% (53/69)    \tSame output weak and strong augmentation: 86.96% (60/69)\n",
            "| Epoch [ 55/100] Iter[ 16/ 32]\t\tLoss: 0.7097 Acc@1: 97.461% \n",
            "Pseudo labeled: 35.491% (1272/3584)    \tCorrect pseudo label: 80.42% (1023/1272)    \tSame output weak and strong augmentation: 83.81% (1066/1272)\n",
            "| Epoch [ 55/100] Iter[ 31/ 32]\t\tLoss: 1.0830 Acc@1: 96.774% \n",
            "Pseudo labeled: 34.749% (2413/6944)    \tCorrect pseudo label: 80.02% (1931/2413)    \tSame output weak and strong augmentation: 83.05% (2004/2413)\n",
            "\n",
            "| Validation Epoch #55\t\t\tLoss: 0.4377 Acc@1: 56.80%\n",
            "\n",
            "=> Training Epoch #56, LR=0.0300\n",
            "| Epoch [ 56/100] Iter[  1/ 32]\t\tLoss: 0.6421 Acc@1: 96.875% \n",
            "Pseudo labeled: 36.607% (82/224)    \tCorrect pseudo label: 79.27% (65/82)    \tSame output weak and strong augmentation: 79.27% (65/82)\n",
            "| Epoch [ 56/100] Iter[ 16/ 32]\t\tLoss: 0.7120 Acc@1: 98.047% \n",
            "Pseudo labeled: 35.296% (1265/3584)    \tCorrect pseudo label: 80.55% (1019/1265)    \tSame output weak and strong augmentation: 84.27% (1066/1265)\n",
            "| Epoch [ 56/100] Iter[ 31/ 32]\t\tLoss: 0.5748 Acc@1: 97.681% \n",
            "Pseudo labeled: 34.778% (2415/6944)    \tCorrect pseudo label: 79.63% (1923/2415)    \tSame output weak and strong augmentation: 83.69% (2021/2415)\n",
            "\n",
            "| Validation Epoch #56\t\t\tLoss: 0.2259 Acc@1: 53.50%\n",
            "\n",
            "=> Training Epoch #57, LR=0.0300\n",
            "| Epoch [ 57/100] Iter[  1/ 32]\t\tLoss: 0.4030 Acc@1: 96.875% \n",
            "Pseudo labeled: 37.054% (83/224)    \tCorrect pseudo label: 80.72% (67/83)    \tSame output weak and strong augmentation: 87.95% (73/83)\n",
            "| Epoch [ 57/100] Iter[ 16/ 32]\t\tLoss: 0.4046 Acc@1: 98.438% \n",
            "Pseudo labeled: 35.156% (1260/3584)    \tCorrect pseudo label: 81.11% (1022/1260)    \tSame output weak and strong augmentation: 86.83% (1094/1260)\n",
            "| Epoch [ 57/100] Iter[ 31/ 32]\t\tLoss: 0.5828 Acc@1: 97.984% \n",
            "Pseudo labeled: 36.766% (2553/6944)    \tCorrect pseudo label: 79.95% (2041/2553)    \tSame output weak and strong augmentation: 85.74% (2189/2553)\n",
            "\n",
            "| Validation Epoch #57\t\t\tLoss: 0.6559 Acc@1: 53.30%\n",
            "\n",
            "=> Training Epoch #58, LR=0.0300\n",
            "| Epoch [ 58/100] Iter[  1/ 32]\t\tLoss: 0.8763 Acc@1: 100.000% \n",
            "Pseudo labeled: 25.000% (56/224)    \tCorrect pseudo label: 87.50% (49/56)    \tSame output weak and strong augmentation: 66.07% (37/56)\n",
            "| Epoch [ 58/100] Iter[ 16/ 32]\t\tLoss: 0.5662 Acc@1: 98.438% \n",
            "Pseudo labeled: 33.566% (1203/3584)    \tCorrect pseudo label: 81.13% (976/1203)    \tSame output weak and strong augmentation: 83.79% (1008/1203)\n",
            "| Epoch [ 58/100] Iter[ 31/ 32]\t\tLoss: 0.4671 Acc@1: 98.286% \n",
            "Pseudo labeled: 35.858% (2490/6944)    \tCorrect pseudo label: 79.88% (1989/2490)    \tSame output weak and strong augmentation: 83.98% (2091/2490)\n",
            "\n",
            "| Validation Epoch #58\t\t\tLoss: 0.7525 Acc@1: 59.75%\n",
            "\n",
            "=> Training Epoch #59, LR=0.0300\n",
            "| Epoch [ 59/100] Iter[  1/ 32]\t\tLoss: 0.4014 Acc@1: 96.875% \n",
            "Pseudo labeled: 39.732% (89/224)    \tCorrect pseudo label: 80.90% (72/89)    \tSame output weak and strong augmentation: 86.52% (77/89)\n",
            "| Epoch [ 59/100] Iter[ 16/ 32]\t\tLoss: 0.7554 Acc@1: 97.266% \n",
            "Pseudo labeled: 37.919% (1359/3584)    \tCorrect pseudo label: 79.99% (1087/1359)    \tSame output weak and strong augmentation: 83.74% (1138/1359)\n",
            "| Epoch [ 59/100] Iter[ 31/ 32]\t\tLoss: 0.6069 Acc@1: 96.371% \n",
            "Pseudo labeled: 37.471% (2602/6944)    \tCorrect pseudo label: 79.98% (2081/2602)    \tSame output weak and strong augmentation: 84.78% (2206/2602)\n",
            "\n",
            "| Validation Epoch #59\t\t\tLoss: 0.4141 Acc@1: 52.85%\n",
            "\n",
            "=> Training Epoch #60, LR=0.0300\n",
            "| Epoch [ 60/100] Iter[  1/ 32]\t\tLoss: 0.4427 Acc@1: 96.875% \n",
            "Pseudo labeled: 37.946% (85/224)    \tCorrect pseudo label: 75.29% (64/85)    \tSame output weak and strong augmentation: 88.24% (75/85)\n",
            "| Epoch [ 60/100] Iter[ 16/ 32]\t\tLoss: 0.6821 Acc@1: 96.094% \n",
            "Pseudo labeled: 34.933% (1252/3584)    \tCorrect pseudo label: 76.68% (960/1252)    \tSame output weak and strong augmentation: 83.95% (1051/1252)\n",
            "| Epoch [ 60/100] Iter[ 31/ 32]\t\tLoss: 1.0150 Acc@1: 95.161% \n",
            "Pseudo labeled: 34.245% (2378/6944)    \tCorrect pseudo label: 79.23% (1884/2378)    \tSame output weak and strong augmentation: 83.94% (1996/2378)\n",
            "\n",
            "| Validation Epoch #60\t\t\tLoss: 0.4807 Acc@1: 55.00%\n",
            "\n",
            "=> Training Epoch #61, LR=0.0300\n",
            "| Epoch [ 61/100] Iter[  1/ 32]\t\tLoss: 0.4454 Acc@1: 96.875% \n",
            "Pseudo labeled: 36.607% (82/224)    \tCorrect pseudo label: 68.29% (56/82)    \tSame output weak and strong augmentation: 84.15% (69/82)\n",
            "| Epoch [ 61/100] Iter[ 16/ 32]\t\tLoss: 0.6395 Acc@1: 96.875% \n",
            "Pseudo labeled: 37.528% (1345/3584)    \tCorrect pseudo label: 78.96% (1062/1345)    \tSame output weak and strong augmentation: 84.31% (1134/1345)\n",
            "| Epoch [ 61/100] Iter[ 31/ 32]\t\tLoss: 0.6764 Acc@1: 96.573% \n",
            "Pseudo labeled: 36.046% (2503/6944)    \tCorrect pseudo label: 78.51% (1965/2503)    \tSame output weak and strong augmentation: 83.70% (2095/2503)\n",
            "\n",
            "| Validation Epoch #61\t\t\tLoss: 0.1190 Acc@1: 58.10%\n",
            "\n",
            "=> Training Epoch #62, LR=0.0300\n",
            "| Epoch [ 62/100] Iter[  1/ 32]\t\tLoss: 0.5826 Acc@1: 100.000% \n",
            "Pseudo labeled: 35.714% (80/224)    \tCorrect pseudo label: 82.50% (66/80)    \tSame output weak and strong augmentation: 81.25% (65/80)\n",
            "| Epoch [ 62/100] Iter[ 16/ 32]\t\tLoss: 0.3171 Acc@1: 98.438% \n",
            "Pseudo labeled: 37.974% (1361/3584)    \tCorrect pseudo label: 82.22% (1119/1361)    \tSame output weak and strong augmentation: 87.44% (1190/1361)\n",
            "| Epoch [ 62/100] Iter[ 31/ 32]\t\tLoss: 0.6800 Acc@1: 98.891% \n",
            "Pseudo labeled: 37.010% (2570/6944)    \tCorrect pseudo label: 82.14% (2111/2570)    \tSame output weak and strong augmentation: 85.99% (2210/2570)\n",
            "\n",
            "| Validation Epoch #62\t\t\tLoss: 0.1477 Acc@1: 61.40%\n",
            "| Saving Best model...\t\t\tTop1 = 61.40%\n",
            "\n",
            "=> Training Epoch #63, LR=0.0300\n",
            "| Epoch [ 63/100] Iter[  1/ 32]\t\tLoss: 0.3254 Acc@1: 100.000% \n",
            "Pseudo labeled: 40.179% (90/224)    \tCorrect pseudo label: 82.22% (74/90)    \tSame output weak and strong augmentation: 93.33% (84/90)\n",
            "| Epoch [ 63/100] Iter[ 16/ 32]\t\tLoss: 0.3863 Acc@1: 98.438% \n",
            "Pseudo labeled: 35.547% (1274/3584)    \tCorrect pseudo label: 81.95% (1044/1274)    \tSame output weak and strong augmentation: 84.69% (1079/1274)\n",
            "| Epoch [ 63/100] Iter[ 31/ 32]\t\tLoss: 0.5865 Acc@1: 97.883% \n",
            "Pseudo labeled: 36.406% (2528/6944)    \tCorrect pseudo label: 79.39% (2007/2528)    \tSame output weak and strong augmentation: 83.94% (2122/2528)\n",
            "\n",
            "| Validation Epoch #63\t\t\tLoss: 0.3426 Acc@1: 59.75%\n",
            "\n",
            "=> Training Epoch #64, LR=0.0300\n",
            "| Epoch [ 64/100] Iter[  1/ 32]\t\tLoss: 0.4057 Acc@1: 100.000% \n",
            "Pseudo labeled: 40.625% (91/224)    \tCorrect pseudo label: 89.01% (81/91)    \tSame output weak and strong augmentation: 84.62% (77/91)\n",
            "| Epoch [ 64/100] Iter[ 16/ 32]\t\tLoss: 0.4914 Acc@1: 97.461% \n",
            "Pseudo labeled: 38.504% (1380/3584)    \tCorrect pseudo label: 81.01% (1118/1380)    \tSame output weak and strong augmentation: 82.90% (1144/1380)\n",
            "| Epoch [ 64/100] Iter[ 31/ 32]\t\tLoss: 0.4659 Acc@1: 97.581% \n",
            "Pseudo labeled: 37.860% (2629/6944)    \tCorrect pseudo label: 80.11% (2106/2629)    \tSame output weak and strong augmentation: 83.45% (2194/2629)\n",
            "\n",
            "| Validation Epoch #64\t\t\tLoss: 0.7540 Acc@1: 58.95%\n",
            "\n",
            "=> Training Epoch #65, LR=0.0300\n",
            "| Epoch [ 65/100] Iter[  1/ 32]\t\tLoss: 0.5339 Acc@1: 100.000% \n",
            "Pseudo labeled: 38.839% (87/224)    \tCorrect pseudo label: 86.21% (75/87)    \tSame output weak and strong augmentation: 87.36% (76/87)\n",
            "| Epoch [ 65/100] Iter[ 16/ 32]\t\tLoss: 0.7192 Acc@1: 99.023% \n",
            "Pseudo labeled: 39.927% (1431/3584)    \tCorrect pseudo label: 82.74% (1184/1431)    \tSame output weak and strong augmentation: 86.37% (1236/1431)\n",
            "| Epoch [ 65/100] Iter[ 31/ 32]\t\tLoss: 0.6788 Acc@1: 98.690% \n",
            "Pseudo labeled: 38.004% (2639/6944)    \tCorrect pseudo label: 81.36% (2147/2639)    \tSame output weak and strong augmentation: 85.71% (2262/2639)\n",
            "\n",
            "| Validation Epoch #65\t\t\tLoss: 0.1317 Acc@1: 59.95%\n",
            "\n",
            "=> Training Epoch #66, LR=0.0300\n",
            "| Epoch [ 66/100] Iter[  1/ 32]\t\tLoss: 0.3209 Acc@1: 96.875% \n",
            "Pseudo labeled: 41.071% (92/224)    \tCorrect pseudo label: 83.70% (77/92)    \tSame output weak and strong augmentation: 91.30% (84/92)\n",
            "| Epoch [ 66/100] Iter[ 16/ 32]\t\tLoss: 0.4355 Acc@1: 98.242% \n",
            "Pseudo labeled: 39.286% (1408/3584)    \tCorrect pseudo label: 80.68% (1136/1408)    \tSame output weak and strong augmentation: 86.93% (1224/1408)\n",
            "| Epoch [ 66/100] Iter[ 31/ 32]\t\tLoss: 1.0728 Acc@1: 97.581% \n",
            "Pseudo labeled: 39.574% (2748/6944)    \tCorrect pseudo label: 80.49% (2212/2748)    \tSame output weak and strong augmentation: 86.03% (2364/2748)\n",
            "\n",
            "| Validation Epoch #66\t\t\tLoss: 0.1364 Acc@1: 61.20%\n",
            "\n",
            "=> Training Epoch #67, LR=0.0300\n",
            "| Epoch [ 67/100] Iter[  1/ 32]\t\tLoss: 0.5077 Acc@1: 100.000% \n",
            "Pseudo labeled: 39.286% (88/224)    \tCorrect pseudo label: 82.95% (73/88)    \tSame output weak and strong augmentation: 82.95% (73/88)\n",
            "| Epoch [ 67/100] Iter[ 16/ 32]\t\tLoss: 0.6785 Acc@1: 99.023% \n",
            "Pseudo labeled: 41.099% (1473/3584)    \tCorrect pseudo label: 80.72% (1189/1473)    \tSame output weak and strong augmentation: 83.91% (1236/1473)\n",
            "| Epoch [ 67/100] Iter[ 31/ 32]\t\tLoss: 0.5548 Acc@1: 97.883% \n",
            "Pseudo labeled: 39.689% (2756/6944)    \tCorrect pseudo label: 79.90% (2202/2756)    \tSame output weak and strong augmentation: 84.43% (2327/2756)\n",
            "\n",
            "| Validation Epoch #67\t\t\tLoss: 0.3083 Acc@1: 60.80%\n",
            "\n",
            "=> Training Epoch #68, LR=0.0300\n",
            "| Epoch [ 68/100] Iter[  1/ 32]\t\tLoss: 0.3862 Acc@1: 100.000% \n",
            "Pseudo labeled: 42.411% (95/224)    \tCorrect pseudo label: 80.00% (76/95)    \tSame output weak and strong augmentation: 88.42% (84/95)\n",
            "| Epoch [ 68/100] Iter[ 16/ 32]\t\tLoss: 0.5628 Acc@1: 99.023% \n",
            "Pseudo labeled: 39.927% (1431/3584)    \tCorrect pseudo label: 82.46% (1180/1431)    \tSame output weak and strong augmentation: 86.44% (1237/1431)\n",
            "| Epoch [ 68/100] Iter[ 31/ 32]\t\tLoss: 0.4657 Acc@1: 98.286% \n",
            "Pseudo labeled: 39.257% (2726/6944)    \tCorrect pseudo label: 81.77% (2229/2726)    \tSame output weak and strong augmentation: 85.51% (2331/2726)\n",
            "\n",
            "| Validation Epoch #68\t\t\tLoss: 0.1239 Acc@1: 61.60%\n",
            "| Saving Best model...\t\t\tTop1 = 61.60%\n",
            "\n",
            "=> Training Epoch #69, LR=0.0300\n",
            "| Epoch [ 69/100] Iter[  1/ 32]\t\tLoss: 0.6419 Acc@1: 100.000% \n",
            "Pseudo labeled: 38.839% (87/224)    \tCorrect pseudo label: 79.31% (69/87)    \tSame output weak and strong augmentation: 79.31% (69/87)\n",
            "| Epoch [ 69/100] Iter[ 16/ 32]\t\tLoss: 0.5403 Acc@1: 99.023% \n",
            "Pseudo labeled: 39.593% (1419/3584)    \tCorrect pseudo label: 80.83% (1147/1419)    \tSame output weak and strong augmentation: 84.99% (1206/1419)\n",
            "| Epoch [ 69/100] Iter[ 31/ 32]\t\tLoss: 0.6969 Acc@1: 97.984% \n",
            "Pseudo labeled: 39.660% (2754/6944)    \tCorrect pseudo label: 80.76% (2224/2754)    \tSame output weak and strong augmentation: 84.35% (2323/2754)\n",
            "\n",
            "| Validation Epoch #69\t\t\tLoss: 0.0452 Acc@1: 56.75%\n",
            "\n",
            "=> Training Epoch #70, LR=0.0300\n",
            "| Epoch [ 70/100] Iter[  1/ 32]\t\tLoss: 0.6153 Acc@1: 96.875% \n",
            "Pseudo labeled: 35.268% (79/224)    \tCorrect pseudo label: 82.28% (65/79)    \tSame output weak and strong augmentation: 74.68% (59/79)\n",
            "| Epoch [ 70/100] Iter[ 16/ 32]\t\tLoss: 0.3601 Acc@1: 99.219% \n",
            "Pseudo labeled: 38.811% (1391/3584)    \tCorrect pseudo label: 82.31% (1145/1391)    \tSame output weak and strong augmentation: 85.55% (1190/1391)\n",
            "| Epoch [ 70/100] Iter[ 31/ 32]\t\tLoss: 0.4953 Acc@1: 98.690% \n",
            "Pseudo labeled: 40.193% (2791/6944)    \tCorrect pseudo label: 81.66% (2279/2791)    \tSame output weak and strong augmentation: 86.21% (2406/2791)\n",
            "\n",
            "| Validation Epoch #70\t\t\tLoss: 0.0375 Acc@1: 60.25%\n",
            "\n",
            "=> Training Epoch #71, LR=0.0300\n",
            "| Epoch [ 71/100] Iter[  1/ 32]\t\tLoss: 0.4564 Acc@1: 96.875% \n",
            "Pseudo labeled: 33.929% (76/224)    \tCorrect pseudo label: 82.89% (63/76)    \tSame output weak and strong augmentation: 89.47% (68/76)\n",
            "| Epoch [ 71/100] Iter[ 16/ 32]\t\tLoss: 0.5049 Acc@1: 99.219% \n",
            "Pseudo labeled: 37.444% (1342/3584)    \tCorrect pseudo label: 82.27% (1104/1342)    \tSame output weak and strong augmentation: 86.89% (1166/1342)\n",
            "| Epoch [ 71/100] Iter[ 31/ 32]\t\tLoss: 0.5517 Acc@1: 98.387% \n",
            "Pseudo labeled: 38.868% (2699/6944)    \tCorrect pseudo label: 81.10% (2189/2699)    \tSame output weak and strong augmentation: 85.29% (2302/2699)\n",
            "\n",
            "| Validation Epoch #71\t\t\tLoss: 0.1033 Acc@1: 57.80%\n",
            "\n",
            "=> Training Epoch #72, LR=0.0300\n",
            "| Epoch [ 72/100] Iter[  1/ 32]\t\tLoss: 0.4493 Acc@1: 100.000% \n",
            "Pseudo labeled: 36.161% (81/224)    \tCorrect pseudo label: 67.90% (55/81)    \tSame output weak and strong augmentation: 86.42% (70/81)\n",
            "| Epoch [ 72/100] Iter[ 16/ 32]\t\tLoss: 0.4595 Acc@1: 98.633% \n",
            "Pseudo labeled: 36.189% (1297/3584)    \tCorrect pseudo label: 76.25% (989/1297)    \tSame output weak and strong augmentation: 83.81% (1087/1297)\n",
            "| Epoch [ 72/100] Iter[ 31/ 32]\t\tLoss: 0.6544 Acc@1: 98.690% \n",
            "Pseudo labeled: 36.953% (2566/6944)    \tCorrect pseudo label: 78.18% (2006/2566)    \tSame output weak and strong augmentation: 83.63% (2146/2566)\n",
            "\n",
            "| Validation Epoch #72\t\t\tLoss: 0.0167 Acc@1: 59.05%\n",
            "\n",
            "=> Training Epoch #73, LR=0.0300\n",
            "| Epoch [ 73/100] Iter[  1/ 32]\t\tLoss: 0.3441 Acc@1: 96.875% \n",
            "Pseudo labeled: 36.161% (81/224)    \tCorrect pseudo label: 91.36% (74/81)    \tSame output weak and strong augmentation: 86.42% (70/81)\n",
            "| Epoch [ 73/100] Iter[ 16/ 32]\t\tLoss: 0.4230 Acc@1: 98.438% \n",
            "Pseudo labeled: 38.560% (1382/3584)    \tCorrect pseudo label: 81.69% (1129/1382)    \tSame output weak and strong augmentation: 85.60% (1183/1382)\n",
            "| Epoch [ 73/100] Iter[ 31/ 32]\t\tLoss: 0.7372 Acc@1: 98.790% \n",
            "Pseudo labeled: 39.257% (2726/6944)    \tCorrect pseudo label: 81.51% (2222/2726)    \tSame output weak and strong augmentation: 85.55% (2332/2726)\n",
            "\n",
            "| Validation Epoch #73\t\t\tLoss: 0.4678 Acc@1: 57.05%\n",
            "\n",
            "=> Training Epoch #74, LR=0.0300\n",
            "| Epoch [ 74/100] Iter[  1/ 32]\t\tLoss: 0.5864 Acc@1: 96.875% \n",
            "Pseudo labeled: 41.964% (94/224)    \tCorrect pseudo label: 80.85% (76/94)    \tSame output weak and strong augmentation: 82.98% (78/94)\n",
            "| Epoch [ 74/100] Iter[ 16/ 32]\t\tLoss: 0.2569 Acc@1: 99.023% \n",
            "Pseudo labeled: 36.496% (1308/3584)    \tCorrect pseudo label: 86.31% (1129/1308)    \tSame output weak and strong augmentation: 86.47% (1131/1308)\n",
            "| Epoch [ 74/100] Iter[ 31/ 32]\t\tLoss: 0.4345 Acc@1: 98.992% \n",
            "Pseudo labeled: 38.666% (2685/6944)    \tCorrect pseudo label: 83.50% (2242/2685)    \tSame output weak and strong augmentation: 87.00% (2336/2685)\n",
            "\n",
            "| Validation Epoch #74\t\t\tLoss: 0.9206 Acc@1: 51.35%\n",
            "\n",
            "=> Training Epoch #75, LR=0.0300\n",
            "| Epoch [ 75/100] Iter[  1/ 32]\t\tLoss: 0.6490 Acc@1: 93.750% \n",
            "Pseudo labeled: 42.857% (96/224)    \tCorrect pseudo label: 85.42% (82/96)    \tSame output weak and strong augmentation: 84.38% (81/96)\n",
            "| Epoch [ 75/100] Iter[ 16/ 32]\t\tLoss: 0.4489 Acc@1: 98.828% \n",
            "Pseudo labeled: 37.640% (1349/3584)    \tCorrect pseudo label: 82.13% (1108/1349)    \tSame output weak and strong augmentation: 83.91% (1132/1349)\n",
            "| Epoch [ 75/100] Iter[ 31/ 32]\t\tLoss: 0.5033 Acc@1: 98.286% \n",
            "Pseudo labeled: 39.415% (2737/6944)    \tCorrect pseudo label: 81.55% (2232/2737)    \tSame output weak and strong augmentation: 85.86% (2350/2737)\n",
            "\n",
            "| Validation Epoch #75\t\t\tLoss: 0.6652 Acc@1: 60.25%\n",
            "\n",
            "=> Training Epoch #76, LR=0.0300\n",
            "| Epoch [ 76/100] Iter[  1/ 32]\t\tLoss: 0.5681 Acc@1: 96.875% \n",
            "Pseudo labeled: 41.071% (92/224)    \tCorrect pseudo label: 79.35% (73/92)    \tSame output weak and strong augmentation: 84.78% (78/92)\n",
            "| Epoch [ 76/100] Iter[ 16/ 32]\t\tLoss: 0.3653 Acc@1: 99.219% \n",
            "Pseudo labeled: 39.760% (1425/3584)    \tCorrect pseudo label: 82.95% (1182/1425)    \tSame output weak and strong augmentation: 85.61% (1220/1425)\n",
            "| Epoch [ 76/100] Iter[ 31/ 32]\t\tLoss: 0.4900 Acc@1: 98.286% \n",
            "Pseudo labeled: 39.401% (2736/6944)    \tCorrect pseudo label: 81.80% (2238/2736)    \tSame output weak and strong augmentation: 85.09% (2328/2736)\n",
            "\n",
            "| Validation Epoch #76\t\t\tLoss: 0.0277 Acc@1: 62.10%\n",
            "| Saving Best model...\t\t\tTop1 = 62.10%\n",
            "\n",
            "=> Training Epoch #77, LR=0.0300\n",
            "| Epoch [ 77/100] Iter[  1/ 32]\t\tLoss: 0.5288 Acc@1: 100.000% \n",
            "Pseudo labeled: 38.393% (86/224)    \tCorrect pseudo label: 83.72% (72/86)    \tSame output weak and strong augmentation: 81.40% (70/86)\n",
            "| Epoch [ 77/100] Iter[ 16/ 32]\t\tLoss: 0.6980 Acc@1: 99.219% \n",
            "Pseudo labeled: 39.704% (1423/3584)    \tCorrect pseudo label: 82.50% (1174/1423)    \tSame output weak and strong augmentation: 85.66% (1219/1423)\n",
            "| Epoch [ 77/100] Iter[ 31/ 32]\t\tLoss: 0.4149 Acc@1: 99.294% \n",
            "Pseudo labeled: 40.006% (2778/6944)    \tCorrect pseudo label: 81.75% (2271/2778)    \tSame output weak and strong augmentation: 85.85% (2385/2778)\n",
            "\n",
            "| Validation Epoch #77\t\t\tLoss: 0.0853 Acc@1: 61.40%\n",
            "\n",
            "=> Training Epoch #78, LR=0.0300\n",
            "| Epoch [ 78/100] Iter[  1/ 32]\t\tLoss: 0.4088 Acc@1: 100.000% \n",
            "Pseudo labeled: 35.714% (80/224)    \tCorrect pseudo label: 81.25% (65/80)    \tSame output weak and strong augmentation: 91.25% (73/80)\n",
            "| Epoch [ 78/100] Iter[ 16/ 32]\t\tLoss: 0.4894 Acc@1: 98.633% \n",
            "Pseudo labeled: 38.867% (1393/3584)    \tCorrect pseudo label: 81.41% (1134/1393)    \tSame output weak and strong augmentation: 86.86% (1210/1393)\n",
            "| Epoch [ 78/100] Iter[ 31/ 32]\t\tLoss: 0.4710 Acc@1: 98.589% \n",
            "Pseudo labeled: 39.559% (2747/6944)    \tCorrect pseudo label: 81.54% (2240/2747)    \tSame output weak and strong augmentation: 85.77% (2356/2747)\n",
            "\n",
            "| Validation Epoch #78\t\t\tLoss: 0.3477 Acc@1: 58.35%\n",
            "\n",
            "=> Training Epoch #79, LR=0.0300\n",
            "| Epoch [ 79/100] Iter[  1/ 32]\t\tLoss: 0.3909 Acc@1: 93.750% \n",
            "Pseudo labeled: 37.946% (85/224)    \tCorrect pseudo label: 82.35% (70/85)    \tSame output weak and strong augmentation: 90.59% (77/85)\n",
            "| Epoch [ 79/100] Iter[ 16/ 32]\t\tLoss: 0.3532 Acc@1: 99.023% \n",
            "Pseudo labeled: 41.518% (1488/3584)    \tCorrect pseudo label: 83.74% (1246/1488)    \tSame output weak and strong augmentation: 86.09% (1281/1488)\n",
            "| Epoch [ 79/100] Iter[ 31/ 32]\t\tLoss: 0.4169 Acc@1: 99.093% \n",
            "Pseudo labeled: 41.215% (2862/6944)    \tCorrect pseudo label: 82.74% (2368/2862)    \tSame output weak and strong augmentation: 86.65% (2480/2862)\n",
            "\n",
            "| Validation Epoch #79\t\t\tLoss: 0.3616 Acc@1: 62.65%\n",
            "| Saving Best model...\t\t\tTop1 = 62.65%\n",
            "\n",
            "=> Training Epoch #80, LR=0.0300\n",
            "| Epoch [ 80/100] Iter[  1/ 32]\t\tLoss: 0.3466 Acc@1: 100.000% \n",
            "Pseudo labeled: 41.071% (92/224)    \tCorrect pseudo label: 88.04% (81/92)    \tSame output weak and strong augmentation: 90.22% (83/92)\n",
            "| Epoch [ 80/100] Iter[ 16/ 32]\t\tLoss: 0.3952 Acc@1: 98.047% \n",
            "Pseudo labeled: 43.750% (1568/3584)    \tCorrect pseudo label: 83.61% (1311/1568)    \tSame output weak and strong augmentation: 89.48% (1403/1568)\n",
            "| Epoch [ 80/100] Iter[ 31/ 32]\t\tLoss: 0.4934 Acc@1: 98.185% \n",
            "Pseudo labeled: 43.275% (3005/6944)    \tCorrect pseudo label: 82.16% (2469/3005)    \tSame output weak and strong augmentation: 87.65% (2634/3005)\n",
            "\n",
            "| Validation Epoch #80\t\t\tLoss: 0.6211 Acc@1: 56.55%\n",
            "\n",
            "=> Training Epoch #81, LR=0.0030\n",
            "| Epoch [ 81/100] Iter[  1/ 32]\t\tLoss: 0.2986 Acc@1: 100.000% \n",
            "Pseudo labeled: 36.161% (81/224)    \tCorrect pseudo label: 86.42% (70/81)    \tSame output weak and strong augmentation: 90.12% (73/81)\n",
            "| Epoch [ 81/100] Iter[ 16/ 32]\t\tLoss: 0.2520 Acc@1: 99.023% \n",
            "Pseudo labeled: 39.593% (1419/3584)    \tCorrect pseudo label: 82.52% (1171/1419)    \tSame output weak and strong augmentation: 87.53% (1242/1419)\n",
            "| Epoch [ 81/100] Iter[ 31/ 32]\t\tLoss: 0.4664 Acc@1: 99.395% \n",
            "Pseudo labeled: 40.366% (2803/6944)    \tCorrect pseudo label: 82.63% (2316/2803)    \tSame output weak and strong augmentation: 87.12% (2442/2803)\n",
            "\n",
            "| Validation Epoch #81\t\t\tLoss: 0.1119 Acc@1: 63.50%\n",
            "| Saving Best model...\t\t\tTop1 = 63.50%\n",
            "\n",
            "=> Training Epoch #82, LR=0.0030\n",
            "| Epoch [ 82/100] Iter[  1/ 32]\t\tLoss: 0.3938 Acc@1: 100.000% \n",
            "Pseudo labeled: 41.964% (94/224)    \tCorrect pseudo label: 78.72% (74/94)    \tSame output weak and strong augmentation: 87.23% (82/94)\n",
            "| Epoch [ 82/100] Iter[ 16/ 32]\t\tLoss: 0.5144 Acc@1: 99.414% \n",
            "Pseudo labeled: 40.123% (1438/3584)    \tCorrect pseudo label: 81.78% (1176/1438)    \tSame output weak and strong augmentation: 86.44% (1243/1438)\n",
            "| Epoch [ 82/100] Iter[ 31/ 32]\t\tLoss: 0.2712 Acc@1: 99.597% \n",
            "Pseudo labeled: 40.524% (2814/6944)    \tCorrect pseudo label: 81.88% (2304/2814)    \tSame output weak and strong augmentation: 86.53% (2435/2814)\n",
            "\n",
            "| Validation Epoch #82\t\t\tLoss: 0.1270 Acc@1: 64.65%\n",
            "| Saving Best model...\t\t\tTop1 = 64.65%\n",
            "\n",
            "=> Training Epoch #83, LR=0.0030\n",
            "| Epoch [ 83/100] Iter[  1/ 32]\t\tLoss: 0.2061 Acc@1: 100.000% \n",
            "Pseudo labeled: 41.964% (94/224)    \tCorrect pseudo label: 76.60% (72/94)    \tSame output weak and strong augmentation: 95.74% (90/94)\n",
            "| Epoch [ 83/100] Iter[ 16/ 32]\t\tLoss: 0.4051 Acc@1: 100.000% \n",
            "Pseudo labeled: 42.941% (1539/3584)    \tCorrect pseudo label: 82.13% (1264/1539)    \tSame output weak and strong augmentation: 87.46% (1346/1539)\n",
            "| Epoch [ 83/100] Iter[ 31/ 32]\t\tLoss: 0.2258 Acc@1: 99.798% \n",
            "Pseudo labeled: 42.382% (2943/6944)    \tCorrect pseudo label: 82.50% (2428/2943)    \tSame output weak and strong augmentation: 87.94% (2588/2943)\n",
            "\n",
            "| Validation Epoch #83\t\t\tLoss: 0.0985 Acc@1: 64.45%\n",
            "\n",
            "=> Training Epoch #84, LR=0.0030\n",
            "| Epoch [ 84/100] Iter[  1/ 32]\t\tLoss: 0.2154 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.196% (99/224)    \tCorrect pseudo label: 83.84% (83/99)    \tSame output weak and strong augmentation: 92.93% (92/99)\n",
            "| Epoch [ 84/100] Iter[ 16/ 32]\t\tLoss: 0.3008 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.555% (1561/3584)    \tCorrect pseudo label: 82.58% (1289/1561)    \tSame output weak and strong augmentation: 87.83% (1371/1561)\n",
            "| Epoch [ 84/100] Iter[ 31/ 32]\t\tLoss: 0.4039 Acc@1: 100.000% \n",
            "Pseudo labeled: 42.886% (2978/6944)    \tCorrect pseudo label: 83.04% (2473/2978)    \tSame output weak and strong augmentation: 87.98% (2620/2978)\n",
            "\n",
            "| Validation Epoch #84\t\t\tLoss: 0.1174 Acc@1: 64.80%\n",
            "| Saving Best model...\t\t\tTop1 = 64.80%\n",
            "\n",
            "=> Training Epoch #85, LR=0.0030\n",
            "| Epoch [ 85/100] Iter[  1/ 32]\t\tLoss: 0.3415 Acc@1: 100.000% \n",
            "Pseudo labeled: 42.857% (96/224)    \tCorrect pseudo label: 82.29% (79/96)    \tSame output weak and strong augmentation: 88.54% (85/96)\n",
            "| Epoch [ 85/100] Iter[ 16/ 32]\t\tLoss: 0.3753 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.025% (1542/3584)    \tCorrect pseudo label: 82.94% (1279/1542)    \tSame output weak and strong augmentation: 87.94% (1356/1542)\n",
            "| Epoch [ 85/100] Iter[ 31/ 32]\t\tLoss: 0.4228 Acc@1: 99.899% \n",
            "Pseudo labeled: 43.332% (3009/6944)    \tCorrect pseudo label: 82.25% (2475/3009)    \tSame output weak and strong augmentation: 87.47% (2632/3009)\n",
            "\n",
            "| Validation Epoch #85\t\t\tLoss: 0.1305 Acc@1: 64.50%\n",
            "\n",
            "=> Training Epoch #86, LR=0.0030\n",
            "| Epoch [ 86/100] Iter[  1/ 32]\t\tLoss: 0.3221 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.196% (99/224)    \tCorrect pseudo label: 89.90% (89/99)    \tSame output weak and strong augmentation: 87.88% (87/99)\n",
            "| Epoch [ 86/100] Iter[ 16/ 32]\t\tLoss: 0.3511 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.331% (1553/3584)    \tCorrect pseudo label: 85.32% (1325/1553)    \tSame output weak and strong augmentation: 87.89% (1365/1553)\n",
            "| Epoch [ 86/100] Iter[ 31/ 32]\t\tLoss: 0.3221 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.520% (3022/6944)    \tCorrect pseudo label: 85.27% (2577/3022)    \tSame output weak and strong augmentation: 87.52% (2645/3022)\n",
            "\n",
            "| Validation Epoch #86\t\t\tLoss: 0.0955 Acc@1: 65.95%\n",
            "| Saving Best model...\t\t\tTop1 = 65.95%\n",
            "\n",
            "=> Training Epoch #87, LR=0.0030\n",
            "| Epoch [ 87/100] Iter[  1/ 32]\t\tLoss: 0.5166 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.750% (98/224)    \tCorrect pseudo label: 80.61% (79/98)    \tSame output weak and strong augmentation: 81.63% (80/98)\n",
            "| Epoch [ 87/100] Iter[ 16/ 32]\t\tLoss: 0.2840 Acc@1: 100.000% \n",
            "Pseudo labeled: 42.578% (1526/3584)    \tCorrect pseudo label: 82.83% (1264/1526)    \tSame output weak and strong augmentation: 87.75% (1339/1526)\n",
            "| Epoch [ 87/100] Iter[ 31/ 32]\t\tLoss: 0.3227 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.606% (3028/6944)    \tCorrect pseudo label: 83.85% (2539/3028)    \tSame output weak and strong augmentation: 87.71% (2656/3028)\n",
            "\n",
            "| Validation Epoch #87\t\t\tLoss: 0.0431 Acc@1: 66.20%\n",
            "| Saving Best model...\t\t\tTop1 = 66.20%\n",
            "\n",
            "=> Training Epoch #88, LR=0.0030\n",
            "| Epoch [ 88/100] Iter[  1/ 32]\t\tLoss: 0.3478 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.643% (100/224)    \tCorrect pseudo label: 84.00% (84/100)    \tSame output weak and strong augmentation: 89.00% (89/100)\n",
            "| Epoch [ 88/100] Iter[ 16/ 32]\t\tLoss: 0.4091 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.555% (1561/3584)    \tCorrect pseudo label: 82.90% (1294/1561)    \tSame output weak and strong augmentation: 87.25% (1362/1561)\n",
            "| Epoch [ 88/100] Iter[ 31/ 32]\t\tLoss: 0.4507 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.635% (3030/6944)    \tCorrect pseudo label: 83.17% (2520/3030)    \tSame output weak and strong augmentation: 86.83% (2631/3030)\n",
            "\n",
            "| Validation Epoch #88\t\t\tLoss: 0.0193 Acc@1: 65.75%\n",
            "\n",
            "=> Training Epoch #89, LR=0.0030\n",
            "| Epoch [ 89/100] Iter[  1/ 32]\t\tLoss: 0.1412 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.089% (101/224)    \tCorrect pseudo label: 87.13% (88/101)    \tSame output weak and strong augmentation: 97.03% (98/101)\n",
            "| Epoch [ 89/100] Iter[ 16/ 32]\t\tLoss: 0.3522 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.643% (1600/3584)    \tCorrect pseudo label: 83.12% (1330/1600)    \tSame output weak and strong augmentation: 87.75% (1404/1600)\n",
            "| Epoch [ 89/100] Iter[ 31/ 32]\t\tLoss: 0.2530 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.484% (3089/6944)    \tCorrect pseudo label: 83.26% (2572/3089)    \tSame output weak and strong augmentation: 87.25% (2695/3089)\n",
            "\n",
            "| Validation Epoch #89\t\t\tLoss: 0.1330 Acc@1: 65.60%\n",
            "\n",
            "=> Training Epoch #90, LR=0.0030\n",
            "| Epoch [ 90/100] Iter[  1/ 32]\t\tLoss: 0.4204 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.536% (102/224)    \tCorrect pseudo label: 81.37% (83/102)    \tSame output weak and strong augmentation: 89.22% (91/102)\n",
            "| Epoch [ 90/100] Iter[ 16/ 32]\t\tLoss: 0.3548 Acc@1: 99.805% \n",
            "Pseudo labeled: 45.145% (1618/3584)    \tCorrect pseudo label: 83.50% (1351/1618)    \tSame output weak and strong augmentation: 88.44% (1431/1618)\n",
            "| Epoch [ 90/100] Iter[ 31/ 32]\t\tLoss: 0.5579 Acc@1: 99.899% \n",
            "Pseudo labeled: 44.844% (3114/6944)    \tCorrect pseudo label: 82.56% (2571/3114)    \tSame output weak and strong augmentation: 87.60% (2728/3114)\n",
            "\n",
            "| Validation Epoch #90\t\t\tLoss: 0.1448 Acc@1: 64.35%\n",
            "\n",
            "=> Training Epoch #91, LR=0.0030\n",
            "| Epoch [ 91/100] Iter[  1/ 32]\t\tLoss: 0.3867 Acc@1: 100.000% \n",
            "Pseudo labeled: 40.179% (90/224)    \tCorrect pseudo label: 91.11% (82/90)    \tSame output weak and strong augmentation: 91.11% (82/90)\n",
            "| Epoch [ 91/100] Iter[ 16/ 32]\t\tLoss: 0.4482 Acc@1: 100.000% \n",
            "Pseudo labeled: 43.945% (1575/3584)    \tCorrect pseudo label: 83.24% (1311/1575)    \tSame output weak and strong augmentation: 87.37% (1376/1575)\n",
            "| Epoch [ 91/100] Iter[ 31/ 32]\t\tLoss: 0.3234 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.153% (3066/6944)    \tCorrect pseudo label: 82.45% (2528/3066)    \tSame output weak and strong augmentation: 87.02% (2668/3066)\n",
            "\n",
            "| Validation Epoch #91\t\t\tLoss: 0.1358 Acc@1: 63.95%\n",
            "\n",
            "=> Training Epoch #92, LR=0.0030\n",
            "| Epoch [ 92/100] Iter[  1/ 32]\t\tLoss: 0.3805 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.089% (101/224)    \tCorrect pseudo label: 91.09% (92/101)    \tSame output weak and strong augmentation: 88.12% (89/101)\n",
            "| Epoch [ 92/100] Iter[ 16/ 32]\t\tLoss: 0.2836 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.564% (1633/3584)    \tCorrect pseudo label: 83.53% (1364/1633)    \tSame output weak and strong augmentation: 88.67% (1448/1633)\n",
            "| Epoch [ 92/100] Iter[ 31/ 32]\t\tLoss: 0.4238 Acc@1: 99.899% \n",
            "Pseudo labeled: 45.190% (3138/6944)    \tCorrect pseudo label: 82.44% (2587/3138)    \tSame output weak and strong augmentation: 88.37% (2773/3138)\n",
            "\n",
            "| Validation Epoch #92\t\t\tLoss: 0.0149 Acc@1: 65.70%\n",
            "\n",
            "=> Training Epoch #93, LR=0.0030\n",
            "| Epoch [ 93/100] Iter[  1/ 32]\t\tLoss: 0.3603 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.643% (100/224)    \tCorrect pseudo label: 85.00% (85/100)    \tSame output weak and strong augmentation: 89.00% (89/100)\n",
            "| Epoch [ 93/100] Iter[ 16/ 32]\t\tLoss: 0.4162 Acc@1: 99.805% \n",
            "Pseudo labeled: 43.834% (1571/3584)    \tCorrect pseudo label: 83.39% (1310/1571)    \tSame output weak and strong augmentation: 88.80% (1395/1571)\n",
            "| Epoch [ 93/100] Iter[ 31/ 32]\t\tLoss: 0.3597 Acc@1: 99.899% \n",
            "Pseudo labeled: 44.859% (3115/6944)    \tCorrect pseudo label: 82.02% (2555/3115)    \tSame output weak and strong augmentation: 88.22% (2748/3115)\n",
            "\n",
            "| Validation Epoch #93\t\t\tLoss: 0.0632 Acc@1: 65.65%\n",
            "\n",
            "=> Training Epoch #94, LR=0.0030\n",
            "| Epoch [ 94/100] Iter[  1/ 32]\t\tLoss: 0.3316 Acc@1: 100.000% \n",
            "Pseudo labeled: 41.071% (92/224)    \tCorrect pseudo label: 88.04% (81/92)    \tSame output weak and strong augmentation: 86.96% (80/92)\n",
            "| Epoch [ 94/100] Iter[ 16/ 32]\t\tLoss: 0.3915 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.699% (1602/3584)    \tCorrect pseudo label: 83.27% (1334/1602)    \tSame output weak and strong augmentation: 88.33% (1415/1602)\n",
            "| Epoch [ 94/100] Iter[ 31/ 32]\t\tLoss: 0.3505 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.600% (3097/6944)    \tCorrect pseudo label: 82.60% (2558/3097)    \tSame output weak and strong augmentation: 88.80% (2750/3097)\n",
            "\n",
            "| Validation Epoch #94\t\t\tLoss: 0.0354 Acc@1: 66.35%\n",
            "| Saving Best model...\t\t\tTop1 = 66.35%\n",
            "\n",
            "=> Training Epoch #95, LR=0.0030\n",
            "| Epoch [ 95/100] Iter[  1/ 32]\t\tLoss: 0.3105 Acc@1: 100.000% \n",
            "Pseudo labeled: 50.000% (112/224)    \tCorrect pseudo label: 79.46% (89/112)    \tSame output weak and strong augmentation: 89.29% (100/112)\n",
            "| Epoch [ 95/100] Iter[ 16/ 32]\t\tLoss: 0.3253 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.810% (1606/3584)    \tCorrect pseudo label: 83.19% (1336/1606)    \tSame output weak and strong augmentation: 89.48% (1437/1606)\n",
            "| Epoch [ 95/100] Iter[ 31/ 32]\t\tLoss: 0.2979 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.089% (3131/6944)    \tCorrect pseudo label: 83.65% (2619/3131)    \tSame output weak and strong augmentation: 89.05% (2788/3131)\n",
            "\n",
            "| Validation Epoch #95\t\t\tLoss: 0.0416 Acc@1: 65.75%\n",
            "\n",
            "=> Training Epoch #96, LR=0.0030\n",
            "| Epoch [ 96/100] Iter[  1/ 32]\t\tLoss: 0.5293 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.536% (102/224)    \tCorrect pseudo label: 75.49% (77/102)    \tSame output weak and strong augmentation: 83.33% (85/102)\n",
            "| Epoch [ 96/100] Iter[ 16/ 32]\t\tLoss: 0.2619 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.866% (1608/3584)    \tCorrect pseudo label: 83.21% (1338/1608)    \tSame output weak and strong augmentation: 86.75% (1395/1608)\n",
            "| Epoch [ 96/100] Iter[ 31/ 32]\t\tLoss: 0.3551 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.196% (3069/6944)    \tCorrect pseudo label: 82.86% (2543/3069)    \tSame output weak and strong augmentation: 87.42% (2683/3069)\n",
            "\n",
            "| Validation Epoch #96\t\t\tLoss: 0.1690 Acc@1: 66.10%\n",
            "\n",
            "=> Training Epoch #97, LR=0.0030\n",
            "| Epoch [ 97/100] Iter[  1/ 32]\t\tLoss: 0.5211 Acc@1: 100.000% \n",
            "Pseudo labeled: 46.429% (104/224)    \tCorrect pseudo label: 83.65% (87/104)    \tSame output weak and strong augmentation: 87.50% (91/104)\n",
            "| Epoch [ 97/100] Iter[ 16/ 32]\t\tLoss: 0.2894 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.871% (1644/3584)    \tCorrect pseudo label: 84.43% (1388/1644)    \tSame output weak and strong augmentation: 87.35% (1436/1644)\n",
            "| Epoch [ 97/100] Iter[ 31/ 32]\t\tLoss: 0.3326 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.781% (3179/6944)    \tCorrect pseudo label: 84.49% (2686/3179)    \tSame output weak and strong augmentation: 87.83% (2792/3179)\n",
            "\n",
            "| Validation Epoch #97\t\t\tLoss: 0.0444 Acc@1: 67.10%\n",
            "| Saving Best model...\t\t\tTop1 = 67.10%\n",
            "\n",
            "=> Training Epoch #98, LR=0.0030\n",
            "| Epoch [ 98/100] Iter[  1/ 32]\t\tLoss: 0.3077 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.536% (102/224)    \tCorrect pseudo label: 85.29% (87/102)    \tSame output weak and strong augmentation: 90.20% (92/102)\n",
            "| Epoch [ 98/100] Iter[ 16/ 32]\t\tLoss: 0.2931 Acc@1: 100.000% \n",
            "Pseudo labeled: 44.978% (1612/3584)    \tCorrect pseudo label: 83.13% (1340/1612)    \tSame output weak and strong augmentation: 88.65% (1429/1612)\n",
            "| Epoch [ 98/100] Iter[ 31/ 32]\t\tLoss: 0.4186 Acc@1: 99.899% \n",
            "Pseudo labeled: 44.945% (3121/6944)    \tCorrect pseudo label: 83.08% (2593/3121)    \tSame output weak and strong augmentation: 88.47% (2761/3121)\n",
            "\n",
            "| Validation Epoch #98\t\t\tLoss: 0.0396 Acc@1: 65.85%\n",
            "\n",
            "=> Training Epoch #99, LR=0.0030\n",
            "| Epoch [ 99/100] Iter[  1/ 32]\t\tLoss: 0.3502 Acc@1: 100.000% \n",
            "Pseudo labeled: 46.875% (105/224)    \tCorrect pseudo label: 81.90% (86/105)    \tSame output weak and strong augmentation: 89.52% (94/105)\n",
            "| Epoch [ 99/100] Iter[ 16/ 32]\t\tLoss: 0.2629 Acc@1: 100.000% \n",
            "Pseudo labeled: 46.540% (1668/3584)    \tCorrect pseudo label: 84.29% (1406/1668)    \tSame output weak and strong augmentation: 89.27% (1489/1668)\n",
            "| Epoch [ 99/100] Iter[ 31/ 32]\t\tLoss: 0.2540 Acc@1: 100.000% \n",
            "Pseudo labeled: 45.060% (3129/6944)    \tCorrect pseudo label: 83.57% (2615/3129)    \tSame output weak and strong augmentation: 88.62% (2773/3129)\n",
            "\n",
            "| Validation Epoch #99\t\t\tLoss: 0.1021 Acc@1: 67.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_final(net, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2h7t1dAXHWm",
        "outputId": "3e83b202-61d9-4c28-d7d9-f4e1fc360e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "| TEST \t\t\tLoss: 2.3513 Acc@1: 65.94%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 1, 8, ..., 5, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7 :\n",
        "Pour éviter le surapprentissage en Deep Learning on peut limiter la taille de nos architectures utilisés en fonction de la taille des données d'entraînement : pour les arbres de décisions on limite la profondeur des arbres, pour les réseaux de neurones on limite le nombre de neurones. Avec une architecture trop grande, on peut apprendre par coeur une base de données. On peut aussi utiliser un paramètre de régularisation pour contrôler le surapprentissage. Une dernière possibilité serait d'utiliser des données sans label pendant l'entraînement comme ça a été fait dans FixMatch, le réseau de neurones ne peut apprendre ces données par coeur étant donné qu'il ne sait pas quelle sortie il doit obtenir sur ces données."
      ],
      "metadata": {
        "id": "hvOnfdkMiELY"
      }
    }
  ]
}